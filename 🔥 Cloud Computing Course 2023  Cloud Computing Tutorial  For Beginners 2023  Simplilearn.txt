Welcome to our cloud computing course in
this course you will explore the
exciting world of cloud technology cloud
computing is like having a virtual
supercomputer that can store data and
run programs making it accessible
anytime anywhere we will show you how
cloud services like Amazon web services
and Microsoft Azure work and why they
are essential for modern businesses you
will learn about the benefits like cost
savings and scalability will keep it
simple and help you grasp the Cloud's
Power by the end you will be ready to
harness the cloud for your future
success so if you are interested in
becoming a cloud engineer or architect
then check our Cloud architect Masters
program simply learns Cloud architect
certification course will build your AWS
Microsoft ASA and Google Cloud platform
expertise from the grounder you will
learn to master the architectural
principles and Services of the top Cloud
platforms design and deploy highly
scalable fall tolerant applications and
develop skills to transform yourself
into an awsn Azure Cloud this program
also has job assist program simply
learns job assist program is an Indian
specific offering in partnership with IM
IM jobs.com to help you landar your
dream job to participate in job assist
program you need to be graduate in
engineering or equalent or complete our
master's program successfully and earn a
master certificate upon completion so
what are you waiting for enroll now what
is cloud computing as we learned what is
cloud computing uh we will also be
learning about how things were before
cloud computing and benefits of cloud
computing different types of cloud
computing available and some of the
famous companies that are using cloud
computing and they're getting benefited
out of it we're going to learn all that
before cloud computing existed if we
need any it servers or applications
let's say a basic web server it does not
come easy now here is an owner of a
business and I know you would have
guessed it already that he's running a
successful business by looking at the
hot and fresh brw coffee in his desk and
lots and lots of paperwork to review and
approve now he had a smart not only
smart looking but a really smart worker
in his office called Mark and on one
fine day he called Mark and said that he
would like to do business online in
other words he would like to take his
business online and for that he needed
his own website as the first thing and
Mark puts all his knowledge together and
comes up with this requirement that his
boss would need lots of servers uh
database and softwares to get his
business online which means a lot of
investment and Mark also adds that his
boss will need to invest on acquiring
technical experties to manage the
hardware and software that they will be
purchasing and also to monitor the
infrastructure structure and after
hearing all this his boss was close to
dropping his plan to go online but
before he made a decision he chose to
check if there are any alternatives
where he don't have to spend a lot of
money and don't have to spend acquiring
technical expertise now that's when Mark
opened this discussion with his boss and
he explained his boss about cloud
computing and he explained his boss the
same thing that I'm going to explain to
you in some time now about what is cloud
computing what is cloud computing cloud
computing is the use of a network of
remote servers hosted on the internet to
store manage and process data rather
than having all that locally and using
local server for that cloud computing is
also storing our data in the internet
from anywhere and accessing our data
from anywhere throughout the internet
and the companies that offer those
services are called Cloud providers
cloud computing is also being able to
deploy and manage our applications
services and network throughout the
globe and manage them through the web
management or configuration portal in
other words cloud computing service
providers give us the ability to manage
our applications and services through a
Global Network or Internet example of
such providers are Amazon web servers
and Microsoft Azure now that we have
known what cloud computing is let's talk
about the benefits of cloud computing
now I need to tell you the cloud
benefits is what is driving Cloud
adoption like anything in the recent
days if you want an IT resource or a
service now with Cloud it's available
for me almost instantaneously and it's
ready for production almost the same
time now this reduces the go life date
and the product and the service hit the
market almost instantaneously compared
to the Legacy environment and because of
this the companies have started to
generate Revenue almost the next day if
not the same day plan planning and
buying the right siiz Hardware has
always been a challenge in Legacy
environment and if you're not careful
when doing this we might need to live
with a hardware that's undersized for
the rest of our lives with Cloud we do
not buy any hardware but we use the
hardware and pay for the time we use it
if that Hardware does not fit our
requirement release it and start using a
better configuration and pay only for
the time you use that new and better
configuration in Legacy environments
forecasting Dem is an full-time job but
with Cloud you can let the monitoring
and automation tool to work for you and
to rapidly scale up and down the
resources based on the need of that R
not only that the resources Services
data can be accessed from anywhere as
long as we are connected to the internet
and even there are tools and techniques
now available which will let you to work
offline and will sync whenever the
internet is available making sure the
data is stored in durable storage and in
a secure fashion is the talk of the
business and Cloud answers that million
dooll question with Cloud the data can
be stored in an highly durable storage
and replicated to multiple regions if
you want and uh the data that we store
is encrypted and secured in a fashion
that's beyond what we can imagine in
local data centers now let's bleed into
the discussion about the types of cloud
computing very lately there are multiple
ways to categorize cloud computing
because it's ever growing now we have
more categories out of all these six
sort of stand out you know categorizing
cloud based on deployments and
categorizing cloud based on services and
again under deployments categorizing
them based on how they have been
implemented you know is it private is it
public or is it hybrid and again
categorizing them based on the service
it provides is it infrastructure as a
service or is it platform as a service
or is it software as a service let's
look at them one by one let's talk about
the different types of cloud based on
the deployment models first in public
Cloud everything is stored and accessed
in and through the internet and um any
internet users with proper permissions
can be given access to some of the
applications and resources and in public
Cloud we literally own nothing be it the
hardware or software everything is
managed by the provider AWS Azure and
Google are some EX examples of public
Cloud private Cloud on the other hand
with private Cloud the infrastructure is
exclusively for an single organization
the organizations can choose to run
their own cloud locally or choose to
Outsource it to a public cloud provider
as managed services and when this is
done the service the infrastructure will
be maintained on a private Network some
examples are wmware cloud and some of
the AWS products are very good example
for private Cloud hybrid H cloud has
taken things to the whole new level with
hybrid Cloud we get the benefit of both
public and private Cloud organizations
will choose to keep some of their
applications locally and some of the
application will be present in the cloud
one good example is NASA it uses hybrid
Cloud it uses private Cloud to store
sensitive data and uses public Cloud to
store and share data which are not
sensitive or confidential let's now
discuss about cloud based on servers
model the first and the broader category
is infrastructure as a service uh here
we would rent the servers network
storage and we'll pay for them in an
early basis but we will have access to
the resources we provision and for some
we will have root level access as well
ec2 in AWS is a very good example it's a
VM for which we have root level access
to the OS and admin access to the
hardware the next type of service model
would be platform as a service now in
this model the providers will give me a
pre-built platform where we can deploy
our codes and our applications and they
will be up and running we only need to
manage the codes and not the
infrastructure here in software as a
service the cloud providers sell the end
product which is a software or an
application and we directly buy the
software on an subscription basis it's
not the infra or the platform but the
end product or the software or
functioning application and we pay for
the hours we use the software and in
here the client maintains full control
of the software and does not maintain
any equipment Amazon and Azure also sell
products that are software as service
this chart sort of explains the
difference between the four models
starting from on premises to
infrastructure as a service to platform
as a service to software as a service
this is self-explanatory that uh the
resource managed by us are huge in on
premises that towards your left as you
watch and it's little less in
infrastructure as a service as we move
further towards the ride and further
reduced in platform as a service and
there's really nothing to manage when it
comes to software as a service because
we buy the software not any
infrastructure component attached to it
there are lots of famous well-known
organization around the world they have
moved or have migrated to the cloud
environment Pinterest is one company
which is one of the world's largest
visual book marketing tool with more
than 70 million monthly active users now
Pinterest was able to scale its business
because it was all built on Amazon web
services with a company with a less
number of employees Pinterest decided
that they do not want a dedicated staff
time to manage a data center instead
Pinterest uses AWS or they used AWS to
manage their Hy performance social
application and store more than 8
billion objects and 400 terab of data in
AWS Cloud using a service called Amazon
simple storage service or in short
Amazon S3 and not only that they are
running 225,000 instance hours a month
and they run that on Amazon compute
service called Amazon ec2 or Amazon
elastic compute Cloud Spotify is an
another company that got benefited using
aw us it's an online music service
offering and it offers instant access to
over 16 million licensed songs Spotify
needed a peculiar requirement it needed
a storage solution that could scale very
quickly without incurring long lead
times for upgrades long story short
Spotify used Amazon S3 which is uh
Amazon simple storage service and Amazon
S3 gave them the confidence in their
ability and to expand their storage
quick quickly while also providing high
dataa durability the third biggest
company I want to mention is Netflix
it's the world's largest internet
television network with more than 100
million members in more than 190
countries Netflix uses Amazon web
services for nearly all its Computing
and storage needs now that includes
database analytic recommendation Engines
video transcoding and a lot more not
only that this company is planning to
use AWS Lambda to build an automated or
an rule-based self-managing
infrastructure and replace some of their
inefficient process to reduce the rate
of errors and replace inefficient
processes to reduce the rate of errors
and save their valuable time xedia is
another famous company that got
benefited by using Cloud xedia provides
travel booking service through its
Flagship site called expedia.com and not
only that they also run 200 plus travel
booking sites around the world xedia is
all on AWS and by using AWS xedia has
become more resilient with an high
scalable infrastructure and better cloud
services because it had offloaded the it
management to the cloud provider itself
in this case AWS and because of this
expedia's developers have been able to
innovate faster while saving the company
millions and millions of dollars we can
categorize the different types of cloud
computing based on two wide categories
one being deployment model and the other
one being servers model let's talk about
the deployment model first deployment
model is categorized into three types
first one is public and then private and
then hybrid cloud in other words public
Cloud private cloud and hybrid Cloud
it'll be easy for me to explain and also
it'll be easy for you to understand if I
walk you through this example consider
the different types of vehicles we use
to commute from one place to another for
example if I want to travel I can pick a
but bus which is accessible to anyone I
get in and I pay for the seat that I
occupy and I pay for the time that I
will be traveling in it and I'm done
cost is very less here a similar kind of
thing happens in the public Cloud I pay
only for the resource that I use and I
pay for how long I use it if I use less
I pay less if I use more I pay more for
that month simple on the other hand
private cloud is like buying your own
car and using it for commuting purpose
here I pay a huge amount UPF front and
it is all owned only by me I do not pay
for it in an odly fashion but completely
and all upfront the cost here is very
huge and thirdly if I want the best of
both types like the comfort of the own
car and still don't want to pay all
upfront otherwise want only to pay for
the time that I use the service I can
rent a car similarly I can have it in an
hybrid environment meaning if I already
have a DC I can integrate it with the
cloud and use both both the DCS and that
would become an hybrid environment all
right so that was good of an uh learning
let's summarize the types of cloud based
on deployment models and as we know now
about the public Cloud public cloud is
an Cloud infrastructure that's made
available to the general public over the
internet and it is owned by the cloud
provider some of the major players as
Cloud providers are AWS Microsoft Azure
IBM's blue cloud and suncloud and
private Cloud now This Cloud
infrastructure is exclusively operated
by a single organization it can be
managed by organizations or third party
and may exist on premises or off
premises doesn't matter but the point
here is this is exclusively operated for
a single organization and some companies
that provide private Cloud are AWS and
VMware and hybrid Cloud gives the best
of both public and the private Cloud for
example the federal agencies they opt
for private clouds for storing and
developing personal data and they use
public Cloud to share the non-sensitive
data with the general public or with
other government departments now let's
talk about different clouds based on the
service model if we need to categorize
them broadly we can categorize them as
infrastructure as a service IAS or
platform as a service Pas or software as
a service s they sometimes are referred
to as I Pas and SAS now at this moment
you could be like this guy thinking Sam
I thought you're done categorizing the
cloud now you're going to talk about
three more categories which one should I
pick well let me explain if all that you
want is just an Wim and you have all the
expertise to install the software on top
of it and make it work then go for is if
you only want a platform or an interface
to program or an interface to upload a
program and make it run then pick pass
or if all that you want is a finished
product hosted in the cloud and be able
to access it through the internet then
go for SAS here you get a username and
password for an application and you can
begin to customize the application based
on your needs all right let's talk about
um IAS in a bit more detail IAS it gives
basic Computing infra it's based on uh
pay for what you use model and some of
the cloud providers who are big players
are AWS Azure and Google and here the
users generally will be it admins in
pass the provider gives you a platform
or a runtime environment for developing
testing and managing application it's
platform ready you buy the platform you
upload your code and you start working
on it and it allows the software
developers to deploy applications
without running the underlying
infrastructure and as you might have
guessed by now the interesting
candidates who would use p is software
developers and in SAS everything is
managed by the vendor be it the hardware
or the software it's managed by the
vendor and we pay for the service and we
pay for it through a pay as you go
subscription model and as you might have
guessed the end users here would be End
customer itself all right let's put
together everything in the same page and
compare and contrast the different types
of service models in this chart it
explains the difference between the four
models starting from on premises to IAS
and then Pas and SAS it is
self-explanatory that the resources
managed by us are huge in on premises
and little Less in is and further less
or reduced in p and nothing to manage
when it comes to SAS let me also explain
the different types of cloud services
through an example like this let's say
that you have a crush on cake and you're
planning to bake one yourself now let's
look at the options you can have you can
make all the ingredients yourself be the
floor uh butter and uh you know put
together and bake the whole thing
yourself using your own oven pan you
know the needed water and the rest you
get an idea right everything is yours
and that's on premises all that you use
is owned by you and nothing is managed
by the vendor the other options you can
have is buy the ingredients and mix and
bake the cake yourself now this would be
like is here the infra is managed by the
provider and we get to use it and
customize it the way we want it here the
cloud service isn't shared
responsibility the other option you
still have on hand is simply pick a
phone and order a cake now this is lot
simpler than the rest we discussed so
far you know it's simply picking the
phone and ordering the cake and pay for
it when it arrives simple and when it
reaches home you will have to arrange
the table garnish the cake if that's
needed and then enjoy the cake it's the
same way with pass just get the platform
in which you would run your code and
upload your code and start running your
application here you and the vendor
still share the responsibility you still
have one more option left that is simply
go out and dine this is a lot lot
simpler that it requires no effort from
us at all you buy the fully finished and
garnished cake and pay for it and walk
out no responsibility on making the cake
it's the same way with SAS we buy the
finished product and pay for the
finished application hello everyone and
welcome to Simply learns YouTube channel
if you have stumbled upon this video
there is a very high probability that
you are wondering about about how to get
a job in the cloud computing domain and
why won't you the cloud industry is
booming with opportunities and it allows
everyone to be a part of its growing
industry even for the people with no
coding skills Yes you heard it right
even if you don't have extensive coding
skills you can join as a cloud computing
professional in some of the top Tire
product companies in this video we will
discuss all the nitty-gritty details of
how you can get a head start and an
entry-level job in the cloud in domain
so without further Ado let's quickly
jump on to the topic but wait to help
you with next step we have our celtech
post graduate program in cloud computing
this course will help you become an
expert in aure AWS and gcp and let you
master key architectural principles and
develop the skills needed to become a
cloud expert this post-graduate program
in cloud computing help you become an
expert in designing planning and scaling
cloud implementations of cloud computing
course helps you master the core skill
sets required to design and deploy
Dynamic scaling and reliable application
on completion of this course you will
gain ktech ctme postgraduate
certification with 40 plus Hands-On
projects along with opportunity to
secure a job in large companies like
Netflix MasterCard Hobby and more you
can check out its Link in the
description box below Cloud technology
is in high demand and organization are
seeking skilled professionals to manage
their Cloud infrastructure this video
will guide you through the steps to
secure an entry-level Cloud job the
first one is gain fundamental knowledge
in that you to understand Cloud
implementation in detail after that
we'll see learn Cloud platforms and then
start networking and security the first
one is understand cloud computing
familiarize yourself with the Core
Concepts of cloud computing including
different deployment models like public
private hybrid more Concepts like
service models like L AAS p and SAS
visualization you also have to learn and
Cloud security next we have learn Cloud
platforms focus on popular Cloud
platforms such as Amazon web services
Microsoft aure and Google Cloud platform
gcp start by understanding their basic
offerings features and services your
next Next Step should be study
networking and security acquire
knowledge of networking fundamentals
tcpi protocols Fireballs load balancing
and network security this knowledge is
crucial for cloud related roles the next
step is build practical skills the first
one in that is on experience the next
one is work on projects I will tell you
them in detail the third one is obtain
certification now let's see how hands on
experience create a personal cloud lab
using free trial account on platforms
like AWS aure or gcp practice deploying
virtual machines configuring networking
and security settings experiment with
different services and get comfortable
with their interfaces the next one is
work on projects undertake personal or
open- Source projects that involves
Cloud Technologies this will provide
practical experience and help you
showcase your skill to protect potential
employers example could include
deploying a web application on cloud
platform or automating infrastructure
the next one we have obtain
certification Cloud certification
demonstrate your expertise and enhance
your credibilities start with entry
level certifications like AWS certified
Cloud practitioner Microsoft Azure
fundamentals or Google Cloud certified
associate Cloud engineer this
certification validate your knowledge
and make your resume stand out Simply
learn on also offers Cloud
certifications that can help you land a
good job In This Cloud domain next we
will discuss networking and professional
development in that the first one is
join online communities the next one is
attend meetups and conferences and the
third one is build a professional online
presence let's talk about join online
communities engage with online Cloud
communities and forums such as stack
Overflow participate in discussion ask
questions and learn from experienced
professionals networking with
like-minded individuals can also lead to
a good opportunities next we will see is
attend meetups and conferences attend
local Tech meetups Cloud conferences and
workshops these events provides
opportunity to networking with industry
professionals learn about latest trends
and gain insights from experts be
proactive in sharing your knowledge and
connecting with potential employees
next we will see build a professional
online presence create a LinkedIn
profile highlighting your Cloud related
skills projects and certifications share
articles contribute to relevant
communities and connect with
Professionals in this field a strong
online presence can attract attention
for recruiters and increase your chance
of getting noticed next we have job
search and preparation the first step
would be refine your resume the next is
practice interviewing and apply for
entry-level position so how to refine
your resume tailor your resume and
emphasize your Cloud related skills
projects and certification highlight any
relevant work experience internship or
project that demonstrate your
understanding of cloud Technologies next
we have to practice interviewing so
let's see about how to practice
interviewing prepare for technical
interviews by reviewing common Cloud
related interview questions and practi
responses be ready to discuss your
hands-on experience problem solving
abilities and how you have applied Cloud
Technologies to solve real world
challenges next we have apply for
entrylevel positions search for
entry-level Cloud jobs opening on online
job portals company websites and
Professional Network apply for position
that match your skill set and career
goals customize your cover letter for
each application showcasing Your
Enthusiasm for cloud computing and the
specific company you are applying to
continue learning and growth Cloud
technology is constantly involving stay
updated with the latest trends new
services and best practices explore
Advanced certification and consider
pursuing higher level cloud roles as you
gain experience now securing an
entry-level Cloud job requires a
combination of fundamental knowledge and
practical skills networking and a
proactive approach by following these
steps continuous learning and
demonstrating your passion for cloud
computing you will increase your chances
of Landing an entry-level Cloud job and
Kickstart your career in this exciting
field Snapchat reports that more than 5
billion Snaps are generated daily and
more than 100 billion messages are sent
on WhatsApp deal do you ever wonder if
storing this data in local storage is
possible the answer is clearly no
according to the projections by 2025
over 100 zaby of data will be stored in
the cloud storage one zetabyte is equal
to trillion gigabytes now imagine the
amount of data the world generates and
how it is being managed so Cloud experts
are responsible for this smooth
transition Google workspace has already
surpassed the mark of 2 billion users in
2020 and 60% of the total corporate data
is already present in the cloud so these
stats are enough to let anyone know
where this technology is headed and what
wonders are awaiting in cloud computing
Tech giants like Google Amazon and
Microsoft are trying to conquer this
exponentially growing Market with your
products like Amazon web services Google
Cloud platform and Microsoft Azu
furthermore in this fast spaced World a
job in this field is more than worth it
the salaries offered in this field are
very lucrative and fascinating among all
the job roles currently available in
cloud computing a cloud architect in
India earns an average sell of 20 lakhs
perm and in the United States it goes
around
$125,000 so these figures are stated by
glass door.com and show how beneficial
it is to bag a job in this sector today
but the fact is nothing comes easy so we
at simply learn will save some of your
time and let you know about the process
of how to become a cloud expert in 2023
we'll take you through the complete
cloud computing road map but before we
begin if you enjoy watching these videos
and find them interesting please
subscribe to our Channel because we
bring the best videos for you daily also
hit the Bell icon to get notified
whenever we drop a new video so without
any further delay let's go through the
agenda for today's video this video will
provide all the Vital Information about
cloud computing we'll start this video
with an introduction to cloud computing
following that will take you through the
skills to become a successful Cloud
expert we'll then take you through the
steps you you can take to become a cloud
engineer and finally we'll explore some
of the potential roles and growth
opportunities in the field of cloud
computing so let's start this video with
what is cloud computing cloud computing
in simple terms refers to the practice
of using remote servers on the internet
to store manage and process data instead
of relying on your local computer it
allows you to access your files
applications and services from anywhere
within active internet connection
providing convenience scalability and
flexibility for individuals and
businesses
alike a number of skills are required to
become a master in the field of cloud
computing the first one is technical
skills Cloud Engineers should have a
strong foundation in areas such as
networking operating systems and
programming languages they should be
familiar with Cloud platforms like
Amazon web services Microsoft Azure or
or Google Cloud platform problem solving
abilities Cloud Engineers often
encounter complex technical challenges
developing strong problem solving and
troubleshooting skills is crucial to
identify and resolve issues efficiently
security and compliance knowledge Cloud
Engineers must understand security
practices data privacy regulations and
compliance standards they need to
protect sensitive data and maintain
compliance with industry regulations
continuous learning cloud technology
evolves rapidly so it's essential for
cloud Engineers to have a thirst for
learning keeping up with the latest
trends attending training programs and
obtaining relevant certifications will
help you stay ahead now that we have a
grasp of the skills required let's
discuss the steps you can take to become
a cloud engineer get familiar with Cloud
Concepts start by gaining a basic
understanding of cloud computing
Concepts familiarize yourself with the
ADV advantages different service models
such as infrastructure as a service
platform as a service and software as a
service and deployment models like
public private and hybrid second is
learn Cloud platforms and Technologies
choose a cloud platform to specialize in
such as AWS Azure or gcp explore their
documentation online tutorials and
resources to understand their offerings
services and tools gain hands-on
experience by experimenting with the
platforms and building simple projects
acquiring relevant certifications Cloud
certifications validate your skills and
demonstrate your expertise to potential
employers consider pursuing
certifications such as AWS certified
Cloud practitioner Azure fundamentals or
Google Cloud certified associate Cloud
engineer these certifications provide a
solid foundation and enhance your
credibility and simply learn has got
your back as always the postgraduate
program in cloud computing designed in
collaboration with Caltech CME helps you
become an Azure AWS and gcp expert at
once this in-depth cloud computing
certification course lets you master key
architectural principles and develop the
skills needed to become a complete Cloud
expert benefits of this post-graduate
program include Caltech CME postgraduate
certificate enrollment in simply learns
job assist you will receive up to 30
from celtech ctme Simply learns job
assist help you get noticed by top
hiring companies you can also attend
master classes from celtech ctme
instructors and live virtual classes led
by industry experts you'll also get
Hands-On projects and integrated Labs
there are many more other features of
this postgraduate program so you can
also FASTT trck your career with this
cloud computing certification and its
in-depth course curriculum which covers
the key concept of azure AWS and gcp
platforms and services such as AWS
Lambda Amazon S3 Azure app services and
many more so this program also covers
the essential skills to become an expert
in cloud computing and you can consider
this program because it provides you
with a certification from keltech ctme a
well reputed university in the United
States so what are you thinking you can
find the link mentioned in the
description box below the next step is
gain practical experience practical
experience is crucial in the field of
cloud engineering look for opportunities
to work on real world projects through
internships freelance work or personal
projects this hands-on experience will
help you apply your knowledge and
develop problem solving skills the last
step to become a cloud expert is
networking and collaboration connect
with Professionals in the cloud
computing industry through networking
events online forums and social media
platforms engage in discussion discs ask
questions and learn from their
experiences building a solid
Professional Network can open doors to
new opportunities as a cloud engineer
you'll have diverse career opportunity
let's explore some of the potential
roles and growth paths in cloud
computing Cloud administrator Cloud
experts or administrators oversee and
manage a company's Cloud infrastructure
including policies security protocols
uptime monitoring and technology updates
Cloud infrastructure engineer this role
focuses on designing and managing the
underlying infrastructure of cloud
platforms ensuring scalability security
and performance Cloud Solutions
architect Cloud Solutions architect
design and Implement cloud-based
solutions for organizations they analyze
business requirements and develop
architectural designs to meet specific
needs Cloud security engineer Cloud
security Engineers specializes in
securing cloud infrastructures and
services they imp Implement robust
security measures monitor for
vulnerabilities and respond to security
incidents the salaries in any of these
fields are lucrative and fascinating
congratulations you have now learned the
steps to become a cloud expert remember
it's a dynamic field that requires
continuous learning and adaptation so
start your journey by building a solid
foundation acquiring relevant
certifications gaining practical
experience and networking with
professionals so if you are interested
in becoming a cloud engineer or
architect then check our Cloud architect
Masters program simply learns Cloud
architect certification course will
build your AWS Microsoft Y and Google
Cloud platform expertise from the
grounder you will learn to master the
architectural principles and services of
the top Cloud platforms design and
deploy highly scalable fall tolerant
applications and develop skills to
transform yourself into an awsn Azure
Cloud this program also has job assist
program simply learns job assist program
is an Indian specific offering in
partnership with IM IM jobs.com to help
you landar your dream job to participate
in job assist program you need to be
graduate in engineering or equivalent or
complete our master's program
successfully and earn a master
certificate upon completion so what are
you waiting for enroll now we have come
a long way from storing stuff on our
computers to using the cloud which is
like a giant virtual store
the amount of data we have is expected
to explode to
175 zettabytes by 2025 that's a lot of
information to handle and that's where
cloud computing comes to the rescue a
gamechanging technology in today's
digital world has transformed how we do
things is the driving force behind
sharing emails videos and running
businesses with ease so getting
certified in Cloud technology is like
getting the key to this digital Treasure
Chest companies are moving their stuff
to the cloud because it's safe flexible
and cost effective as organizations
increasingly migrate to the cloud the
demand for skilled professionals who can
design manage and secure Cloud
environments is skyrocketing so whether
you are a seasoned IT professional or
just starting your Tech Journey a cloud
certification not only signifies your
commitment to staying ahead but also
opens the door to exciting opportunities
in this Dynamic field so here we are
with the top five Cloud certifications
you should watch out for in 2024 hey
everyone and you are already watching
simply Lo before we begin with the top
five Cloud certifications make sure that
you have subscribe to our YouTube
channel and press that Bell icon to
never miss any updates from Simply so
without any further delay let's get
started let me share some fascinating
statistics with you that illustrate the
impact and potential of this
game-changing technology before we delve
into the fascinating world of cloud
computing certifications so according to
glass door the average salary of a cloud
engineer is
$142,000 in the United States and in
India is 7.5 lakh rupees perom with
additional cash benefit so let's move on
to the top five cloud computing
certifications for
2024 at number one we have the cloud
architect Masters program this program
will help you build your AWS Microsoft
Azure and Google Cloud platform
expertise from the ground up you will
learn to master the architectural
principles and services of the top Cloud
platforms design and deploy highly
scalable fall tolerant applications and
develop skills to transform yourself
into an AWS and Azure Cloud expert this
program will give you an in-depth
understanding of cloud services such as
AWS cloud formation Azure resource
manager ec2 S3 Route 53 wepc Azure app
services gcp and more you will acquire
the Knowledge and Skills for passing
Cloud architect certifications such as
AWS architect and Azure architect Cloud
architecture certification program
consists of a structured learning path
designed by leading industry experts
you'll have access to 60 plus live
instructor Le online classrooms 100 plus
hours of self-paced video content
simulation exams a community motivated
by experts and other resources that
ensure you follow the optimal path to
your desired role of cloud architect the
course includes 16 plus real world
industry projects that let you work your
way through the technical challenges
associated with cloud computing
candidates with OnePlus year of
experience are preferred to enroll in
this program so do check out the link
mentioned in the description box below
for more details at number two we have
the AWS Cloud architect Masters
program this AWS Cloud architect
certification course will make you an
expert in Amazon web services in this
program you'll become familiar with the
architectural principles and services of
AWS learn how to design and deploy
highly scalable and fall tolerant
applications on on Amazon web services
Implement AWS security and testing and
become an expert in AWS components such
as S3 and cloud formation this AWS Cloud
architect certification training will
enable you to master the course skills
required for Designing and deploying
dynamically scalable highly available
fall tolerant and reliable applications
on one of the top Cloud providers the
Amazon web services so candidates with
one plus years of experience are
preferred to enroll in this program for
more details check out the link
mentioned in the description box below
moving on to number three at number
three we have the Azure Cloud architect
Masters program Azure Cloud architect
Masters program will help you master the
Azure infrastructure by understanding
Azure Cloud architect Technology
Solutions implementing workloads and
Security in Azo creating and deploying
apps in Azure and securing data in
Microsoft Azo a Microsoft Azure
certification validates your Cloud
skills and demonstrate your expertise
for a given rule
it can help you improve your earning
potential and stay ahead of your peers
it is predicted that around 80% of all
Enterprise workloads will move to the
cloud by 2025 this means that there will
be high demand for professionals who can
develop Cloud applications and manage
cloud infrastructures and a Microsoft
Azure training certification will help
you gain these skills also candidate
with OnePlus years of experience are
preferred to enroll in this program so
for more details check out the link
mentioned in the description box below
moving on to number four at number four
we have professional certificate program
in cloud computing and devops with a
professional certificate program in
cloud computing and devops with E and
ICT Academy IIT guti become an Azure AWS
devops and Cloud infrastructure design
expert gain hands-on experience through
our real well projects for an exciting
career in it our programs offer
comprehensive training on designing and
implementing Solutions using AWS and
pleasure you'll also gain Proficiency in
Cloud architecture infrastructure design
Administration and automation so prepare
for certifications acquire Real World
skills and boost your cloud and devops
career this program covers multiple
skills like application migration Cloud
workloads Auto scaling web services and
apis database management multicloud
deployment Cloud migration and
deployment disaster recovery and many
more candidates with one plusus year of
work experience are preferred to role in
this program and for more details check
out the link mentioned in the
description box below at number five we
have cloud computing boot camp by
celtech ctm becoming an expert in AWS
and Azure is made easy with the celtech
cloud computing boot camp this in-depth
online course equips you with the
essential skills and Architectural
principles needed to excel in cloud
computing Master the art of cloud
technology and become a sought after
Cloud expert this program includes 40
plus Hands-On projects and integrated
ated Labs Capstone projects in four
different domains simply learn career
service helps you get noticed by the top
hiring companies and keltech ctme boot
camp certificate validates your
expertise so join the simply learn cloud
computing boot camp and unlock a world
of opportunities in this rapidly
expanding field candidates with one plus
years of work experience are preferred
to enroll in this program so visit our
website today to enroll and take the
first step toward becoming a certified
cloud computing professional link to
this program is mentioned in the
description box below so with that we
have come to the end of this video on
top five cloud computing certifications
in
2024 now let's take a minute to hear it
out from our Learners who have
experienced massive success in their
careers with simply learn hey I am Salah
quatra and I am currently living I
wanted to experience what is like to
leave I also realized that to get a new
job I needed to have a professional
certification in cloud computing so last
year I started the postgraduate program
in cloud computing in association with C
with this course I had the choice to
study while I continue and that is how I
got this new job offer with 60% salary
heke in Finland I will be leading the
cloud computing unit we cannot wait to
start our new life in Finland we are
also excited switching carers can be
both exciting and daunting especially if
you're eyeing the rapidly growing field
of cloud computing the cloud computing
industry is booming and businesses
across the globe are increasingly moving
their operations to the cloud now this
means that cloud computing professionals
are high in demand and it's an excellent
time to switch your career to this field
however before you take the plunge it's
essential to understand what cloud
computing is and what you need to do to
switch to this field so here's a new
video by simply learn on how to switch
ker to cloud computing to help you if
you're considering a carer switch to
cloud computing so let's get started but
before that do subscribe to our YouTube
channel and hit the Bell icon to never
miss an update from Simply learn so
moving on here's a road map to help you
get started first is to identify your
goals now the first step is to identify
your career goals and aspirations in
cloud computing determine what kind of
cloud computing job you want to pursue
and which cloud computing platforms
interest you this will help you narrow
down your focus and choose a specific
area to specialize in next next is to
get certified now cloud computing is a
highly technical field and having the
right certification can set you apart
from the competition consider getting
certified in popular cloud computing
platforms such as AWS Azure or Google
Cloud these certifications demonstrate
your experties in specific areas of
cloud computing and increase your
employability now to help you with this
step we have a CTIC postgraduate program
in cloud computing this course will help
you become an expert in aure AWS and gcp
and let you master key architectural
principles and develop the skills needed
to become a cloud expert now this
post-graduate program in cloud computing
helps you become an expert in designing
planning and scaling Cloud
implementations our cloud computing
course helps you master the course skill
sets required to design and deploy
dynamically scalable and reliable
applications on completion of this
course you will gain Caltech ctme
postgraduate certificate with 40 plus
Hands-On projects along with
opportunities to secure job in large
companies like Netflix MasterCard Adobe
and more you can check out its Link in
the description following that you need
to build your skills now cloud computing
is a constantly evolving field and
staying up toate with the latest
Technologies and Trends is crucial
attend training sessions take online
courses or enroll in a certification
program to develop your skills in cloud
computing additionally build your
technical skills by gaining hands-on
experience with cloud computing
platforms through projects or
internships this will not only enhance
your resume but also provide you with
the Practical experience and insights in
the field our CTIC postgraduate program
will also help you learn skills like
cloud provider selection application
migration performance testing Cloud
workloads identity access management
Autos scaling and many more to learn
more about these skills and tools you
can check out the course link mentioned
in the description and then is to gain
work experience now to break into cloud
computing gaining work experience is
vital consider taking entry-level
position or internship in cloud
computing to build your skills and gain
exposure to real world scenarios
additionally leverage your existing
experience and skills to find
opportunities in cloud computing related
to your current field now next and the
final step is to create an impressive
resume your resume is the first
impression you make on potential
employers so Make It Count highlight
your technical skills relevant work
experience and certification in cloud
computing additionally tailor your
resume to the specific job your applying
for and include any relevant projects or
achievements in conclusion switching
your career to cloud computing requires
dedication and effort but it's a
rewarding and lucrative feel by
following these steps you can prepare
yourself for a successful career in
cloud
computing let's have a look at some of
the skills required to become a cloud
administrator first off you need
experience with programming languages
like CP and.net you'll also need to be
experienced with devops tools like
Jenkins Docker anible and Chef
you'll need to have an understanding of
database configuration so that you can
take advantage of all the relevant
information about the hardware and
software components used by the
organization you'll also need to have
experience with Cloud infrastructure
systems like servers storage Network and
visualization software finally you'll
also need to configure virtual machines
vpns and Cloud servers now let's have a
look at the salary offered to Cloud
administrators now in the United States
the average salary of a cloud
administrator is approximately $65,000
perom similarly in India it's
approximately 7 lakh rupees perom now
let's have a look at some of the
companies hiring for cloud
administrators we have companies like
Vio infosis Accenture IBM and so on so
here I see a comment which says I'm a
fresher and want to learn about AWS how
can I start so actually any fresher can
make a career in AWS as long as you have
interest towards the subject now if you
are from a non-technical background you
need to put in a lot more hard work and
have a lot of patience so I would
recommend that before you take up the
AWS course you have a look at the course
curriculum types of AWS courses
opportunities in the market for AWS
certified candidates and so on so now
let's go to number six Cloud application
developer now a cloud application
developer mainly focuses on implementing
and maintaining an organization's Cloud
infrastructure now they're involved with
with designing building creating
analyzing and maintaining Cloud systems
now these individuals are also involved
with ensuring that there's an effective
design of business processes in the
cloud they're also involved with a
number of different tasks like
optimizing efficiency and performance
scaling application components and
security issues now let's have a look at
some of the skills required to become a
cloud application developer first off
you need to have experience with
database languages like MySQL SQL and
mongod B then you need to have
experience with programming languages
like python Ruby and pearl so that you
can code and create cloud computing
applications you'll also need to have
experience with Linux now this is
because most Cloud infrastructures are
created with Linux servers you'll also
need to have experience with cloud
service providers like Amazon web
services Google Cloud platform and
Microsoft zure you'll need to have
experience with information security
with the help of certifications you'll
also need to know how to create
microservices and to create Cloud
applications now let's have a look at
the salary offered to a cloud
application developer in the United
States it's approximately $70,000 perom
in India the average salary of a cloud
application developer is approximately 8
lakh rupees perom now let's have a look
at some of the companies hiring Cloud
application developers you have
companies like Bosch mecafe sap and so
on so now let's go to number five Cloud
network engineer a cloud network
engineer is responsible for implementing
ing supporting maintaining and
optimizing the network Hardware software
and communication Links of the
organization's Cloud infrastructure
Hoshi basically focuses on Automation
and security while building the cloud
infrastructure enhancing Network tooling
visibility and improving productivity
now let's have a look at some of the
skills required to become a cloud
network engineer first off obviously you
need to have experience with networking
which means a familiarity with the
internet and Van communication
Technologies protocols and best
practices you need to have an
understanding of cloud security and how
you can design a public cloud with
multiple options you'll need to have an
experience with data center
Administration which basically means an
understanding on infrastructure design
operations and life cycle management and
finally you need to have experience with
cloud computing platforms like Amazon
web services Microsoft as your and
Google Cloud platform next let's have a
look at the salaries offered to a cloud
network engineer firstly the average
salary of a cloud network engineer in
the United States is approximately
$72,000 perom in India the average
salary of a cloud network engineer is
approximately 4 lakh rupees perom now
that we're done with this let's have a
look at the company's hiring Cloud
Network Engineers we have companies like
Amazon web services Rakuten Cisco and so
much more now for number four we have
Cloud automation engineer a cloud
automation engineer focuses on cloud
automation orchestration and integration
he or she implements optimizes and
supports the cloud infrastructure and
ensures it has high availability they
also have to increase the cost
Effectiveness and availability of the
cloud now let's have a look at some of
the skills required to become a cloud
automation engineer first off since the
role is cloud-based experience with a
cloud service platform like Microsoft as
your AWS or Google Cloud platform is an
absolute must you'll also need to have
experience with programming languages
like Python and go that will help you
make the process of automation easier
next experience with devops tools like
chef anible and puppet are seen as a
huge plus you'll also need to have an
understanding of Docker and containers
experience with databases like post SQL
and MySQL that can handle multiple
workloads would be very useful and
finally you need to have experience with
virtualization which means you need to
know how you can work with virtual
servers applications storage and
networks with this you can reduce the
amount of resources required by the
organization now let's have a look at
the salary offered to Cloud automation
engineers in the United States the
average salary of a cloud automation
engineer is approximately $79,000 perom
the average salary of a cloud automation
engineer in India is approximately 5
lakh rupees perom now that we're done
let's have a look at some of the
companies hiring Cloud automation
Engineers we have companies like Oracle
Google Kappa Gemini Disney and so on and
now to number three Cloud security
manager a cloud security manager is
someone who's responsible for providing
security for cloud-based digital
platforms and protecting the
organization's data he or she may be
involved with creating new security
methods or to analyze existing ones they
may also have to create cloud-based
applications performing threat
simulations and providing security
recommendations now let's have a look at
some of the skills required to become a
cloud security manager first off you you
will need to have experience with at
least one of the popular cloud service
providers like Amazon web services
Microsoft as your and gcp you'll also
need to have experience in programming
languages like python experience with
commonly used devops tools like jenin so
that you can Implement continuous
integration or continuous deployment
models would be very helpful you'll also
need to be well wored with TCP IP
protocols and other networking Concepts
you need to be well versed with pki SSL
SSH h gtps and so on experience with
web-based analytics and services would
also be very helpful now let's have a
look at the salary offered to a cloud
security manager in the United States
the average salary of a cloud security
manager is approximately $999,000 per
anom in India the average salary for
cloud security manager is approximately
11 lakh rupees per anom now let's have a
look at some of the companies hiring
Cloud security managers we have
companies like deoe VMware Cisco Dell
and so on now let's move on to number
two Cloud engineer a cloud engineer is
an individual who is responsible for any
technological duties that are associated
with cloud computing including design
planning management maintenance and
support they're also involved with
orchestrating and automating cloud-based
platforms throughout the organization
let's have a look at the skills required
to become a cloud engineer first off
you'll need to have experience with at
least one of the popular cloud service
providers like WS Microsoft as your or
the Google Cloud platform you'll need to
have an understanding of networking
Concepts like building and accessing
servers virtual networks and so on this
enables Cloud engineers make sure that
the network is responsive to the users
next you need to have experience with
virtualization with virtualization you
can reduce how many Hardware units you
need with the help of virtual machines
it also makes resources scalable and
fall tolerant in an organization
experience with the Linux operating
system system would also be very helpful
considering how 30% of the servers that
powers your are Linux based you'll need
to know about apis to design restful
Services experience with devops is also
a major skill to have since it'll be
able to help handle work dependencies
between the development and operation
teams and finally you need to have
programming experience with languages
like Java python C++ and Ruby next let's
have a look at the salary offered to a
cloud engineer in the United States the
average salary of a cloud engineer is
approximately
$105,000 per anom the average salary in
India is approximately 5 lakh rupees
perom now let's have a look at some of
the companies hiring Cloud Engineers we
have companies like Mecha IBM JP Morgan
visa and so on now I see a pretty good
question in the chat how do you become a
cloud engineer so to become a cloud
engineer you need to have experience
with the programming language experience
with at least one one cloud service
platform which is Amazon web services or
Microsoft is your or Google Cloud
platform the choice is yours and you
need to specialized in a particular
service be it storage networking
disaster recovery and so on and now for
number one Cloud architect a cloud
architect is responsible for managing
cloud computing architecture in an
organization he or she handles
everything to do with front-end
platforms servers storage delivery and
networks now let's have a look at some
of the skills required to become a cloud
architect first off you need to have
knowledge in programming knowledge about
Pearl python Ruby PHP Java and net can
provide users with the ability to build
deploy and manage applications quickly
you'll need to know about the basics of
networking since most of the work what
you'll be doing would be web related
knowledge about networking can be really
helpful knowledge about data storage
fundamentals are also really important
this provides you with the knowledge to
determine which data storage option to
use and when being experienced with
cloud service platforms is also really
important platforms like AWS Google
Cloud platform and Microsoft aure are
what you're are going to be basing most
of your work on experience with them is
pretty important and finally Cloud
security this will help you make sure
that your data is secure and only
authorized code is run and the right
people are allowed to run it now let's
talk about the salary of a cloud
architect the average salary of a cloud
architect is a approximately $107,000
perom in India the average salary of a
cloud architect is approximately 16 lakh
rupees perom and there you go those are
the top job roles in the field of cloud
computing now let's have a look at some
of the companies hiring Cloud Architects
we have companies like ey vpro Huawei
hulet Packer Enterprise and so on hello
everyone let me introduce myself as Sam
a multiplatform cloud architect and
trainer and I'm so glad and I'm equally
excited to talk and walk you through the
session about what AWS is and talk to
you about some services and offerings
and about how companies get benefited by
migrating their applications and infra
into AWS so what's AWS let's talk about
that now before that let's talk about
how life was without any cloud provider
and in this case how life was without
AWS so let's walk back and picture how
things were back in 2000 which is not so
long ago but lot of changes lot of
changes for better had happened since
that time now back in 2000 a request for
a new server is not an happy thing at
all because lot of uh money lot of
validations lot of planning are involved
in getting a server online or up and
running and even after we've finally got
the server it's not all said and done
there a lot of optimization that needs
to be done on that server to make it
worth it and get a good return on
investment from that server and uh even
after we have optimized for a good
return on investment the work is still
not done there will often be a frequent
increase and decrease in the capacity
and you know even news about our website
getting popular and getting more hits
It's still an Bittersweet experience
because now I need to add more servers
to the environment which means that it's
going to cost me even more but thanks to
the present day Cloud technology the
same situation were to happen today my
new server it's almost ready and it's
ready instantaneously and with the Swift
tools and technologies that Amazon is
providing u in provisioning my server
instantaneously and adding any type of
workload on top of it and making my
storage and server secure you know
creating a durable storage where data
that I stored in the cloud never gets
lost with all that features Amazon has
got our back so let's talk about what is
AWS there are a lot of definitions for
it but uh I'm going to put together a
simple and a precise definition as much
as possible now let me iron that out
Cloud still runs on and Hardware all
right and uh there are certain features
in that infrastructure in that cloud
infrastructure that makes cloud cloud or
that makes AWS a cloud provider now we
get all the services all the
Technologies all the features and all
the benefits that we get in our local
data center like you know security and
compute capacity and uh databases and in
fact you know we get even more cool
features like uh content caching in
various global locations around the
planet but again out of all the features
the best part is that I get or we get
everything on a pay as we go model the
less I use the less I pay and the more I
use the less I pay per unit very
attractive isn't it right and that's not
all the applications that we provision
in AWS are very reliable because they
run on an reliable infrastructure and
it's very scalable because it runs on an
ond demand infrastructure and it's very
flexible because of the designs and
because of the design options available
for me in the cloud let's talk about how
all this happened AWS was launched in
2002 after the Amazon we know as the
online retail store wanted to sell their
reminding or unused infrastructure as a
service or as an offering for customers
to buy and use it from them you know
sell infrastructure as a service the
idea sort of clicked and the AWS
launched their first product first
product in 2006 that's like 4 years
after the idea launch and in 2012 they
held a big-sized customer event to
together input and concerns from
customers and they were very dedicated
in making those requests happen and that
habit is still being followed it's still
being followed as U reinvent by AWS and
at 2015 Amazon announced its Revenue to
be 4.6 billion and in 2015 through 2016
AWS launched products and services that
helped migrate customer services into
AWS well there were products even before
but this is when a lot of focus was
given on developing migrating services
and in the same year that's in 2016
Amazon's revenue was 10 billion and not
but not the least as we speak Amazon has
more than 100 products and services
available for customers and get
benefited from all right let's talk
about the uh services that are available
in uh Amazon let's start with this
product called S3 now S3 is a great tool
for internet backup and it's it's the
cheapest storage option in the object
storage category and not only that the
data that we put in S3 is retriable from
the internet S3 is really cool and we
have other products like migration and
data collection and data transfer
products and here we can not only
collect data seamlessly but also in a
realtime way monitor the data or analyze
the data that's being received that they
cool products like uh AWS data transfers
available that helps achieve that and
then we have products like uh ec2
elastic compute Cloud that's an
resizable computer where we can anytime
anytime alter the size of the computer
based on the need or based on the
forecast then we have SIMPLE
notification Services systems and tools
available in Amazon to update us with
notifications through email or through
SMS now anything anything can be sent
through email or through SMS if we use
that service it could be alarms or uh it
could be service notifications if you
want stuff like that and then we have
some security tools like KMS key
management system which uses a 256bit
encryption to encrypt our data at rest
then we have Lambda as service for which
we pay only for the time in seconds
seconds it takes to execute our code and
uh we're not paying for the
infrastructure here it's just the
seconds the program is going to take to
execute the code for the short program
will be paying in milliseconds if it's a
bit bigger program we'll be probably
paying in 60 seconds or 120 seconds but
that's lot cheap Lots simple and lots
cost effective as against paying for
service on an odly basis which a lot of
other services are well that's cheap but
using Lambda is a lot cheaper than that
and then we have services like uh Route
53 at DNS service in the cloud now I do
not have to maintain an DNS account
somewhere else and my cloud environment
with AWS I can get both in the same
place all right let me talk to you about
um how AWS makes life easier or how
companies got benefited by using AWS as
their it provider for their applications
or for the infrastructure now uniliver
is a company and um they had a problem
right and they had a problem and they
picked AWS as a solution to their
problem all right now this company was
sort of spread across 190 countries and
they were relying on a lot of digital
marketing for promoting their products
and their existing environment their
legacy local environment proved not to
support their changing it demands and
they could not standardize their old
environment now they chose to move part
of their applications to AWS because
they were not getting what they wanted
in their local environment and since
then you know rollouts were easy
provisioning new applications became
easy and even provisioning
infrastructure became easy and they were
able to do all that that in push button
scaling and uh needless to talk about uh
backups that are safe and backups that
can be securely access from the cloud as
needed now that company is growing along
with AWS because of their Swift speed in
rolling out deployments and uh being
able to access secure backups from
various places and generate reports and
in fact useful reports out of it that
helps their business now on the same
lines let me also talk to you about kogs
and how they got benefited by using
Amazon now Kelloggs had a different
problem it's one of its kind now their
business model was very dependent on an
infra that will help to analyze data
really fast right because they were
running promotions based on the analyzed
data that they get so they being able to
respond to the analyzed data as soon as
possible was critical or vital in their
environment and luckily sap running on
Hannah Environ is what they needed and
uh you know they picked that service in
the cloud and that sort of solved the
problem now the company does not have to
deal with maintaining their legacy infra
and maintaining their heavy compute
capacity and maintaining their database
locally all that is now moved to the
cloud or they are using Cloud as their
it service provider and and now they
have a greater and Powerful it
environment that very much complement
their business so if you are are
interested in becoming a cloud engineer
or architect then check our Cloud
architect Masters program simply learns
Cloud architect certification course
will build your AWS Microsoft Y and
Google Cloud platform expertise from the
ground up you will learn to master the
architectural principles and services of
the top Cloud platforms design and
deploy highly scalable fall tolerant
applications and develop skills to
transform yourself into an awsn Azure
cloud this program also has job assist
program simply learns job assist program
is an Indian specific offering in
partnership with imj jobs.com to help
you learn your dream job to participate
in job assist program you need to be
graduate in engineering or equivalent or
complete our master's program
successfully and earn a master
certificate upon completion so what are
you waiting for enroll now hi there I'm
Samuel a multiplatform cloud architect
and I'm very excited and honored to walk
you through this learning series about
AWS let me start the session with this
scenario let's imagine how life would
have been without Spotify for those who
are hearing about Spotify for the first
time uh Spotify is an online music
service offering and it offers instant
access to over 16 million licensed songs
Spotify now uses AWS Cloud to store the
data and share it with their customers
but prior to AWS they had some issues
imagine using spotify before AWS let's
talk about that back then then users
were often getting errors because
Spotify could not keep up with the
increased demand for storage every new
day and that led to users getting upset
and users canceling the subscription the
problem Spotify was facing at that time
was their users were present globally
and were accessing it from everywhere
and uh they had different latency in
their applications and Spotify had a
demanding situation where they need to
frequently catalog the songs released
yesterday today and in the future and
this was changing every new day and the
songs coming in rate was about 20,000 a
day and back then they could not keep up
with this requirement and needless to
say they were badly looking for way to
solve this problem and that's when they
got introduced to AWS and it was a
perfect fit and match for their problem
AWS offered a dynamically increasing
storage and that's what they needed AWS
also offered tools and techniques like
storage life cycle management and
trusted advisor to properly utilize the
resource so we always get the best out
of the resource used AWS address their
concerns about easily being able to
scale yes you can scale the AWS
environment very easily how easily one
might ask it's just a few button clicks
and AWS solved spotify's problem let's
talk about how it can help you with your
organization's problem let's talk about
what is AWS first and then let's bleed
into how AWS became so successful and
the different types of services that AWS
provides and what's the future of cloud
and AWS in specific let's talk about
that and finally we'll talk about a use
case where you will see how easy it is
to create a web application with AWS all
right let's talk about what is AWS AWS
or Amazon web services is a secure cloud
service platform it is also pay as you
go type bilding model where there is no
upfront or Capital cost we'll talk about
how soon the service will be available
well the servers will be available in a
matter of seconds with AWS you can also
do identity and access management that
is authenticating and authorizing a user
or a program on the flight and almost
all the services are available on demand
and most of them are available
instantaneously and as we speak Amazon
offers 100 plus services and this list
is growing every new week now that would
make you wonder how AWS became so
successful of course it's their
customers let's talk about the list of
well-known companies that has their it
environment in AWS Adobe Adobe uses AWS
to provide multi- terabyte operating
environments for its customers by
integrating its system with AWS Cloud
adob can focus on deploying and
operating its own software instead of
trying to you know deploy and manage the
infrastructure Airbnb is another company
it's an Community Marketplace that
allows property owners and travelers to
connect each other for the purpose of
renting unique vacation spaces around
the world and the rbnb community users
activities are conducted on the website
and through iPhones and Android
applications Airbnb has a huge
infrastructure in AWS and they're almost
using all the services in AWS and are
getting benefited from it another
example would be Autodesk Autodesk
develops software for engineering
designing and entertainment Industries
using services like Amazon RDS or
rational database servers and Amazon S3
or Amazon simple storage servers
Autodesk can focus on deploying or
developing its machine learning tools
instead of spending that time on
managing the infrastructure AOL or
American online uses AWS and using AWS
they have been able to close data
centers and decommission about 14,000
in-house and collocated servers and move
Mission critical workload to the cloud
and extend its Global reach and save
millions of dollars ERS on energy
resources Bit Defender is an internet
security software firm and their
portfolio of softwares include antivirus
and anti- spyware products Bit Defender
uses ec2 and they're currently running
few hundred instances that handle about
5 terab of data and they also use
elastic load balancer to load balance
the connection coming in to those
instances across availability zones and
they provide seamless Global delivery of
service because of that the BMW group it
uses AWS for its new connected Car
application that collects sensor data
from BMW 7 Series cars to give drivers
dynamically updated map information
canons offers Imaging products division
benefits from faster deployment times
lower cost and Global reach by using AWS
to deliver cloud-based services such as
mobile print the office Imaging products
division uses AWS such as Amazon S3 and
Amazon Route 53 Amazon cloudfront and
Amazon IM for their testing development
and Production Services Comcast is the
world's largest cable company and the
leading provider of internet service in
the United States Comcast uses AWS in a
hybrid environment out of all the other
Cloud providers Comcast ches AWS for its
flexibility and scalable hybrid
infrastructure Docker is a company
that's helping redefine the way
developers build ship and run
applications this company focuses on
making use of container ERS for this
purpose and in AWS the service called
the Amazon ec2 container service is
helping them achieve it the esa or
European Space Agency although much of
esa's work is done by satellites some of
the programs data storage and Computing
infrastructure is built on Amazon web
services Esa chose AWS because of its
economical pay as ego system as well as
its quick startup time the Guardian
newspaper uses AWS and it uses a wide
range of AWS services including Amazon
Kinesis Amazon red shift that power an
analytic dashboard which editors used to
see how stories are trending in real
time Financial Times ft is one of the
world's largest leading business news
organization and they used Amazon red
shift to perform their analysis A Funny
Thing Happened Amazon red shift
performed so quickly that some
analysists thought it was malfunctioning
they were used to running queries
overnight and they found that the
results were indeed correct just as much
faster by using Amazon Redi FD is
supporting the same business functions
with costs that are 80% lower than what
was before general electric GE is at the
moment as we speak migrating more than
9,000 workloads including 300 desperate
Erp systems to AWS while reducing its
data center footprint from 34 to 4 over
the next 3 years similarly Howard
Medical School HDC IMDb McDonald's NASA
Kelloggs and a lot more are using the
services Amazon provides and are getting
benefited from it and this huge success
and customer portfolio is just the tip
of the iceberg and if we think why so
many adapt AWS and if we let AWS answer
that question this is what AWS would say
people are adapting AWS because of the
security and durability of the data and
endtoend privacy and encryption of the
data and storage experience we can also
rely on aw's way of doing things by
using the AWS tools and techniques and
suggested best practices built upon the
years of experience it has gained
flexibility there is a greater
flexibility in AWS that allows us to
select the OS language and database easy
to use swiftness in deploying we can
host our applications quickly in AWS be
it a new application or migrating an
existing application into AWS
scalability the application can be
easily scaled up or scaled down
depending on the user requirement cost
saving we only pay for the compute power
storage and other resources you use and
that to without any long-term
commitments now let's talk about the
different types of services that AWS
provides the services that we talk about
fall in any of the following categories
you see like you know compute storage
database Security customer engagement
desktop and streaming Mission learning
developers tool stuff like that and if
you do not see the service that you're
looking for it's probably is because AWS
is is creating it as we speak now let's
look at some of them that are very
commonly used within Computer Services
we have Amazon ec2 Amazon elastic bean
stock Amazon light sale and Amazon
Lambda Amazon ec2 provides compute
capacity in the cloud now this capacity
is secure and it is resizable based on
the user's requirement now look at this
the requirement for the web traffic
keeps changing and behind the scenes in
the cloud ec2 can expand its environment
to three instances and during no load it
can shrink its environment to just one
resource elastic beanock it helps us to
scale and deploy web applications and
it's made with a number of programming
languages elastic beanock is also an
easy to use service for deploying and
scaling web applications and services
deployed be in Java net PHP nodejs
python Ruby Docker and lot other
familiar services such as Apache
passenger and IIs we can simply upload
our code and elastic bean stock
automatically handles the deployment
from capacity provisioning to load
balancing to autoscaling to application
Health monitoring and Amazon lightell is
a virtual private server which is easy
to launch and easy to manage Amazon
lightell is the easiest way to get
started with AWS for developers who just
need a virtual private server lightell
includes everything you need to launch
your project quickly on a virtual
machine like SSD based storage a virtual
machine tools for data transfer DNS
management and a static IP and that to
for a very low and predictable price AWS
Lambda has taken Cloud Computing
Services to a whole new level it allows
us to pay only for the compute time no
need for provisioning and managing
servers an AWS Lambda is a compute
service that lets us run code without
provisioning or managing servers Lambda
executes your code only when needed and
scales automatically from few request
per day to thousands per second you pay
only for the compute time you consume
there is no charge when your core is not
running let's look at some storage
services that Amazon provides like
Amazon S3 Amazon Glacier Amazon abs and
Amazon elastic file system Amazon S3 is
an object storage that can store and
retrive data from anywhere websites
mobile apps iot sensors and so on can
easily use Amazon S3 to store and
retrive data it's an object storage
built to store and retrive any amount of
data from anywhere with its features
like flexibility in managing data and
the durab ility it provides and the
security that it provides Amazon simple
storage service or S3 is a storage for
the internet and Glacier Glacier is a
cloud storage service that's used for
archiving data and long-term backups and
this Glacier is an secure durable and
extremely lowcost cloud storage service
for data archiving and long-term backups
Amazon EBS Amazon elastic Block store
provides Block store volumes for the
instances of ec2 and this elastic Block
store is highly available and a reliable
storage volume that can be attached to
any running instance that is in the same
availability Zone ABS volumes that are
attached to the eud instances are
exposed as storage volumes that
persistent independently from the
lifetime of the instance and Amazon
elastic file system or EFS provides an
elastic file storage which can be used
with AWS cloud service and resources
that are on premises an Amazon elastic
file system it's an simple it's scalable
it's an elastic file storage for use
with Amazon cloud services and for on
premises resources it's easy to use and
offers a simple interface that allows
you to create and configure file systems
quickly and easily Amazon file system is
built to elastically scale on demand
without disturbing the application
growing and shrinking automatically as
you add and remove files so your
application have the storage they need
and when they need it now let's talk
about databases the two major database
flavors are Amazon auds and Amazon red
shift Amazon auds it really eers the
process involved in setting up operating
and scaling a rational database in the
cloud Amazon audius provides cost
efficient and resizable capacity while
automating time consuming administrative
tasks such as Hardware provisioning
database setup patching and backups it
sort of frees us from managing the
hardware and sort of helps us to focus
on the application it's also
costeffective and resizable and it's
also optimized for memory performance
and input and output operations not only
that it ALS also automates most of the
services like taking backups you know
monitoring stuff like that it automates
most of those Services Amazon red shift
Amazon red shift is a data warehousing
service that enables users to analyze
the data using SQL and other business
intelligent tools Amazon R shift is an
fast and fully managed data warehouse
that makes it simple and costeffective
analyze all your data using standard SQL
and your existing business intelligent
tools it also allows you to run complex
analysis queries against terabyte or
structured data using sophisticated
query optimizations and most of the
results they generally come back in
seconds all right let's quickly talk
about some more services that AWS offers
there are a lot more services that AWS
provides but we're going to look at some
more services that are widely used AWS
application Discovery Services help
Enterprise customers plan migration
projects by gathering information about
their on premises data centers in a
planning a data center migration can
involve thousands of workflows they are
often deeply interdependent server
utilization data and dependency mapping
are important early first step in
migration process and this AWS
application Discovery service collects
and presents configuration usage and
behavior data from your servers to help
you better understand your workloads
Route 53 it's a network and content
delivery service it's an highly
available and scalable Cloud domain name
system or DNS service and Amazon Route
53 is fully compliant with IPv6 as well
elastic load balancing it's also a
network and content delivery service
elastic load balancing automatically
distributes incoming application traffic
across multiple targets such as Amazon
ec2 instance containers and IP addresses
it can handle the varing load of your
application traffic in a single
availability zones and also across
availability zones a is auto scaling it
monitors your application and
automatically adjusts the capacity to
maintain steady and predictable
performance at a lowest possible cost
using AWS Autos scaling it's easy to set
up application scaling for multiple
resources across multiple services in
minutes Autos scaling can be applied to
web services and also for DB Services
AWS identity and access management it
enables you to manage access to AWS
services and resources securely using IM
you can create and manage AWS users and
groups and use permissions to allow and
deny their access to AWS resources and
moreover it's a free service now let's
talk about the future of AWS well let me
tell you something cloud is here to stay
here's what in store for AWS in the
future as years pass by we're going to
have variety of cloud applications born
like iot artificial intelligence
business intelligence serverless
Computing and so on cloud will also
expand into other markets like
healthcare banking space automated cars
and so on as I was mentioning some time
back a lot or greater Focus will be
given to artificial intelligence and
eventually because of the flexib ibility
and advantage that cloud provides we're
going to see a lot of companies moving
into the cloud all right let's now talk
about how easy it is to deploy an web
application in the cloud so the scenario
here is that our users like a product
and we need to have a mechanism to
receive input from them about their
likes and dislikes and uh you know give
them the appropriate product as per
their need all right though the setup
and the environment it sort of looks
complicated we don't have to worry
because aw has tools and Technologies
which can help us to achieve it now
we're going to use services like Route
53 services like cloudwatch ec2 S3 and
lot more and all these put together are
going to give an application that's
fully functionable and an application
that's going to receive the information
uh like using the services like Route 53
cloudwatch ec2 and S3 we're going to
create an application and that's going
to meet our need so back to our original
requirement all I want is to deploy a
web application for a product that keeps
our users updated about the happenings
and the new comings in the market and to
fulfill this requirement here is all the
services we would need ec2 here is used
for provisioning the computational power
needed for this application and ec2 has
a vast variety of family and types that
we can pick from for the types of
workloads and also for the intents of
the workloads we're also going to use S3
for storage and S3 provides any
additional storage requirement for the
resources or any additional storage
requirement for the web applications and
we are also going to use cloud watch for
monitoring the environment and
cloudwatch monitors the application and
the environment and it uh provides
trigger for scaling in and scaling out
the infrastructure and we're also going
to use Route 53 for DNS and Route 53
helps us to register the domain name for
our web application and with all the
tools and Technologies together all of
them put together we're going to make an
application a perfect application that
CS our need all right so I'm going to
use use elastic beant stock for this
project and the name of the application
is going to be as you see GSG signup and
the environment name is GSG signup
environment 1 let me also pick a name
let me see if this name is available yes
that's available that's the domain name
so let me pick that and the application
that I have is going to run on node.js
so let me pick that platform and launch
now as you see elastic beant stock this
is going to launch an instance it's
going to launch the monitoring setup or
the monitoring environment it's going to
create a load balancer as well and it's
going to take care of all the security
features needed for this
application all right look at that I was
able to go to that URL which is what we
gave and it's now having an default page
shown up meaning all the dependencies
for the software is installed and it's
just waiting for me to upload the code
or in specific the page required so
let's do
that let me upload the code I already
have the code saved
here that's my code and that's going to
take some time all right it has done its
thing and now if I go to the same URL
look at that I'm being thrown an
advertisement page all right so if I
sign up with my name email and stuff
like that you know it's going to receive
the information and it's going to send
an email to the owner saying that
somebody had subscribed to your service
that's the default feature of this app
look at that email to the owner saying
that somebody had subscribed to your app
and this is their email address stuff
like that not only that it's also going
to create an entry in the database and
Dynamo DB is the service that this
application uses to store data there's
my Dynamo DB and and if I go to tables
right and go to items I'm going to see
that a user with name Samuel and email
address so and so has said okay or has
shown interest in the preview of my site
or product so this is where or this is
how I collect those information right
and some more things about the
infrastructure itself is it is running
behind an load balancer look at that it
had created a load balancer it had also
created an autoscaling group now that's
the feature of elastic load balancer
that we have chosen it has created an
Autos Skilling group and now let's put
this URL you see this it's it's not a
fancy URL right it's an Amazon given URL
a dynamic URL so let's put this URL
behind our DNS let's do that so go to
Services go to Route
53 go to hostage Zone and there we can
find the DNS name right so that's a DNS
name all
right all right let's create an n
entry and map that URL to our load
balancer right and create now
technically if I go to this URL it
should take me to that application all
right look at that I went to my custom
URL and now that's pointed to my
application previously my application
was having a random URL and now it's
having a custom URL without further Ado
let's dive head first and before that if
you are one of the aspiring Cloud
Enthusiast looking for online training
and graduating from the best
universities or a professional who
elicits to switch careers in cloud
computing by learning from the experts
then try giving a short to Simply learns
postgraduate program in cloud computing
in collaboration with ctech Center for
technology and management education the
course link is mentioned in the
description box that will navigate you
to the course page where you can find a
complete overview of the program being
offered so let's Dive Right In the
details and explore explore the magic
behind AWS step functions so the first
thing we will explore is understanding
the AWS step function challenges so
before we get into the specifics of AWS
step functions let's understand the
problem IT addresses as you build larger
applications with many different parts
managing and coordinating them can
become quite tricky absolutely imagine
you have a bunch of different task that
need to happen in a specific order to
complete a big project for example if
you want to build a house you need to
follow specific sequence of steps like
laying the foundation building the balls
putting on the roof and so on but what
if something goes wrong in the middle of
the process like the wall building part
doesn't work correctly or you run out of
bricks that's where the challenge lies
with traditional methods handling these
errors and coordinating everything can
become a nightmare and here comes the
AWS step functions now we'll have an
introduction to AWS stem function
so here AWS stem function comes to
rescue with these challenges so AWS St
functions are like having a master
conductor who organizes and orchestrates
all the task in your application it
helps you build workflows as a series of
steps or tasks making it easier to
manage the entire process that's right
just like a conductor guides the
musicians in an orchestra to play their
instruments at the right time AWS step
functions guides you different services
and functions to work together
harmoniously it does this by using
something called State machines so a
state machine is like a big map that
shows all the different steps your
application needs to take to finish its
work each step in the state machine is a
specific task that your application
needs to do it could be running a piece
of code processing some data or even
making decisions based on certain
conditions and now we'll see the
components of AWS step functions now
that we have basic understanding let's
talk about the key components of AWS
step functions the first and most
important component is the state each
state represents a single task or a step
in your workflow and there are different
types of States like task choice and
parallel a task state does a specific
job like running a Lambda function or an
activity a choice State makes decisions
based on conditions and a parallel State
let you do multiple task at once that
right and what's really cool is that AWS
step functions automatically manages the
flow between these states it makes sure
that each task happens in the right
order just like following the steps to
build a house and here's the best part
if something goes wrong during one of
the task AWS step functions can handle
it it can retry the task a few times or
even go to different part of the
workflow to deal with the problem and
now you can see the state machine
diagram on the screen so this state
machine starts with the start state
which represents the beginning of the
workflow from the start state it goes to
the check item stock that is a state
which is a task state that checks if the
requested item is available in the
stores inventory after completing the
check item stock task the state machine
proceeds to process payment State
another task test that processes the
customer's payment based on the choosen
payment method the notify method state
is a choice state that evaluates whether
the customer prefers to be notified
while via email or SMS if the customer
prefers email the state machine goes to
notify customer email state which is a
task state that sends an order
confirmation email to the customer if
the customer prefers SMS the state
machine goes to notify customer SMS
state which another task State like
which is another task state that sends
an order confirmation SMS to the
customer the parallel state is
responsible for running both notifi
customer email and notify customer SMS
task simultaneously once the task in the
parallel state are completed the state
machine reaches the end state which
marks the end of the workflow the visual
representation of the state machine
provides a clear overview of how AWS
step functions coordinate in the
different task and branches in the
workflow it helps in understanding the
flow and logic of the serverless
application and enables developers to
manage and modify the workflow
efficiently and now we'll see how AWS
step functions work and now let's see
how they will work imagine you are a
chef and you want to bake a cake you
have different steps like mixing the
ingredients putting the batter in the
oven and decorating the cake with AWS
step functions you can define a state
machine for baking a cake the state
machine will list all the steps and the
order they need to happen in so when you
start the state machine it will take you
through each step one by one just like
following a recipe and if you
accidentally put too much sugar in the
battle AWS step functions can handle
that it can go back and give you another
chance to mix the right amount of sugar
or if the oven suddenly stops working
AWS step functions can pause the baking
process and wait for the oven to be
fixed before continuing and now we'll
see the benefits of AWS step functions
AWS step functions offer several
benefits let's highlight a few of them
first they make your application more
reliable with buil-in arror handling and
automatic retri you can be confident
that your workflows will work smoothly
even if something goes wrong absolutely
an aw step functions also make your life
as a developer easier the visual
workflow designer in the AWS Management
console allows you to see and modify
your workflows graphically plus it's
highly scalable as your application
grows AWS step functions can handle more
and more complex workflows without a
hitch and let's not forget about cost
Effectiveness you only pay for the state
Transitions and the time your workflows
are running which means you can save
money while building powerful
applications so these were the benefits
of AWS step functions now we'll see the
real world use cases AWS step functions
are incredibly versatile and can be used
in many real world scenarios for example
if you have a big online store you can
use AWS step functions to handle the
entire order process from receiving the
order to receiving the payment checking
the inventory and finally shipping the
products and let's not forget about data
processing AWS step functions are
perfect for automating data pipelines
where you need to extract transform and
load data from one place to another it's
also a great tool for managing
microservices if you have different
parts of your application running
independently AWS step functions can
help you coordinate this interactions
and now we conclude this topic that is
AWS step functions so to wrap things up
AWS St functions are like having a
magical conductor for your applications
they make it easier to manage and
coordinate all the different task in
your serverless workflows with AWS step
functions you get reliability Simplicity
scalability and cost Effectiveness all
in one package so if you're working on
AWS and want to simplify your serverless
architecture give AWS step functions a
try and now let's take a minute to hear
from our Learners who have experienced
massive success in their careers
I will be permanently moving to Europe
with my family soon simply learn course
has helped me back a great job offer
there with 60% salary hike we cannot
wait to start our new life in Finland we
are all so excited hey I am Salah quatra
and I am currently living in Nigeria I'm
working as Chief Information Technology
officer at AR ties after working for 23
years in it sector in Algeria I felt
that my career had become stagnant here
I wanted to experience what is like to
leave in Europe so I started applying to
various jobs there as someone who is
responsible for making decision I wanted
to upgrade my skills I also realized
that to get a new job I needed to have a
professional certification in cloud
computing so last year I started the
postgraduate program in cloud computing
in association with ctech from Sly learn
it's not easy to get access to ctech but
simply learn provided that with this
course I had the choice to study while I
continued with my
job I learned Technologies like ews and
aure during the course luckily my new
employers were looking for someone who
knew these Technologies I have just
completed the course by but my new
employers were aware that I was taking
this course and that is how I got this
new job offer with 60% salary high in
Finland I will be leading the cloud
computing unit of my new
company I'm really excited not just for
myself but for my family as well I have
three daughters I think I will be able
to help them with their higher studies
in Europe as a father you always want to
make decision that have a positive
impact on your children as for me I'm
going to leave my dream now I think
dreams come true when you work hard to
achieve with them welcome to this video
about AWS Bedrock if you're new to cloud
or looking to get up to the speed on AWS
this is the perfect place to start AWS
Bedrock is a foundation considering of a
set of AWS services that that can be
used to build reusable and scalable
applications in this video we will cover
what AWS Bedrock consists of and why
it's important to use it whether you are
a season developer or just getting
started you will learn about AWS bedrock
in just a minute so let's dive in but
before that cloud computing is a highly
technical field and having a right
certification can set you apart from the
competition consider getting certified
in popular cloud computing platforms
like AWS edor or Google Cloud now to
help you with this step we have our
keltech postgraduate program in cloud
computing this course will help you
become an expert in aor AWS and gcp and
let you master fundamental architecture
principles and develop the skills needed
to become a cloud expert this
postgraduate program in cloud computing
will help you become an expert in
designing planning and scaling Cloud
implementations after completing this
course you will gain keltech ctme
postgraduate certificate with 40 plus
Hands-On projects you can check out its
Link in the description box below hey I
am Salah quatra and I am currently
living in Nigeria I wanted to experience
what is like to leave I also realized
that to get a new job I needed to have a
professional certification in cloud
computing so last year I started the
postgraduate program in cloud computing
in association with ctech with this
course I had the choice to study while I
contined and that is how I got this new
job offer with 60% salary high in
Finland I will be leading the cloud
computing unit of my new company we
cannot wait to start our new life in
Finland we are also now let's see the
agenda for this video in this video we
will see what is Amazon Bedrock after
that we will see what can Amazon Bedrock
do moving ahead we will see what is is a
foundational model and then we will see
the use cases of AWS bedrock and
conclude this video so there is no doubt
that major tech companies are actively
completing to gain a significant share
of a rapidly expanding artificial
intelligence Market the release of open
AI revolutionary chart GPT surveys has
further intensified this race capturing
the both interest of it and non-it
professionals according to various
reports the it industry is predicted to
survey to a value of $90 billion or more
than that by
2025 now let's see what is a Amazon
Bedrock Amazon Bedrock is a recently
launched machine learning platform by
Amazon web services that provides user
with a convinced way to build and expand
AI application using foundational model
also known as FMS this platform greatly
accelerates the development process by
lever baging foundational model without
the need of handle physical
infrastructure or the associated
operational
complexities also users have the
flexibility to choose from a variety of
foundational models including those
offered by AI 21 Labs atropic or
internally by AWS additionally
organization can customize these
Foundation model using their own data
and utilize similar AWS tools and
capabilities ensuring the development of
scalable and highly secure generative AI
applications now let's see what Amazon
Bedrock can do Amazon Bedrock a
userfriendly machine learning platform
similar to Amazon Sage maker enables the
building and scaling of a generative AI
application using Foundation model
unlike the sage maker which ml Engineers
primarily use for custom model
development Bedrock focuses on
leveraging FMS for ease of use now you
must be thinking what FM is now let's
see what is a foundation
model foundational model also known as
FMS are models that are trained on
diverse data and can be adapted by
multiple Downstream tasks unlike High
Learning model designed for specific use
cases foundational models serve as a
foundation that can be utilized across
various applications instead of inv
investing extensive time and resources
into training separate custom models for
specific task the focus is on the
building adaptable and versatile model
capable of Performing multiple functions
this approach promotes efficiency by
creating a model that can handle various
task rather than a specified model
limited to a single process now you must
have gotten the idea what foundational
model is now let's see the use cases of
Amazon
Bedrock text generation it enables the
generation of originally written content
such as short stories social media post
articles web page copy and even School
essays now we have chat boots Bedrock
facilitates the creation of conventional
interfaces like chat boards and virtual
assistants to ensure user experience
integration with Amazon Lex AWS
chatboard services may be possible next
we have search in search user can easily
search find and get the information from
a diverse data sources allowing various
questions moving ahead we have text
summarization this platform offers the
capability to summarize text content
from sources like blog post essays books
and documents providing conscious
summaries without the need for lengthy
reading next next we have image
generation Amazon bedro can generate the
realistic and artistic image based on
specific subject environment and scenes
next we have personalization the
platform's AI service enables
personalized customer interaction
allowing user to search for exactly what
they are looking for with the relevant
product ke recommendations now Amazon
Bedrock empowers user to build and scale
generative AI application for tasks such
as Tech generation chat boards search
and text summarization image generation
and personalization of approach to
leveraging foundational models now in
conclusion Amazon Bedrock is a powerful
machine learning platform offered by AWS
allowing user to build and scale
generative AI application using
foundational model with the rapid growth
of the AI Market Amazon Bedrock position
itself as a valuable tool for
organization looking to of generative AI
without the complexities of custom model
development by leveraging foundational
model user can unlock the potential of
AI in areas such as text generation chat
boards search summarization image
generation and personalization driving
Innovation and ensuring user experience
welcome to the realm of cutting Ed
technology have you ever wondered what
it would like to harness the immense
power of Google's Computing
infrastructure right at your fingertips
look no further for in digital Ren that
there exist a phenomenon known as Google
collab an interesting Fusion of cloud
computing and collaborative progress
imagine a world where you can
effortlessly explore the Limitless
possibilities of artificial intelligence
machine learning and data analysis
without the need for expensive Hardware
or complex setups Google collab emerges
as Celestial Century offering you a
virtual laboratory to experiment create
and collaborate with like-minded
enthusiasts from every corner of the
globe in this exciting video we will
understand what is Google collab and
then we will have a complete overview of
it so let's start with the first topic
what is Google
collab so Google collab is a free online
tool that lets you do coding and data
related work on the Internet it's like
having a virtual notebook where you can
write and run python code without
needing to install anything on your
computer with collab you can also get
data from different places and share
your work with others easily another
cool thing is that it gives you access
to powerful processors like gpus and
tpus which make tasks like machine
learning and data science faster and
more efficient so it's a great tool for
Learning and working on coding and data
projects all right now let's have a look
at Google collab let's have a complete
overview of
it so first of all Google collab
requires a Google account for access to
begin visit the link welcome to
collaboratory write welcome
to collaboratory as you can see we'll
click on
this then we'll click on this open this
one and sign in using our Google account
or credentials if you have already have
a Google account then you can just sign
in with
that all right now let's start with the
Google collab we'll simply
write Google
collab we click on the
this all right so this is the window
that appears when I click on that first
of all here we have is example tab so
the example tab offers some initial
examples to help you begin using collab
for a comprehensive understanding of
collaborative features and efficient
usage of collab documents refer to the
document title overview of collaboratory
features it covers the fundamental
aspects to get you started
efficiently then there is recent tab all
right so the recent tab displays a
collection of all the latest documents
you have been working on all right now
next is our Google Drive tab the Google
Drive tab features allows you to import
any of your previous notebooks directly
from your Google Drive all right then
next is GitHub tab so with the GitHub
tab you have the option to import
notebooks from your own GitHub
repository or any public repository
simply provide the GitHub URL and you
can easily import notebooks from the
desired public repository then we have
is upload tab so the upload feature
allows you to bring and work on your own
J notebooks that you have created on
your computer you can easily upload any
file from your local Machine by
selecting the choose file option here it
is choose file option now next is our
creating a notebook as we can see here's
a new notebook option and there's a
cancel option so creating a notebook so
to create a new notebook you have the
option to use a new notebook button
located at the bottom by clicking on
this button a new Untitled notebook will
be generated to give it a specific name
and simply click on the current untitle
name if we want to name it so as we have
clicked on it now to give it a specific
name as we just said simply click on the
current untitle name on The Notebook and
make the desired changes so let's say we
want to make
it
sp1 let's just say it a name all right
so next is our
cell here we can see this is a cell in a
notebook cell serve as the fundamental
building blocks encompassing everything
within there are two types of cells
actually one is code cell as you can see
it contains executable code and has a
run button on the left side to execute
its content
this one all right the output is
displayed its output is displayed below
the code cell after running right then
the next one is other one is text cell
so a text cell can include text images
links and more you can edit its content
by double clicking it the text cell
supports markdown markup language but
you can also use the provided options on
top on the top for formatting the right
half of the cell shows you how your edit
text will
appear all right now the next point
would be adding a new cell like how to
add a new cell to add a new code or text
cell use the respective option at the
top of the work area as you can see
these code or text by clicking on these
we can add code cell and text cell so
clicking on any of these button creates
a new cell right below the current one
you can like let's say we want to add
this so now we want to add this we can
add this also now you can rearrange the
cell order using the arrow options
located at the top right corner of each
cell as you can
see by using these we can do
that yeah the up Arrow moves the cell
one position up while the down arrow
moves it down by one
position as we can see
now adding and running a codee let's
talk about this so by default Google
collab provides One initial code cell
which can be supplemented with
additional cells as desired these cells
serve as a platform for writing and
executing python code for instance let's
consider the following code let's say
first of all I have to let us delete all
these this one
also yeah
so first of all we'll try one code let's
see how it goes so we'll simply write
the code
print yeah
print my favorite
color is yellow all right so now let's
try to execute it we can run it back
clicking on this it is running
executing so as you can see my favorite
color is yellow is being printed so you
can either press on this play button to
run the code or you can press control+
enter to run the code as you can see
control+ enter to run the cell now next
is changing the order of the cell so in
Google collab you have multiple options
for rearranging cells you can utilize
the upsell and down sell button located
in the toolbar above the notebook as we
discussed
previously alternatively you can employ
keyboard shortcuts such as control shift
up or control shift down to move the
chosen cell up or down Additionally you
have the flexibility to reorder cells by
clicking on the cell number in the left
Gutter and dra dragging it to a
different position all right now
deleting the current tab so to delete
the current app in Google collab you can
use the delete icon available over the
top of the cell this icon looks like a
trash can and it will remove the
selected cell from The Notebook as we
can see this is the trash can and this
is just at the right above corner of the
cell by clicking on this we can delete
the tab alternately you can also use the
keyboard shortcut control+ m and d to
delete the current cell you can also
right click on the cell and select
delete cells from the context menu as
you can see delete
cell all right now we will understand
how to add data sets so to add data sets
from your local device go to the left
corner and click on the folder icon as
we can see this is the left corner and
this is a folder icon we'll click on
that now click on the upload icon and
upload the desired file this is the
upload icon we'll click on
that now we can upload the desired file
whichever we
want all right you can also upload files
by writing a particular command let's
try writing that command okay so we'll
write
from
Google
laab import files let's import files all
right after that we'll
write upload
equals files
do
upload after that we'll put on
brackets
all right now we'll press control and
enter and here we can see choose files
now from here you can choose files so
both the ways you can upload files I'm
just
telling now let's understand how to like
import libraries in Google
collab so first of all we have to cancel
uplo we click on this all right so to
import it we'll
write import ters
as
PD all right after
that we'll write pd.
read so here we are importing the CSV
files actually so we have to write like
xd. rore
CSV and inside this we'll write
a file let's say I have to check what
what all files like this is the sample
dat data files right so you have to
write the file name actually which you
want to import that CSV file name I'm
writing sample _ data all
WR test the location you have to
put do
CSV so this is the
location all right so if we want to
display 10 rows we'll
write DX F do
head write 10 we'll press control and
enter and we can see 10 rows are being
displayed so this is how you can import
and like showcase the data and
all so this was about the Google collab
we have covered major things in that
many important things in that there are
there must be many more things in that
that you will explore when you will
start using it so after understanding
about Google collab and hearing about
various Cloud Technologies if you want
to become a cloud engineer then check
our postgraduate program in cloud
computing our comprehensive course
covers Microsoft a AWS and gcp
empowering you to deploy Dynamic and
independable application seamlessly
discover the Ines of these leading Cloud
platforms and master the core skill sets
needed for Success join us to transform
your career and step confidently into
the world of cloud computing enroll now
and embark on an exciting Journey
towards a bright future in the cloud
industry don't miss this opportunity so
if you are interested in becoming a
cloud engineer or architect then check
our Cloud architect Masters program
simply learns Cloud architect
certification course will build your AWS
Microsoft and Google Cloud platform
expertise from the ground up you will
learn to master the architectural
principles and services of the top Cloud
platforms design and deploy highly
scalable fault tolerant applications and
develop skills to transform yourself
into an awsn Azure Cloud this program
also has job assist program simply
learns job assist program is an Indian
specific offering in partnership with IM
imj jobs.com to help you learn your
dream job to participate in job assist
program you need to be graduate in
engineering or equalent or complete our
master's program successfully and earn a
master certificate upon completion so
what are you waiting for enroll now so
now what is azure what's the big cloud
service provider all about so Azure is a
cloud computing platform provided by
Microsoft now it's basically an online
portal through which you can access and
manage resources and services now
resources and services are nothing but
you know you can store your data and you
can transform the data using services
that Microsoft provides again all you
need is the internet and being able to
connect to the Azo portal then you get
access to all of the resources and their
services in case you want to know more
about how it's different from its rival
which is AWS I suggest you click on the
top right corner and watch the AWS
versus AO video so that you can clearly
tell how both these cloud service
providers are different from each other
now here are some things that you need
to know about as year it was launched in
February 1st 2010 which is significantly
later than when AWS was launched it's
free to start and has a pay per use
model which means like I said before you
need to pay for the services you use
through a
and one of the most important selling
points is that 80% of Fortune 500
companies use Azure Services which means
that most of the bigger companies of the
world actually recommend using AZ and
then azir supports a wide variety of
programming languages the C nodejs Java
and so much more another very important
selling point of aure is the amount of
data centers it has across the world now
it's important for a cloud service
provider to have many data centers
around the world because it means that
they can provide their services to a
wider audience now Azor has 42 which is
more than any cloud service provider has
at the moment it expects to have 12 more
in a period of time which brings its
total number of regions it covers to 54
now let's talk about Azure Services now
Azure Services have 18 categories and
more than 200 services so we clearly
can't go through all of them it has
services that cover compute a and
machine learning integration management
tools identity devops web and so much
more you're going to have a hard time
trying to find a domain that Azure
doesn't cover and if it doesn't cover it
now you can be certain they're working
on it as we speak so first let's start
with the compute Services first virtual
machine with this service what you're
getting to do is to create a virtual
machine of Linux or Windows operating
system it's easily configurable you can
add RAM you can decrease RAM you can add
storage remove it all of it is is
possible in a matter of seconds now
let's talk about the second service
cloud service now with this you can
create a application within the cloud
and all of the work after you deploy it
deploying the application that is is
taken care of by aard which includes you
know provisioning the application load
balancing ensuring that the application
is in good health and all of the other
things are handled by aure next up let's
talk about service fabric now with
service fabric the process of developing
a micros service is greatly simplified
so you might be wondering what exactly
is a microservice now a microservice is
basically an application that consists
of smaller applications coupled together
next up functions now with functions you
can create applications in any
programming language that you want
another very important part is that you
don't have to worry about any hardware
components you don't have to worry what
Ram you require or how much storage you
require all of that is taken care of by
a z all you need is to provide the code
to Azure and it'll execute it and you
don't have to worry about anything else
now let's talk about some networking
Services first up we have Azure CDN or
the content delivery Network now the Azo
CDN service is basically for delivering
web content to users now this content is
of high bandwidth and can be transferred
or can be delivered to any person across
the world now these are actually a
network of servers that are placed in
strategic positions across the world so
that the customers can obtain this data
as fast as possible next up we have
expess R now with this you can actually
connect your on promise Network onto the
Microsoft cloud or any of the services
that you want through a private
connection so the only communication
that happens is between your on promise
Network and the service that you want
then you have virtual Network now with
virtual Network you can have any of the
AZ Services communicate with each other
in a secure manner in a private manner
next we have azard DNS so a DNS is a
hosting service which allows you to host
their DNS or domain name system domains
in Azure so you can host your
application using a your DNS now for the
storage Services first up we have dis
storage with dis storage you're given a
costeffective option of choosing HDD or
solid state drives to go along with your
virtual machines based on your
requirements then you have blob storage
now this is actually optimized to ensure
that they can store massive amounts of
unstructured data which can include Text
data or even binary data next you have
file storage which is a managed file
storage and can be accessible via the
SMB protocol or the server message block
protocol and finally you have q storage
now with Q storage you can provide
durable message queuing for an extremely
large workload and the most important
part is that this can be accessed from
anywhere in the world now let's talk
about how a can be used firstly for
application development it could be any
application mostly web app applications
then you can test the application see
how well it works you can host the
application on the internet you can
create virtual machines like I mentioned
before with the service you can create
these virtual Machines of any size or
Ram that you want you can integrate In
Sync features you can collect and store
matrices for example how the data Works
how the current data is how you can
improve upon it all of that is possible
with these services and you have virtual
hard drives which is an extension of the
virtual machines where these services
are able to provide you a large amount
of storage where data can be stored
let's talk about Azia Services as I told
you Azia provides services for a wide
range of domains now let's have a look
at some of these domains there's Ai and
machine learning compute containers
database identity management tools
networking Security Storage and so much
more now let's have a look at some of
the individual services within these
domains firstly you have AZ virtual
machines with Az virtual machines what
you get is the opportunity to create
Windows or Linux virtual machines now
all of this is possible in a matter of
seconds with a large amount of
customization now let's have a look at
some of its features firstly you can
choose from a wide variety of virtual
machine options then you have a large
amount of optimization available to you
for example what size of operating
system do you want how much size do you
want allocated to it what version of the
system is it and so much more then it
provides low cost and per minute billing
now Azure provides you per minute
billing which means that you're only
charged for how much time you use the
service and finally you have enhanced
security and protection for your virtual
machines next we have service fabric now
with service fabric you have a platform
which enables you to create
microservices now this also makes the
process of application life cycle
management a whole lot easier as a
direct result you can create
applications with a faster time to
Market it supports Windows Linux on
promises or other clouds and it enables
you to do a tremendous amount of scaling
up depending on your requirement and
finally we have functions now with
functions you can build applications
with the help of serverless computing
here the users only pay for the amount
of resources that they've used you can
create applications in any language that
you want and the only thing you need to
worry about is the code of the
application everything other than that
that is the hardware requirements are
taken care of by Azure now let's have a
look at the networking Services firstly
we have the Azor CDN or the content
delivery network with Azor CDN what you
get is the ability to deliver your
content with reduced load times fast
responsiveness and less bandwidth now
CDN can be integrated with several other
Azure services so that the process can
move at a fast rate it can handle heavy
loads and traffic spikes with ease it
also provides a robust security system
now with the content that's delivered
you can get Advanced analytic data with
which you can understand how customers
are using your content next we have
express route with express route you can
connect your or on premisis network to
aure through a private Network Now by
default this lowest latency it increases
the emphasis on reliability and speed
and it can be of great use when you have
to transfer large amounts of data
between networks now another way this
can be useful is if it's used to add
compute or storage capacity to Data
Centers next we have Azure DNS domain
name service or Azure DNS can be used to
host your domains on Azure this provides
High availability and great performance
it provides fast responses to DNS
queries by taking advantage of
Microsoft's Global Network it also
provides High availability next we have
virtual Network Azure virtual Network
allows the Azure resources to
communicate with each other or other on
promise networks via the Internet and
all of this is kept extremely secure now
with this users can create their own
private Network for communication it
provides users with an isolated and
extremely secure environment for their
applications to run now all of the
traffic stays entirely within the AZ
Network and it also allows users to
design their own networks next we have
traffic manager now with traffic manager
you can route incoming traffic to
improve your performance and
availability now one thing it provides
is multiple failover options so if a
particular situation goes wrong there's
always an option to consider to salvage
the situation it helps reduce
applications runtime and enables the
distribution of user traffic across
multiple locations it also helps the
people who are using it to know where
the customers connecting from across the
world next we have load balancer with
this you have provided the ability to
instantly scale applications at the same
time providing High availability and
improved Network performance for users
applications it can be integrated into
virtual machines and cloud services it
provides highly reliable applications it
also allows users to secure and
integrate security groups finally we
have AO VPN Gateway now this this allows
users to connect their on promise
networks to aure using a sight tosite
VPN now this allows users to connect
their virtual machine to anywhere in the
world through a pointto site VPN and
also it's very easy to manage and is
highly available now let's talk about
the storage Services first we have data
Lake storage now with this what you get
is a scalable data storage with an
emphasis on cost Effectiveness and
scalability now it comes of Maximum use
when You' integrated with other services
so that you can get analytics on how the
data is being used it is also integrated
with other services like the Azo blob
storage now it is also optimized for Big
Data analysis tools like Pache spark and
Hadoop next up we have blob storage now
blob storage provides a storage capacity
for data now depending on how often a
particular data is used it is classified
into different tiers now all the data
that is within the blob storage is
unstructured data now it has a way of
ensuring that the data Integrity is
maintained every time a particular
object is being changed or the data is
being accessed and it also helps improve
app performance and reduces bandwidth
consumption next we have q storage now
with this you have a message queuing
system for large workloads this allows
users to build flexible applications and
separate functions not to mention with
this you can be sure that your
individual components will not fail it
also makes sure that your application is
scalable Q storage provides Q monitoring
which helps ensure that the customer
demands are met then we have file
storage now with file storage you can
perform file sharing with the help of
the SMB protocol or the server message
block protocol now this data is
protected by SMB 3.0 and the https
protocol in this CL like we mentioned in
functions AO takes care of all the
hardware needs and the operating system
deployments on its own it also improves
on prises performance and other
capabilities lastly we have table
storage with table storage you can
deploy semi-structured data sets and
nosql key value store now this is used
for creating applications which have a
flexible data schema and also
considering how it has a very strong
consistency model it's mainly aimed for
Enterprises next let's have a look at
some web and mobile services first we
have the Azure search now with Azure
search you get a cloud search service
which is powered by artificial
intelligence with this you can develop
web applications as well as mobile
applications now one big Advantage is
that you don't have to set up or manage
your search indices as your takes care
of that and by extension it increases
your development speed the artificial
intelligence also will provide insights
and structured information that you can
use to improve the search and structured
information next we have logic apps now
with this you can create integration
Solutions which can connect applications
that are important to your business now
with this you can visually create
business processes and workflows you can
integrate SAS or software as a service
applications and Enterprise applications
and more importantly it allows you to
unlock data within the firewall and
securely connect to services next we
have web applications now with web apps
you can create deploy and scale web
applications according to business
requirements now it supports both
windows and Linux platforms and it helps
with continuous integration or
deployment abilities another way
important aspect of this is that the
data can be deployed and hosted across
multiple locations in the world and
finally we have mobile apps with mobile
apps you can create applications for iOS
Android and Windows platforms one
advantage is that it automatically
scales Up and Down based on your
requirements now in situations where you
have network issues offline data syncing
ensures that your applications work
anyway and you can create crossplatform
applications or native applications for
iOS Android and Windows next let's have
a look at some container services first
let's talk about ACS or a z container
services it is also known as the azer
kubernets services as it's a fully
managed kubernets container
orchestration service now what this
means is that it eases the process of
container integration and deployment it
also can be used with other resources
from security like virtual networks
cryptographic keys and so much more to
ensure that your container is kept
secure next we have container instances
now this is similar to functions in a
way just that in this we're using
containers without having to manage
servers now applications can be
developed here without managing virtual
machines or learning new tools all that
is a your's problem to take care of and
it enables building applications without
having to manage the infrastructure that
is all you need to worry about is
running the container next let's have a
look at some database Services first we
have the SQL database now with SQL
database what you get is a relational
Cloud database service now this means
that it helps accelerate your app
development and makes it easier for you
to maintain your application now SQL
database is also used extensively in
migrating workloads to the cloud and
hence saves time and cost it also helps
improve your performance by integrating
machine learning and Adaptive
Technologies into your database next we
have Azure Cosmos DB now this is a
globally distributed multimodel database
service now what this means is that with
this you can create application with
support nosql it provides a high-grade
security system has high availability
and low latency now this is usually used
in situations where you have a diverse
and highly unpredictable workload now
let's have a look at some security and
identity Services firstly we have the
Azure active directory now if you want
to know more about Azor active directory
I suggest you click on the top right
corner and watch our video on the Azor
your active directory this is just an
introduction so with this you can manage
user identities and you can make sure
the resources are kept safe with the
help of access policies most of these
are intelligence driven now one of the
main features is that you can have
access to your applications from any
location or device it helps increase
your efficiency and helps down cutting
costs when it comes to having a help
desk it can also help improve security
and can respond to Advanced threats in
real time next have as your active
directory b2c it helps provide customer
identity and access management in the
cloud now protecting customer identity
is extremely important for an
organization and that's what aure ad b2c
does now it also enables the application
to be scaled to great amounts even
billions of customers next we have the
Azure security Center this is basically
like a command post with which you get a
complete view of the security across
users on your own Rises and Cloud
workloads so with this you given threat
protection method that adapts to
situations and helps reduce exposing you
to threats it also has rapid threat
response and makes the process of
finding and fixing vulnerabilities a
whole lot easier next up let's talk
about monitoring and Management Services
so first let's have a look at Azure
advisor now Azure advisor is basically a
guide for the best practices when it
comes to Azure now when you follow these
it improves performance security cost
and increases availability now it also
learns from how you use the services on
your configuration and usage pattern and
the adjustments that it suggests can be
implemented very quickly and easily next
we have Network Watcher now with this
you can monitor diagnose and understand
the working of your network now you can
monitor your network without actually
having to log in to your virtual machine
now you can also use something known as
network security flow logs to understand
the traffic pattern how much traffic is
coming towards you how much you're
giving and so much more it also helps
diagnose VPN problems that you might
have with detail logs and finally you
have the Azure resource manager now with
this you can ensure that the resources
that you have are managed and deployed
at a consistent rate now this makes it
extremely easy for you to manage and
visualize your resources that are used
in your applications or some other
requirements and you can control who can
access your resources as well as perform
actions on it hi guys I'm rul from
Simply learn and today I'd like to
welcome you all to the greatest debate
of the century today I'm joined by two
giants of the cloud computing industry
they'll be going head-to-head with each
other to decide who amongst them is
better it's going to be one hell of
fight now let's meet our candidates on
my left we have AWS who's voiced by AA
hi guys and on my right we have
Microsoft a your who's voiced by Angeli
hey there so today we'll be deciding
who's better on the basis of of their
origin and the features they provide
their performance in the present day and
comparing them on the basis of pricing
market share and options free tier and
instance configuration now let's listen
to their opening statements let's start
with AWS launched in 2006 AWS is one of
the most commonly used cloud computing
platforms across the world companies
like Adobe Netflix Airbnb HTC Pinterest
and Spotify have put their faith in ews
for their proper function it also
dominates the cloud computing domain
with almost 40% of the entire market
share so far nobody's even gotten close
to beating that number AWS also provides
a wide range of services that covers a
great number of domains domains like
compute networking storage migration and
so much more now let's see what Azure
has to say about that Azure was launched
in 2010 and is trusted by almost 80% of
all Fortune 500 companies companies the
best of the best companies in the world
choose to work only with Azure Azure
also provides its services to more
regions than any other cloud service
provider in the world Azure covers 42
regions already and 12 more are being
planned to be made a also provides more
than 100 Services spanning a variety of
domains now that the opening statements
are done let's have a look at the
current market status of each of our
competitors this is the performance
round here we have the stats for the
market share of AWS Azo and other cloud
service providers this is for the early
2018 period Amazon web services takes up
a whopping 40% of the market share
closely followed by aor at 30% and other
cloud services adding 30% this 40%
indicates most organizations clear
interest in using AWS we are number one
because of our years of experience and
Trust we've created among our users sure
you're the market leader but we are not
very far behind let me remind you more
than 80% of the Fortune 500 companies
trust Azure with their cloud computing
needs so it's only a matter of time
before Azure takes the lead the rest of
the 30% that is in AWS or Azure accounts
to the other cloud service providers
like Google Cloud platform Rackspace IBM
soft layer and so on now for our next
round the comparison round first we'll
be comparing pricing we'll be looking at
the cost of a very basic instance which
is a virtual machine of two virtual CPUs
and 8 GBS of RAM for AWS this will cost
you approximately
0.928 per hour and for the same instance
in aor it'll cost you approximately
0.096 per hour next up let's compare
market share and options as I mentioned
before AWS is the Undisputed market
leader when it comes to the cloud
computing domain taking up 40% of the
market share by 2020 AWS is also
expected to produce twice its current TR
Revenue which comes close to $44 billion
not to mention AWS is constantly
expanding its already strong roer of
more than 100 services to fulfill the
shifting business requirements of
organizations all that is great really
good for you but the research company
Gardner has released a magic quadrant
that you have to see you see the
competition is now neck to neck between
Azure and AWS it's only a matter of time
before Azure can increase from its 30%
Market and surpass AWS this becomes more
likely considering how all companies are
migrating from AWS to Azure to help
satisfy their business needs Azure is
not far behind AWS when this comes to
Services as well azure's service
offerings are constantly updated and
improved on to help users satisfy their
cloud computing requirements now let's
compare AWS and a your's free offerings
AWS provides a significant number of
services for free helping users get
hands-on experience with the platform
products and services the free tier
Services fall under two categories
services that will remain free forever
and the others that are valid only for
one year the always free category offers
more than 20 services for example Amazon
SNS sqs cloudwatch Etc and the valid for
a year category offers approximately 20
services for example Amazon S3 ec2
elastic cache Etc both types of services
have limits on the usage for example
storage number of requests compute time
Etc but users are only charged for using
services that fall under the valid for a
year category after a year of their
usage a sh provides a free tier as well
it also provides services that belong to
the categories of free for a year and
always free there are about 25 plus
always free services provided by aure
these include app service functions
container service active directory and
lots more and as of the valid for a year
there are eight services offered there's
Linux or Windows Virtual machines blob
storage SQL database and few more Azure
also provides the users with credits of
200 US to access all their services for
30 days now this is a unique feature
that Azure provides where it users can
use their credits to utilize any service
of a choice for the entire month now
let's compare instance configur ER ation
the largest instance that AWS offers is
that of a warping 256 GBS of RAM and 16
virtual CPUs the largest that aor offers
isn't very far behind either 224 GBS of
RAM and 16 virtual CPUs and now for the
final round now each of our contestants
will be shown facts and they have to
give explanations for these facts we
call it the rapid fire round first we
have features in which AWS is good and
Azure is better AWS does not not cut
down on the features it offers its users
however it requires slightly more
Management on the users part aure go
slightly deeper with the services that
fall under certain categories like
platform as a service and infrastructure
as a service next we have hybrid Cloud
where AWS is good and Azure is better
okay although AWS did not emphasize on
hybrid Cloud earlier they are focusing
more on technology now Azure has always
emphasized on hybrid cloud and has
features supporting it since the days of
its inception for developers AWS is
better and Azure is good of course it's
better because AWS supports integration
with thirdparty applications well Azure
provides access to data centers that
provide a scalable architecture for
pricing both AWS and Azure are at the
same level it's good for AWS because it
provides a competitive and constantly
decreasing pricing model and in the case
of aure it provides offers that are
constantly experimented upon to provide
its users with the best experience and
that's it our contestants have finished
giving their statements now let's see
who won surprisingly nobody each cloud
computing platform has its own pros and
cons choosing the right one is based
entirely on your organization's
requirements in this video we will
compare and contrast AWS Azure and gcp
based on a few related Concepts around
these cloud computing platform forms it
will help us understand the functioning
of these top Cloud platforms and will
also let us figure out the individuality
of each one of them but before starting
with the comparison let's have a quick
introduction of AWS versus Azure versus
gcp so let's get
started Amazon web services or AWS is a
cloud computing platform that manages
and maintains hardware and
infrastructure reducing the expense and
complexity of purchasing and running
resources onsite for businesses and
individuals these resources are
available for free or for a fee per
usage Microsoft Azure is a cloud
computing service that offers a
collection of Cloud Computing Services
for building testing deploying and
managing applications in the cloud
including remotely hosted and managed
versions of Microsoft Technology ology
Google Cloud platform offers a variety
of Cloud Computing Services for building
deploying scaling monitoring and
operating a cloud the services are
identical to those that power Google
products such as Google search Gmail
YouTube and Google Drive now let's move
on to the comparison between AWS Azure
and
gcp we will be comparing them based on a
few major parameters like origin
service
integration availability
Zone Cloud tools like
compute
storage
networking market
share
pricing and at last who uses
them now let's move ahead and start with
the first comparison
origin in the year 2006 Amazon web
services or AWS was introduced to the
market and in the year 2010 Azure
launched its services where as on the
other hand gcp was established in the
year
2008 from the start AWS has been
supportive of the open source concept
but the open source Community has a
tense relationship with
Azure on the other hand gcp similar to
AWS provides Google cloud with managed
open Source services that are tightly
linked AWS offers services on a large
and complex scale that could be
manipulated but Azure support is
comparatively low quality whereas gcps
monthly support price is almost $150 for
the silver class which is the most basic
of services and is quite
expensive now let's move on to the
service integration of these Cloud
platforms service integration is a set
of tools and technology that connects
different applications systems
repositories and data and process
interchange in real time AWS makes it
simple for users to combine services
such as Amazon ec2 Amazon S3 beanock and
others and on the other hand Azure
allows customers to effortlessly combine
as your VMS as your app service SQL
databases and other Services whereas
users can utilize gcp to combine
services such as compute engine cloud
storage and cloudsql now that we know
briefly about all these Cloud platforms
let's have a look at the availability
zones of these platforms because AWS was
the first in the cloud domain they have
had more time to build and extend their
network but Azure and gcp both have
various locations around the world but
the distinction is in the amount of
availability zones they have AWS now
offers 66 availability zones with an
additional 12 on the pipeline close to
it Azure is available in 140 countries
and is available in 54 regions
throughout the world but Google Cloud
platform is now available in 20 Global
areas with three more on the
way now let's move on to the next
important factor which is tools now
let's move ahead and have a look at the
first feature which is
compute elastic compute cloud or ec2 is
aws's compute service which offers a
wide range of features including a large
number of instances support for both
windows and Linux high performance
Computing and more Azure on the other
hand as virtual machines is Microsoft
azure's core cloud-based compute
solution it includes Linux Windows
server and other operating systems as
well as better security and Microsoft
program
integration in comparison to its
competitors Google's Computing Services
catalog is somewhat smaller compute
engine that company's principal service
offers custom and predefined machine
types per second invoicing Linux and
Windows support and carbon neutral
infrastructure that uses half the energy
of traditional data centers
within the compute category Amazon's
different container services are gaining
prominence it has Docker kubernetes and
it's also fargate service which
automates server and cluster management
when using containers as well as other
Alternatives Azure unlike AWS uses
virtual machine scale sets of two
container services Azure container
services is based on kubernetes I and
container service uses Docker Hub and
Azure container registry for management
for Enterprises interested in deploying
containers Google offers the kubernetes
engine and it's also worth noting that
Google was significantly involved in the
kubernetes project providing an
extensive knowledge in this
field now let's move on to the next
parameter of comparison which is
storage simple storage service for
object storage elastic block storage for
persistent block storage and elastic
file system for file storage are among
aws's storage
offerings block storage for rest-based
object storage of unstructured data Q
storage for a large volume workload file
storage and disk storage are among
Microsoft Azure core storage Services
gcp offers an increasing number of
storage options it's unified object stor
service cloud storage also has a
persistent dis option relational
database service or RDS Dynamo DB no SQL
database elastic and memory data store
redshift data warehouse Neptune graph
database and database migration service
are all SQL compatible databases offered
by
Amazon the database choices in Azure are
specifically wide SQL database my SQL
database and postgre SQL database are
the three SQL based choices now when it
comes to databases gcp offers the
sql-based cloudsql and Cloud spanner a
relational database built for Mission
critical workloads now the next
parameter is
networking AWS uses Amazon virtual
private cloud or
VPC on the other hand Azure uses azzure
virtual Network or
vnet and gcp uses Cloud virtual Network
now let's move on to another factor
which is market share and pricing all
these cloud services are based on
comparative pricing strategies which
means you need to pay on the basis of
its usage according to Canalis the
worldwide Cloud Market Rose 35% to 41.8
billion in the first quarter of
2021 AWS accounts for 32% of the market
with Azure accounting for 19% and Google
accounting for
7% on one hand Amazon charges on a
yearly basis and on the other hand
Microsoft Azure and Google services
charge on a minute basis and also all of
them provide you a standard price for
you to access these Services AWS charges
roughly $69 per month for a very basic
instance with two virtual CPUs and 8 GB
of RAM and AWS largest instance with
3.84 TB of RAM and 128 vcpus will set
you back roughly
$33.97 per hour but in Azure the same
type of instance one with two vcpus and
8 GB of RAM cost roughly $70 us per
month and azure's largest instance has
3.89 TB of RAM and 128 virtual CPUs and
it cost about
$6.79 per
hour compared to AWS gcp will supply you
with the most basic instance which
includes two virtual CPUs and 8 GB of
RAM for 25% less and as a result it will
s you back roughly $52 every month and
the largest instance that includes is
3.75 TB of RAM and 160 CPUs and it will
cost you about
$532 per hour Amazon other than this
also provides spot instances reserved
instances and dedicated host where you
can look for multiple offers and
discounts but for Azure it provides
special prices to developers based on
situations or even Azure hybrid benefit
which benefits your organization up to
40% if it uses Microsoft software in
their data
centers whereas Google offers quite a
sorted pricing to its customer compared
to the other two it gives you sustained
use discounts which activate if you use
the same instance for a
month the perable instance which is very
similar to Amazon spot instances but one
thing is common in all three cloud
services which is that they all offer
long-term
discounts now let's have a look at the
last comparison which is the companies
that are using them because AWS is the
oldest player in the cloud business it
has the largest user base and Community
Support as a result AWS has the largest
number of high-profile and well-known
clients including Netflix Airbnb
Unilever BMW Samsung MinGa and others
with time Azure is getting a large
number of high-profile customers asure
currently boasts around 80% of Fortune
500 firms as customers Johnson Controls
polycom Fujifilm HP Honeywell apple and
others are among its key clients Google
Cloud on the other hand uses the same
infrastructure as Google search and
YouTube and as a result many high-end
Enterprises trust Google Cloud HSBC
PayPal 20th Century Fox Bloomberg
Domino's and other are among Google
Cloud's many clients remember to hit
that subscribe button and tap the
notification Bell so you are always in
the know and before we begin if you're
someone who is interested in building a
career in cloud computing by graduating
from the best universities or a
professional who elicits to switch
careers with cloud computing by learning
from the experts then try giving a short
to Simply lears postgraduate programming
cloud computing with certificates
aligned with AWS partner Network and
silver Microsoft partner the link is
mentioned in the description box below
that will navigate you to the course
page and you can have a complete overw
of the program being offered now let's
Dive Right In so first we'll see the
career with Cloud associate Cloud
engineer leave the server X behind and
Venture into the dynamic world of cloud
computing the perfect moment has arrived
and now let's talk about what this
certification means for you your
associate Cloud engineer certification
is like a bon signaling to prospective
employers your progress in Google Cloud
as an associate Cloud engineer you will
be adapt at deploying and securing
application and infrastructure you will
maintain Enterprise solutions to meet
performance standards and keep a
watchful eye on the operations of
multiple Cloud projects but that's not
all associate Cloud Engineers also prove
their Mastery in using the Google Cloud
console and command line interface you
will effortlessly manage and scale Cloud
Solutions leveraging Google managed or
self-managed services on Google cloud
and many of our peers once dwell in the
own premises realm meticulously setting
up servers now they prepared to level up
their skills for the cloud era the
associate Cloud engineer certification
is your stepping stone to a flourishing
it career so picture yourself as a cloud
developer architect security engineer
systems engineer or network engineer the
possibilities are endless so let's get
started with the benefits of doing gcp
AC so the first benefit you can gain by
acing this certification is you will
have the membership to Google credential
holder portal so I will show you so so
this is the Google Cloud certified
directory here you can find all the
people who have cleared this
certification and you can just click on
the LinkedIn profile and see what skills
they process and you have other filters
also that is you can search by the
credentials locations or skills so this
is the first benefit of doing gcp AC now
moving back second benefit is exposure
to all gcp services while preparation
will boost your confidence and then this
will will set a good foundation for
professional architect exam and Google
certification and badge to be used in
your profile for visibility that will
uphold your profile and will gain you
many opportunities and now we'll see
steps what you can follow to Ace the gcp
AC certification exam so before we dive
in it's essential to grasp the exam
structure the Google associate Cloud
engineer certification exam consists of
50 multiple choice questions and you
have a total to of 2 hours to complete
it a passing score requires at least 70%
correctness this exam evaluates your
knowledge of Google Cloud platform
Services basic networking Concepts and
cloud computing fundamentals and the
recommended experience for this
certification is 6 Plus months and the
prerequisites are none for this
certification exam and the link to
register for this exam I will mention
that link in the description box below
and I will show you the link also so so
this is the link here you have to go and
make your profile if you don't have an
account and after that you can log in so
this is here where you will register for
the exam and moving back now we'll see
the step two that is getting familiar
with gcp so to succeed you need to
become best friends with Google Cloud
platform luckily Google offers a free
tire that allows you to explore gcps
product and services without cost and
don't forget about the comprehensive gcp
documentation it's your treasure Pro of
insights into various services and
functionalities so you can just go to
the documentation and read it and the
third is enroll in a course or training
program so education is the key here
enroll in a course or training program
tailored to the Google associate Cloud
engineer exam the simply learn CCH cloud
computing boot camp course lets you
master key architectural principles and
develop the skills needed to become a
cloud expert and provides in-depth
coverage of exam topics or if you prefer
hands-on experience the associate Cloud
engineer exam prep Quest from Quick
laabs is a great choice and I will
mention the link for the boot camp in
the description box you can go there and
you can enroll in a course or training
program to Ace the preparation and now
the step four take practice test sharpen
your skills with practice test Google
Cloud offers official practice test for
purchase which give you a real feel for
the exam environment Cloud Guru and Wiz
laabs also provide valuable practice
exams and if you're budget conscious
exam Labs offer free practice test and
now moving on to the step five review
exam objectives and resources so stay
focused by reviewing the exam objectives
outlined by Google Cloud these guides
serve as your road map to success dive
deep into Google Cloud's documentation
and white papers for additional study
materials don't forget to engage with
the Google Cloud community on Reddit for
valuable insights and tips and now
talking about the syllabus I will move
to the website directly only so this is
the syllabus for Google Cloud architect
so here you will learn and you should
know the setting up a Cloud solution
environment for setting up organization
resources that is then you should have a
knowledge on planning and configuring a
Cloud solution deploying and
implementing a Cloud solution and
ensuring successful operation of a Cloud
solution so these all are the things
that are covered in the cabus so you
should have a hands on that as I told
you about about the boot camp so all
these cabus topics are covered in that
boot camp or the postgraduate program
that I mentioned in the starting so if
you want to H program you can just
enroll in the course or training program
and now moving back now we'll just have
a look at the tips to a this exam so the
first tiep is book the exam in advance
before starting preparation so you don't
miss out and the second tip is practice
practice and practice that will help you
clear that c certification and the third
tip is start the exam with relaxed mind
and take poses after five questions each
time that really helps and then we have
the fourth tip that is understand
intention of question look for keywords
in questions and answers and the tip
five while choosing options focus on
available option do not worry about
perfect answer and there you have a tech
explorers your gateway to a cloud
powered future awaits the cloud engineer
learning path crowned by the revamp
preparing for the associate Cloud
engineer certification course is a
compass to steer your career toward New
Horizons now let's take a minute to hear
from our Learners who have experienced
massive success in their careers cloud
computing has completely changed our
world it allows us to store and access
our data from anywhere making our life
more convenient plus we can now work
with people from all over the world
without a hitch all thanks to cloud
computing so Cloud projects are a big
part of this change they help us learn
and try out new things with Cloud
technology which is really important
it's like a playground for Learning and
solving real world problems so whether
you making an intelligent Gadget
creating a website or even predicting
the weather cloud computing does play an
important role so here we are with
another video on top 10 cloud computing
projects in 2024 whether you are a
beginner an intermediate level cloud
Enthusiast or an advanced level cloud
expert we have got you covered here so
hey everyone and you are already
watching simply before starting with the
top 10 cloud computing projects for 2024
subscribe to our Channel because we
bring the best videos for you daily also
hit the Bell icon to never miss any
updates from simply also do check out
the cloud architect Masters program by
simply learn this program will help you
build your AWS Microsoft Azure and
Google Cloud platform expertise from the
ground you'll learn to master the
architectural principles and services of
the top Cloud platforms design and
deploy highly scalable fall tolerant
applications and develop skills to
transform yourself into an AWS and Azure
Cloud export this program will give you
an in-depth understanding of cloud
services such as AWS cloud formation
asure resource manager ec2 S3 Route 53
VPC aszure app services gcp and much
more you'll acquire the Knowledge and
Skills for passing Cloud architect
certification such as AWS architect and
Azure architect candidates with one
plusus year of work experience are
preferred to enroll in this program by
simpling so check out the link mentioned
in the description box below for more
details moving on to the top 10 cloud
computing projects we have divided this
video into three parts the first part is
for beginners moving on to the first
project for beginners we have a
cloud-based file storage in this project
you will create a simple cloud-based
file storage system similar to a Dropbox
or a Google Drive users can upload
download and manage files stored in the
cloud the part to create this project
will start by choosing a cloud storage
service select a cloud storage service
provider like awss 3 Google Cloud
Storage or Azure blob storage the next
step is creating an account sign up for
an account with the choosen cloud
provider if you don't already have one
the next step is to set up a bucket or a
container create a storage bucket or
container to store your files the next
step is to develop a web interface
create a web- based interface for users
to interact with your storage system you
can use HTML CSS and JavaScript for this
the next step is to implement file
upload and download add functionality
for users to upload and download files
to or from their storage bucket using
the cloud providers SDK or API the next
step is user authentication Implement
user authentication to secure access to
files you can use services like Firebase
authentication or build one of your own
the next step is testing and deployment
test your file storage system locally
and once satisfied deploy it to the
cloud make it publically accessible if
needed the key learning points of this
project is you will learn the basics of
cloud storage Services file uploading
and downloading and user authentication
moving on to project number two we have
a website hosting service this project
involves setting up an essential website
on a cloud platform like AWS Azure or
Google Cloud you'll deploy a static or
dynamic website and make it accessible
to users worldwide let's move on to the
path to create this project the first
step is to select a cloud hosting
service choose a cloud hosting platform
like Amazon web services Azure or Google
Cloud the next step is to design your
website create the content and design
for your website you can use HTML CSS
and JavaScript for static websites or
web Frameworks for dynamic ones then
register a domain name purchase a domain
name from a domain regist for example
GoDaddy name chep Etc the next step is
to configure DNS configure the DNS
setting to point to your Cloud hosting
servers IP address the next step is to
set up a virtual Server create a virtual
server instance on your chosen Cloud
platform for example AWS ec2 Azure VM
and Google compute engine the next step
is to install web server software
install and configure web server
software like Apache on your virtual
server and the last step is to upload
website files upload your website files
to the server and then you are done with
the project the key learning points of
this project you will learn how to
configure a web server you will deploy
web applications and manage domain names
and finally you will ensure High
availability the next project we have
for beginners is a cloud-based
calculator create a simple web-based
calculator application and deploy it on
a cloud platform like Heroku users can
perform basic calculations using this
calculator let's talk about the path to
create this project you will start by
selecting a cloud platform choose a
cloud platform like Haku AWS or Azure
for deployment then develop the
calculator create a simple web based
calculator you can use HTML CSS and
JavaScript for this then set up a
development environment install
necessary development tools and
libraries on your local machine then
move ahead with Version Control use
version control systems like G to manage
your project then create a cloud account
sign up for an account with your chosen
Cloud platform then comes the deployment
part deploy your calculator application
to the cloud platform of your choice for
Heroku this might involve pushing your
code to a g repository and then comes
the testing part ensure that the
calculator functions correctly on the
Cloud Server let's talk about the key
learning points of this project you'll
gain experience in setting up Cloud
Server environments deploying web app
applications and understanding server
client interactions moving on to
intermediate level projects these
projects are for people with decent
knowledge of cloud computing Basics the
first project we have in this category
is an iot data analytics project build a
system that collects data from iot
devices sensors smart devices Etc and
stores it in Cloud databases for example
AWS Dynamo DB or Azure Cosmos database
Implement analytics to gain insights
from the collected data let's talk about
the path to create this project the
first step is iot device setup set up
iot devices or sensors to collect data
then choose a cloud database select a
cloud database service for example AWS
Dynamo database as your Cosmos database
for data storage then comes the data
inje part write code to send data from
iot devices to the cloud database then
comes data analytics Implement data
analytics tools or scripts to analyze
the collected data then comes data
visualization create visualizations to
present insights from the data using
tools like AWS quick site or data
visualizations libraries and then the
last part is monitoring and scaling
Implement monitoring and scaling
mechanisms to handle increased data
volumes so let's talk about the key
learning points of this project you will
explore iot data inje Cloud database
management data analytics and of course
data visualization moving on to the next
project we have a video streaming
service so you will create a video
streaming service where users can upload
and stream videos from the cloud
Implement features like video encoding
content delivery and user authentication
let's talk about the path to create this
project you will start by selecting
cloud services choose cloud services for
video storage for example AWS S3 find
coding you can choose AWS elastic
transcoder and for Content delivery you
can choose AWS Cloud front the next step
is is to design the application plan the
architecture of your video streaming
platform including user interfaces for
uploading and streaming the next step is
user authentication Implement user
authentication using services like AWS
Cognito then comes the video uploading
part allow users to upload videos to the
cloud storage and then comes the video
encoding Implement video encoding to
create different quality versions of
uploaded videos then comes the content
delivery use a Content delivery Network
or CDN to distribute videos efficiently
to the users and the last step is
testing and scalability Test video
streaming and ensure its scales to
handle concurrent users and varrying
network conditions let's talk about the
key learning points for this project you
will learn about video processing
content delivery networks and secure
user access control moving on to the
next project we have cloud-based
e-commerce website build an e-commerce
platform hosted on cloud develop
features like product listing shopping
carts and secure Payment Processing
let's talk about the path to create this
project you'll start by selecting Cloud
platform choose a cloud platform for
example AWS or AO to host your
e-commerce application then comes the
e-commerce framework choose an
e-commerce framework for example
woocommerce or Shopify or build a custom
solution then comes the product listings
spot at product listings and
descriptions with images then comes the
shopping cart Implement a shopping cart
functionality for users to add products
then comes the secure Payment Processing
set up secure Payment Processing using
payment gateways like stripe or PayPal
then comes the user authentication part
Implement user authentication for
customer accounts and finally the
testing and security thoroughly test
your e-commerce website ensuring it's
secure and capable of handling
transactions what are the key points of
this project you will gain experience in
building scalable web applications
handling online transactions secure
purely and managing customer data
talking about advanced level cloud
computing projects for advanced level
cloud computing projects you should
Master Cloud infrastructure and cloud
services the first advanced level
project we have for today is machine
learning with Cloud develop a machine
learning model and deploy It On A Cloud
Server for scalable processing this
project involves working with large data
sets and realtime data analysis the
first step is machine learning model
develop a machine learning model using
Library like tlow or CET learn then
comes the data preparation part prepare
and clean the data for training and
testing then choose a cloud machine
learning service select a cloud machine
learning service for example AWS Sage
maker Google AI platform and Etc then
comes the model deployment part deploy
your machine learning model on the cloud
platform and finally the scalability
ensure the model can handle real-time
predictions and scale as needed let's
talk about the key learning points of
this project you will delve into machine
learning cloud-based data processing and
model deployment the next project we
have in this list is the cloud-based
virtual desktop create a system that
allows users to access virtualized
desktop environments hosted on the cloud
this project focuses on remote desktop
Solutions talking about the path to
create this project you should start by
selecting cloud service choose a cloud
service for virtual desktop for example
Amazon workspace Windows Virtual desktop
or Azure then comes the configuration
part configure virtual desktop instances
with desired specifications user
management create and manage user
accounts for accessing virtual desktops
security Implement security measures for
data protection during remote desktop
access then comes the access control
part setup Access Control policies to
restrict user permissions and lastly
testing test the remote desktop access
from different devices and locations
talking about the key learning points of
this project you'll learn about
virtualization remote desktop
Technologies and user Management in a
cloud-based context moving on to the
third advanced level cloud project we
have a cloud gaming service build a
cloud-based gaming service similar to
Google stadia this project involves GPU
virtualization low latency streaming and
multiplayer game server management
talking about the path to create this
project you should start by selecting
Cloud infrastructure choose a cloud
infrastructure you can either choose AWS
or Azure for hosting game servers then
comes the games server setup set up Game
servers for hosting games then comes the
low latency streaming implement low
latency streaming Technologies for
gamepl then comes the multiplayer
support add multiplayer support for
users to play together then comes the
user management create user accounts and
manage players profiles and finally
comes load balancing Implement load
balancing to handle increased player
loads talking about the key learning
points of this project you will explore
cloud-based gaming infrastructure server
management and realtime multiplayer
networking moving on to the last cloud
computing project we have a healthcare
data management system develop a
cloud-based system for storing and
managing healthcare related data such as
patient records ensure compliance with
healthcare industry standards for
example
hiaa talking about the path to create
this project you should start by
ensuring compliance with healthcare
industry standards Hippa compliance
understand and are there to HIPAA
compliance regulation
Cloud platform selection choose a HIPAA
compliant Cloud platform for example AWS
Healthcare apis and Azure for healthcare
then comes the data storage part create
a secure cloud-based data storage system
for healthcare records then comes the
access control Implement strict access
controls and encryption for data
security then comes the audit trials
maintain audit trials for data access
and modifications and then at last comes
the user training ensure staff are
trained on hi AA compliance and data
handling protocols talking about the key
learning points of this project you will
gain expertise in Cloud security data
privacy and compliance while addressing
real world Healthcare data challenges
these projects provide a progressive
learning path allowing individuals to
start with basic Cloud Concepts and
gradually advance to more complex and
impactful cloud computing applications
each project offers valuable experience
and skills that can be applied to real
life scenarios and career development in
the cloud Computing field so if you are
interested in becoming a cloud engineer
or architect then check our Cloud
architect Masters program simply learns
Cloud architect certification course
will build your AWS Microsoft and Google
Cloud platform expertise from the
grounder you will learn to master the
architectural principles and services of
the top Cloud platforms design and
deploy highly scalable fall tolerant
applications and develop skills to
transform yourself into an AWS and Azure
Cloud this program also has job assist
program simply learns job assist program
is an Indian specific offering in
partnership with IM IM jobs.com to help
you landar your dream job to participate
in job assist program you need to be
graduate in engineering or equivalent or
complete our master's program
successfully and earn a master
certificate upon completion so what are
you waiting for enroll now hey everyone
welcome to Simply LS YouTube channel
today we will be discussing the cloud
computing interview questions but before
that let me share a few facts with you
according to O'Reilly more than 90% of
the organizations are expected to
increase their Cloud infrastructure in
2021 the upshot is that the majority of
cloud users plan to scale their business
in the cloud rather than reducing their
Cloud usage share suppose you are very
much interested in Cloud industry then
you have come to the right place welcome
welcome to this video on cloud computing
interview questions in this video we
will learn everything about AWS and ASR
in detail our interview questions are
divided into three segments beginner
level intermediate level and advanced
level by the end of this video I can
assure you that all your AWS and Azure
related queries would have been answered
for this training with me I have our
experienced AWS and Azure expert Sam who
will take you through the various topics
of as so let's get started with an
exciting video on cloud computing
interview questions before we begin
please make sure to get subscribed to
our YouTube channel and hit that Bell
icon to never miss an update from Simply
learn hi there I'm Samuel and I'm here
to walk you through some of the AWS
interview questions which we find are
important and our hope is that you would
use this material in your interview
preparation and be able to crack that
cloud interview and and step into your
dream Cloud job by the way I'm an Cloud
technical architect trainer and an
interview panelist for cloud Network and
devops so as you progress in watching
you're going to see that these questions
are practical scenario based questions
that tests the depth of the knowledge of
a person in a particular AWS product or
in a particular AWS architecture so why
wait let's move on all right so in an
interview you would find yourself with a
question that might ask you define and
explain the three basic types of cloud
services and the AWS products that are
built based on them see here it's a very
straightforward question just explain
three basic types of cloud service and
when we talk about basic type of cloud
service it's compute obviously that's a
very basic service storage obviously uh
because you need to store your data
somewhere and it works working that
actually connects a couple of other
services to your application these basic
will not include monitoring these basic
will not include analytics because they
are considered as optional they are
considered as Advanced Services you
could choose a non-cloud service or a
product for monitoring of and for
analytics so they're not considered as
Basics so when we talk about Basics they
are compute storage and networking and
the second part of the question says
explain some of the AWS products that
are built based on them of course
compute ec2 is a major one that's that's
the major share of the compute resource
and then we have platform as a service
which is elastic bean stock and then
function as a service which is Lambda
autoscaling and light sale are also part
of compute services so the compute
domain it really helps us to run any
application and the compute service
helps us in managing the scaling and
deployment of an application again
Lambda is a compute service so the
compute service also helps in running
event initiated stateless applications
the next one was storage a lot of
emphasis is on storage these days
because if there's one thing that grows
in a network on a daily basis that's
storage every new day we have new data
to store process manage so a storage is
again a basic and an important cloud
service and the products that are built
based on the storage services are S3
object storage Glacier for archiving EBS
elastic block storage as uh Drive
attachment for the ec2 instances and EFS
file share for the ec2 instances so the
storage domain helps in the following
aspects it holds all the information
that the application uses so it's the
application data and we can also archive
old data using storage which would be
Glacier and any object files and any
requirement for Block storage can be met
through elastic blog store and S3 which
is again an object storage talking about
uh networks it it's just not important
to answer the question with the name of
the services and the name of the product
it'll also be good if you could go in
depth and explain how they can be used
right so that actually proves you to be
a person knowledgeable enough in that
particular service or product so talking
about networking domain VPC networking
can't imagine networking without VPC in
in the cloud environment especially in
AWS Cloud environment and then we have
Route 53 for domain resolution or uh for
DNS and then we have cloudfront which is
an edge caching service that helps
customers get or customers to read their
application with the low latency so
networking domain helps with some of the
following use cases it controls and
manages the connectivity of the AWS
services within our account and we can
also pick an IP address range if you're
a network engineer or if you are
somebody who works in networks or are
planning to work in network you will
soon realize the importance of choosing
your own IP address for easy remembering
so having an option to have your own IP
address in the cloud own range of IP
address in the cloud it really helps
really really helps in Cloud networking
the other question that get asked would
be the difference between the
availability Zone and the region
actually the question generally gets
asked so to test how well you can
actually differentiate and also
correlate the availability Zone and the
region relationship all right so a
region is a separate geographic area
like the US West one I mean which
represents North California or the AP
South which represents Mumbai so regions
are a separate geographic area on the
contrary availability Zone resides
inside the region you shouldn't stop
there you should go further and explain
about availability zones and
availability zones are isolated from
each other and some of the services will
replicate themselves within the
availability zone so availability Zone
does replication within them but regions
they don't generally do replication
between them the other question you
could be asked is uh what is autoscaling
what do we achieve by Autos scaling so
in short autoscaling it helps us to
automatically provision and launch new
instances Whenever there is an demand it
not only helps us meeting the increasing
demand it also helps in reducing the
resource usage when there is is low
demand so Autos scaling also allows us
to decrease the resources or resource
capacity as per the need of that
particular AR now this helps business in
not worrying about putting more effort
in managing or continuously monitoring
the server to see if they have the
needed resource or not because
autoscaling is going to handle it for us
so business does not need to worry about
it and autoscaling is one big reason why
people would want to go and pick a cloud
service especially an aw service the
ability to increase and Shrink based on
the need of that are that's how powerful
is Autos scaling the other question you
could get asked is what's Doo targeting
in Cloud front now we know that cloud
front is caching and it caches content
globally in the Amazon caching service
globalwide the whole point is to provide
users worldwide access to the data from
a very nearest server possible that's
the whole point in using or going for
cloud front then what do you mean by Geo
targeting geot targeting is showing
customer and specific content based on
language we can customize the content
based on what's popular in that place we
can actually customize the content the
URL is the same but we could actually
change the content a little bit not the
whole content otherwise it would be
dynamic but we can change the content a
little bit a specific a file or a
picture or a particular Link in a
website and show customized content to
users who will be in different parts of
the globe so how does it happen
cloudfront will dedu the country where
the viewers are located and it will
forward the country code to the origin
server and once the origin server gets
the specialized or a specific country
code it will change the content and it
will send to the caching server and get
cashed there forever and the user gets
to view a Content which is personalized
for them for the country they are in the
other question you could get asked is
the steps involved in using cloud
formation or creating a cloud formation
or backing up an environment with an
cloud formation template we all know
that if there is a template we can
simply run it and it Provisions the
environment but there is a lot more
going into it so the first step in
moving towards infrastructure as a code
is to create the cloud formation
template which as of now supports Json
and yaml file format so first create the
cloud formation template and then save
the code in an S3 bucket S3 bucket
serves as the repository for our code
and then from the cloud formation call
the file in the S3 bucket and create a
stack and now cloud formation uses the
file re reach the file understands
services that are being called
understands the order understands how
they are connected with each other cloud
formation is actually an intelligent
service it understands the relation
based on the code it would understand
the relationship between the different
services and it would set an order for
itself and then would provision the
services one after the other let's say a
service has a dependency and the
dependent service the other service
which this service let's say Service A
and B service B is dependent on service
a let's say cloud formation is an
intelligent service it would provision
the resource a first and then would
provision resource B what happens if we
inverse the order if we inverse the
order resource B first gets provision
and because it does not have dependency
chances that the cloud formation's
default behavior is that if something is
not provisioned properly something is
not healthy it would roll back chances
that the environment provisioning will
roll back so to avoid that cloud
formation
first Provisions all the services that
has or that's dependent on that's
depended by another service so it
Provisions those service first and then
Provisions the services that has
dependencies and if you're are being
hired for a devops or you know if the
interviewer wanted to test your skill on
systems side this definitely would be a
question in his list how do you upgrade
or downgrade a system with near zero
downtime now everybody's moving towards
zero downtime or near zero downtime all
of them want their application to be
highly available so the question would
be how do you actually upgrade or
downgrade a system with near zero
downtime now we all know that I can
upgrade an ec2 instance to a better ec2
instance by changing the uh instance
type stopping and starting but stopping
and starting is going to cause a
downtime right so that's you should be
answering or you shouldn't be thinking
in those terms because that's a wrong
answer specifically the interviewer
wants to know how do you upgrade a
system with zero downtime so upgrading
system with zero downtime it includes
launching another system parall with the
bigger uh ec2 instance type with a
bigger capacity and install all that's
needed if you're are going to use an Ami
of the old machine well and good you
don't have to go through installing all
the updates and installing all the
application from the Ami once you have
launched it in a bigger instance locally
test the application to see if it is
working don't put it on production yet
test the application to see if it is
working and if the application works we
can actually swap if your server is
behind and behind uh Route 53 let's say
all that you could do is go to Route 53
update the uh information with the new
IP address new IP address of the new
server and that's going to send traffic
to the new server now so the cutover is
handled or if you're using static IP you
can actually remove the static IP from
the old machine and assign it to the new
machine that's one way of doing it or if
you are using elastic Nick card you can
actually remove the KN card from the old
machine and attach the KN card to the
new machine so that way we would get
near zero downtime if you're hired for
an architect level you should be
worrying about cost as well along with
the technology and this question would
test how well you manage cost so what
are the tools and techniques we can use
in AWS to identify and correct identify
and know that we are paying the correct
amount for the resources that we are
using or how do you get a visibility of
your AWS resources running one way is to
check the billing there's a place where
you can check the top services that were
utilized it could be free and it it
could be paid Service as well top
services that can be utilized it's
actually in the dashboard of the cost
Management console so that table here
shows the top five most used services so
looking at it you can get it all right
so I'm using a lot of storage I'm using
a lot of ec2 why is storage high you can
go ahead and try to justify that and you
will find if you are storing things that
shouldn't be storing and then clean it
up why is computer capacity so high why
is data transfer so high so if you start
thinking in those levels you'll be able
to dig in and clean up unnecessary and
be able to save your bill and there are
cost Explorer services available which
will help you to view your usage pattern
or view your spending for the past 13
months or so and it'll also forecast for
the next 3 months now how much will you
be using if your pattern is like this so
that will actually help and will give
you a visibility on on how much you have
spent how much you will be spending if
the trend continues budgets are another
excellent way to control cost you can
actually set a budget all right this is
how much I am willing to spend for this
application for this steam or for this
month for this particular resource so
you can actually put a budget Mark and
anytime it exceeds anytime it's nearing
you would get an alarm saying that well
we're about to reach the allocated
budget amount stuff like that that way
you can go back and know and you know
that how much the bill is going to be
for that month or you can take steps to
control bill amount for that particular
month so aw's budget is another very
good tool that you could use cost
allocation tags helps in identifying
which team or which resource has spent
more in that particular month instead of
looking at the bill as one list with no
specifications into it and looking at it
as an expenditure list you can actually
break it down and tag the expenditure to
the teams with cost allocation tags the
dev team has spent so much the uh
production team has spent so much the
training team has spent more than the
dev and the production team why is that
you'll be able to you know think in
those levels only if you have cost
allocation taxs now cost allocation taxs
are nothing but the taags that you would
put when you create a resource so for
Production Services you would put as a
production
tag you would create a production tag
and you would associate that resources
to it and at a later point when you
actually pull up your bill that's going
to show a detailed a list of this is the
owner this is the group and this is how
much they have used in the last month
and you can move forward with your
investigation and encourage or stop
users using more services with the cost
allocation tax the other famous question
is are there any other tools or is there
any other way of accessing accessing AWS
resource other than the console console
is GUI right so in other words other
than GUI how would you use the AWS
resource and how familiar are you with
those tools and Technologies the other
tools that are available that we can
leverage and access the AWS resource are
of course puty you can configure puty to
access the AWS resources like log into
an ec2 instance and ec2 instance does
not always have to be logged in through
the console you could use puty to Lo L
into an ec2 instance and like the jump
box like the proxy machine and like the
Gateway machine and from there you can
actually access the rest of the
resources so this is an alternative to
the console and of course we have the aw
CLI in any of the Linux machines or
Windows machines we can install so
that's 2 3 and 4 we can install AWS CLI
for Linux Windows also for Mac so we can
install them and from there from your
local machine we can access run AWS
commands and access provision monitor
the AWS resources the other ones are we
can access the uh AWS resource
programmatically using AWS SDK and
Eclipse so these are bunch of options we
have to use the AWS resource other than
the console if you're interviewed in a
company or buy a company that focuses
more on security and want to use AWS
native services for their security then
you would come across this question what
services can be used to create a
centralized logging solution the basic
Services we could use are cloudwatch
logs store them in S3 and then use
elastic search to visualize them and use
Kinesis to move the data from S3 to
elastic search right so log management
it actually helps organizations to track
the relationship between operational and
security changes and the events that got
triggered based on those logs instead of
logging into an instance or instead of
logging into the environment and
checking the resources physically I can
come to a fair conclusion by just
looking at the logs every time there's a
change the system would scream and it
gets tracked in the cloud watch and then
Cloud watch pushes it to S3 Kinesis
pushes the data from S3 to elastic
search and uh I can do a Time based
filter and I would get an a fair
understanding of what was going on in
the environment for the past one hour or
whatever the time window that I wanted
to look at so it helps in getting a good
understanding of the infrastructure as a
whole all the logs are getting saved in
one place so all the infrastructure logs
are getting saved in one place so it's
easy for me to look at it in an
infrastructure perspective so we know
the services that can be used and here
are some of the services and how they
actually connect to each other it could
be logs that belongs to One account it
could be logs that belongs to multiple
accounts it doesn't matter you know
those three services are going to work
fairly good and they going to inject or
they're going to like suck logs from the
other accounts put it in one place and
help us to monitor so as you see you
have Cloud watch here that actually
tracks the metrics you can also use
cloud trail if you want to log API calls
as well push them in an S3 bucket so
there are different types of log flow
logs are getting captured in an instance
application logs are getting captured
from the same VPC from a different VPC
from the same account from a different
account and all of them are analyzed
using elastic search using the kibana
client so step one is to deploy the ECS
cluster step two is to restrict access
to the ECS cluster because it's valid
data you don't want anybody to put their
hands and access their data so rest
access to the ECS dashboard and we could
use Lambda also to push the uh data from
cloud watch to the elastic search domain
and then kibana is actually the
graphical tool that helps us to
visualize the logs instead of looking at
log as just statements or in a bunch of
characters a bunch of files kibana helps
us to analyze the logs in a graphical or
a chart or a bar diagram format again in
an inter the interviewer is more
concerned about testing your knowledge
on AW security products especially on
the logging monitoring event management
or Incident Management then you could
have a question like this what are the
native aw security logging capabilities
now most of the services have their own
logging in them like have their own
logging like S3 S3 has its own login and
cloudfront has its own login DS has its
own login VPC has its own loging in
additional there are account level
logins like cloud trail and AWS config
services so there are variety of logging
options available in the AWS like cloud
trail config Cloud front red shift
logging RDS logging VPC flow logs S3
object logging S3 access logging stuff
like that so we're going to look at uh
two servers in specific cloud trail now
this cloud trail the very first product
in that picture we just saw the cloud
trail provides an very high level
history of the API calls for all the
account and with that we can actually
perform a very good security analysis a
security analysis of our account and
these logs are actually delivered to you
can configure it they can be delivered
to S3 for long time archival and based
on a particular event it can also send
an email notification to us saying hey
just got this error thought I'll let you
know stuff like that the other one is
config service now config service helps
us to understand the configuration
changes that happened in our environment
and we can also set up notifications
based on the configuration changes so it
records the cumulative changes that are
made in a short period of time so if you
want to go through the lifetime of a
particular resource what are the things
that happened what are the things it
went through they can be looked at using
AWS config
all right the other question you could
get asked is if uh you know your role
includes taking care of cloud security
as well then the other question you
could get asked is the native services
that Amazon provides to mitigate dos
which is denial of service now not all
companies would go with Amazon native
services but there are some companies
which want to stick with Amazon native
Services just to save them from the
headache of managing the other softwares
are bringing in another tool a third
party tool into managing DS they simply
want to stick with Amazon proprietary
Amazon native services and a lot of
companies are using Amazon service to
prevent dos denial of service now denial
of service is if you already know what
denial of service is well and good if
you do not know then let's know it now
denial of service is a user trying to or
maliciously making attempt to access a
website or an appc application the user
would actually create multiple sessions
and he would occupy all the sessions and
he would not let legimate users access
the service so he's in turn denying the
service for the user a quick uh picture
review of what denial of services now
look at it these users instead of making
one connection they are making multiple
connections and there are cheap software
programs available that would actually
trigger connections from different
computers in the internet with different
Mac addresses so everything kind of
looks legimate for the server and it
would accept those connections and it
would keep the sessions open the actual
users won't be able to use them so
that's denying the service for the
actual users denial of service all right
and distributed denial of service is uh
generating a tax from multiple places
you know from a distributed environment
so that's distributed denial of service
so the tools the native tools that help
us to prevent the denial of service
attacks in AWS is cloud shield and web
access firewall AWS WF now they are the
major ones they are designed to mitigate
a denial of service if your website is
often bothered by denial of service then
we should be using AWS Shield or AWS W
and there are a couple of other tools
that also does when I say that also does
denial of service is not their primary
job but you could use them for denial of
service route 53's purpose is to provide
DNS cloudfront is to provide caching
elastic load balancer lb's work is to
provide load balancing VPC is to create
an secure virtual private environment
but they also support mitigating denial
of service but not to the extent you
would get in AWS shield and AWS wav so
AWS shield and WF are the primary ones
but the rest can also be used to
mitigate distrib Ed denial of service
the other tricky question is this
actually will test your familiarity with
the region and the services available in
the region so when you're trying to
provision a service in a particular
region you're not seeing the service in
that region how do we go about fixing it
or how do we go about using the service
in the cloud it's a tricky question and
if you have not gone through such
situation you can totally blow it away
you really need to have a good
understanding on regions the services of
available in those regions and what if a
particular service is not available how
to go about doing it the answer is not
all services are available in all
regions anytime Amazon announces a new
service they don't immediately publish
them on all regions they start small and
as in when the traffic increases as in
when it becomes more likable to the
customers they actually move the service
to different regions so as you see in
this picture within America not Virginia
has more services compared to Ohio or
Compared to North California So within
North America itself North Virginia is
the preferred one so similarly there are
preferred regions within Europe Middle
East and Africa and preferred regions
within Asia Pacific so anytime you don't
see a service in a particular region
chances that the service is not
available in that region yet we got to
check the documentation and find the
nearest region that offers that service
and start using the service from that
Reg region now you might think well if
I'm looking for a service in Asia let's
say in Mumbai and if it is not available
why not simply switch to North Virginia
and start using it you could but you
know that's going to add more latency to
your application so that's why we need
to check for application which is check
for region which is very near to the
place where you want to serve your
customers and find nearest region
instead of always going back to North
Virginia and deploying an application in
North Virginia again there's a place
there's a link in aws.com that you can
go and look for services available in
different region and that's exactly what
you're seeing here and if your service
is not available in a particular region
switch to the other region that provides
your service the nearest other region
that provides that service and start
using service from there with the uh
coming up of cloud a lot of companies
have turned down their monitoring team
instead they want want to go with the
monitorings that cloud provides you know
nobody wants to or at least many people
don't want to go through the hassle of
at least new startups and new companies
that are thinking of having a monitoring
environment now they don't want to go
with traditional knock monitoring
instead they would like to leverage AWS
monitorings available because it
monitors a lot of stuff not just the
availability but it monitors a lot of
stuff like failures errors it also
triggers emails stuff like that so how
do you actually set up a monitor to
website I mean how do you set up a
Monitor to Monitor the uh website
metrics in real time in AWS the simple
way anytime you have a question about U
monitoring cloudwatch should strike your
mind because cloudwatch is meant for
monitoring is meant for collecting
metrics is meant for providing graphical
representation of uh what's going on in
a particular Network at a particular
point of time so Cloud watch cloudwatch
helps us to monitor applications and
using cloudwatch we can monitor the
state changes not only the state changes
the autoscaling life cycle events
anytime there there are more services
added there is a reduction in the number
of servers because of less usage and
very informative messages can be
received through cloudwatch any
cloudwatch can now support scheduled
events if you want to schedule anything
cloudwatch has an event that would
schedule an action all right schedu a
Trigger Time based not incident based
you know anything happening and then you
get an action happening that's incident
based on the other hand you can simply
schedule few things on time based so
that's possible with Cloud watch So This
Cloud watch integrates very well with a
lot of other services like notifications
for notifying uh the user or for
notifying the administrator about it and
it can integrate well with Lambda so the
trigger an action anytime you're
designing an auto healing environment
This Cloud watch can actually monitor
and send an email if we are integrating
it with SNS simple notification service
or this Cloud watch can monitor and uh
based on what's Happening it can trigger
an event in Lambda and that would in
turn run a function till the uh
environment comes back to normal so
cloudwatch integrates well with a lot of
other aw Services all right so
cloudwatch has uh three statuses green
when everything is going good lello when
the service is degraded and red when the
service is not available green is good
so we don't have to do anything about it
but anytime there's an loo the picture
that we're looking at it's actually
calling an Lambda function to debug the
application and to fix it and anytime
there's a red alert it immediately
notifies the um owner of the application
about well the service is down and here
is the report that I have here is the
metrics that I've collected Ed about the
service stuff like that if the job role
requires you to manage the service as
well there are certain job roles which
are on the system side there are certain
job roles which is development plus
system side now you're responsible for
the application and the server as well
so if that's the case you might be
tested with some basic questions like
the different types of virtualization
and ads and what are the difference
between them all right the three major
types of virtualization are h VM which
is Hardware virtual machine the other
one is PV par virtualization and the
third one is PV on hbm par
virtualization on Hardware virtual
module all right the difference between
them or actually describing them is
actually the difference between them hvm
it's actually a fully virtualized
Hardware you know the whole Hardware is
virtualized and all virtual machines act
uh separate from each other and these
VMS are booted by executing m
boot record in the root block and when
we talk about par virtualization parag
grub is actually the special boot loader
which boots the uh PV Amis and when we
talk about PV on hvm it's it's actually
the the marriage between hvm and PV and
this par virtualization on hvm in other
words PV on hvm it actually helps
operating system take advantage in
storage and the network input output
available through the host another good
question is name some of the services
that are not a region specific now
you've been thought that all services
are within a region and some services
are within an availability zone for
example ec2 is within an availability
Zone EBS is within an availability Zone
S3 is region specific Damo DB is region
specific stuff like that VPC is both
availability and uh region specific
meaning you know subnets are
availability Zone specific and vpc's
region specific stuff like that so you
might have thought you might have
learned in that combination but there
could be some tricky questions that
tests you how well you have understood
the region non region and availability
non-availability Services I should say
there are services that are not region
specific that would be IM am so we can't
have IM am for every availability Zone
and for every region which means you
know users will have to use one username
and password for one region and anytime
they switch to another region they will
have to use another username and
password that that's more work and
that's not a good design as well
authentication has to be Global so IM is
a global Service and which means it's
not region specific on the other hand
Route 53 is again a regional specific so
we can't have Route 53 for every region
Route 53 is not a region specific
service it's a global Service and it's
one application users access from
everywhere or from every part of the
world so we can't have one URL or one
DNS name for each region if your
application is a global application and
then web application firewall works well
with cloudfront and cloudfront is a
region based service so the web
application firewall it's not region
specific service it's a global Service
and Cloud front is again a global
Service though you can uh you know cash
content on a continent and country basis
it's still considered a global Service
all right it's not bound to any region
so when you activate Cloud front you're
activating it away from region or
availability zone so when you're
activating a web application firewall
because it's not a region specific
service you're activating it away from
availability Zone and regions so a quick
recap IM users groups roles and accounts
they are Global Services they can be
used globally
Route 53 services are offered at Edge
locations and they are Global as well
web application firewall a service that
protects our web application from common
web exploits they are global Service as
well Cloud front cloudfront is global
content delivery Network CDN and they
are offered at Edge locations which are
a global Service in other words non
region specific service or Beyond region
service all right this is another good
question as well in the project that you
are being interviewed if they really
want to secure their environment using
natat or if they are already securing
their environment using natat by any of
these two methods like natat Gateway or
Nat instances you can expect this
question what are the difference between
a Nat Gateway and Nat instances now they
both serve the same thing all right so
they're not two different Services
trying to achieve two different things
they both both serve the same thing but
still they do have differences in them
all right on a high level they both
achieve providing nting for the service
behind it but the difference comes when
we talk about the availability of it Nat
Gateway is a managed service by Amazon
whereas Nat instance is managed by us
now I'm talking about the third Point
maintenance here Nat Gateway is managed
by Amazon Nat instance is managed by us
and availability of nat gate Gateway is
very high and availability of natat
instance is less compared to the natat
Gateway because it's managed by us you
know it's on an E2 instance which could
actually fail and if it fails we'll have
to relaunch it but if it is not Gateway
if something happens to that service
Amazon would take care of reprovision it
and talking about bandwidth it can burst
up to 75 gbits now traffic through the N
Gateway can burst up to 7 5 gbits but
for that instance it actually depends on
the server that we launch and if we are
launching a T2 micro it barely gets any
bandwidth so there's a difference there
and the performance because it's highly
available because of the bigger pipe 75
gbits the performance of the N Gateway
is very high but the performance of the
N instance is going to be average again
it depends on the size of the natat
instance that we pick and billing a
billing for Nat Gateway is the number of
gateways that we provision and the
duration for which we use the natat
Gateway but billing for Nat instances
number of instance and the type of
instance that we use of course number of
instance duration and the type of
instance that we use Security in that
Gateway cannot be uh assigned meaning it
already comes with full packed security
but in that instance security is a bit
customizable I can go and change the
security because it's a server managed
by me or managed by us I can always
change the security well allow this
allow don't allow this stuff like that
size and load of the not Gateway is
uniform but the size and the load of the
N instance changes as per a that Gateway
is a fixed product but not instance can
be small instance can be a big instance
so the size and the load through it
varies right the other question you
could get asked is what are the
difference between stopping and
terminating an ec2 instance now you will
be able to answer only if you have
worked on environments where you have
your instance stopped and where you have
your instance terminated if you have
only used lab and are attending the
interview chances are that you might
your alwayss lost when answering this
question it might look like both are the
same well stopping and terminating both
are the same but there is a difference
in it so when you stop an instance it
actually performs a normal shutdown on
the instance and it simply moves the
instance to the sto state but when you
actually terminate the instance the
instance is moved to this stop State the
EBS volumes that are attached to it are
deleted and removed and we'll never be
able to recover them again so that's a
big difference between stopping and
terminating an instance if you're
thinking of using the instance again
along with the data in it you should
only be thinking of stopping the
instance but you should be terminating
the instance only if you want to get rid
of that instance forever if you are
being interviewed for an architect level
position or a junior architect level
position or even an Cloud consultant
level position or even in an engineering
position this is a very common question
that get asked what are the different
types of easy2 instances based on their
cost or based on how we pay them right
they're all computer capacity for
example the different types are on
demand instances spot instances and
reserved instances it it kind of looks
the same they all provide the compute
capacity they all provide the same type
of Hardwares for us but if you're
looking at Cost saving or optimizing
cost in our environment we got to be
very careful about which one are we
picking and we might think that well
I'll go with on demand instance because
I pay on a per hour basis which is cheap
you know I can use them anytime I want
and anytime I don't want I can simply
get rid of it by terminating it you're
right but if the requirement is to use
use the service for one year the
requirement is to use the service for 3
years then you'll be wasting a lot of
money buying on demand instances you'll
be wasting a lot of money paying on an
hourly basis instead we should be going
for reserved instance where we can
reserve the capacity for the complete
one year or complete 3 years and save
huge amount in buying reserved instances
all right so underman is cheap to start
with if you're only planning to use it
for a short while but if you're planning
to run it it for a long while then we
should be going for reserved instance
that is what is cost efficient so spot
instance is cheaper than on demand
instance and there are different use
cases for spot instance as well so let's
look at one after the other the on
demand instance the on demand instance
is purchased at a fixed rate per hour
this is very shortterm and irregular
workloads and for testing for
development on demand instance is a very
good use case we should be using on
demand for production spot instance spot
instance allows users to purchase ec2 at
a reduced price and anytime we have more
instances we can always go and sell it
in spot instances I'm referring to
anytime we have more reserved instances
we can always sell them in spot instance
uh catalog and the way we buy Spot
instance is we actually put a budget
this is how much I'm willing to pay all
right would you be able to give service
within this cost so anytime the price
comes down and meets the cost that we
have put in will be assigned an instance
and anytime the price shoots up the
instance will be taken away from us but
in case of on demand instances we have
bought that instance for that particular
R and it stays with us but with spot
instances it varies based on the price
if you meet the price you get the
instance if you don't meet the price
goes away to somebody else and the spot
instance availability is actually based
on supply and demand in the market
there's no guarantee that you will get
spot stance at all time all right so
that's a caveat there you should be
familiar with that's a caveat there you
should be aware when you are proposing
somebody that we can go for spot
instance and save money it's not always
going to be available if you want your
spot instance to be available to you
then we need to carefully watch the
history of the price of the spot
instance now how much was it last month
and how much was it how much is it this
month so how can I code or how much can
I code stuff like that so you got to
look at those history before you propose
somebody that well we're going to save
money using spot instance on the other
hand reserved instance provide cost
savings for the company or we can opt
for reserved instances for you know one
year or 3 years there are actually three
types of reserved instances light medium
and heavy reserved instances they are
based on the amount that we would be
paying and cost benefit also depends
with reserved instance the cost benefit
also depends based on are we doing all
upfront or no upfront or partial payment
then split the rest as monthly payments
so there are many purchase options
available but overall if you're looking
at using an application for the next 1
year and 3 years you should not be going
for on demand instance you should be
going for reserved instance and that's
what gives you the cost benefit and in
an AWS interview sometimes you might be
asked you know how you interact with the
AWS environment are you using using CLI
are using console and depending on your
answer whether console or CLI the
panelist put a score okay this person is
CLI specific this person is console
specific or this person has used aw's
environment through the SDK stuff like
that so this question tests whether you
are a CLI person or an console person
and the question goes like this how do
you set up SSH agent forwarding so that
you do not have to copy the key every
time you log in if you have use Puri
anytime if you want to log into an ec2
instance you will have to put the IP and
the port number along with that you will
have to map or we will have to map the
key in the Puri and this has to be done
every time that's what we would have
done in our lab environments right but
in production environment using the same
key or mapping the same key again and
again every time it's actually an hazle
it's considered as a blocker so you
might want to cach it you might want to
permanently add it in your puty session
so you can can immediately log in and
start using it so here in the place
where you would actually map the private
key there's a quick button that actually
fixes or that actually binds your SSH to
your puty instance so we can enable SSH
agent forwarding uh that will actually
bind our key to the SSH and next time
when we try to log in we don't have to
always go through mapping the key and
trying to log in all right this question
what are Solaris and ax operating system
are they available with AWS that
question generally gets asked to test
how familiar are you with the uh Amis
available how familiar are you with ec2
how familiar are you with the ec2
Hardwares available that basically test
that now the first question or the first
thought that comes to your mind is well
everything is available with AWS I've
seen Windows I've seen Ubuntu I've seen
Red Hat I've seen Amazon uh Amis and if
I don't see my operating system there I
can always go to Marketplace and try
them if I don't find in Marketplace I
can always go to community and try them
so the lot of Amis available there lot
of operating systems available I will be
able to find Solaris and ax but that's
not the case Solaris and ax are not
available with AWS that's because
Solaris uses a different I me Solaris
does not support the architecture does
not support public Cloud currently the
same goes for ax as well and they run on
power CPU and not on Intel and as of now
Amazon does not provide Power machines
this should not be confused with the HPC
which is high performance Computing
should not be confused with that now
these are different Hardwares different
CPU itself that the cloud providers they
do not provide yet another question you
could get asked in organizations that
would want to automate their
infrastructure using Amazon native
Services would be how do you actually
recover and E ec2 instance or Auto
recover an ec2 instance when it fails
well we know that ec2 instances are
considered as immutable meaning
irreparable we don't spend time fixing
bugs in an OS stuff like that you know
once an ec2 instance crashes like it
goes on a o Panic or there are various
reasons why it would fail so we don't
have to really worry about fixing it we
can always relaunch that instance and
that would fix it but what if it happens
at 2:00 in the night what if it happens
at during a weekend when nobody's in
office looking or monitoring those
insten so you would want to automate
that not only on a weekend or during
midnights but it's general practice good
to automate it so you could face this
question how do you actually automate an
ec2 instance once it fails and the
answer to that question is using Cloud
watch we can recover the instance so as
you see there is an alarm thres hold a
set in Cloud watch and once the
threshold is met meaning if there is an
error if there is a failure if the uh E2
instance is not responding for a certain
while we can set an alarm and once the
alarm is met let's say the CPU
utilization stayed high for 5 minutes
all right it's not taking any new
connections or the instance is not
pinging for 5 minutes or in this case
it's 2 minutes it's not pinging so it's
not going to respond connection so in
those cases you would want to
automatically recover that ec2 instance
by rebooting the instance all right now
look at this they take this action
section under the action so there we
have a bunch of options like recover
this instance meaning reboot the
instance so that's how we would recover
the other two options are beyond the
scope of the question but still you can
go ahead and apply just like I'm going
to do it so the other option is stop the
instance that's very useful when you
want to stop instances that are having
low U utilizations nobody's using the
system as of now you don't want them to
be running and wasting the uh Cloud
expenditure so you can actually set an
alarm that stops the ec2 instance that's
having low utilization so somebody was
working in an instance and they left it
without or they forgot to shut down that
instance and it gets I mean they will
only use it again the next day morning
so in between there could be like 12
hours that the system is running idle
nobody's using it and you're paying for
it so you can identify such instances
and actually stop them when the CPU
utilization is low meaning nobody is
using it the other one is to terminate
let's say you want to give system to
somebody temporarily and you don't want
them to hand the system back to you all
right this is actually an idea in other
words this is actually the scenario so
you hand over a system to somebody and
when they're done they're done we can
actually terminate the system so you
could instruct the other person to
terminate the system when they're done
and they could forget and the instance
could be running forever or you can
monitor the system after the specified
time is over and you can terminate the
system or best part you can automate the
system termination so you assign a
system to somebody and then turn on this
Cloud watch action to terminate the
instance when the CPU is low for like 2
hours meaning they've already left or
CPU is low for 30 minutes meaning
they've already left stuff like that so
that's possible and if you're getting
high for an system side architect or
even on the sisoft side you could face
this question what are the common and
different types of Ami designs there are
a lot of Ami designs the question is the
common ones and the difference between
them so the common ones are the full
back Amis and the other one is just
enough OS Ami j e OS Ami and the other
one is hybrid type Amis so let's look at
the difference between them the fullback
Ami just like the name says it's fully
baked it's uh ready to use Ami and this
is the simplest Ami to deploy can be a
bit expensive it can be a bit cumbersome
because you'll have to do a lot of work
beforehand you could use the Ami so a
lot of planning a lot of thought process
will go into it and the Ami is ready to
use right you hand over the Ami to
somebody and it's ready to use or if you
want to reuse the Ami it's already ready
for you to use so that's full baked Ami
the other one is just enough operating
system Ami just like the name says uh it
has uh I mean as you can also see in the
diagram or in the picture it covers a
part of the OS all bootstraps are
already packed properly and the security
monitoring logging and the other stuff
are configured at the time of deployment
or at the time you would be using it so
not much thought process will go in here
the only focus is on choosing the
operating system syst and what goes the
operating system specific agents or
bootstraps that goes into the operating
system that's all we worry about the
advantage of this is it's flexible
meaning you can choose to install
additional softwares at the time of
deploying but that's going to require an
additional expertise on the person who
will be using the Ami so that's another
overhead there but the advantage is that
it's kind of flexible I can change the
configurations during the time of
deployment the other one is hybrid Ami
now the hybrid Ami actually falls in
between the fully baked Ami and just
enough operating system options so these
Amis have some features of the big type
and some features of the just enough OS
type so as you see the security
monitoring logging are packed in that
Ami and the runtime environments are
installed during the time of deployment
so this is where the strict company
policies would go into the a company
policies like you got to log this you
got to monitor this these are the ports
that generally gets open in all our
systems stuff like that so they strictly
go into the Ami and sits in an Ami
format and during deployment you have
the flexibility of choosing the
different runtime and the application
that sits in an E2 instance another very
famous question you would face in an
interview is how can you recover login
to an ec2 instance to which you lost the
key well we know that if the key is lost
we can't recover it there are some
organizations that integrate their E2
instances with an ad that's different
all right so you can go and reset the
password in the ad and you will be able
to log in with the new password but here
the specific tricky question is you are
using a key to log in and how do you
recover if you have lost the key
generally companies would have made a
backup of the key so we can pick from
the backup but here the specific
question is we have lost the key
literally no backups on the key at all
so how how can we log in and we know
that we can't log in to the instance
without the key present with us so the
steps to recover is that make the
instance use another key and use that
key to log in once the key is lost it's
lost forever we won't be able to recover
it you can't raise a ticket with Amazon
not possible they're not going to help
it's beyond the scope so make the
instance use another key it's only the
key that's the problem you still have
valid data in it you got to recover the
data it's just the key that's having the
problem
so we can actually focus on the key part
alone and change the key and that will
allow us to log in so how do we do it
step by-step procedure so first verify
the ec2 config service is running in
that instance uh if you want you can
actually beforehand install the ec2
config in that service or you can
actually make the ec2 config run through
the console just couple of button clicks
and that will make the ec2 config run in
that ec2 instance and then detach the
root what volume for that instance of
course it's going to require a stop and
start so detach the root volume from the
instance attach the root volume to
another instance as a temporary volume
or it could be a temporary instance that
youve launched only to fix this issue
and then log in to that instance and to
that particular volume and modify the
configuration file configuration file
modify it to use the new key and then
move the root volume back to its
original position and restart the
instant and now the instance is going to
have the new key and you also have the
new key with which you can log in so
that's how we go ahead and fix it now
let's move on to some product specific
or S3 product specific questions a
general perception is S3 and EBS can be
used interchangeably and the interviewer
would want to test your knowledge on S3
and EBS well EBS uses S3 that's true but
they can't be interchangeably used so
you might face this question what are
some key key differences between AWS S3
and EBS well the differences are S3 is
an object store meaning you can't
install anything in it you can store
drive files but you can't actually
install in it it's not a file system but
EBS is a file system you can install
Services I mean install applications in
it and that's going to run stuff like
that and talking about performance S3 is
much faster and EBS is uh super faster
when accessing from the instance because
from the instance if you need to access
S3 you'll actually have to go out
through the internet and access the S3
or S3 is an external service very
external service you'll have to go
through or you'll have to go outside of
your VPC to access S3 S3 does not come
under a VPC but EBS comes under a VPC
it's on the same VPC so you would be
able to use it kind of locally compared
to S3 EBS is very local so that way it's
going to be faster and redundancy
talking about redundancy of S3 and EBS
S3 is replicated the data in S3 is
replicated across the data centers but
EBS is replicated within the data center
meaning S3 is replicated across
availability zones EBS is within an
availability zone so that way redundancy
is a bit less in EBS in other words
redundancy is higher in S3 than EPs and
talking about security of S3 a S3 can be
made private as well as public anybody
can access S3 from anywhere in the
internet that's possible with S3 but EBS
can only only be accessed when attached
to an ec2 instance right just one
instance can access it whereas S3 is
publicly directly accessible the other
question related to S3 security is how
do you allow access to a user to a
certain a user to a certain bucket which
means this user is not having access to
S3 at all but this user needs to be
given access to a certain bucket how do
we do it the same casee applies to
servers as well in few cases there could
be an instance where a person is new to
the team and you actually don't want
them to access the production service
now he is in the production group and by
default he or she's granted access to
that server but you specifically want to
deny access to that production server
till the time he or she is matured
enough to access or understand the
process understand the dos and don'ts
before they can put their hands on the
production server so how do we go about
doing it so first we would categorize
our instances well these are critical
instances these are normal instances and
we would actually put a tag on them
that's how we categorize right so you
put a tag on them put a tag saying well
they are highly critical they are medium
critical and they are not critical at
all still they in production stuff like
that and then you would pick the users
who wants to or who should be or should
not be given access to a certain server
and you would actually allow the user to
access or not access servers based on a
specific tag in other words you can use
actually tags in in the previous step we
put tags on the critical server right so
you would Define that this user is not
going to use this tag all right this
user is not allowed to use the resources
with this tag so that's how you would
make your step forward so you would
allow or deny based on the tags that you
have put so in this case he or she will
not be allowed to servers which are TAG
critical servers so that's how you allow
deny access to them and the same goes
for bucket as well if an organization is
excessively using S3 for their data
storage because of the benefit that it
provides the cost and the durability you
might get asked this question which is
organizations would replicate the data
from one region to another region for
additional data durability and for
having data redundancy not only for that
they would also do the that for Dr
purposes for Disaster Recovery if the
whole region is down you still have the
data available somewhere else and you
can pick and use it some organizations
would store data in different regions
for compliance reasons to provide low
latency access to their users who are
local to that region stuff like that so
when companies do replication how do you
make sure that there is consistency in
the replication how do you make sure
that a replication is not failing and
the data gets transferred for sure and
there are logs for that replication this
is something that the companies would
use where they're excessively using S3
and they're fully relying on the
replication in running their business
and the way we could do it is we can set
up a replication monitor it's actually a
set of tools that we could use together
to make sure that the cloud replication
region level replication is happening
properly so this is how it happens now
on this side on the left hand hand side
we have the region one and on the right
hand side we have region two and region
one is the source bucket and region two
is the destination bucket right so
object is put in the source bucket and
it has to go directly to the region two
bucket or or made a copy in the region 2
bucket and the problem is sometimes it
fails and there is no consistency
between them so the way you would do it
is connect these Services together and
create an cross replication or cross
region replication monitor that actually
monitors that actually monitors your
environment so there are Cloud watch
that make sure that the data is uh moved
no data is failing again there's Cloud
watch on the other end make sure that
the data is moving and then we have the
logs generated through cloud trail and
that's actually written in Dynamo DB and
if there is an error if something is
failing you get notified through an SMS
or you get notified through an email
using the SNS service so that's how we
could l leverage these tools and set up
an cross region replication monitor that
actually monitors your data replication
some common issues that company
companies face in VPC is that we all
know that I can use Route 53 to resolve
an IP address externally from the
internet but by default the servers
won't connect to the other servers using
our custom DNS name that it does not do
that by default so it's actually a
problem there are some additional things
that as an administrator or as an
architect or as a person who uses it you
will have to do and that's what we're
going to discuss so the question could
be VPC is not resolving the server
through the DNS you can access it
through the IP but not through the DNS
name and what could be the issue and how
do you go about fixing it and you will
be able to answer this question only if
you have done it already it's a quick
and simple step by default VPC does not
allow that's the default feature and we
will have to enable the um DNS host name
resolution before now this is for the
custom DNS not for the default DNS that
comes along this is for the custom DNS
so we will have to enable the uh DNS
host name resolution so our we'll have
to enable the DNS hostname resolution so
they actually resolve let's say I want
to connect to a server 1. simply
learn.com by default it's not allowed
but if I enable this option then I will
be able to connect to server one simply
learn.com if a company has wpcs in
different regions and they have head
office in a central place and the rest
of them are Branch officers and they are
connecting to the head office for Access
or you know for saving data or for
accessing certain files or certain data
or storing data all right so they would
actually mimic the huban spoke tropology
where you have the VPC which is
centrally in an accessible region a
accessable region and then you would
have a local vpcs or Branch offices in
different other regions and they get
connected to the VPC in the central
location and the question is how do you
actually connect the multiple sites to a
VPC and make communication happen
between them by default it does not do
that we know that vpcs they need to be
paired between them in order to access
the resources let's look at this picture
right so I have like uh customer Network
or Branch officers in different parts
and they get connected to a VPC that's
fine so what we have achieved is those
different offices the remote offices
they are connecting to the VPC and
they're talking but they can't connect
or they can't talk to each other that's
what we have built but the requirement
is the traffic needs to or they should
be able to talk to each other but they
should not have direct connection
between them which means that they will
have to come and hit the VPC and then
reach the other customer Network which
is in Los Angeles or which is in New
York right that's the requirement so
that's possible with some architecting
in the cloud so that's using wepn Cloud
Hub you look at this dotted lines which
actually allows customers or which
actually allows the uh corporate uh
networks to talk to each other through
the VPC Again by default it doesn't
happen cloudhub is an architecture that
we should be using to make this happen
and what's the advantage of it as a
central office or as the headquarters
office which is in the VPC or
headquarters data center which is in the
VPC you have control or the VPC has
control on who talks to who and what
traffic can talk to I mean what traffic
can be routed to the other head office
stuff like that that centralized control
is on the VPC the other question you
could get asked is name and explain some
security products and features available
in VPC well VPC itself is an Security
Service it provides security service to
the application but how do you actually
secure the VPC itself that's the
question and yes there are products that
can actually secure the VPC or the VPC
delivers those products to secure the
application access to the VPC is
restricted through a network access
control list all right so that's an
security product in VPC and a VPC has
Security Group groups that protects the
instances from unwanted inbound and
outbound traffic and network access
control list protects the subnets from
unwanted inbound and outbound axis and
there are flow logs we can capture in
VPC that captures incoming and outgoing
traffic through a VPC which will be used
for later analysis as in what's the
traffic pattern what's the behavior of
the traffic pattern stuff like that so
there are some security products and
features of available in VPC now how do
you monitor VPC VPC is a very important
uh concept very important Service as
well everything sits in a VPC most of
the service sits in a VPC except for
Lambda and S3 and Dynamo DB and a couple
of other services most of them sit in a
VPC for security reason so how do you
monitor your VPC how do you gain some
visibility on your VPC well we can gain
visibility on our VPC using VPC flow log
that's the Bas basic Service as you see
it actually captures what's allowed
what's not allowed stuff like that which
IP is allowed which IP is not allowed
stuff like that so we can gather it and
we can use that for analysis and the
other one is cloud watch and Cloud watch
logs the data transfers that happen so
this is you know who gets allowed and
who does not get allowed I mean the flow
logs is who is allowed and who's not
allowed that kind of detail and Cloud
watch gives information about the data
transfer how much data is getting
transferred we can actually pick unusual
data transfers if there is a sudden hike
in the graph there's a sudden hike and
something happens at 12 on a regular
basis and you weren't expecting it there
something suspicious it could be valid
backups it could be a malicious activity
as well so that's how you know by
looking at Cloud watch logs and Cloud
watch dashboard as we wrap up our cloud
computing course it's time to reflect on
what you have learned you now have a
solid understand understanding of cloud
technology and how it can transform
businesses and careers remember the
cloud is always evolving so staying
informed about the latest trends and
advancements will be important we
encourage you to continue exploring and
applying your knowledge thank you for
being a part of this course and we wish
you success as your Venture into the
world of cloud computing the sky is not
the limit the cloud is your gateway to
Endless Possibilities staying ahead in
your career requires continuous learning
and upskilling whether you're a student
aiming to learn today's top skills or a
working professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in cuttingedge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know
more hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos to nerd up and get certified
click
here