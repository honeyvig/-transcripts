1
00:00:01,020 --> 00:00:04,220
[Music]

2
00:00:04,220 --> 00:00:06,899
so hello there over there and welcome to

3
00:00:06,899 --> 00:00:09,720
another tutorial my name is Tammy bakshi

4
00:00:09,720 --> 00:00:11,040
and this time we're going to be going

5
00:00:11,040 --> 00:00:14,160
over how you can use Cuda kudazi for

6
00:00:14,160 --> 00:00:17,160
general purpose GPU Computing now this

7
00:00:17,160 --> 00:00:19,020
is actually a very interesting new

8
00:00:19,020 --> 00:00:20,760
series that I'm about to be working on

9
00:00:20,760 --> 00:00:22,859
uh this is actually the first part of

10
00:00:22,859 --> 00:00:24,900
this of the uh of this of this new

11
00:00:24,900 --> 00:00:27,500
series uh very first video in the series

12
00:00:27,500 --> 00:00:29,939
uh in today's video I'll be talking a

13
00:00:29,939 --> 00:00:32,820
bit about generally uh how gpus work how

14
00:00:32,820 --> 00:00:35,280
they compare to CPUs uh and how Cuda

15
00:00:35,280 --> 00:00:38,760
itself Works uh now Cuda is actually a

16
00:00:38,760 --> 00:00:40,620
programming language uh that has C

17
00:00:40,620 --> 00:00:43,200
syntax that allows you to actually run

18
00:00:43,200 --> 00:00:46,320
general purpose code on gpus to use

19
00:00:46,320 --> 00:00:49,680
their enormous parallel compute power uh

20
00:00:49,680 --> 00:00:51,660
now I will be talking about that in just

21
00:00:51,660 --> 00:00:53,579
a moment but just before we begin I'd

22
00:00:53,579 --> 00:00:55,800
like to tell you uh that if you have if

23
00:00:55,800 --> 00:00:57,960
you've already watched my video where I

24
00:00:57,960 --> 00:01:00,660
actually show you uh benchmarks of

25
00:01:00,660 --> 00:01:02,820
Highly parallel random number generation

26
00:01:02,820 --> 00:01:06,060
on CPUs using digitalocean servers I'd

27
00:01:06,060 --> 00:01:08,040
recommend you actually go see that right

28
00:01:08,040 --> 00:01:10,020
now uh there's actually going to be a

29
00:01:10,020 --> 00:01:11,460
link in the description if you haven't

30
00:01:11,460 --> 00:01:13,860
seen that already because cause that is

31
00:01:13,860 --> 00:01:16,500
a good primer to this video to introduce

32
00:01:16,500 --> 00:01:18,840
you to the concept of multi-processing

33
00:01:18,840 --> 00:01:22,979
and parallel parallel Computing but

34
00:01:22,979 --> 00:01:24,000
today

35
00:01:24,000 --> 00:01:25,680
I'm going to talk about how you can

36
00:01:25,680 --> 00:01:28,200
actually use Nvidia gpus in the Cuda

37
00:01:28,200 --> 00:01:30,479
programming language to implement simple

38
00:01:30,479 --> 00:01:33,299
Cuda applications and later we'll get

39
00:01:33,299 --> 00:01:35,640
much more advanced and I'll show you how

40
00:01:35,640 --> 00:01:37,439
to integrate things like neural networks

41
00:01:37,439 --> 00:01:39,900
and more and even other programming

42
00:01:39,900 --> 00:01:42,479
languages like Python and Swift with

43
00:01:42,479 --> 00:01:44,159
Cuda to create GPU accelerated

44
00:01:44,159 --> 00:01:47,280
applications uh in all of the all these

45
00:01:47,280 --> 00:01:48,720
different use cases

46
00:01:48,720 --> 00:01:50,640
all right but today let's talk a little

47
00:01:50,640 --> 00:01:52,740
bit about the concept of this in the

48
00:01:52,740 --> 00:01:54,780
first place also by the way you need to

49
00:01:54,780 --> 00:01:57,360
know C for this to actually work and for

50
00:01:57,360 --> 00:01:58,680
you to actually understand what's going

51
00:01:58,680 --> 00:02:01,259
on in the first place uh so if you don't

52
00:02:01,259 --> 00:02:03,240
already know C do not worry because in

53
00:02:03,240 --> 00:02:05,159
the next few weeks I will be releasing

54
00:02:05,159 --> 00:02:07,799
an entirely new series also about how

55
00:02:07,799 --> 00:02:10,500
scene General Works uh beginning to end

56
00:02:10,500 --> 00:02:13,080
sort of uh tutorial series on the scene

57
00:02:13,080 --> 00:02:15,180
C plus specifically programming

58
00:02:15,180 --> 00:02:17,580
languages and how you can use them all

59
00:02:17,580 --> 00:02:19,140
right but now let's get started with

60
00:02:19,140 --> 00:02:22,800
Cuda first of all GPU CPU what's the

61
00:02:22,800 --> 00:02:23,580
difference

62
00:02:23,580 --> 00:02:26,220
well gpus are meant for graphics

63
00:02:26,220 --> 00:02:28,080
processing quite literally as you could

64
00:02:28,080 --> 00:02:30,120
probably tell uh their name is a

65
00:02:30,120 --> 00:02:33,660
graphics Processing Unit uh and so the

66
00:02:33,660 --> 00:02:35,340
real difference between the GPU and the

67
00:02:35,340 --> 00:02:38,220
CPU is that since gpus are meant to

68
00:02:38,220 --> 00:02:40,800
drive monitors with sometimes millions

69
00:02:40,800 --> 00:02:43,440
of pixels uh of course it needs to be

70
00:02:43,440 --> 00:02:46,080
able to do uh tens of thousands to

71
00:02:46,080 --> 00:02:48,720
hundreds of thousands of things at once

72
00:02:48,720 --> 00:02:51,120
to quickly uh sort of you know calculate

73
00:02:51,120 --> 00:02:52,620
all the values for all these sort of

74
00:02:52,620 --> 00:02:54,959
pixels uh that are on your marker right

75
00:02:54,959 --> 00:02:58,379
now uh and so what happens they say that

76
00:02:58,379 --> 00:03:01,080
you've got an average CPU okay

77
00:03:01,080 --> 00:03:03,239
and your CPU can do a lot of things they

78
00:03:03,239 --> 00:03:07,140
can do them very very quickly uh so say

79
00:03:07,140 --> 00:03:08,940
of course you know the average CPU I

80
00:03:08,940 --> 00:03:10,620
don't know maybe you've got you know a

81
00:03:10,620 --> 00:03:13,620
Mac or you've gotten Intel i7 uh usually

82
00:03:13,620 --> 00:03:16,379
these things are you know quad core uh

83
00:03:16,379 --> 00:03:21,659
so some average CPU that you might use

84
00:03:21,659 --> 00:03:24,900
um I have four cores uh however Intel

85
00:03:24,900 --> 00:03:27,659
has a technology called hyper threading

86
00:03:27,659 --> 00:03:30,180
meaning that each core can have two

87
00:03:30,180 --> 00:03:33,239
threads on the chip at once uh now

88
00:03:33,239 --> 00:03:35,220
theoretically you can have many more

89
00:03:35,220 --> 00:03:38,760
cores than just two on a chip at once uh

90
00:03:38,760 --> 00:03:40,920
however they would have to keep uh

91
00:03:40,920 --> 00:03:43,319
coming into and out of the cache of the

92
00:03:43,319 --> 00:03:45,540
CPU uh due to the fact that of course

93
00:03:45,540 --> 00:03:48,060
the CPU can only hold two in each core

94
00:03:48,060 --> 00:03:50,099
uh and so what that means is that at

95
00:03:50,099 --> 00:03:53,159
maximum at one time our eight threads

96
00:03:53,159 --> 00:03:56,280
can exist on the CPU so times two

97
00:03:56,280 --> 00:03:58,620
because each core can hold two and of

98
00:03:58,620 --> 00:04:00,180
course that turns out to be eight

99
00:04:00,180 --> 00:04:03,780
threads on uh on the chip at once

100
00:04:03,780 --> 00:04:05,640
uh however this is a little bit

101
00:04:05,640 --> 00:04:08,220
different for gpus because of course

102
00:04:08,220 --> 00:04:11,099
CPUs weren't necessarily meant to drive

103
00:04:11,099 --> 00:04:14,340
displays say 5K displays with hundreds

104
00:04:14,340 --> 00:04:16,620
of thousands to Millions to tens of

105
00:04:16,620 --> 00:04:19,340
millions of pixels forget multi-displays

106
00:04:19,340 --> 00:04:22,919
however gpus were built to do this

107
00:04:22,919 --> 00:04:25,680
so gpus however

108
00:04:25,680 --> 00:04:28,080
are quite different

109
00:04:28,080 --> 00:04:30,180
and not only in what I'm about to tell

110
00:04:30,180 --> 00:04:31,680
you but they're also different in other

111
00:04:31,680 --> 00:04:33,060
ways and I'll talk about that in a

112
00:04:33,060 --> 00:04:34,320
moment

113
00:04:34,320 --> 00:04:37,080
now say that you've got a GPU and say

114
00:04:37,080 --> 00:04:40,560
this is an Nvidia Titan XP or say yeah a

115
00:04:40,560 --> 00:04:41,820
Titan XP

116
00:04:41,820 --> 00:04:44,460
a Titan XP oh yeah let's do the example

117
00:04:44,460 --> 00:04:47,280
of a GTX 1070 that's a better one uh so

118
00:04:47,280 --> 00:04:51,360
a GTX 1070 GeForce GTX 1070 regular GPU

119
00:04:51,360 --> 00:04:56,280
buy-invideo uh has around 1900.

120
00:04:56,280 --> 00:04:59,100
of course that is a lot

121
00:04:59,100 --> 00:05:02,820
but the best part is that each core can

122
00:05:02,820 --> 00:05:05,880
hold 12 threads

123
00:05:05,880 --> 00:05:08,639
and so what this means at once 12

124
00:05:08,639 --> 00:05:10,740
threads at once at least and so what

125
00:05:10,740 --> 00:05:13,620
this means is that 1900 times 12 I mean

126
00:05:13,620 --> 00:05:17,460
what is that uh what is 1900 times 12.

127
00:05:17,460 --> 00:05:19,380
um you know or whatever that is but

128
00:05:19,380 --> 00:05:22,380
you're holding tens of thousands of

129
00:05:22,380 --> 00:05:26,460
things uh of of threads on the chip at

130
00:05:26,460 --> 00:05:28,919
once and what that means is that of

131
00:05:28,919 --> 00:05:31,139
course you can do tens of thousands of

132
00:05:31,139 --> 00:05:33,180
things at once

133
00:05:33,180 --> 00:05:35,520
uh and so there are a few limitations

134
00:05:35,520 --> 00:05:36,660
though because then you're probably

135
00:05:36,660 --> 00:05:38,340
wondering and you might even have seen

136
00:05:38,340 --> 00:05:40,560
the static overflow question uh well

137
00:05:40,560 --> 00:05:42,300
then why don't we just replace all these

138
00:05:42,300 --> 00:05:44,759
CPUs or gpus then if these GPS are so

139
00:05:44,759 --> 00:05:46,139
great then why don't we just create

140
00:05:46,139 --> 00:05:48,360
these sort of GPU CPU hybrids or just

141
00:05:48,360 --> 00:05:51,720
use the GPU for the CPU well there are a

142
00:05:51,720 --> 00:05:54,840
number of drawbacks uh from the GPU side

143
00:05:54,840 --> 00:05:56,639
first drawback is of course operating

144
00:05:56,639 --> 00:05:58,979
systems just can't run on them there are

145
00:05:58,979 --> 00:06:01,380
some basic core features of a CPU that

146
00:06:01,380 --> 00:06:03,600
the GPU just doesn't have and that's the

147
00:06:03,600 --> 00:06:06,600
reason that the GPU can do so

148
00:06:06,600 --> 00:06:09,180
so uh and in fact here so

149
00:06:09,180 --> 00:06:12,479
this would be around 22

150
00:06:12,479 --> 00:06:13,740
000

151
00:06:13,740 --> 00:06:16,440
um 800

152
00:06:16,440 --> 00:06:18,960
threads on the chip at once

153
00:06:18,960 --> 00:06:21,240
uh and so what's uh that's a round

154
00:06:21,240 --> 00:06:22,560
though because it doesn't exactly have

155
00:06:22,560 --> 00:06:25,259
1900 cores it's actually a few more uh

156
00:06:25,259 --> 00:06:27,780
plus or minus like two or three uh but

157
00:06:27,780 --> 00:06:29,819
still you get a pretty good idea of how

158
00:06:29,819 --> 00:06:31,560
many tens of thousands of things you can

159
00:06:31,560 --> 00:06:34,500
actually run at once on a GPU

160
00:06:34,500 --> 00:06:37,680
uh but the second limitation however is

161
00:06:37,680 --> 00:06:40,380
that gpus can do a lot of things at once

162
00:06:40,380 --> 00:06:43,199
but each thing that it does it does with

163
00:06:43,199 --> 00:06:45,660
less precision and it does it slower

164
00:06:45,660 --> 00:06:48,660
than a CPU let me explain the reason the

165
00:06:48,660 --> 00:06:51,419
GPU is able to fit so many cores into

166
00:06:51,419 --> 00:06:54,300
such a tight space is because it it

167
00:06:54,300 --> 00:06:57,000
removes some of those is checks that the

168
00:06:57,000 --> 00:06:59,819
CPU makes to make sure that it's very

169
00:06:59,819 --> 00:07:02,460
very precise in its calculations for

170
00:07:02,460 --> 00:07:03,780
example if you were to do a calculation

171
00:07:03,780 --> 00:07:07,139
on the GPU you might be ever so slightly

172
00:07:07,139 --> 00:07:09,120
off with your floating Point Precision

173
00:07:09,120 --> 00:07:11,160
uh due to the fact that of course it

174
00:07:11,160 --> 00:07:13,319
doesn't have those checks that CPUs have

175
00:07:13,319 --> 00:07:15,780
which is why it's able to do so many

176
00:07:15,780 --> 00:07:17,520
things at once

177
00:07:17,520 --> 00:07:20,340
and also second each individual thing

178
00:07:20,340 --> 00:07:23,099
that it does it does slower than a CPU

179
00:07:23,099 --> 00:07:25,440
meaning that if you're only running one

180
00:07:25,440 --> 00:07:28,199
task on a GPU and one task on a CPU

181
00:07:28,199 --> 00:07:31,020
you'd be way better off running it on a

182
00:07:31,020 --> 00:07:33,900
CPU because it can do that one task much

183
00:07:33,900 --> 00:07:36,060
faster than a GPU ever could

184
00:07:36,060 --> 00:07:39,419
in fact the gpus each core can only

185
00:07:39,419 --> 00:07:41,280
really be used when you're using almost

186
00:07:41,280 --> 00:07:43,680
all of them at once or at least a

187
00:07:43,680 --> 00:07:46,139
considerable amount of these threads to

188
00:07:46,139 --> 00:07:48,300
make sure that you're using the GPU to

189
00:07:48,300 --> 00:07:50,639
its full potential

190
00:07:50,639 --> 00:07:53,099
oh but that's just new radically what

191
00:07:53,099 --> 00:07:55,080
they're capable of and why we don't just

192
00:07:55,080 --> 00:07:58,800
replace all these CPUs with gpus in fact

193
00:07:58,800 --> 00:08:01,979
a sort of good analogy here uh would be

194
00:08:01,979 --> 00:08:05,400
a CPU is a collection of say four uh

195
00:08:05,400 --> 00:08:08,099
extremely intelligent people who can do

196
00:08:08,099 --> 00:08:10,259
things very quickly and they can do a

197
00:08:10,259 --> 00:08:12,599
wide variety of tasks and in fact

198
00:08:12,599 --> 00:08:14,460
they're so good it's to the point that

199
00:08:14,460 --> 00:08:16,199
each person can do two things at once

200
00:08:16,199 --> 00:08:18,419
meaning of course hybrid setting so you

201
00:08:18,419 --> 00:08:20,160
can do eight things at once with this

202
00:08:20,160 --> 00:08:21,780
group of four people and each thing is

203
00:08:21,780 --> 00:08:25,080
going on very fast however when you load

204
00:08:25,080 --> 00:08:28,919
these four people with a billion tasks

205
00:08:28,919 --> 00:08:31,379
or even just say 10 million they will

206
00:08:31,379 --> 00:08:34,500
get stressed however imagine that you've

207
00:08:34,500 --> 00:08:39,000
got a group of 22 800 slightly less

208
00:08:39,000 --> 00:08:41,219
intelligent people uh what's going to

209
00:08:41,219 --> 00:08:42,899
happen is you might have a few errors in

210
00:08:42,899 --> 00:08:44,459
the calculations that these people make

211
00:08:44,459 --> 00:08:46,680
uh these people might be slower running

212
00:08:46,680 --> 00:08:49,019
the calculations themselves but you're

213
00:08:49,019 --> 00:08:51,240
doing it in parallel everybody's doing a

214
00:08:51,240 --> 00:08:53,399
task uh and that means that of course

215
00:08:53,399 --> 00:08:54,839
you're going to get to 10 million or

216
00:08:54,839 --> 00:08:57,779
even a billion much much quicker than

217
00:08:57,779 --> 00:09:00,420
you ever would with the CPU and this

218
00:09:00,420 --> 00:09:03,120
really explains the concept of how one

219
00:09:03,120 --> 00:09:05,700
task is fast on the CPU and slower on

220
00:09:05,700 --> 00:09:07,800
the GPU because one intelligent person

221
00:09:07,800 --> 00:09:10,500
doing a task uh is of course going to be

222
00:09:10,500 --> 00:09:12,600
faster than one slightly less

223
00:09:12,600 --> 00:09:15,000
intelligent person doing a task and of

224
00:09:15,000 --> 00:09:17,640
course much more precise

225
00:09:17,640 --> 00:09:21,060
overview of the GPU versus CPU sort of

226
00:09:21,060 --> 00:09:22,080
comparison

227
00:09:22,080 --> 00:09:23,640
but one thing I would like to tell you

228
00:09:23,640 --> 00:09:25,560
to tell you here is that gpus of course

229
00:09:25,560 --> 00:09:27,779
are meant for graphics processing the

230
00:09:27,779 --> 00:09:29,700
entire concept running general purpose

231
00:09:29,700 --> 00:09:32,519
code on a GPU is very very new or at

232
00:09:32,519 --> 00:09:34,860
least relatively very very new

233
00:09:34,860 --> 00:09:36,839
uh this has actually not been around for

234
00:09:36,839 --> 00:09:39,540
too long uh it's a very New Concept

235
00:09:39,540 --> 00:09:41,459
which is why the community is still sort

236
00:09:41,459 --> 00:09:42,839
of building around this although it has

237
00:09:42,839 --> 00:09:44,760
a very big sort of following the Deep

238
00:09:44,760 --> 00:09:46,080
learning and machine Learning Community

239
00:09:46,080 --> 00:09:48,180
which is in fact why I'm not interested

240
00:09:48,180 --> 00:09:50,220
in this topic and why I'm creating this

241
00:09:50,220 --> 00:09:52,920
series today or you know the series on

242
00:09:52,920 --> 00:09:54,240
my YouTube channel because I want to

243
00:09:54,240 --> 00:09:55,920
show you how to incorporate deep

244
00:09:55,920 --> 00:09:58,500
learning Technologies with gpus in order

245
00:09:58,500 --> 00:10:00,120
to accelerate your deep learning

246
00:10:00,120 --> 00:10:03,120
workloads uh and also one more thing I'd

247
00:10:03,120 --> 00:10:05,279
like to mention here imagine and I mean

248
00:10:05,279 --> 00:10:06,899
if you're familiar with the concept of a

249
00:10:06,899 --> 00:10:08,339
neural network you'll probably get this

250
00:10:08,339 --> 00:10:10,740
I imagine you've got a very deep

251
00:10:10,740 --> 00:10:12,300
convolutional neural network with

252
00:10:12,300 --> 00:10:15,000
recurrent layers etc etc or you know

253
00:10:15,000 --> 00:10:16,800
just imagine a convolutional neural

254
00:10:16,800 --> 00:10:20,240
network say Inception V3 okay by Google

255
00:10:20,240 --> 00:10:24,839
now this is a huge convolutional neural

256
00:10:24,839 --> 00:10:27,839
network layer after layer after layer it

257
00:10:27,839 --> 00:10:30,120
is just absolutely huge

258
00:10:30,120 --> 00:10:33,200
but it's also huge in the in terms of

259
00:10:33,200 --> 00:10:36,540
individual trainable weights

260
00:10:36,540 --> 00:10:39,060
imagine this you're doing a feed forward

261
00:10:39,060 --> 00:10:41,760
pass through this neural network so

262
00:10:41,760 --> 00:10:43,140
you're giving input into the neural

263
00:10:43,140 --> 00:10:46,079
network and expecting output from it now

264
00:10:46,079 --> 00:10:48,959
say that you've got of course uh a few

265
00:10:48,959 --> 00:10:51,779
hundred million uh trainable parameters

266
00:10:51,779 --> 00:10:53,880
now these few hundred million trainable

267
00:10:53,880 --> 00:10:55,860
parameters if you were to run that on

268
00:10:55,860 --> 00:11:00,660
CPU that would be very very slow however

269
00:11:00,660 --> 00:11:02,579
if you were to run that on a GPU that

270
00:11:02,579 --> 00:11:05,640
would be much much faster faster than

271
00:11:05,640 --> 00:11:07,440
the point that deep learning becomes

272
00:11:07,440 --> 00:11:09,779
practical in fact that's the only reason

273
00:11:09,779 --> 00:11:11,820
why deep learning is used today and why

274
00:11:11,820 --> 00:11:14,040
why it wasn't used in the past because

275
00:11:14,040 --> 00:11:16,740
now we have this computing power to

276
00:11:16,740 --> 00:11:18,540
actually run deep learning networks and

277
00:11:18,540 --> 00:11:21,360
have it practically run uh in terms of

278
00:11:21,360 --> 00:11:23,100
time because you don't want to have to

279
00:11:23,100 --> 00:11:25,620
wait for a month uh training your neural

280
00:11:25,620 --> 00:11:27,420
network model just to bound up just to

281
00:11:27,420 --> 00:11:29,399
find out that it has you know it

282
00:11:29,399 --> 00:11:31,860
overfitted to your data uh you do not

283
00:11:31,860 --> 00:11:33,120
want that to happen you want to do

284
00:11:33,120 --> 00:11:35,279
things very quickly so you can of course

285
00:11:35,279 --> 00:11:37,620
do the you can sort of you know deploy

286
00:11:37,620 --> 00:11:40,680
these models very very quickly

287
00:11:40,680 --> 00:11:42,600
oh but that's the first concept I wanted

288
00:11:42,600 --> 00:11:43,560
to explain

289
00:11:43,560 --> 00:11:45,720
second let's talk a little bit about

290
00:11:45,720 --> 00:11:49,079
memory shall we uh now there are a lot

291
00:11:49,079 --> 00:11:51,120
of different uh a lot of different

292
00:11:51,120 --> 00:11:52,680
terminology that I'm going to be using

293
00:11:52,680 --> 00:11:54,899
as I as I explained memory so let's talk

294
00:11:54,899 --> 00:11:57,660
about terminology first and even before

295
00:11:57,660 --> 00:12:00,019
we get to terminology I have to explain

296
00:12:00,019 --> 00:12:03,000
how you can actually run code on a GPU

297
00:12:03,000 --> 00:12:04,320
in the first place

298
00:12:04,320 --> 00:12:07,200
now theoretically this should be very

299
00:12:07,200 --> 00:12:10,620
very hard however thank like I mean

300
00:12:10,620 --> 00:12:12,720
thank you Nvidia and the great people

301
00:12:12,720 --> 00:12:15,240
who are developing uh Frameworks like

302
00:12:15,240 --> 00:12:18,959
opencl uh because now thanks to

303
00:12:18,959 --> 00:12:22,019
Frameworks like opencl and Cuda it's

304
00:12:22,019 --> 00:12:24,959
very very or at least much more easy uh

305
00:12:24,959 --> 00:12:27,480
to create these GPU enabled applications

306
00:12:27,480 --> 00:12:30,839
let me explain there are two sort of uh

307
00:12:30,839 --> 00:12:33,240
mainstream GPU acceleration options

308
00:12:33,240 --> 00:12:35,519
available in the market today uh the

309
00:12:35,519 --> 00:12:37,560
first one is of course opencl it's an

310
00:12:37,560 --> 00:12:40,019
open source uh platform that allows you

311
00:12:40,019 --> 00:12:42,779
to do GPU development general purpose

312
00:12:42,779 --> 00:12:46,740
GPU Computing uh on our wide variety of

313
00:12:46,740 --> 00:12:48,720
different processors now this can

314
00:12:48,720 --> 00:12:51,720
actually be uh your your CPU opencl runs

315
00:12:51,720 --> 00:12:54,360
on CPU as well by the way it also runs

316
00:12:54,360 --> 00:12:56,579
on the integrated Graphics of your CPU

317
00:12:56,579 --> 00:13:00,420
it also runs on AMD gpus it also runs on

318
00:13:00,420 --> 00:13:02,399
Nvidia gpus although it's not very

319
00:13:02,399 --> 00:13:04,940
performance efficient

320
00:13:05,700 --> 00:13:08,899
however Cuda is basically a replacement

321
00:13:08,899 --> 00:13:14,519
uh to opencl the Nvidia has developed uh

322
00:13:14,519 --> 00:13:15,959
and so basically the difference between

323
00:13:15,959 --> 00:13:17,820
this is that it's proprietary it's not

324
00:13:17,820 --> 00:13:19,620
open source code has not open source

325
00:13:19,620 --> 00:13:21,860
it's developed and maintained by Nvidia

326
00:13:21,860 --> 00:13:25,380
uh and it is specifically optimized down

327
00:13:25,380 --> 00:13:29,040
to the core to work on Nvidia processors

328
00:13:29,040 --> 00:13:32,040
and Nvidia gpus and Nvidia code is not

329
00:13:32,040 --> 00:13:34,680
compatible with AMD gpus or any other

330
00:13:34,680 --> 00:13:37,260
GPU only Nvidia gpus

331
00:13:37,260 --> 00:13:40,320
however Cuda is a lot simpler program

332
00:13:40,320 --> 00:13:42,360
for which is why I'm explaining that

333
00:13:42,360 --> 00:13:44,459
right now I might have another another

334
00:13:44,459 --> 00:13:47,040
Series in the future about opencl and

335
00:13:47,040 --> 00:13:48,360
its development and of course if you'd

336
00:13:48,360 --> 00:13:50,339
like a tutorial about that please do let

337
00:13:50,339 --> 00:13:52,800
me know and of course I will be glad uh

338
00:13:52,800 --> 00:13:55,079
to create those sorts of tutorials uh

339
00:13:55,079 --> 00:13:57,180
Bucky team for now let's talk a little

340
00:13:57,180 --> 00:13:59,100
bit about terminology now that you know

341
00:13:59,100 --> 00:14:01,620
a little bit about Kudo open CL there

342
00:14:01,620 --> 00:14:04,019
are a few more like metal uh there

343
00:14:04,019 --> 00:14:05,760
there's stuff like Vulcan but I won't

344
00:14:05,760 --> 00:14:08,040
talk about that right now uh for now

345
00:14:08,040 --> 00:14:10,019
let's talk about the terminology that

346
00:14:10,019 --> 00:14:13,079
goes behind this development

347
00:14:13,079 --> 00:14:14,700
and now there is actually quite a bit of

348
00:14:14,700 --> 00:14:16,920
terminology that goes behind this

349
00:14:16,920 --> 00:14:18,839
but one that you there too that you'll

350
00:14:18,839 --> 00:14:22,500
hear very very often the first one is

351
00:14:22,500 --> 00:14:24,360
host

352
00:14:24,360 --> 00:14:28,339
the second one is device

353
00:14:28,980 --> 00:14:30,420
let me explain

354
00:14:30,420 --> 00:14:33,180
now in essence host and vice are just

355
00:14:33,180 --> 00:14:35,880
fancier terms for CPU and GPU

356
00:14:35,880 --> 00:14:38,220
respectively the host is the CPU because

357
00:14:38,220 --> 00:14:40,860
it's hosting the entire code uh the

358
00:14:40,860 --> 00:14:42,779
device is the GPU it's the device that

359
00:14:42,779 --> 00:14:45,180
all this code is running on uh and

360
00:14:45,180 --> 00:14:47,100
that's why it's called host and device

361
00:14:47,100 --> 00:14:48,660
there is a little bit more terminology

362
00:14:48,660 --> 00:14:53,639
though one main one without being kernel

363
00:14:53,639 --> 00:14:57,120
now at first uh this might scare you uh

364
00:14:57,120 --> 00:14:58,680
that you know we're doing kernel

365
00:14:58,680 --> 00:15:00,060
development now

366
00:15:00,060 --> 00:15:03,180
uh all this is is

367
00:15:03,180 --> 00:15:05,339
um when you develop the uh the the

368
00:15:05,339 --> 00:15:07,800
actual function or the code that will be

369
00:15:07,800 --> 00:15:10,680
run on the GPU it's called a kernel uh

370
00:15:10,680 --> 00:15:12,000
just like for example your operating

371
00:15:12,000 --> 00:15:14,279
system has a kernel uh it's the same

372
00:15:14,279 --> 00:15:15,839
thing it's just a code that's going to

373
00:15:15,839 --> 00:15:18,480
run on the GPU nothing more about that

374
00:15:18,480 --> 00:15:21,600
uh however now let's talk a little bit

375
00:15:21,600 --> 00:15:24,240
about the steps you have to take towards

376
00:15:24,240 --> 00:15:26,940
GPU development to actually incorporate

377
00:15:26,940 --> 00:15:29,279
Technologies like GPU acceleration into

378
00:15:29,279 --> 00:15:31,139
your applications

379
00:15:31,139 --> 00:15:33,959
now of course it has begin with creating

380
00:15:33,959 --> 00:15:36,300
a CPU version of your parallel

381
00:15:36,300 --> 00:15:39,420
application now what I recommend is

382
00:15:39,420 --> 00:15:41,040
actually creating a CPU version of your

383
00:15:41,040 --> 00:15:42,720
application before you try porting it

384
00:15:42,720 --> 00:15:44,760
over to Cuda however there are a few

385
00:15:44,760 --> 00:15:46,199
challenges with that which I'll tell you

386
00:15:46,199 --> 00:15:48,300
in just a moment but let's just imagine

387
00:15:48,300 --> 00:15:50,699
that I want to do something like oh I

388
00:15:50,699 --> 00:15:52,800
don't know matrix multiplication which

389
00:15:52,800 --> 00:15:54,779
is something that of course deep neural

390
00:15:54,779 --> 00:15:57,660
networks require or even if I'm going to

391
00:15:57,660 --> 00:15:59,760
create a simple function that can take

392
00:15:59,760 --> 00:16:01,680
an array of you know millions of values

393
00:16:01,680 --> 00:16:05,519
and run sigmoid on each value that is a

394
00:16:05,519 --> 00:16:07,380
huge help to deep neural networks and

395
00:16:07,380 --> 00:16:09,300
even even if it's not sigmoid it can be

396
00:16:09,300 --> 00:16:11,060
you know rectified linear unit

397
00:16:11,060 --> 00:16:13,260
hyperbolic tangent it's a soft Max

398
00:16:13,260 --> 00:16:15,959
whatever it might be basically just find

399
00:16:15,959 --> 00:16:18,779
a specific activation for all the values

400
00:16:18,779 --> 00:16:21,899
in this array gpus can do that very very

401
00:16:21,899 --> 00:16:24,240
efficiently but again depending on how

402
00:16:24,240 --> 00:16:25,980
many of these elements you have which

403
00:16:25,980 --> 00:16:28,680
I'll talk about in a moment as well

404
00:16:28,680 --> 00:16:30,899
uh so imagine you wanted to build a CPU

405
00:16:30,899 --> 00:16:33,000
version of this application the first

406
00:16:33,000 --> 00:16:34,680
step you would take

407
00:16:34,680 --> 00:16:36,600
uh is you would of course initialize

408
00:16:36,600 --> 00:16:39,000
your variables uh by initialize I mean

409
00:16:39,000 --> 00:16:41,820
you would declare or you would Define

410
00:16:41,820 --> 00:16:45,060
and allocate memory for your variables

411
00:16:45,060 --> 00:16:46,620
because again this is C you're going to

412
00:16:46,620 --> 00:16:48,839
have to do this sort of manual memory

413
00:16:48,839 --> 00:16:50,399
management sometimes

414
00:16:50,399 --> 00:16:52,139
uh but what you do is you would

415
00:16:52,139 --> 00:16:54,800
initialize

416
00:16:57,440 --> 00:17:01,440
your variables

417
00:17:03,360 --> 00:17:06,660
uh I will fix that uh but once I've done

418
00:17:06,660 --> 00:17:08,819
initializing your variables

419
00:17:08,819 --> 00:17:12,240
there's still quite a bit left

420
00:17:12,240 --> 00:17:14,400
however again you're probably used to

421
00:17:14,400 --> 00:17:16,140
CPU development so this shouldn't be too

422
00:17:16,140 --> 00:17:16,980
hard

423
00:17:16,980 --> 00:17:19,140
what you do as you would initialize your

424
00:17:19,140 --> 00:17:20,280
variables

425
00:17:20,280 --> 00:17:23,339
uh you would fill

426
00:17:23,339 --> 00:17:25,679
uh the variables or I'll just call them

427
00:17:25,679 --> 00:17:30,919
vars with the actual values

428
00:17:32,580 --> 00:17:34,440
then once you're done filling it up with

429
00:17:34,440 --> 00:17:37,740
values uh you would go ahead and then

430
00:17:37,740 --> 00:17:39,840
run sigmoid on the entire thing using

431
00:17:39,840 --> 00:17:42,660
something like a for Loop so you use a

432
00:17:42,660 --> 00:17:45,140
for Loop

433
00:17:45,600 --> 00:17:48,900
to run sigmoid

434
00:17:48,900 --> 00:17:52,500
on all the values

435
00:17:52,500 --> 00:17:54,840
sigmoid the values

436
00:17:54,840 --> 00:17:56,820
now once you've run sigmoid on the on

437
00:17:56,820 --> 00:17:59,280
all the values you're almost done all

438
00:17:59,280 --> 00:18:01,320
you need to do now is actually use those

439
00:18:01,320 --> 00:18:04,620
values in your application

440
00:18:04,620 --> 00:18:07,220
foreign

441
00:18:09,559 --> 00:18:11,580
you're ready to continue to the next

442
00:18:11,580 --> 00:18:13,980
layer or do whatever else you need to

443
00:18:13,980 --> 00:18:16,500
however with GPU development up there is

444
00:18:16,500 --> 00:18:18,960
quite a bit more so get ready

445
00:18:18,960 --> 00:18:21,179
um because with GPU development it's not

446
00:18:21,179 --> 00:18:22,740
that easy because with GPU development

447
00:18:22,740 --> 00:18:25,500
you've got all this sort of memory

448
00:18:25,500 --> 00:18:28,740
copying allocation uh and you know

449
00:18:28,740 --> 00:18:30,780
transfer issues which let me talk about

450
00:18:30,780 --> 00:18:31,980
that

451
00:18:31,980 --> 00:18:34,020
when you're doing GPU development you've

452
00:18:34,020 --> 00:18:37,440
got two entirely separate memory spaces

453
00:18:37,440 --> 00:18:38,820
you've got something called device

454
00:18:38,820 --> 00:18:40,260
number and you've got something called

455
00:18:40,260 --> 00:18:42,720
host memory the host memory is your

456
00:18:42,720 --> 00:18:44,160
system memory you're familiar with this

457
00:18:44,160 --> 00:18:45,299
you use it every day when you're

458
00:18:45,299 --> 00:18:47,640
programming this is the memory that all

459
00:18:47,640 --> 00:18:49,679
of your you know applications or code

460
00:18:49,679 --> 00:18:52,020
for the CPU run on then you've got your

461
00:18:52,020 --> 00:18:54,299
graphics Ram or your you know the the

462
00:18:54,299 --> 00:18:56,940
graphics vram now this is the actual Ram

463
00:18:56,940 --> 00:19:00,059
stored on your graphics card in the case

464
00:19:00,059 --> 00:19:02,400
of a GTX 1070 you've got around 12

465
00:19:02,400 --> 00:19:06,179
gigabytes of this DDR ddr5x I believe

466
00:19:06,179 --> 00:19:07,620
memory

467
00:19:07,620 --> 00:19:10,320
uh and so that again this is very fast

468
00:19:10,320 --> 00:19:12,299
memory but you have to understand though

469
00:19:12,299 --> 00:19:16,200
that the GPU cannot necessarily quickly

470
00:19:16,200 --> 00:19:20,100
access uh the variables stored on CPU

471
00:19:20,100 --> 00:19:21,900
memory and CPU memory cannot quickly

472
00:19:21,900 --> 00:19:24,480
access uh what's on the GPU memory

473
00:19:24,480 --> 00:19:26,460
because again you're linking this via

474
00:19:26,460 --> 00:19:31,200
PCI or pcie uh and so what happens uh is

475
00:19:31,200 --> 00:19:34,140
there is a there's quite a bottleneck of

476
00:19:34,140 --> 00:19:38,340
that PCI uh from the GPU to the CPU it's

477
00:19:38,340 --> 00:19:42,720
not as instant as RAM in those dim slots

478
00:19:42,720 --> 00:19:45,720
and so you have to uh you have to

479
00:19:45,720 --> 00:19:46,980
account for that sort of bottleneck

480
00:19:46,980 --> 00:19:48,539
because Imagine This

481
00:19:48,539 --> 00:19:50,160
what you've got is you've got this thing

482
00:19:50,160 --> 00:19:51,660
called a device and of course the device

483
00:19:51,660 --> 00:19:54,559
is your GPU

484
00:19:58,440 --> 00:19:59,940
and inside of your device you've got

485
00:19:59,940 --> 00:20:02,520
this thing called you know DVR

486
00:20:02,520 --> 00:20:05,220
or or dram you've got this

487
00:20:05,220 --> 00:20:07,260
dram in your GPU

488
00:20:07,260 --> 00:20:08,880
and this is where you're storing of

489
00:20:08,880 --> 00:20:10,080
course all the variables that will be

490
00:20:10,080 --> 00:20:11,820
used in your kernel in your kernel of

491
00:20:11,820 --> 00:20:13,320
course being the function that is

492
00:20:13,320 --> 00:20:15,539
actually called on the GPU

493
00:20:15,539 --> 00:20:17,760
uh however of course you've also got

494
00:20:17,760 --> 00:20:19,260
your hopes and you have to account for

495
00:20:19,260 --> 00:20:21,419
the host

496
00:20:21,419 --> 00:20:23,640
and the host will actually do all the

497
00:20:23,640 --> 00:20:25,080
data generation

498
00:20:25,080 --> 00:20:27,480
uh and so you have to have some sort of

499
00:20:27,480 --> 00:20:28,919
way

500
00:20:28,919 --> 00:20:32,100
to copy the variables from the host over

501
00:20:32,100 --> 00:20:33,600
to the device

502
00:20:33,600 --> 00:20:35,220
now of course you've also got memory

503
00:20:35,220 --> 00:20:37,140
inside the host but there are two

504
00:20:37,140 --> 00:20:38,880
separate types of memory

505
00:20:38,880 --> 00:20:42,200
there's pageable memory

506
00:20:44,520 --> 00:20:47,419
and there's pain management

507
00:20:50,700 --> 00:20:52,340
these are two separate types of memory

508
00:20:52,340 --> 00:20:55,620
the pageable memory is actually I guess

509
00:20:55,620 --> 00:20:57,960
you could say uh not it's not very

510
00:20:57,960 --> 00:20:59,880
performance efficient uh it does this

511
00:20:59,880 --> 00:21:01,440
thing called paging which I won't talk

512
00:21:01,440 --> 00:21:03,059
about right now that'll get very you

513
00:21:03,059 --> 00:21:05,640
know low level and Technical uh well

514
00:21:05,640 --> 00:21:06,960
we'll have to get too deep into that

515
00:21:06,960 --> 00:21:08,400
maybe for another time maybe in the C

516
00:21:08,400 --> 00:21:10,980
tutorials however what this means is

517
00:21:10,980 --> 00:21:12,660
that sometimes you could be using real

518
00:21:12,660 --> 00:21:14,220
Ram sometimes you could be you know I

519
00:21:14,220 --> 00:21:16,620
mean you will be paging uh you might be

520
00:21:16,620 --> 00:21:18,660
using swap rang you might be using you

521
00:21:18,660 --> 00:21:20,580
know your hard disk as virtual Ram sort

522
00:21:20,580 --> 00:21:22,679
of thing is what swap means

523
00:21:22,679 --> 00:21:26,340
uh however with pin memory there's

524
00:21:26,340 --> 00:21:28,919
actually a dedicated block of system

525
00:21:28,919 --> 00:21:32,280
memory dedicated towards this this these

526
00:21:32,280 --> 00:21:35,220
objects or this specific object that you

527
00:21:35,220 --> 00:21:36,539
that you have

528
00:21:36,539 --> 00:21:39,059
uh and so the pin memory is the only

529
00:21:39,059 --> 00:21:40,559
type of memory that can actually

530
00:21:40,559 --> 00:21:43,740
communicate uh with the dram on the

531
00:21:43,740 --> 00:21:46,559
device and so somehow you have to use

532
00:21:46,559 --> 00:21:49,919
pin memory to send data up to the dram

533
00:21:49,919 --> 00:21:52,620
and down back from the dram

534
00:21:52,620 --> 00:21:54,980
uh however in order for this to happen

535
00:21:54,980 --> 00:21:57,659
uh if you store your variables in

536
00:21:57,659 --> 00:22:00,360
pageable memory which by default sees

537
00:22:00,360 --> 00:22:02,159
malloc function from the standard

538
00:22:02,159 --> 00:22:03,020
Library

539
00:22:03,020 --> 00:22:05,820
uh and generally whenever you allocate

540
00:22:05,820 --> 00:22:07,980
you are allocating on pageable memory

541
00:22:07,980 --> 00:22:09,480
because of course the operating system

542
00:22:09,480 --> 00:22:11,460
doesn't want you to take up a lot of

543
00:22:11,460 --> 00:22:13,320
memory they're the operating system will

544
00:22:13,320 --> 00:22:14,820
automatically give you this pageable

545
00:22:14,820 --> 00:22:15,780
memory

546
00:22:15,780 --> 00:22:19,440
uh and so you got two bottlenecks uh in

547
00:22:19,440 --> 00:22:21,419
this case you got the bottleneck of

548
00:22:21,419 --> 00:22:24,020
pageable depend and then the bottleneck

549
00:22:24,020 --> 00:22:27,539
of the of pinned to dram now the reason

550
00:22:27,539 --> 00:22:29,760
this becomes a problem uh is because

551
00:22:29,760 --> 00:22:33,059
Cuda has to do a lot more work uh to

552
00:22:33,059 --> 00:22:35,760
actually copy from pageable to pins to

553
00:22:35,760 --> 00:22:39,360
dram and from dram to things to pageable

554
00:22:39,360 --> 00:22:42,059
it's not good it's not efficient

555
00:22:42,059 --> 00:22:45,120
you have to have a more efficient way of

556
00:22:45,120 --> 00:22:47,100
doing this memory transfer and that's

557
00:22:47,100 --> 00:22:48,900
actually the hardest part of GPU

558
00:22:48,900 --> 00:22:51,480
Computing uh while each core might be

559
00:22:51,480 --> 00:22:53,700
ever so slightly slower than a GPU core

560
00:22:53,700 --> 00:22:55,860
what happens is an even bigger

561
00:22:55,860 --> 00:22:57,720
bottleneck is actually introduced by the

562
00:22:57,720 --> 00:22:59,640
fact that you have to copy variables

563
00:22:59,640 --> 00:23:01,740
from CPU to GPU you have to do

564
00:23:01,740 --> 00:23:04,200
processing on the GPU and then copy them

565
00:23:04,200 --> 00:23:08,100
back to the CPU it's not efficient which

566
00:23:08,100 --> 00:23:10,080
is why you need to be doing a lot of

567
00:23:10,080 --> 00:23:12,840
tasks in parallel for GPU Computing to

568
00:23:12,840 --> 00:23:15,000
even be worth the extra time that you're

569
00:23:15,000 --> 00:23:16,039
spending

570
00:23:16,039 --> 00:23:19,140
however there is a way you can make this

571
00:23:19,140 --> 00:23:21,539
quite a bit more efficient from say 12

572
00:23:21,539 --> 00:23:23,820
to 13 gigabytes per second

573
00:23:23,820 --> 00:23:26,960
the way you do that is by quite simply

574
00:23:26,960 --> 00:23:29,880
erasing the pageable memory you're just

575
00:23:29,880 --> 00:23:32,280
not going to use pageable memory only is

576
00:23:32,280 --> 00:23:34,200
pin memory and it will create a

577
00:23:34,200 --> 00:23:36,000
performance difference of positive

578
00:23:36,000 --> 00:23:38,340
performance difference you will get

579
00:23:38,340 --> 00:23:40,320
performance gains

580
00:23:40,320 --> 00:23:43,620
now the reason this is is because kuna

581
00:23:43,620 --> 00:23:46,500
is able to do a direct transfer without

582
00:23:46,500 --> 00:23:49,740
another bottleneck in the way uh and so

583
00:23:49,740 --> 00:23:52,860
you're just doing direct dramed pendant

584
00:23:52,860 --> 00:23:56,280
dram converter transfers uh it should be

585
00:23:56,280 --> 00:23:59,460
theoretically much faster and cuda's mem

586
00:23:59,460 --> 00:24:02,460
copy or memory copy function becomes a

587
00:24:02,460 --> 00:24:05,159
lot lot faster this way now if you've

588
00:24:05,159 --> 00:24:07,500
already used C and standard Library you

589
00:24:07,500 --> 00:24:08,820
know about all these functions that I'm

590
00:24:08,820 --> 00:24:10,679
mentioning I'm mentioning malloc I'm

591
00:24:10,679 --> 00:24:13,740
mentioning mem copy uh I

592
00:24:13,740 --> 00:24:16,080
and it's a great internal functions uh

593
00:24:16,080 --> 00:24:19,140
but Cuda has their own version uh of of

594
00:24:19,140 --> 00:24:22,260
all these functions so for example when

595
00:24:22,260 --> 00:24:26,100
you need to copy a variable from say you

596
00:24:26,100 --> 00:24:27,840
know the host to the device there's

597
00:24:27,840 --> 00:24:30,120
actually a function called cuda mem copy

598
00:24:30,120 --> 00:24:32,760
which will allow you to copy from the

599
00:24:32,760 --> 00:24:34,440
host to the device

600
00:24:34,440 --> 00:24:36,960
uh however theoretically

601
00:24:36,960 --> 00:24:39,000
of course if you were to just use a

602
00:24:39,000 --> 00:24:42,419
native C function uh to to allocate your

603
00:24:42,419 --> 00:24:45,059
memory it would as I mentioned allocate

604
00:24:45,059 --> 00:24:47,700
and pageable memory however there is

605
00:24:47,700 --> 00:24:49,980
actually a Cuda function called cuda

606
00:24:49,980 --> 00:24:52,620
host alloc uh or there's also cool

607
00:24:52,620 --> 00:24:54,240
malloc host but I won't talk about that

608
00:24:54,240 --> 00:24:57,360
right now and the Cuda host analog uh

609
00:24:57,360 --> 00:25:00,000
will actually allow you to to on the

610
00:25:00,000 --> 00:25:00,840
host

611
00:25:00,840 --> 00:25:05,220
uh basically create or allocate uh this

612
00:25:05,220 --> 00:25:07,440
direct this ping memory that can

613
00:25:07,440 --> 00:25:10,020
communicate directly with the GPU for

614
00:25:10,020 --> 00:25:12,059
much faster transfer speeds whenever

615
00:25:12,059 --> 00:25:13,740
you're using this variable to copy to

616
00:25:13,740 --> 00:25:15,480
and for the GPU

617
00:25:15,480 --> 00:25:17,700
and so that's exactly how all the memory

618
00:25:17,700 --> 00:25:20,280
memory logic works and that sounds a

619
00:25:20,280 --> 00:25:21,600
little confusing and you probably don't

620
00:25:21,600 --> 00:25:24,299
get it entirely right now however in the

621
00:25:24,299 --> 00:25:25,740
next part when you actually see the code

622
00:25:25,740 --> 00:25:28,080
which is coming out very soon uh you

623
00:25:28,080 --> 00:25:29,880
will understand this in much greater

624
00:25:29,880 --> 00:25:31,740
detail it's actually quite simple it's

625
00:25:31,740 --> 00:25:33,779
not as complicated as I'm making it seem

626
00:25:33,779 --> 00:25:35,760
it's really just one-liners for example

627
00:25:35,760 --> 00:25:37,860
when you need to allocate you do Cuda

628
00:25:37,860 --> 00:25:40,320
host analog you'd point you pass in a

629
00:25:40,320 --> 00:25:42,240
pointer to your variable you tell it how

630
00:25:42,240 --> 00:25:43,740
big your variable will be and there you

631
00:25:43,740 --> 00:25:45,720
go you've done it you've got variable in

632
00:25:45,720 --> 00:25:47,760
pin memory on your host

633
00:25:47,760 --> 00:25:49,559
that when it needs a copy all you need

634
00:25:49,559 --> 00:25:51,360
to do is pass it the desk a pointer to

635
00:25:51,360 --> 00:25:52,799
the destination variable in your device

636
00:25:52,799 --> 00:25:56,220
a pointer to the uh tar the you know the

637
00:25:56,220 --> 00:25:58,860
source variable on your host you pass it

638
00:25:58,860 --> 00:26:00,659
the size and where you want it to go to

639
00:26:00,659 --> 00:26:03,000
the host or to the device

640
00:26:03,000 --> 00:26:06,059
and that's really all there is to it uh

641
00:26:06,059 --> 00:26:08,100
they're really just a lot of one-liners

642
00:26:08,100 --> 00:26:10,740
in terms of code but getting back to the

643
00:26:10,740 --> 00:26:13,320
point from this memory sort of tension

644
00:26:13,320 --> 00:26:14,940
here

645
00:26:14,940 --> 00:26:15,539
um

646
00:26:15,539 --> 00:26:17,940
now this is how you would code in a

647
00:26:17,940 --> 00:26:20,159
batch sigmoid on the CPU you can

648
00:26:20,159 --> 00:26:21,779
initialize your variables you'd fill the

649
00:26:21,779 --> 00:26:23,760
variables with values you would use a

650
00:26:23,760 --> 00:26:25,559
for Loop to run sigmoid on all values

651
00:26:25,559 --> 00:26:27,419
and then you would use your values

652
00:26:27,419 --> 00:26:29,820
and support that's four steps and of

653
00:26:29,820 --> 00:26:31,679
course there's no real complete

654
00:26:31,679 --> 00:26:33,720
bottleneck with sort of you know memory

655
00:26:33,720 --> 00:26:36,059
copies from from one piece of Rand to

656
00:26:36,059 --> 00:26:37,860
another to another no it's it's all

657
00:26:37,860 --> 00:26:41,220
mostly at least mostly clean except for

658
00:26:41,220 --> 00:26:42,779
step number three step number three

659
00:26:42,779 --> 00:26:45,240
becomes a huge bottleneck now because

660
00:26:45,240 --> 00:26:48,419
now you've got say 10 million values and

661
00:26:48,419 --> 00:26:50,760
you're individually running each one of

662
00:26:50,760 --> 00:26:52,440
those 10 million values and trying to

663
00:26:52,440 --> 00:26:55,919
run sigmoid on them not efficient at all

664
00:26:55,919 --> 00:26:59,039
this is where the GPU comes in if you

665
00:26:59,039 --> 00:27:00,960
were to implement the same application

666
00:27:00,960 --> 00:27:03,059
on a GPU there would be a few

667
00:27:03,059 --> 00:27:05,159
differences let's take a look the first

668
00:27:05,159 --> 00:27:06,779
two steps would remain the same you

669
00:27:06,779 --> 00:27:10,500
would first of all initialize

670
00:27:11,820 --> 00:27:14,700
I'm going to call them vars now

671
00:27:14,700 --> 00:27:17,700
initializer bars or variables

672
00:27:17,700 --> 00:27:19,559
then what you do all right I'm just

673
00:27:19,559 --> 00:27:20,820
going to space it out so you can

674
00:27:20,820 --> 00:27:22,140
actually take a look at the all these

675
00:27:22,140 --> 00:27:22,980
steps

676
00:27:22,980 --> 00:27:26,100
uh second what you do uh easy to

677
00:27:26,100 --> 00:27:27,480
actually fill up those variables with

678
00:27:27,480 --> 00:27:29,840
values

679
00:27:37,559 --> 00:27:40,200
now once your variables have values it's

680
00:27:40,200 --> 00:27:42,840
time to get to GPU Computing because

681
00:27:42,840 --> 00:27:44,640
what you have to do now is actually

682
00:27:44,640 --> 00:27:47,340
initialize

683
00:27:47,340 --> 00:27:49,980
and remember initialize

684
00:27:49,980 --> 00:27:51,200
meaning

685
00:27:51,200 --> 00:27:54,419
defined clear uh and of course allocate

686
00:27:54,419 --> 00:27:58,799
memory four your variables

687
00:27:58,799 --> 00:28:01,020
on the GPU so you need to initialize

688
00:28:01,020 --> 00:28:04,440
variables on the GPU

689
00:28:04,440 --> 00:28:06,419
on its dram

690
00:28:06,419 --> 00:28:08,279
once that's done

691
00:28:08,279 --> 00:28:12,480
step number four is to actually copy

692
00:28:12,480 --> 00:28:14,460
the variables

693
00:28:14,460 --> 00:28:16,919
from host

694
00:28:16,919 --> 00:28:20,659
to device memory

695
00:28:22,200 --> 00:28:24,120
so as you can see basically what this

696
00:28:24,120 --> 00:28:26,279
will do is it will take the variables

697
00:28:26,279 --> 00:28:27,659
that actually have values in them that

698
00:28:27,659 --> 00:28:29,460
you create in Step number two

699
00:28:29,460 --> 00:28:32,340
uh and it will copy them onto device

700
00:28:32,340 --> 00:28:35,100
memory into the variables you initialize

701
00:28:35,100 --> 00:28:37,980
on the GPU this will allow the kernel to

702
00:28:37,980 --> 00:28:41,760
access these variables very very quickly

703
00:28:41,760 --> 00:28:43,559
after that of course will copy those

704
00:28:43,559 --> 00:28:46,260
variables onto the device from The Host

705
00:28:46,260 --> 00:28:49,140
after that you have to run your kernel

706
00:28:49,140 --> 00:28:52,440
so you run the kernel

707
00:28:52,440 --> 00:28:55,980
which will do sigmoid operation on all

708
00:28:55,980 --> 00:28:58,980
of the arrays elements

709
00:28:58,980 --> 00:29:01,799
and then number six is you copy the

710
00:29:01,799 --> 00:29:03,539
result back onto the host from the

711
00:29:03,539 --> 00:29:05,720
device

712
00:29:12,840 --> 00:29:17,279
so from device of course to

713
00:29:17,279 --> 00:29:18,720
post

714
00:29:18,720 --> 00:29:21,000
and then once that's done you are ready

715
00:29:21,000 --> 00:29:22,679
to use

716
00:29:22,679 --> 00:29:25,980
the values that you get back in your

717
00:29:25,980 --> 00:29:28,860
application that's an entire three extra

718
00:29:28,860 --> 00:29:31,440
steps uh now of course this might not

719
00:29:31,440 --> 00:29:34,140
see that's a lot uh however think about

720
00:29:34,140 --> 00:29:36,779
this there are a lot of bottlenecks and

721
00:29:36,779 --> 00:29:38,580
if you're not doing nothings in parallel

722
00:29:38,580 --> 00:29:40,679
you will run into performance issues and

723
00:29:40,679 --> 00:29:43,140
you will find that the CPU is way faster

724
00:29:43,140 --> 00:29:46,080
than the GPU in some operations

725
00:29:46,080 --> 00:29:48,419
for example if I'm only running say 10

726
00:29:48,419 --> 00:29:51,539
sigmoid values then initializing the

727
00:29:51,539 --> 00:29:54,240
variables in the GPU copying variables

728
00:29:54,240 --> 00:29:56,700
from a hosted device running the kernel

729
00:29:56,700 --> 00:29:58,919
itself and then copying those variables

730
00:29:58,919 --> 00:30:01,620
back onto the host from the device will

731
00:30:01,620 --> 00:30:04,200
actually take more time than just step

732
00:30:04,200 --> 00:30:05,779
three or really the entire program

733
00:30:05,779 --> 00:30:09,120
itself is just not worth the extra time

734
00:30:09,120 --> 00:30:11,580
unless you're running highly parallel

735
00:30:11,580 --> 00:30:13,679
applications that require a highly

736
00:30:13,679 --> 00:30:16,620
parallel power of the GPU

737
00:30:16,620 --> 00:30:18,480
okay now I do know that that sounded

738
00:30:18,480 --> 00:30:20,340
like a lot and you probably are starting

739
00:30:20,340 --> 00:30:21,779
to understand a little bit of the

740
00:30:21,779 --> 00:30:24,419
concept and the sort of you know uh

741
00:30:24,419 --> 00:30:26,940
these these sort of beginner aspects or

742
00:30:26,940 --> 00:30:29,760
the the starting aspect of Cuda and how

743
00:30:29,760 --> 00:30:32,220
you should begin queer development now

744
00:30:32,220 --> 00:30:33,539
of course there will be a part two where

745
00:30:33,539 --> 00:30:35,279
I'll show you some actual code I think

746
00:30:35,279 --> 00:30:36,960
this video is long enough for now you

747
00:30:36,960 --> 00:30:38,220
might just want to you know go ahead and

748
00:30:38,220 --> 00:30:40,260
want to see some more Cuda blogs just

749
00:30:40,260 --> 00:30:42,360
want to digest all this all this Con all

750
00:30:42,360 --> 00:30:45,240
this content uh that I just gave you uh

751
00:30:45,240 --> 00:30:46,320
but that's going to be all for this

752
00:30:46,320 --> 00:30:47,760
video thank you very much for joining it

753
00:30:47,760 --> 00:30:48,960
today I really do hope you enjoyed

754
00:30:48,960 --> 00:30:50,340
today's video if you did please do make

755
00:30:50,340 --> 00:30:51,360
sure to leave a like down below and

756
00:30:51,360 --> 00:30:52,500
share the video with your family and

757
00:30:52,500 --> 00:30:54,000
friends if you think it could help that

758
00:30:54,000 --> 00:30:56,460
help them out too of course if you have

759
00:30:56,460 --> 00:30:57,539
any more questions suggestions or

760
00:30:57,539 --> 00:30:58,860
feedback please leave it down in the

761
00:30:58,860 --> 00:31:00,240
comment section below email it to me at

762
00:31:00,240 --> 00:31:01,980
teddymania gmail.com or to read it to me

763
00:31:01,980 --> 00:31:04,020
at tajimani of course if you really like

764
00:31:04,020 --> 00:31:05,340
my content you want to see more please

765
00:31:05,340 --> 00:31:06,720
do consider subscribing to my YouTube

766
00:31:06,720 --> 00:31:09,299
channel uh and of course turning on

767
00:31:09,299 --> 00:31:11,279
notifications if you think these videos

768
00:31:11,279 --> 00:31:12,480
help you out and you want to be notified

769
00:31:12,480 --> 00:31:14,940
whenever I release new content all right

770
00:31:14,940 --> 00:31:16,140
so thank you very much for joining me

771
00:31:16,140 --> 00:31:17,220
today that's going to be all for the

772
00:31:17,220 --> 00:31:19,500
video uh of course do do make sure to

773
00:31:19,500 --> 00:31:21,240
leave a like down below and subscribe if

774
00:31:21,240 --> 00:31:23,580
this content helps you out uh and you

775
00:31:23,580 --> 00:31:25,140
want to see more of it thank you very

776
00:31:25,140 --> 00:31:28,100
much goodbye
