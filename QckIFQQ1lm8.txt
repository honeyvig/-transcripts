1
00:00:00,000 --> 00:00:03,710
[Music]

2
00:00:03,710 --> 00:00:06,330
so hello there and welcome to another

3
00:00:06,330 --> 00:00:08,820
tutorial my name is Tammy Bakshi and

4
00:00:08,820 --> 00:00:11,370
welcome to another episode of AI cafe

5
00:00:11,370 --> 00:00:14,219
this is episode number 2 this time I'm

6
00:00:14,219 --> 00:00:16,590
currently in Boston at the AI worlds

7
00:00:16,590 --> 00:00:19,020
conference where I was invited for a

8
00:00:19,020 --> 00:00:21,810
discussion on a luncheon session

9
00:00:21,810 --> 00:00:24,269
actually with my mentor the CTO and VP

10
00:00:24,269 --> 00:00:27,090
of IBM Watson Rob hi who's not joining

11
00:00:27,090 --> 00:00:28,529
us for this very excel for the actual

12
00:00:28,529 --> 00:00:31,170
second episode of AI cafe so welcome Rob

13
00:00:31,170 --> 00:00:34,530
yeah hi Tim hey hey you guys great so

14
00:00:34,530 --> 00:00:36,450
now let's begin now in today's episode

15
00:00:36,450 --> 00:00:38,340
of AI cafe we're gonna be talking a lot

16
00:00:38,340 --> 00:00:40,770
about artificial intelligence on what to

17
00:00:40,770 --> 00:00:43,710
expect from AI but mainly what not to

18
00:00:43,710 --> 00:00:46,829
expect from AI you know there's a lot of

19
00:00:46,829 --> 00:00:49,050
hype around artificial intelligence you

20
00:00:49,050 --> 00:00:52,440
know what it can do or what a lot of

21
00:00:52,440 --> 00:00:54,120
people think it can do at least right

22
00:00:54,120 --> 00:00:55,800
yeah but since they're not actually in

23
00:00:55,800 --> 00:00:57,510
the backend you know do on the

24
00:00:57,510 --> 00:00:59,460
development side of AI they don't really

25
00:00:59,460 --> 00:01:02,070
have a very clear picture of what

26
00:01:02,070 --> 00:01:02,520
exactly

27
00:01:02,520 --> 00:01:04,890
AI is capable offering and how exactly

28
00:01:04,890 --> 00:01:07,110
it works I look for example a few days

29
00:01:07,110 --> 00:01:09,090
ago when I came from I attended IBM Talk

30
00:01:09,090 --> 00:01:11,580
I do not clarify the point that just

31
00:01:11,580 --> 00:01:13,290
because you know there are these are

32
00:01:13,290 --> 00:01:15,450
algorithms Karl Popper called artificial

33
00:01:15,450 --> 00:01:17,729
neural networks that doesn't mean that

34
00:01:17,729 --> 00:01:20,159
they're an exact replica of biological

35
00:01:20,159 --> 00:01:22,590
neural networks they are not human mind

36
00:01:22,590 --> 00:01:24,210
is incredibly common

37
00:01:24,210 --> 00:01:26,640
there's a lot of things about it that we

38
00:01:26,640 --> 00:01:28,020
don't even fully understand let alone

39
00:01:28,020 --> 00:01:30,540
try to recreate them exactly and Plus

40
00:01:30,540 --> 00:01:31,799
even apart from the fact that we don't

41
00:01:31,799 --> 00:01:33,150
completely understand them as you say

42
00:01:33,150 --> 00:01:35,159
why would we want to replicate it in the

43
00:01:35,159 --> 00:01:37,439
first place right why also take the

44
00:01:37,439 --> 00:01:39,479
limitations that our human mind has and

45
00:01:39,479 --> 00:01:41,400
put the same limitations in technology

46
00:01:41,400 --> 00:01:43,290
right there's no point to it so instead

47
00:01:43,290 --> 00:01:44,790
I have to really emphasize that

48
00:01:44,790 --> 00:01:46,710
artificial neural networks are instead

49
00:01:46,710 --> 00:01:49,110
loosely inspired by the way our brains

50
00:01:49,110 --> 00:01:51,750
work instead instead of being you know

51
00:01:51,750 --> 00:01:53,640
exact copies of the algorithms of the

52
00:01:53,640 --> 00:01:55,500
structure the structure is just slightly

53
00:01:55,500 --> 00:01:57,360
inspired by the way the brain works as a

54
00:01:57,360 --> 00:01:59,820
network of neurons and other nodes all

55
00:01:59,820 --> 00:02:02,189
but the actual algorithms are entirely

56
00:02:02,189 --> 00:02:04,500
different we have no idea how our brain

57
00:02:04,500 --> 00:02:05,240
functions

58
00:02:05,240 --> 00:02:08,000
itself all we know is that artificial

59
00:02:08,000 --> 00:02:09,160
neural networks use back propagation

60
00:02:09,160 --> 00:02:12,200
yeah that's right yeah we should we know

61
00:02:12,200 --> 00:02:13,880
what they don't do but you know I do

62
00:02:13,880 --> 00:02:14,959
think that this is a really important

63
00:02:14,959 --> 00:02:16,099
point because you know the end of the

64
00:02:16,099 --> 00:02:19,340
day we as human beings have certain

65
00:02:19,340 --> 00:02:21,769
capacities that make us human

66
00:02:21,769 --> 00:02:24,410
they say define you know who we are they

67
00:02:24,410 --> 00:02:26,959
define how well we do what we do but

68
00:02:26,959 --> 00:02:28,340
there's also limitations to what we

69
00:02:28,340 --> 00:02:30,709
always give a base to it some love you

70
00:02:30,709 --> 00:02:32,920
gotta ask why would we want to replicate

71
00:02:32,920 --> 00:02:35,810
exactly human mind both because you know

72
00:02:35,810 --> 00:02:37,069
look we've got like human minds out

73
00:02:37,069 --> 00:02:39,590
there already but also why we don't want

74
00:02:39,590 --> 00:02:41,600
to replicate the flaws oh yeah right

75
00:02:41,600 --> 00:02:43,519
it'd be so much more powerful what we

76
00:02:43,519 --> 00:02:45,500
could do is use the cognitive systems as

77
00:02:45,500 --> 00:02:48,260
AI systems to pick up from where he

78
00:02:48,260 --> 00:02:50,420
leave off so and then bring them

79
00:02:50,420 --> 00:02:52,100
together to work together to kind of

80
00:02:52,100 --> 00:02:54,200
salt some so the way they you know by

81
00:02:54,200 --> 00:02:55,519
themselves either one of them would say

82
00:02:55,519 --> 00:02:57,799
no exactly well and so what we can do

83
00:02:57,799 --> 00:03:01,010
with cognitive computing as we call it

84
00:03:01,010 --> 00:03:04,250
here um is we're not only looking at

85
00:03:04,250 --> 00:03:05,660
okay you know how can we replicate the

86
00:03:05,660 --> 00:03:07,549
human mind we're taking a look at how

87
00:03:07,549 --> 00:03:09,560
can we make humans and Technology

88
00:03:09,560 --> 00:03:11,900
collaborate in a better way right right

89
00:03:11,900 --> 00:03:14,510
how can we make it so humans want to and

90
00:03:14,510 --> 00:03:16,640
are you know and make it easy for

91
00:03:16,640 --> 00:03:19,010
actually humans to collaborate with

92
00:03:19,010 --> 00:03:20,989
technology like right now even doing

93
00:03:20,989 --> 00:03:22,250
something really simple forget like

94
00:03:22,250 --> 00:03:23,390
cancer screaming they're bringing in

95
00:03:23,390 --> 00:03:25,760
doing things simple ah simple tasks on

96
00:03:25,760 --> 00:03:26,420
your phone

97
00:03:26,420 --> 00:03:28,670
these can be annoying and the reason

98
00:03:28,670 --> 00:03:29,840
they're annoying is because it let's say

99
00:03:29,840 --> 00:03:31,670
I'm communicating with you wrong or you

100
00:03:31,670 --> 00:03:34,670
the viewing and I tell you as we were

101
00:03:34,670 --> 00:03:36,890
mentioning before send alarm for 6:00

102
00:03:36,890 --> 00:03:38,510
a.m. for me right you'll go to the clock

103
00:03:38,510 --> 00:03:40,549
is set alarm that was so natural

104
00:03:40,549 --> 00:03:42,440
mm-hm right you I didn't need to

105
00:03:42,440 --> 00:03:43,760
communicate I didn't need to click a

106
00:03:43,760 --> 00:03:45,920
button on your anything yeah with your

107
00:03:45,920 --> 00:03:47,660
phone you have to actually go over to

108
00:03:47,660 --> 00:03:49,459
the clock you just set the alarm it's

109
00:03:49,459 --> 00:03:52,420
such a manual and tedious process but

110
00:03:52,420 --> 00:03:55,010
through artificial intelligence systems

111
00:03:55,010 --> 00:03:57,470
we can create that collaboration you can

112
00:03:57,470 --> 00:03:59,209
bridge that gap between the humans and

113
00:03:59,209 --> 00:04:01,220
the technology and what we can do then

114
00:04:01,220 --> 00:04:03,470
is we can say oh Siri set an alarm for

115
00:04:03,470 --> 00:04:05,630
6:00 a.m. right and it does that but

116
00:04:05,630 --> 00:04:07,100
there's still something lacking in so

117
00:04:07,100 --> 00:04:08,450
Rob's would you like to sort of expand a

118
00:04:08,450 --> 00:04:11,700
little bit more on why what AI

119
00:04:11,700 --> 00:04:14,280
well I'm but what a guy is missing in

120
00:04:14,280 --> 00:04:16,169
their current implementations of it is a

121
00:04:16,169 --> 00:04:18,840
sense of what I call presence yeah so

122
00:04:18,840 --> 00:04:20,430
when you and I are talking and if you

123
00:04:20,430 --> 00:04:21,870
ask me to set the alarm for 6:00 a.m.

124
00:04:21,870 --> 00:04:25,290
the you know there it's not just the

125
00:04:25,290 --> 00:04:26,880
fact that I might be able to go do that

126
00:04:26,880 --> 00:04:29,970
for you in question but in doing so I'm

127
00:04:29,970 --> 00:04:31,770
also anticipating your need and I'm

128
00:04:31,770 --> 00:04:34,530
recognizing that hey if you pause for a

129
00:04:34,530 --> 00:04:36,180
moment in the process of asking me to go

130
00:04:36,180 --> 00:04:38,250
set alarm there's something meaningful

131
00:04:38,250 --> 00:04:40,410
behind that exactly on the flip side

132
00:04:40,410 --> 00:04:43,139
that is a having asked me to go set the

133
00:04:43,139 --> 00:04:45,720
alarm for you for 6 a.m. you're also

134
00:04:45,720 --> 00:04:47,760
getting some feedback from me right you

135
00:04:47,760 --> 00:04:49,500
know we have eye contact we have facial

136
00:04:49,500 --> 00:04:52,080
expression we have we have arm and hand

137
00:04:52,080 --> 00:04:53,970
movements and all which are breathe

138
00:04:53,970 --> 00:04:56,040
enforcing none of the fact that I

139
00:04:56,040 --> 00:04:57,540
understand what you just asked me to do

140
00:04:57,540 --> 00:04:59,880
I can now you can tell from my my facial

141
00:04:59,880 --> 00:05:01,680
gestures exactly that you know that I

142
00:05:01,680 --> 00:05:03,479
understood what you just asked for yeah

143
00:05:03,479 --> 00:05:05,580
but I can also use that to understand a

144
00:05:05,580 --> 00:05:06,450
little bit better whether that's

145
00:05:06,450 --> 00:05:08,010
something they is that the only thing

146
00:05:08,010 --> 00:05:09,540
they're looking for is there's something

147
00:05:09,540 --> 00:05:12,060
else going on and that back and forth is

148
00:05:12,060 --> 00:05:14,040
really essential in human communication

149
00:05:14,040 --> 00:05:16,410
right it's what makes it natural but

150
00:05:16,410 --> 00:05:17,880
it's also if we're really going to get

151
00:05:17,880 --> 00:05:20,250
these cognitive systems to amplify our

152
00:05:20,250 --> 00:05:21,810
own thinking exactly they're gonna have

153
00:05:21,810 --> 00:05:23,430
to do something similar exactly exactly

154
00:05:23,430 --> 00:05:25,470
but then again they wanna do something

155
00:05:25,470 --> 00:05:27,120
similar but what a lot of people think

156
00:05:27,120 --> 00:05:28,500
is that we're trying to replicate them

157
00:05:28,500 --> 00:05:30,750
yeah not sure yeah we're trying to make

158
00:05:30,750 --> 00:05:32,460
it so we can bridge that gap yet at the

159
00:05:32,460 --> 00:05:34,500
same time leave enough of gap that the

160
00:05:34,500 --> 00:05:37,590
limitations are left in that gap like

161
00:05:37,590 --> 00:05:39,180
for example cancer treatment okay

162
00:05:39,180 --> 00:05:42,810
one of the you know promising parts of

163
00:05:42,810 --> 00:05:44,789
AI is that it can do cancer treatment

164
00:05:44,789 --> 00:05:47,100
you know can do diagnosis so much faster

165
00:05:47,100 --> 00:05:48,510
and so much more accurately than a human

166
00:05:48,510 --> 00:05:48,720
can

167
00:05:48,720 --> 00:05:50,700
but the thing is what a lot of people

168
00:05:50,700 --> 00:05:53,460
don't realize is that AI won't be making

169
00:05:53,460 --> 00:05:55,680
the decision for the Kansas specialists

170
00:05:55,680 --> 00:05:57,210
Yeah right that's right and said what's

171
00:05:57,210 --> 00:05:58,320
gonna be doing is it's going to be

172
00:05:58,320 --> 00:06:00,900
providing them a lot of information very

173
00:06:00,900 --> 00:06:03,990
quickly that they can use to make a more

174
00:06:03,990 --> 00:06:06,660
informed a better decision yeah that's

175
00:06:06,660 --> 00:06:07,950
right in some cases that may be just

176
00:06:07,950 --> 00:06:09,300
simply reinforcing what they already

177
00:06:09,300 --> 00:06:10,680
knew absolutely but now

178
00:06:10,680 --> 00:06:12,330
given the evidence and now understand

179
00:06:12,330 --> 00:06:14,460
why what they were exacting and what

180
00:06:14,460 --> 00:06:16,139
they were thinking makes sense or in

181
00:06:16,139 --> 00:06:18,060
some cases is going to bring up ideas

182
00:06:18,060 --> 00:06:20,250
that they hadn't thought of themselves

183
00:06:20,250 --> 00:06:22,410
right maybe about something that's new

184
00:06:22,410 --> 00:06:23,820
that in the market that they're not

185
00:06:23,820 --> 00:06:25,949
aware of or they didn't know exactly how

186
00:06:25,949 --> 00:06:27,419
that could be applied to that patient's

187
00:06:27,419 --> 00:06:29,460
actually if all we can do is kind of

188
00:06:29,460 --> 00:06:31,080
reinforce their own thinking and then

189
00:06:31,080 --> 00:06:33,330
extend it with some new ideas exactly

190
00:06:33,330 --> 00:06:34,680
we're gonna make a tremendous difference

191
00:06:34,680 --> 00:06:36,090
in the healthcare industry completely

192
00:06:36,090 --> 00:06:37,770
Greek in fact I may have actually shared

193
00:06:37,770 --> 00:06:40,259
this saw on another another episode on

194
00:06:40,259 --> 00:06:41,759
my youtube channel all of as you

195
00:06:41,759 --> 00:06:42,870
probably know you know you're working

196
00:06:42,870 --> 00:06:44,820
with IBM Watson of course so you

197
00:06:44,820 --> 00:06:47,250
probably all remember this example there

198
00:06:47,250 --> 00:06:49,889
was a an IBM er who actually wanted to

199
00:06:49,889 --> 00:06:52,680
see if they can create or find new drugs

200
00:06:52,680 --> 00:06:56,280
for Parkinson's with IBM Watson hmm so

201
00:06:56,280 --> 00:06:56,759
what did they do

202
00:06:56,759 --> 00:06:58,889
mm hmm they talked I've been watching

203
00:06:58,889 --> 00:07:01,080
this drug discovery service and they you

204
00:07:01,080 --> 00:07:02,880
know fed on all these sorts of data

205
00:07:02,880 --> 00:07:04,770
points using the you know doctors health

206
00:07:04,770 --> 00:07:06,449
of special itself of course are not

207
00:07:06,449 --> 00:07:08,729
placing that we're helping on what it

208
00:07:08,729 --> 00:07:10,770
did is it once through the entire posit

209
00:07:10,770 --> 00:07:13,830
ori of drugs that has and it says these

210
00:07:13,830 --> 00:07:16,770
drugs which have never even been thought

211
00:07:16,770 --> 00:07:18,810
before yeah yeah by doctors to be linked

212
00:07:18,810 --> 00:07:20,400
to parkinson's apparently are more

213
00:07:20,400 --> 00:07:22,139
effective than current medicine well if

214
00:07:22,139 --> 00:07:23,880
I can find the association between the

215
00:07:23,880 --> 00:07:25,770
drugs that are out there the kinds of

216
00:07:25,770 --> 00:07:27,900
proteins of the act on exactly what that

217
00:07:27,900 --> 00:07:29,729
chemical reaction is and then therefore

218
00:07:29,729 --> 00:07:32,220
understand what their correlation might

219
00:07:32,220 --> 00:07:34,409
be between that drug that protein and

220
00:07:34,409 --> 00:07:36,240
other diseases that have similar kinds

221
00:07:36,240 --> 00:07:38,729
of protein and based effects and you

222
00:07:38,729 --> 00:07:40,380
know those are those are opening up a

223
00:07:40,380 --> 00:07:43,110
whole new idea of how these things that

224
00:07:43,110 --> 00:07:44,370
we may already know about could be

225
00:07:44,370 --> 00:07:46,349
reapplied to new things completely agree

226
00:07:46,349 --> 00:07:48,360
in fact if you think about it automation

227
00:07:48,360 --> 00:07:49,919
is something that's taking over us our

228
00:07:49,919 --> 00:07:52,560
lives so we're gonna write we've have we

229
00:07:52,560 --> 00:07:54,030
have these virtual agents for our phones

230
00:07:54,030 --> 00:07:56,699
right the the we make cars almost

231
00:07:56,699 --> 00:07:58,349
completely automatically this is our jaw

232
00:07:58,349 --> 00:08:01,159
then the cars drive themselves mm-hmm

233
00:08:01,159 --> 00:08:03,539
but what we haven't completely done yet

234
00:08:03,539 --> 00:08:07,259
is imagine you're a doctor okay and

235
00:08:07,259 --> 00:08:08,940
you're going through you know spending

236
00:08:08,940 --> 00:08:11,990
years finding drugs for diseases

237
00:08:11,990 --> 00:08:14,660
that is such an inefficient process hmm

238
00:08:14,660 --> 00:08:16,580
you want to actually take a look at what

239
00:08:16,580 --> 00:08:17,960
we've done with you know Watson and they

240
00:08:17,960 --> 00:08:19,850
are drug discover you think why haven't

241
00:08:19,850 --> 00:08:21,740
we mended this before Yeah right

242
00:08:21,740 --> 00:08:23,630
and that's where the AI comes in well it

243
00:08:23,630 --> 00:08:25,220
isn't is but it was interesting about

244
00:08:25,220 --> 00:08:26,810
the case that you described is this a

245
00:08:26,810 --> 00:08:29,180
perfect example where it in efficiencies

246
00:08:29,180 --> 00:08:32,330
exist because we all have our biases act

247
00:08:32,330 --> 00:08:35,270
right we tend to as if you're in the

248
00:08:35,270 --> 00:08:37,580
drug discovery space we go back to the

249
00:08:37,580 --> 00:08:39,620
things that we know say and we know the

250
00:08:39,620 --> 00:08:40,850
things that we know because we've been

251
00:08:40,850 --> 00:08:43,400
reinforced on how well those things have

252
00:08:43,400 --> 00:08:45,080
worked for us in the past and that

253
00:08:45,080 --> 00:08:47,750
creates this sort of tight loop exactly

254
00:08:47,750 --> 00:08:50,690
in results and bias and so we only look

255
00:08:50,690 --> 00:08:52,130
for answers in the way that we think

256
00:08:52,130 --> 00:08:54,590
about the problem exactly whereas most

257
00:08:54,590 --> 00:08:56,930
of the opportunity I think exists in

258
00:08:56,930 --> 00:08:58,910
places where we're not thinking about

259
00:08:58,910 --> 00:09:00,020
the questions without thinking to ask

260
00:09:00,020 --> 00:09:02,420
exactly ever you find a system that

261
00:09:02,420 --> 00:09:04,850
inspires a spoon finance system that

262
00:09:04,850 --> 00:09:06,530
brings just the right information to the

263
00:09:06,530 --> 00:09:09,050
right moment right in the right way and

264
00:09:09,050 --> 00:09:11,000
interact with this in a way that causes

265
00:09:11,000 --> 00:09:13,190
us to think differently the result will

266
00:09:13,190 --> 00:09:14,780
be that it opens our mind to different

267
00:09:14,780 --> 00:09:17,630
possibilities and you know being more

268
00:09:17,630 --> 00:09:19,130
effective and more efficiently

269
00:09:19,130 --> 00:09:22,670
exactly in fact some of the barebone

270
00:09:22,670 --> 00:09:24,680
reasons for why AI is so much better

271
00:09:24,680 --> 00:09:26,930
than us it's first of all again not

272
00:09:26,930 --> 00:09:28,280
trying to replicate the human mind so

273
00:09:28,280 --> 00:09:30,740
those limitations like for example are

274
00:09:30,740 --> 00:09:32,300
biased towards simple and repeatable

275
00:09:32,300 --> 00:09:34,730
patterns yeah they're moved yeah but for

276
00:09:34,730 --> 00:09:36,860
example if I'm looking at you know the

277
00:09:36,860 --> 00:09:38,570
Bitcoin price over the past few years

278
00:09:38,570 --> 00:09:42,440
right my brain will tend to go towards

279
00:09:42,440 --> 00:09:43,670
simple in the fuel patterns

280
00:09:43,670 --> 00:09:46,010
yeah and my brain won't see those habits

281
00:09:46,010 --> 00:09:47,600
yeah my brain will think it's just

282
00:09:47,600 --> 00:09:51,010
random noise yeah but AI can find small

283
00:09:51,010 --> 00:09:55,550
patterns that aren't necessarily simple

284
00:09:55,550 --> 00:09:58,220
right it can find patterns that don't

285
00:09:58,220 --> 00:09:59,930
repeat themselves very often it'll find

286
00:09:59,930 --> 00:10:02,330
those very very small distinct patterns

287
00:10:02,330 --> 00:10:04,220
yeah the patterns of meaning exactly

288
00:10:04,220 --> 00:10:07,220
find the meaning in such vast complex

289
00:10:07,220 --> 00:10:09,950
data yeah that's why it's so special and

290
00:10:09,950 --> 00:10:11,660
that's why it's so useful for example as

291
00:10:11,660 --> 00:10:14,330
mentioned drug discovery and the rob was

292
00:10:14,330 --> 00:10:15,410
actually mentioning this during our

293
00:10:15,410 --> 00:10:17,660
session later earlier this

294
00:10:17,660 --> 00:10:19,850
earlier today and that is that for

295
00:10:19,850 --> 00:10:22,070
example as humans let's just say we find

296
00:10:22,070 --> 00:10:24,140
this truck right you might think oh wait

297
00:10:24,140 --> 00:10:25,580
we just someone upon the drug this is

298
00:10:25,580 --> 00:10:27,050
our first answer this is something that

299
00:10:27,050 --> 00:10:28,700
we might want to go towards this is

300
00:10:28,700 --> 00:10:29,870
something that we want to continue

301
00:10:29,870 --> 00:10:31,370
research there right there

302
00:10:31,370 --> 00:10:33,080
but the thing that AI does is it says it

303
00:10:33,080 --> 00:10:34,700
won't just stop at the first answer if

304
00:10:34,700 --> 00:10:36,530
it'll continue looking through all the

305
00:10:36,530 --> 00:10:40,370
answers and say this yeah these are the

306
00:10:40,370 --> 00:10:42,350
drugs that you need to test it'll say

307
00:10:42,350 --> 00:10:44,660
these drugs definitely won't work filter

308
00:10:44,660 --> 00:10:46,460
them out mmm look at these always test

309
00:10:46,460 --> 00:10:48,980
these on the doctors boys test them

310
00:10:48,980 --> 00:10:51,200
I'm similarly with question answering

311
00:10:51,200 --> 00:10:55,160
systems okay our decisions right sort of

312
00:10:55,160 --> 00:10:57,260
decision system it's not stopping how

313
00:10:57,260 --> 00:10:58,310
the first answer it's looking through

314
00:10:58,310 --> 00:11:00,380
everything saying where could really be

315
00:11:00,380 --> 00:11:02,990
the best of all will turned an example

316
00:11:02,990 --> 00:11:03,770
that we got to bring to your attention

317
00:11:03,770 --> 00:11:06,290
exactly and that's right yeah I mean in

318
00:11:06,290 --> 00:11:07,910
the point that we were making earlier is

319
00:11:07,910 --> 00:11:10,610
that often times in any kind of business

320
00:11:10,610 --> 00:11:12,710
in the situation we're a little bit

321
00:11:12,710 --> 00:11:14,840
motivated just to find the first best

322
00:11:14,840 --> 00:11:17,030
answer exactly right not the best answer

323
00:11:17,030 --> 00:11:18,500
but the first one that we find he's good

324
00:11:18,500 --> 00:11:20,630
enough if it's the problem exact because

325
00:11:20,630 --> 00:11:22,430
if it works then we're going to use it

326
00:11:22,430 --> 00:11:25,160
on the next issue exactly and our day is

327
00:11:25,160 --> 00:11:27,050
spent almost you know I'm in and out

328
00:11:27,050 --> 00:11:28,940
going through this series of decisions

329
00:11:28,940 --> 00:11:31,070
like that completely the result being of

330
00:11:31,070 --> 00:11:32,750
course this is what drives the same two

331
00:11:32,750 --> 00:11:35,810
holes and so we have dark alleys and two

332
00:11:35,810 --> 00:11:38,450
things that we can't get out of just

333
00:11:38,450 --> 00:11:39,560
because we didn't consider what the

334
00:11:39,560 --> 00:11:41,090
alternatives were and of course you know

335
00:11:41,090 --> 00:11:42,740
there's a time essence to all this as

336
00:11:42,740 --> 00:11:44,050
well yeah we got to find these answers

337
00:11:44,050 --> 00:11:46,820
really without it being something that I

338
00:11:46,820 --> 00:11:49,100
drag off like 10 issue this you can't

339
00:11:49,100 --> 00:11:51,170
spend the entire month off just one oh

340
00:11:51,170 --> 00:11:51,680
that's right

341
00:11:51,680 --> 00:11:53,180
right you have to do it quickly but at

342
00:11:53,180 --> 00:11:54,590
the same time it needs to be effective

343
00:11:54,590 --> 00:11:56,270
there's the quantity but it also has to

344
00:11:56,270 --> 00:11:57,740
be you know high quality yeah that's

345
00:11:57,740 --> 00:11:59,690
right that's what helps us do it helps

346
00:11:59,690 --> 00:12:01,880
us find the best decisions in the

347
00:12:01,880 --> 00:12:04,100
fastest way right because it allows us

348
00:12:04,100 --> 00:12:06,650
to do our jobs so much more efficiently

349
00:12:06,650 --> 00:12:08,090
that's right and again it's not about it

350
00:12:08,090 --> 00:12:09,680
making the decisions for us it's about

351
00:12:09,680 --> 00:12:11,960
it Britain inspiring us too big better

352
00:12:11,960 --> 00:12:14,870
decision exactly exactly so there's a

353
00:12:14,870 --> 00:12:16,820
lot to be that to be said about that but

354
00:12:16,820 --> 00:12:18,050
I also think there are some things we're

355
00:12:18,050 --> 00:12:20,650
missing yes yeah I'm sure Zee presuming

356
00:12:20,650 --> 00:12:23,590
hey I can do everything now that humans

357
00:12:23,590 --> 00:12:25,870
can do guys it's very easy for us as

358
00:12:25,870 --> 00:12:28,570
human beings to imagine yeah that this

359
00:12:28,570 --> 00:12:30,250
because it can solved this problem which

360
00:12:30,250 --> 00:12:31,630
is very similar to the problem that I'm

361
00:12:31,630 --> 00:12:33,670
familiar with being able to solve means

362
00:12:33,670 --> 00:12:35,110
that it's necessarily I'll be able to

363
00:12:35,110 --> 00:12:36,760
answer every other kind of question out

364
00:12:36,760 --> 00:12:41,800
there it's not about solving the broad

365
00:12:41,800 --> 00:12:43,810
range of things that human beings are

366
00:12:43,810 --> 00:12:47,350
able to think of but we also shouldn't

367
00:12:47,350 --> 00:12:49,780
presume that that's our goal either no

368
00:12:49,780 --> 00:12:52,540
yes not we're not thriving to go great

369
00:12:52,540 --> 00:12:54,340
there you know as he said replicas of

370
00:12:54,340 --> 00:12:55,690
the human mind what we got otherwise

371
00:12:55,690 --> 00:12:57,820
referred to as jelly I yeah there are

372
00:12:57,820 --> 00:12:59,860
places where we can apply the technique

373
00:12:59,860 --> 00:13:02,920
of artificially reasoning about a

374
00:13:02,920 --> 00:13:05,500
problem that by itself doesn't

375
00:13:05,500 --> 00:13:07,270
necessarily replicate the human but yet

376
00:13:07,270 --> 00:13:09,070
still causes yeah think that things

377
00:13:09,070 --> 00:13:11,080
differently and don't presume that we

378
00:13:11,080 --> 00:13:12,460
understand the human mind well enough to

379
00:13:12,460 --> 00:13:15,250
be able to assume that later on we could

380
00:13:15,250 --> 00:13:17,830
ever get to the point of creating a

381
00:13:17,830 --> 00:13:19,510
fully replicated human mind in these

382
00:13:19,510 --> 00:13:21,520
artificial intelligence systems exactly

383
00:13:21,520 --> 00:13:23,110
and as we said earlier that's not even

384
00:13:23,110 --> 00:13:25,240
the point anyway because doing so is

385
00:13:25,240 --> 00:13:26,350
only mean that we're replicating the

386
00:13:26,350 --> 00:13:28,510
same flaws yeah exactly

387
00:13:28,510 --> 00:13:30,640
but you know there is an opportunity and

388
00:13:30,640 --> 00:13:32,770
there's economic incentive to build a

389
00:13:32,770 --> 00:13:34,960
system that will augment our intolerance

390
00:13:34,960 --> 00:13:37,210
absolutely no extend it was sort of

391
00:13:37,210 --> 00:13:39,220
strengthen our own cognitive

392
00:13:39,220 --> 00:13:42,430
capabilities and extend our intelligence

393
00:13:42,430 --> 00:13:45,540
our reach right your cognitive reach um

394
00:13:45,540 --> 00:13:48,610
which makes it very similar to almost

395
00:13:48,610 --> 00:13:51,420
every other tool yes that we have ever

396
00:13:51,420 --> 00:13:53,950
experienced that has had lasting value

397
00:13:53,950 --> 00:13:55,690
I'll think about the history of all the

398
00:13:55,690 --> 00:13:56,980
tools that have ever been created

399
00:13:56,980 --> 00:13:58,360
yeah the one thing that you'll find

400
00:13:58,360 --> 00:14:00,520
consistent across all those tools is

401
00:14:00,520 --> 00:14:01,840
they've had the effect of either

402
00:14:01,840 --> 00:14:04,150
increase our strength or sting our reach

403
00:14:04,150 --> 00:14:06,850
right whether those were hydraulics or

404
00:14:06,850 --> 00:14:09,610
pneumatics or pulleys and levers or

405
00:14:09,610 --> 00:14:11,080
hammers or I mean all these kinds of

406
00:14:11,080 --> 00:14:13,060
tools of good they go yeah have had that

407
00:14:13,060 --> 00:14:15,610
same character absolutely absolutely and

408
00:14:15,610 --> 00:14:17,770
like for example now if we would use

409
00:14:17,770 --> 00:14:19,600
artificial intelligence if we were to

410
00:14:19,600 --> 00:14:23,230
use what AI is good at for

411
00:14:23,230 --> 00:14:24,610
for example pattern

412
00:14:24,610 --> 00:14:26,949
okay if we were to use it in fields like

413
00:14:26,949 --> 00:14:28,809
say self-driving cars yeah

414
00:14:28,809 --> 00:14:30,129
that's extending our reach it's

415
00:14:30,129 --> 00:14:33,089
extending what we can do as humans yeah

416
00:14:33,089 --> 00:14:35,739
like for example as a cancer specialist

417
00:14:35,739 --> 00:14:37,649
you don't need to spend as much time

418
00:14:37,649 --> 00:14:39,670
necessarily finding the correct

419
00:14:39,670 --> 00:14:41,589
information and diagnosing the patient

420
00:14:41,589 --> 00:14:43,269
then working on the treatment that's all

421
00:14:43,269 --> 00:14:45,369
you need to do is use the AI find the

422
00:14:45,369 --> 00:14:47,739
right resources and from there yeah I

423
00:14:47,739 --> 00:14:48,999
know you'd make advantage it makes

424
00:14:48,999 --> 00:14:50,949
better decisions and faster decisions

425
00:14:50,949 --> 00:14:51,610
that's what yeah

426
00:14:51,610 --> 00:14:53,439
thank you Michael without sacrificing on

427
00:14:53,439 --> 00:14:54,970
accuracy in fact increasing yeah yeah

428
00:14:54,970 --> 00:14:56,379
and this becomes a little bit more

429
00:14:56,379 --> 00:14:57,549
obvious we'll talk about something like

430
00:14:57,549 --> 00:14:59,739
ecology and the benefits that will bring

431
00:14:59,739 --> 00:15:02,319
to the healthcare professions I mean but

432
00:15:02,319 --> 00:15:03,790
think about it in our everyday lives

433
00:15:03,790 --> 00:15:05,290
oh how many decisions we make every

434
00:15:05,290 --> 00:15:07,869
single day and we don't know home or in

435
00:15:07,869 --> 00:15:10,179
the office or you know in in you know

436
00:15:10,179 --> 00:15:12,610
going to the doctor or they're driving

437
00:15:12,610 --> 00:15:14,379
their cars how many of those decisions

438
00:15:14,379 --> 00:15:16,959
that is he said we don't think about but

439
00:15:16,959 --> 00:15:19,149
yeah if we had the benefits of a

440
00:15:19,149 --> 00:15:21,730
cognitive system sort of challenging us

441
00:15:21,730 --> 00:15:22,899
to think about the problem well

442
00:15:22,899 --> 00:15:24,610
differently would change the way that we

443
00:15:24,610 --> 00:15:27,100
come to these conclusions and the

444
00:15:27,100 --> 00:15:28,329
efficiencies of our day

445
00:15:28,329 --> 00:15:31,980
exactly alright so that concludes a

446
00:15:31,980 --> 00:15:35,679
ihcafe episode number two thank you very

447
00:15:35,679 --> 00:15:36,819
much everyone for joining you today

448
00:15:36,819 --> 00:15:38,139
thank you very much for joining wrong

449
00:15:38,139 --> 00:15:39,730
thank you

450
00:15:39,730 --> 00:15:41,470
of course thank you I hope to do another

451
00:15:41,470 --> 00:15:43,029
video with you very soon in fact if you

452
00:15:43,029 --> 00:15:44,319
haven't already watched the previous

453
00:15:44,319 --> 00:15:46,329
video I did with Rob please do check

454
00:15:46,329 --> 00:15:47,649
that out there will be a link down in

455
00:15:47,649 --> 00:15:48,669
the description below

456
00:15:48,669 --> 00:15:50,290
apart from that though if you enjoyed

457
00:15:50,290 --> 00:15:51,369
this video please do make sure to leave

458
00:15:51,369 --> 00:15:53,619
a like down below apart from that if you

459
00:15:53,619 --> 00:15:55,059
have any more questions suggestions or

460
00:15:55,059 --> 00:15:56,589
feedback you can leave it down in the

461
00:15:56,589 --> 00:15:57,999
comment section below email it to me

462
00:15:57,999 --> 00:15:59,860
attaching a gmail comm unit to me

463
00:15:59,860 --> 00:16:02,230
attaching any and raah hi where can the

464
00:16:02,230 --> 00:16:04,329
viewers contact you at our high ion

465
00:16:04,329 --> 00:16:08,110
tweet on Twitter and as Robert hi on

466
00:16:08,110 --> 00:16:08,649
LinkedIn

467
00:16:08,649 --> 00:16:11,199
great apart from that though if you

468
00:16:11,199 --> 00:16:13,389
really do you know enjoy this content

469
00:16:13,389 --> 00:16:14,529
and want to see more of it please do

470
00:16:14,529 --> 00:16:15,790
consider subscribing to the channel as

471
00:16:15,790 --> 00:16:16,869
models that really does help out a lot

472
00:16:16,869 --> 00:16:18,249
and that's gonna be it for this video

473
00:16:18,249 --> 00:16:20,199
thank you very much goodbye everyone

474
00:16:20,199 --> 00:16:22,559
thank you
