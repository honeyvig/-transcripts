1
00:00:00,030 --> 00:00:02,040
so hello there and welcome to another

2
00:00:02,040 --> 00:00:04,410
tutorial my name is Terry Bakshi and

3
00:00:04,410 --> 00:00:07,109
today we're going to be going over LLVM

4
00:00:07,109 --> 00:00:10,620
compiler infrastructure now LLVM is an

5
00:00:10,620 --> 00:00:13,290
absolutely fascinating piece of software

6
00:00:13,290 --> 00:00:16,470
and the idea is this how can you make it

7
00:00:16,470 --> 00:00:18,930
easier how can we make it faster how can

8
00:00:18,930 --> 00:00:22,050
we introduce more reuse of code in the

9
00:00:22,050 --> 00:00:24,990
compiler development world now first of

10
00:00:24,990 --> 00:00:26,910
all let's take a bit of a step back and

11
00:00:26,910 --> 00:00:28,619
let's start off by talking about

12
00:00:28,619 --> 00:00:31,710
compilers now of course as developers

13
00:00:31,710 --> 00:00:34,320
what you interact with on a day to day

14
00:00:34,320 --> 00:00:36,329
basis would be compilers whatever you

15
00:00:36,329 --> 00:00:41,010
write C or C++ or swift or Julia or rust

16
00:00:41,010 --> 00:00:44,070
code you are interacting with a compiler

17
00:00:44,070 --> 00:00:46,500
when you writes a Python code Ruby code

18
00:00:46,500 --> 00:00:48,390
you're interacting with what's known as

19
00:00:48,390 --> 00:00:50,219
an interpreter we'll talk about those

20
00:00:50,219 --> 00:00:52,020
later and why they're special but for

21
00:00:52,020 --> 00:00:54,030
today let's talk a bit more about

22
00:00:54,030 --> 00:00:57,149
compilers now think about this let's

23
00:00:57,149 --> 00:00:59,070
just say I were to give you as a

24
00:00:59,070 --> 00:01:02,129
developer some sort of C code so of

25
00:01:02,129 --> 00:01:04,830
course I would be writing a dot C file

26
00:01:04,830 --> 00:01:07,530
or if I were writing C++ code this

27
00:01:07,530 --> 00:01:09,540
depends on your convention but you would

28
00:01:09,540 --> 00:01:13,110
usually call it a CPP or a C X X file

29
00:01:13,110 --> 00:01:16,610
right so single now think about how

30
00:01:16,610 --> 00:01:19,710
exactly your computer your machine

31
00:01:19,710 --> 00:01:22,320
actually knows what to do with the code

32
00:01:22,320 --> 00:01:24,180
that you've written now of course your

33
00:01:24,180 --> 00:01:27,119
CPU is not gonna understand C code it

34
00:01:27,119 --> 00:01:29,549
needs to be translated down to machine

35
00:01:29,549 --> 00:01:32,340
code individual instructions that your

36
00:01:32,340 --> 00:01:34,619
CPU can go ahead and execute or at least

37
00:01:34,619 --> 00:01:37,380
understand we'll get more into what

38
00:01:37,380 --> 00:01:39,360
exactly the differences in future

39
00:01:39,360 --> 00:01:41,790
episodes but for now let's just say we

40
00:01:41,790 --> 00:01:45,360
need to take our C C++ files and we need

41
00:01:45,360 --> 00:01:47,550
to convert them to some kind

42
00:01:47,550 --> 00:01:50,400
of machine code so we need to convert

43
00:01:50,400 --> 00:01:55,400
from here to say x86 or maybe arm

44
00:01:55,400 --> 00:01:58,430
assembly maybe we need to convert to

45
00:01:58,430 --> 00:02:02,490
PowerPC right so it really depends on

46
00:02:02,490 --> 00:02:04,410
what architecture you're trying to learn

47
00:02:04,410 --> 00:02:06,840
the code on and this is the role of the

48
00:02:06,840 --> 00:02:09,330
compiler taking your high-level code

49
00:02:09,330 --> 00:02:12,210
that's relatively much easier to write

50
00:02:12,210 --> 00:02:14,880
and converting it down to machine code

51
00:02:14,880 --> 00:02:17,520
but there's a bit of a problem when you

52
00:02:17,520 --> 00:02:20,580
write code you have intentions for what

53
00:02:20,580 --> 00:02:22,860
you want the computer to achieve you

54
00:02:22,860 --> 00:02:24,720
have some sort of input you want to get

55
00:02:24,720 --> 00:02:26,760
some sort of output and you're providing

56
00:02:26,760 --> 00:02:28,740
the computer with a way to translate

57
00:02:28,740 --> 00:02:31,650
that input to output not the compiler

58
00:02:31,650 --> 00:02:35,000
needs to understand your underlying

59
00:02:35,000 --> 00:02:37,800
intentions behind the code because if it

60
00:02:37,800 --> 00:02:40,800
can't then it's gonna do a kind of naive

61
00:02:40,800 --> 00:02:42,570
translation from your code to machine

62
00:02:42,570 --> 00:02:45,290
code and that is extremely inefficient

63
00:02:45,290 --> 00:02:48,650
think about it like a loop where you say

64
00:02:48,650 --> 00:02:55,320
X is equal to five right and while X is

65
00:02:55,320 --> 00:02:59,550
less than ten go ahead and increment X

66
00:02:59,550 --> 00:03:04,200
so go ahead and take X and increment it

67
00:03:04,200 --> 00:03:07,260
by one now really what you're doing is

68
00:03:07,260 --> 00:03:09,060
you're trying to say all right we want X

69
00:03:09,060 --> 00:03:11,550
to be nine and if the compiler were to

70
00:03:11,550 --> 00:03:13,350
just run this as it is

71
00:03:13,350 --> 00:03:15,750
you would get X's equals nine eventually

72
00:03:15,750 --> 00:03:18,450
but it would take a bunch of CPU cycles

73
00:03:18,450 --> 00:03:21,570
so what if the compiler could

74
00:03:21,570 --> 00:03:23,910
automatically understand that hey you

75
00:03:23,910 --> 00:03:26,100
just want X to be nine so instead of

76
00:03:26,100 --> 00:03:28,530
setting it to five and then looping

77
00:03:28,530 --> 00:03:30,209
through and checking the condition every

78
00:03:30,209 --> 00:03:31,920
time and incrementing and doing all of

79
00:03:31,920 --> 00:03:34,260
this nonsense why not just send it

80
00:03:34,260 --> 00:03:36,660
tonight it's that simple this is called

81
00:03:36,660 --> 00:03:39,950
constant folding it's one of the many

82
00:03:39,950 --> 00:03:42,300
optimizations that a compiler can apply

83
00:03:42,300 --> 00:03:44,400
to your code to automatically make it

84
00:03:44,400 --> 00:03:46,620
faster without you needing to write

85
00:03:46,620 --> 00:03:48,180
better code in the first place it's

86
00:03:48,180 --> 00:03:49,980
super convenient there's all sorts of

87
00:03:49,980 --> 00:03:51,420
other optimizations like for example

88
00:03:51,420 --> 00:03:54,120
function inlining where when you call a

89
00:03:54,120 --> 00:03:56,490
function if it's short enough instead of

90
00:03:56,490 --> 00:03:58,830
actually going and calling the function

91
00:03:58,830 --> 00:04:00,390
things in stock and plopping them after

92
00:04:00,390 --> 00:04:02,400
what it's gonna do is it's just gonna

93
00:04:02,400 --> 00:04:04,560
take the code from that function and

94
00:04:04,560 --> 00:04:07,110
align it wherever you called it it's

95
00:04:07,110 --> 00:04:07,890
that simple

96
00:04:07,890 --> 00:04:10,710
and by doing so it can in some cases the

97
00:04:10,710 --> 00:04:13,080
greatly improve the performance of your

98
00:04:13,080 --> 00:04:16,580
programs but there's a bit of a problem

99
00:04:16,580 --> 00:04:20,280
almost all of the compilers written in

100
00:04:20,280 --> 00:04:20,940
the past

101
00:04:20,940 --> 00:04:23,940
we're monolithic compilers what that

102
00:04:23,940 --> 00:04:25,440
means is that they would have their own

103
00:04:25,440 --> 00:04:28,730
little sets of optimizations or or

104
00:04:28,730 --> 00:04:30,690
transformations that they plan your code

105
00:04:30,690 --> 00:04:33,960
and only that compiler would ever be

106
00:04:33,960 --> 00:04:35,940
able to use those optimizations and if

107
00:04:35,940 --> 00:04:37,200
you want to introduce new

108
00:04:37,200 --> 00:04:39,180
transformations maybe you want to insert

109
00:04:39,180 --> 00:04:40,770
some instrumentation only we have a

110
00:04:40,770 --> 00:04:42,510
brand new idea of how you can make your

111
00:04:42,510 --> 00:04:44,070
programs faster for a very specific

112
00:04:44,070 --> 00:04:46,620
domain well you're kind of out of luck

113
00:04:46,620 --> 00:04:47,880
because you have to deal with the

114
00:04:47,880 --> 00:04:49,680
monolithic nature of the compiler and

115
00:04:49,680 --> 00:04:52,110
somehow integrate your passes your

116
00:04:52,110 --> 00:04:54,930
transformations into it and this is

117
00:04:54,930 --> 00:04:57,750
where LLVM comes in instead of having

118
00:04:57,750 --> 00:05:00,810
this one blackbox compiler that takes

119
00:05:00,810 --> 00:05:03,390
your code and just widely translates the

120
00:05:03,390 --> 00:05:07,200
machine code instead LLVM has a modular

121
00:05:07,200 --> 00:05:09,840
architecture enabling anyone to go ahead

122
00:05:09,840 --> 00:05:12,930
and extend it however they wish so think

123
00:05:12,930 --> 00:05:14,850
about it like this instead of going

124
00:05:14,850 --> 00:05:17,460
directly from C to assembly with a bunch

125
00:05:17,460 --> 00:05:20,490
of who knows what in between what if we

126
00:05:20,490 --> 00:05:23,570
could clearly define what exactly that

127
00:05:23,570 --> 00:05:26,040
intermediate stage represents for your

128
00:05:26,040 --> 00:05:30,390
code this is called an IR intermediate

129
00:05:30,390 --> 00:05:32,340
representation where particularly in

130
00:05:32,340 --> 00:05:36,300
this case it's called the LLVM IR LLVM

131
00:05:36,300 --> 00:05:38,460
intermediate representation so what's

132
00:05:38,460 --> 00:05:40,350
gonna happen is you're gonna take let's

133
00:05:40,350 --> 00:05:44,340
just say a C file it's going to go to a

134
00:05:44,340 --> 00:05:47,910
dot ll file which is your dot LLVM IR

135
00:05:47,910 --> 00:05:50,760
file and this will be converted to your

136
00:05:50,760 --> 00:05:53,880
assembly and of course your machine code

137
00:05:53,880 --> 00:05:57,300
now when you convert C to LLVM I arm

138
00:05:57,300 --> 00:06:01,110
it's not just static code the LLVM AR

139
00:06:01,110 --> 00:06:04,460
goes through a series of transformations

140
00:06:04,460 --> 00:06:10,460
and then from those transformations back

141
00:06:10,460 --> 00:06:12,600
into LLVM i

142
00:06:12,600 --> 00:06:15,270
code and this will happen over and over

143
00:06:15,270 --> 00:06:18,150
and over again until LLVM says I'm done

144
00:06:18,150 --> 00:06:20,670
optimizing this program then an

145
00:06:20,670 --> 00:06:23,910
LLVM back-end will kick in and the

146
00:06:23,910 --> 00:06:26,970
backend will take this platform generic

147
00:06:26,970 --> 00:06:29,730
LLVM code and you can read the platform

148
00:06:29,730 --> 00:06:33,360
specific assembly code for example let's

149
00:06:33,360 --> 00:06:35,370
just say you're compiling on x86 arm

150
00:06:35,370 --> 00:06:38,880
risk 5 PowerPC whatever it might be no

151
00:06:38,880 --> 00:06:41,040
matter what you're gonna have in most

152
00:06:41,040 --> 00:06:45,180
cases the same LLVM IR code it'll be

153
00:06:45,180 --> 00:06:47,310
optimized the same way but then

154
00:06:47,310 --> 00:06:49,050
depending on the architecture you're

155
00:06:49,050 --> 00:06:51,150
compiling for a different back-end will

156
00:06:51,150 --> 00:06:53,400
kick in and convert that to native

157
00:06:53,400 --> 00:06:56,700
assembly that is the idea behind LLVM

158
00:06:56,700 --> 00:06:59,520
now there are many many more things you

159
00:06:59,520 --> 00:07:01,920
can do with LLVM for example let's take

160
00:07:01,920 --> 00:07:03,510
a look at some other languages now we

161
00:07:03,510 --> 00:07:07,500
know that clang for a fact uses LLVM

162
00:07:07,500 --> 00:07:12,030
clang is of course a c compiler now GCC

163
00:07:12,030 --> 00:07:14,640
and other c compilers jumped it's only

164
00:07:14,640 --> 00:07:18,420
clang that uses LOV m however there are

165
00:07:18,420 --> 00:07:21,840
other languages altogether that use LLVM

166
00:07:21,840 --> 00:07:23,910
compiler infrastructure some of these

167
00:07:23,910 --> 00:07:26,550
most notably would be swift rust and

168
00:07:26,550 --> 00:07:28,860
Julia Julia you may know as a

169
00:07:28,860 --> 00:07:31,620
just-in-time compiled language that's

170
00:07:31,620 --> 00:07:33,600
right LLVM doesn't just need to be ahead

171
00:07:33,600 --> 00:07:35,700
of time compiled like this it can even

172
00:07:35,700 --> 00:07:38,520
be just-in-time compiled as the Julia

173
00:07:38,520 --> 00:07:40,620
compiler does enabling them to have

174
00:07:40,620 --> 00:07:42,750
super powerful in language features

175
00:07:42,750 --> 00:07:45,750
enabling lengths or frameworks like flux

176
00:07:45,750 --> 00:07:48,920
and zygote to even exist anyhow back to

177
00:07:48,920 --> 00:07:52,410
LLVM now think about this there's a set

178
00:07:52,410 --> 00:07:54,900
of transformations over here inside of

179
00:07:54,900 --> 00:07:59,670
this LLVM ir domain but sometimes the

180
00:07:59,670 --> 00:08:02,670
thing is that it's important to

181
00:08:02,670 --> 00:08:05,550
understand the high level code that the

182
00:08:05,550 --> 00:08:08,400
Rossi file provides in order to provide

183
00:08:08,400 --> 00:08:11,660
more meaningful and language specific

184
00:08:11,660 --> 00:08:14,340
optimizations if you think about it C is

185
00:08:14,340 --> 00:08:16,920
still relatively low level and so when

186
00:08:16,920 --> 00:08:18,040
you go from seat

187
00:08:18,040 --> 00:08:20,920
I are sure you're decomposing structure

188
00:08:20,920 --> 00:08:23,640
a little bit but it's not too bad

189
00:08:23,640 --> 00:08:26,860
however when it comes to a really high

190
00:08:26,860 --> 00:08:29,590
level language like swift where you give

191
00:08:29,590 --> 00:08:32,110
up a lot of control to the compiler you

192
00:08:32,110 --> 00:08:34,560
in most cases don't manage memory

193
00:08:34,560 --> 00:08:37,180
manually you hand it over to automatic

194
00:08:37,180 --> 00:08:39,130
reference counting things like this

195
00:08:39,130 --> 00:08:42,520
because of that the LLVM code is a lot

196
00:08:42,520 --> 00:08:44,920
more lengthy it contains a lot more

197
00:08:44,920 --> 00:08:47,380
instructions to do almost the same thing

198
00:08:47,380 --> 00:08:50,050
that you wouldn't see so when you go

199
00:08:50,050 --> 00:08:59,380
from Swift to LLVM ir to eventually or

200
00:08:59,380 --> 00:09:02,230
assembly if the architecture looked like

201
00:09:02,230 --> 00:09:04,750
this you would be losing a lot of

202
00:09:04,750 --> 00:09:06,940
architectural information about the

203
00:09:06,940 --> 00:09:10,110
program between these two stages

204
00:09:10,110 --> 00:09:13,030
therefore the Swift compiler team

205
00:09:13,030 --> 00:09:15,760
thought that hey instead of going

206
00:09:15,760 --> 00:09:18,670
directly to LLVM ir which is kind of

207
00:09:18,670 --> 00:09:22,180
like assembly with types kind of like in

208
00:09:22,180 --> 00:09:25,120
between c and assembly what if we had

209
00:09:25,120 --> 00:09:28,660
two intermediate representations what if

210
00:09:28,660 --> 00:09:31,960
we went from swift to a different

211
00:09:31,960 --> 00:09:34,990
language altogether what if we went from

212
00:09:34,990 --> 00:09:38,370
Swift to this new thing called SIL and

213
00:09:38,370 --> 00:09:42,970
then from SIL to LLVM SI l being swift

214
00:09:42,970 --> 00:09:45,790
intermediate language then when we went

215
00:09:45,790 --> 00:09:47,350
from Swift intermediate language to ir

216
00:09:47,350 --> 00:09:50,620
and an ir to assembly each individual

217
00:09:50,620 --> 00:09:53,830
stage introduces its own optimization

218
00:09:53,830 --> 00:09:55,930
passes enabling your program to run

219
00:09:55,930 --> 00:09:59,170
faster and here's the thing because this

220
00:09:59,170 --> 00:10:01,000
is slightly higher level it can

221
00:10:01,000 --> 00:10:03,310
understand higher level details about

222
00:10:03,310 --> 00:10:05,500
your program enabling it to do higher

223
00:10:05,500 --> 00:10:07,750
level optimizations that enable better

224
00:10:07,750 --> 00:10:11,260
and more canonicalized LLVM ir which can

225
00:10:11,260 --> 00:10:13,480
then be further optimized by the LLVM

226
00:10:13,480 --> 00:10:16,270
compiler and its transformations finally

227
00:10:16,270 --> 00:10:19,240
converted to assembly code and here's

228
00:10:19,240 --> 00:10:21,060
the interesting thing the same

229
00:10:21,060 --> 00:10:23,230
optimizations that were written for C

230
00:10:23,230 --> 00:10:25,720
are now instantly applicable to Swift

231
00:10:25,720 --> 00:10:27,370
the Swift compiler team didn't need to

232
00:10:27,370 --> 00:10:28,790
rewrite

233
00:10:28,790 --> 00:10:30,470
worth of optimization and

234
00:10:30,470 --> 00:10:32,510
transformations that was already done by

235
00:10:32,510 --> 00:10:36,290
the LLVM compiler team this is why LLVM

236
00:10:36,290 --> 00:10:38,660
is so important being able to reuse code

237
00:10:38,660 --> 00:10:41,900
across compilers across languages and

238
00:10:41,900 --> 00:10:43,520
they learn people to get things done

239
00:10:43,520 --> 00:10:46,370
faster enabling all languages to benefit

240
00:10:46,370 --> 00:10:49,700
from just a single compiler that's the

241
00:10:49,700 --> 00:10:52,010
idea behind LLVM and there's so many

242
00:10:52,010 --> 00:10:54,020
more things the great teams at the

243
00:10:54,020 --> 00:10:56,650
elevator are working on now the primary

244
00:10:56,650 --> 00:10:59,360
maintainer of the LLVM compiler and a

245
00:10:59,360 --> 00:11:01,400
clan compiler actually as it's the only

246
00:11:01,400 --> 00:11:03,560
C compiler supporting Objective C has

247
00:11:03,560 --> 00:11:06,590
been Apple of course but now Google is

248
00:11:06,590 --> 00:11:08,150
contributing a lot to the project as

249
00:11:08,150 --> 00:11:09,800
well you may have heard of the new Swift

250
00:11:09,800 --> 00:11:11,300
for tensorflow framework which is

251
00:11:11,300 --> 00:11:14,630
extensively powered by LLVM features of

252
00:11:14,630 --> 00:11:15,920
course because chris laughing is a

253
00:11:15,920 --> 00:11:18,380
creator of both LLVM and the Swift

254
00:11:18,380 --> 00:11:21,620
language left Apple to join the Google

255
00:11:21,620 --> 00:11:24,740
team for their accelerators and now of

256
00:11:24,740 --> 00:11:26,030
course leaving the Swift for tensorflow

257
00:11:26,030 --> 00:11:28,430
team and they are also contributing

258
00:11:28,430 --> 00:11:31,430
something else something called ml IR

259
00:11:31,430 --> 00:11:33,770
which will further increase the amount

260
00:11:33,770 --> 00:11:36,530
of reuse we can have a cross compilers

261
00:11:36,530 --> 00:11:38,690
even to things like for example Google's

262
00:11:38,690 --> 00:11:41,750
TP use and other accelerators but that's

263
00:11:41,750 --> 00:11:45,140
a topic for an entirely separate video

264
00:11:45,140 --> 00:11:47,210
this however is what we're going to be

265
00:11:47,210 --> 00:11:49,070
getting into today we're gonna take a

266
00:11:49,070 --> 00:11:50,510
look at if your different languages like

267
00:11:50,510 --> 00:11:53,540
Swift Julia and C we need to be specific

268
00:11:53,540 --> 00:11:55,610
we're gonna take a look at how exactly

269
00:11:55,610 --> 00:11:58,220
these individual intermediate

270
00:11:58,220 --> 00:12:00,410
representations work what they mean and

271
00:12:00,410 --> 00:12:03,140
how they're optimized and in a future

272
00:12:03,140 --> 00:12:05,120
video you're going to be able to see how

273
00:12:05,120 --> 00:12:06,980
you can develop your own transformation

274
00:12:06,980 --> 00:12:10,340
and optimization passes and how you can

275
00:12:10,340 --> 00:12:12,080
go ahead and do things like insert

276
00:12:12,080 --> 00:12:14,500
instrumentation entirely automatically

277
00:12:14,500 --> 00:12:17,600
and now let's take a look at how these

278
00:12:17,600 --> 00:12:19,430
compilers client Swift and Julia

279
00:12:19,430 --> 00:12:21,790
actually use LLVM compiler

280
00:12:21,790 --> 00:12:24,170
infrastructure right so now let's take a

281
00:12:24,170 --> 00:12:26,360
look at how you can actually see what's

282
00:12:26,360 --> 00:12:28,850
going on behind the scenes inside of the

283
00:12:28,850 --> 00:12:31,820
LLVM compiler infrastructure tooling now

284
00:12:31,820 --> 00:12:34,730
I will say that while you can use the

285
00:12:34,730 --> 00:12:36,710
compiler tools directly you can actually

286
00:12:36,710 --> 00:12:40,550
invoke clang or Swift C or the Julia

287
00:12:40,550 --> 00:12:43,250
pilot with certain arguments to see your

288
00:12:43,250 --> 00:12:46,340
LLVM code another great way to take a

289
00:12:46,340 --> 00:12:48,770
look at LLVM code and even assembly code

290
00:12:48,770 --> 00:12:50,870
is through something called a god bolt

291
00:12:50,870 --> 00:12:53,660
compiler explorer it's available at god

292
00:12:53,660 --> 00:12:55,760
bolt or gets entirely online they

293
00:12:55,760 --> 00:12:57,260
provide you with tons of different

294
00:12:57,260 --> 00:12:59,480
compilers tons of different kinds of

295
00:12:59,480 --> 00:13:01,550
compilers and different languages for

296
00:13:01,550 --> 00:13:03,860
example over here I can switch over to a

297
00:13:03,860 --> 00:13:06,950
c compiler i can choose which kind of c

298
00:13:06,950 --> 00:13:09,980
compiler i want i can choose a GCC i can

299
00:13:09,980 --> 00:13:12,290
choose the MSV c compiler the microsoft

300
00:13:12,290 --> 00:13:15,050
compiler i can choose the power

301
00:13:15,050 --> 00:13:17,870
compilers use the Excel compilers and of

302
00:13:17,870 --> 00:13:20,930
course I can choose clang compilers so

303
00:13:20,930 --> 00:13:22,730
take a look at this I can go up to clang

304
00:13:22,730 --> 00:13:24,980
9 I can you even go to trunk but let's

305
00:13:24,980 --> 00:13:29,140
just say we want x86 Clank 9 compilation

306
00:13:29,140 --> 00:13:33,530
now over here on the Left I type in my C

307
00:13:33,530 --> 00:13:35,900
code which is in this case just in

308
00:13:35,900 --> 00:13:39,080
square in num return num times nothing

309
00:13:39,080 --> 00:13:42,710
simple squaring logic but let's just see

310
00:13:42,710 --> 00:13:44,000
I did something a little bit different

311
00:13:44,000 --> 00:13:47,150
let's just say I did int factorial and I

312
00:13:47,150 --> 00:13:50,510
provided index and we said if X is equal

313
00:13:50,510 --> 00:13:55,940
to 1 then just return 1 otherwise return

314
00:13:55,940 --> 00:14:01,850
X x factorial X minus 1 now this is a

315
00:14:01,850 --> 00:14:05,150
super simple classic factorial

316
00:14:05,150 --> 00:14:07,580
implementation now look at this on the

317
00:14:07,580 --> 00:14:09,110
right we get some assembly code that

318
00:14:09,110 --> 00:14:11,930
represents the factorial function super

319
00:14:11,930 --> 00:14:13,670
simple just like that as a matter of

320
00:14:13,670 --> 00:14:15,500
fact if I like I can even go ahead and

321
00:14:15,500 --> 00:14:20,030
include stdio.h or file and I can

322
00:14:20,030 --> 00:14:22,630
actually go ahead and print out the

323
00:14:22,630 --> 00:14:28,190
factorial of 5 so just like that we're

324
00:14:28,190 --> 00:14:29,990
printing out the factorial of 5 we get a

325
00:14:29,990 --> 00:14:31,820
main function as you can see we're

326
00:14:31,820 --> 00:14:34,100
moving the number 5 to a register or

327
00:14:34,100 --> 00:14:36,230
calling the factorial function we're

328
00:14:36,230 --> 00:14:37,490
moving the results over to other

329
00:14:37,490 --> 00:14:39,830
registers calling printf and so on and

330
00:14:39,830 --> 00:14:43,760
so forth classic stuff but wait we're

331
00:14:43,760 --> 00:14:46,400
using the clang compiler so we know that

332
00:14:46,400 --> 00:14:49,760
before goes to assembly it goes to LLVM

333
00:14:49,760 --> 00:14:50,510
in turn

334
00:14:50,510 --> 00:14:52,740
representation so how do we take a look

335
00:14:52,740 --> 00:14:56,040
at that well if we pass the - s flag -

336
00:14:56,040 --> 00:14:57,960
clang that's just telling it a bit

337
00:14:57,960 --> 00:14:59,130
assembly so it's gonna admit the same

338
00:14:59,130 --> 00:15:01,770
thing as it was before but there's one

339
00:15:01,770 --> 00:15:05,240
more flag you should pass - Annette -

340
00:15:05,240 --> 00:15:09,240
LLVM when you pass this flag it's gonna

341
00:15:09,240 --> 00:15:11,610
change entirely and now we're gonna see

342
00:15:11,610 --> 00:15:15,360
is LLVM IR code now this looks a lot

343
00:15:15,360 --> 00:15:18,000
less intimidating than the assembly code

344
00:15:18,000 --> 00:15:19,890
looked although I will say that it's

345
00:15:19,890 --> 00:15:22,920
still not great from a sort of first

346
00:15:22,920 --> 00:15:24,270
time you take a look at this it looks

347
00:15:24,270 --> 00:15:26,490
intimidating still so let's go ahead and

348
00:15:26,490 --> 00:15:28,920
try and understand a bit of how LLVM

349
00:15:28,920 --> 00:15:31,290
works and the way LLVM works is it's

350
00:15:31,290 --> 00:15:33,360
written in phone called SS a single

351
00:15:33,360 --> 00:15:36,000
static assignment now I will link to

352
00:15:36,000 --> 00:15:37,470
some resources so you can figure out

353
00:15:37,470 --> 00:15:39,060
more about SSA and what it does

354
00:15:39,060 --> 00:15:41,790
essentially LLVM works on the sort of

355
00:15:41,790 --> 00:15:44,760
infinite registers concept so as you can

356
00:15:44,760 --> 00:15:46,320
see here for example within the

357
00:15:46,320 --> 00:15:49,110
factorial function we have these many

358
00:15:49,110 --> 00:15:51,180
registers we register two three four

359
00:15:51,180 --> 00:15:52,890
five at Sentara

360
00:15:52,890 --> 00:15:54,960
and these are just labels for different

361
00:15:54,960 --> 00:15:56,730
registers that we're storing things and

362
00:15:56,730 --> 00:15:59,450
over here and here and here at cetera

363
00:15:59,450 --> 00:16:02,640
now there are also other labels for

364
00:16:02,640 --> 00:16:06,720
example % one is the label for the first

365
00:16:06,720 --> 00:16:08,760
parameter passed into the function

366
00:16:08,760 --> 00:16:11,790
itself and over here you can see that

367
00:16:11,790 --> 00:16:13,590
we're specifying the type of that is a

368
00:16:13,590 --> 00:16:16,560
32-bit integer over here we also happen

369
00:16:16,560 --> 00:16:18,860
to find that the function will return a

370
00:16:18,860 --> 00:16:21,720
32-bit integer as well within the

371
00:16:21,720 --> 00:16:22,740
function there are a few different

372
00:16:22,740 --> 00:16:24,270
things we do for example the first thing

373
00:16:24,270 --> 00:16:27,960
is we have two separate registers where

374
00:16:27,960 --> 00:16:30,660
we're going to store the pointer to an

375
00:16:30,660 --> 00:16:33,210
allocation of a 32-bit integer so we're

376
00:16:33,210 --> 00:16:35,220
allocating two different 32-bit integers

377
00:16:35,220 --> 00:16:37,290
in memory and storing their pointer

378
00:16:37,290 --> 00:16:40,950
addresses inside of those registers then

379
00:16:40,950 --> 00:16:43,530
we're actually storing let's see what

380
00:16:43,530 --> 00:16:45,180
are we sort here we're storing the

381
00:16:45,180 --> 00:16:47,730
argument that came into the function

382
00:16:47,730 --> 00:16:51,360
inside of this third register over here

383
00:16:51,360 --> 00:16:54,840
now I will say one thing a few of these

384
00:16:54,840 --> 00:16:57,480
instructions are absolutely useless this

385
00:16:57,480 --> 00:17:00,570
is not the best this code can be but why

386
00:17:00,570 --> 00:17:02,790
is that you may ask well it's because

387
00:17:02,790 --> 00:17:03,880
would cleanse

388
00:17:03,880 --> 00:17:07,360
it's been a blind translation from the C

389
00:17:07,360 --> 00:17:10,270
code you gave it right to some LLVM code

390
00:17:10,270 --> 00:17:12,459
the most obvious translation possible

391
00:17:12,459 --> 00:17:15,640
that works but is it fast it's doing a

392
00:17:15,640 --> 00:17:18,699
lot of unnecessary operations so how can

393
00:17:18,699 --> 00:17:21,520
we reduce that it has an entire register

394
00:17:21,520 --> 00:17:24,880
year that doesn't even use and here's

395
00:17:24,880 --> 00:17:25,660
how you can do it

396
00:17:25,660 --> 00:17:28,449
we gotta tell LLVM or client more

397
00:17:28,449 --> 00:17:30,730
specifically to actually optimize the

398
00:17:30,730 --> 00:17:33,220
code to do this we're gonna pass it the

399
00:17:33,220 --> 00:17:35,919
- oh flag now there are a few different

400
00:17:35,919 --> 00:17:38,409
levels of optimization there's - 0 which

401
00:17:38,409 --> 00:17:40,150
is don't even think about optimizing

402
00:17:40,150 --> 00:17:44,110
whatsoever there's a 102 3 and then

403
00:17:44,110 --> 00:17:47,590
there's fast fast means enable some

404
00:17:47,590 --> 00:17:49,510
experimental potentially unsafe

405
00:17:49,510 --> 00:17:51,850
operations like for example working with

406
00:17:51,850 --> 00:17:53,470
less accurate floating point division

407
00:17:53,470 --> 00:17:55,840
and things like this I usually use oh

408
00:17:55,840 --> 00:17:57,820
fast because the particular applications

409
00:17:57,820 --> 00:17:59,559
that I develop don't need the extra

410
00:17:59,559 --> 00:18:03,010
safety but in most circumstances sort of

411
00:18:03,010 --> 00:18:04,960
production level applications are gonna

412
00:18:04,960 --> 00:18:06,760
use oh three because it's the safer

413
00:18:06,760 --> 00:18:09,610
option in this case though what's the

414
00:18:09,610 --> 00:18:11,020
worst that can happen let's use Oh

415
00:18:11,020 --> 00:18:14,230
faster so I'm gonna go - oh fast and my

416
00:18:14,230 --> 00:18:17,140
compiler options here and would you look

417
00:18:17,140 --> 00:18:21,190
at that Wow we went from a little bit of

418
00:18:21,190 --> 00:18:27,549
LLVM code to a lot of LLVM code now why

419
00:18:27,549 --> 00:18:29,950
is this you may ask well there's one

420
00:18:29,950 --> 00:18:31,330
thing I want you to think about let's

421
00:18:31,330 --> 00:18:34,720
just say we remove a fast and let's take

422
00:18:34,720 --> 00:18:36,370
a look at our code as you can see it's a

423
00:18:36,370 --> 00:18:38,530
blind translation therefore on line 21

424
00:18:38,530 --> 00:18:40,690
we're calling the factorial function I

425
00:18:40,690 --> 00:18:42,340
mean obviously it's a recursive function

426
00:18:42,340 --> 00:18:45,429
so we be calling the function again it's

427
00:18:45,429 --> 00:18:49,270
recursive but if I add the optimization

428
00:18:49,270 --> 00:18:52,570
plan back watch this if I try and search

429
00:18:52,570 --> 00:18:56,470
for factorial I only get one result the

430
00:18:56,470 --> 00:18:58,299
factorial function isn't calling itself

431
00:18:58,299 --> 00:19:01,690
guess what happened LLVM removed the

432
00:19:01,690 --> 00:19:03,730
recursiveness from the function it

433
00:19:03,730 --> 00:19:05,860
understood what the function was trying

434
00:19:05,860 --> 00:19:07,809
to accomplish and made it a non

435
00:19:07,809 --> 00:19:10,450
recursive implementation of the same

436
00:19:10,450 --> 00:19:11,670
function isn't

437
00:19:11,670 --> 00:19:14,870
fascinating now because it's sort of

438
00:19:14,870 --> 00:19:17,400
canonicalized standardized the

439
00:19:17,400 --> 00:19:19,530
implementation of that function it was

440
00:19:19,530 --> 00:19:21,030
able to do another really interesting

441
00:19:21,030 --> 00:19:24,450
thing now look at this inside of our C

442
00:19:24,450 --> 00:19:26,760
code there are three times factorial is

443
00:19:26,760 --> 00:19:30,060
mentioned once for its definition wants

444
00:19:30,060 --> 00:19:32,550
to call itself recursively and another

445
00:19:32,550 --> 00:19:34,320
time to actually call it from the main

446
00:19:34,320 --> 00:19:36,000
function but watch this

447
00:19:36,000 --> 00:19:38,430
there's only one reference to it the

448
00:19:38,430 --> 00:19:41,040
LLVM code is the main function not

449
00:19:41,040 --> 00:19:42,750
calling the factorial function well

450
00:19:42,750 --> 00:19:45,300
actually it isn't so the constant

451
00:19:45,300 --> 00:19:46,860
folding I was telling you about just a

452
00:19:46,860 --> 00:19:50,340
moment ago what happens is this LLVM

453
00:19:50,340 --> 00:19:53,700
actually runs your variables or your

454
00:19:53,700 --> 00:19:55,440
constants in this case your literal

455
00:19:55,440 --> 00:19:59,160
values through the function at compile

456
00:19:59,160 --> 00:20:01,470
time and it's like hey factorial is such

457
00:20:01,470 --> 00:20:04,800
a simple function I might as well just

458
00:20:04,800 --> 00:20:07,470
hard-code the result for you take a look

459
00:20:07,470 --> 00:20:11,400
at this on line 111 in the main function

460
00:20:11,400 --> 00:20:14,370
we're calling the printf function but

461
00:20:14,370 --> 00:20:16,590
the printf function doesn't call we're

462
00:20:16,590 --> 00:20:18,330
not calling factorial to figure out what

463
00:20:18,330 --> 00:20:21,990
the print LLVM has hard-coded the result

464
00:20:21,990 --> 00:20:25,280
of factorial 5 into the program for you

465
00:20:25,280 --> 00:20:28,290
LLVM is not looking at the name of the

466
00:20:28,290 --> 00:20:30,540
function or what it is rather it's

467
00:20:30,540 --> 00:20:32,250
looking at the functionality it's doing

468
00:20:32,250 --> 00:20:34,440
constant full and say hey you know what

469
00:20:34,440 --> 00:20:37,350
we don't need to do all this calculation

470
00:20:37,350 --> 00:20:39,150
at runtime we might as well just print

471
00:20:39,150 --> 00:20:41,190
out 120 because that's what they want us

472
00:20:41,190 --> 00:20:42,300
to do what's that that's what the

473
00:20:42,300 --> 00:20:44,460
programmer wants us to do and that's

474
00:20:44,460 --> 00:20:46,550
LLVM sort of thought process they're

475
00:20:46,550 --> 00:20:48,660
iteratively going through these

476
00:20:48,660 --> 00:20:51,210
different optimization passes it enables

477
00:20:51,210 --> 00:20:54,390
you to create faster code first of all

478
00:20:54,390 --> 00:20:56,250
it's a moving that recursiveness it's

479
00:20:56,250 --> 00:20:58,680
making it interative on top of that it's

480
00:20:58,680 --> 00:21:00,570
making it a better implementation you

481
00:21:00,570 --> 00:21:02,400
see the factorial function when

482
00:21:02,400 --> 00:21:04,530
optimized becomes a lot longer but at

483
00:21:04,530 --> 00:21:06,180
the same time it's faster because each

484
00:21:06,180 --> 00:21:08,490
individual instruction is a lot faster

485
00:21:08,490 --> 00:21:11,010
and fewer instructions end up being as

486
00:21:11,010 --> 00:21:12,360
you would if you were clock cycle are

487
00:21:12,360 --> 00:21:15,270
taken on top of that what happens is it

488
00:21:15,270 --> 00:21:17,340
in mind is a function so it puts the

489
00:21:17,340 --> 00:21:19,290
factorial implementation inside of

490
00:21:19,290 --> 00:21:22,020
and then it does constant falling it

491
00:21:22,020 --> 00:21:24,000
says hmm inside of the main function we

492
00:21:24,000 --> 00:21:25,650
have all this unnecessary computation

493
00:21:25,650 --> 00:21:26,910
that I can do now that I don't need to

494
00:21:26,910 --> 00:21:28,860
do at runtime let's just finish this now

495
00:21:28,860 --> 00:21:32,550
and that is why these compilers are so

496
00:21:32,550 --> 00:21:34,890
great that's why these are necessary

497
00:21:34,890 --> 00:21:37,050
tools is because they enable you to

498
00:21:37,050 --> 00:21:38,820
write such good code as a matter of fact

499
00:21:38,820 --> 00:21:40,440
in the vast majority of circumstances

500
00:21:40,440 --> 00:21:42,660
writing assembly code manually is

501
00:21:42,660 --> 00:21:45,030
actually it actually ends up giving you

502
00:21:45,030 --> 00:21:47,250
slower code than writing in a

503
00:21:47,250 --> 00:21:49,200
higher-level language because then you

504
00:21:49,200 --> 00:21:51,300
have all these compiler optimizations

505
00:21:51,300 --> 00:21:53,400
that are making your code faster for you

506
00:21:53,400 --> 00:21:56,400
so that is a quick look at LLVM for c

507
00:21:56,400 --> 00:21:58,200
but there's still two more languages to

508
00:21:58,200 --> 00:21:59,670
cover so let's take a look at them now

509
00:21:59,670 --> 00:22:01,560
first of all I'm gonna take a look at

510
00:22:01,560 --> 00:22:04,410
just using the actual clen compiler

511
00:22:04,410 --> 00:22:07,020
locally to help put this LLVM code it's

512
00:22:07,020 --> 00:22:08,580
gonna be super simple so let's just say

513
00:22:08,580 --> 00:22:10,680
we do test dot see again this time we'll

514
00:22:10,680 --> 00:22:12,780
do the square example

515
00:22:12,780 --> 00:22:15,590
so we'll do number times number and

516
00:22:15,590 --> 00:22:19,310
we're just gonna print out the result of

517
00:22:19,310 --> 00:22:23,160
one hundred squared all right

518
00:22:23,160 --> 00:22:26,520
just because we want to avoid a warning

519
00:22:26,520 --> 00:22:28,170
we're going to include this header file

520
00:22:28,170 --> 00:22:29,820
as well so we're just printing out the

521
00:22:29,820 --> 00:22:32,520
square of a hundred now if I go ahead

522
00:22:32,520 --> 00:22:35,550
and do clang test dot C then it'll

523
00:22:35,550 --> 00:22:37,560
output a binary that I can run and it'll

524
00:22:37,560 --> 00:22:41,130
print out the square of 100 but what I

525
00:22:41,130 --> 00:22:44,040
can also do is pass it the dash S flag

526
00:22:44,040 --> 00:22:46,740
which will create a test on s file which

527
00:22:46,740 --> 00:22:49,410
is the assembly code for the code that I

528
00:22:49,410 --> 00:22:53,250
just wrote if I also pass it emit LLVM

529
00:22:53,250 --> 00:22:56,190
then it'll output a test dot ll file

530
00:22:56,190 --> 00:22:59,610
which is the LLVM code so now here's

531
00:22:59,610 --> 00:23:01,590
what I'm gonna do I'm gonna remove the

532
00:23:01,590 --> 00:23:05,370
binary and the S file and now we've only

533
00:23:05,370 --> 00:23:08,190
got the LLVM code so I'm gonna say C

534
00:23:08,190 --> 00:23:13,350
example ll or every test ll see example

535
00:23:13,350 --> 00:23:16,170
ll and there we go so we've got test dot

536
00:23:16,170 --> 00:23:19,080
C and C example ll which is the LLVM

537
00:23:19,080 --> 00:23:23,580
code for that C code but now let's take

538
00:23:23,580 --> 00:23:26,340
a look at some Swift code shall we so

539
00:23:26,340 --> 00:23:27,960
let's just say I go ahead and type in

540
00:23:27,960 --> 00:23:30,630
test on Swift so we're gonna create a

541
00:23:30,630 --> 00:23:32,890
super simple Swift file

542
00:23:32,890 --> 00:23:34,000
we're gonna create a function called

543
00:23:34,000 --> 00:23:36,490
square it takes number which is an

544
00:23:36,490 --> 00:23:38,140
integer returns another integer which is

545
00:23:38,140 --> 00:23:40,870
just a number times number and it prints

546
00:23:40,870 --> 00:23:47,260
out square of 100 all right now if I run

547
00:23:47,260 --> 00:23:50,290
Swift test on Swift it prints out 10,000

548
00:23:50,290 --> 00:23:52,990
just like clang did but I can do Swift C

549
00:23:52,990 --> 00:23:57,250
test on Swift I can tell it to emit IR

550
00:23:57,250 --> 00:24:01,050
which will emit the LLVM IR code now

551
00:24:01,050 --> 00:24:03,850
yeah so I can tell it to me IR and I can

552
00:24:03,850 --> 00:24:07,240
tell it to output to Swift example dot

553
00:24:07,240 --> 00:24:09,580
that well now watch this if I open up

554
00:24:09,580 --> 00:24:12,220
this file get ready to see quite a bit

555
00:24:12,220 --> 00:24:17,620
of code there we are so much code now if

556
00:24:17,620 --> 00:24:18,940
you take a look at what's actually

557
00:24:18,940 --> 00:24:21,970
happening here as I mentioned Swift is a

558
00:24:21,970 --> 00:24:24,640
much higher level language than CEA's

559
00:24:24,640 --> 00:24:27,610
and therefore there are many more

560
00:24:27,610 --> 00:24:30,330
operations that go behind doing

561
00:24:30,330 --> 00:24:34,510
essentially the same thing in Swift now

562
00:24:34,510 --> 00:24:36,430
when this gets compiled down to assembly

563
00:24:36,430 --> 00:24:38,830
likely a lot of this stuff is gonna go

564
00:24:38,830 --> 00:24:42,580
away but in this case it isn't this is

565
00:24:42,580 --> 00:24:46,150
raw LLVM ir from the swift compiler

566
00:24:46,150 --> 00:24:49,090
remember both clang and Swift that we've

567
00:24:49,090 --> 00:24:50,620
taken a look at so far have not

568
00:24:50,620 --> 00:24:53,920
introduced any optimization passes we'll

569
00:24:53,920 --> 00:24:55,630
take a look at what it looks like then

570
00:24:55,630 --> 00:24:58,840
in just a moment but as you can see this

571
00:24:58,840 --> 00:25:02,380
is all of the LLVM IR code that Swift

572
00:25:02,380 --> 00:25:08,290
generates that is a lot of IR code at

573
00:25:08,290 --> 00:25:11,530
least relatively all right but now let's

574
00:25:11,530 --> 00:25:13,840
take a look at Julia now remember that

575
00:25:13,840 --> 00:25:18,040
julia is an is a just-in-time compiled

576
00:25:18,040 --> 00:25:20,410
language so we can't just call it and

577
00:25:20,410 --> 00:25:22,810
say emit the IR for this entire file

578
00:25:22,810 --> 00:25:24,930
because it does it function by function

579
00:25:24,930 --> 00:25:29,080
not file by file so let's go ahead and

580
00:25:29,080 --> 00:25:31,720
actually run the Julia repo and go ahead

581
00:25:31,720 --> 00:25:34,110
and interact with a little bit

582
00:25:34,110 --> 00:25:36,360
but first a quick primer on the Julian

583
00:25:36,360 --> 00:25:39,510
language the star operator is a bit

584
00:25:39,510 --> 00:25:41,549
special in this language so for example

585
00:25:41,549 --> 00:25:43,110
you can do 5 times 5 and of course you

586
00:25:43,110 --> 00:25:47,059
would get 25 you can do 25.6 times 20

587
00:25:47,059 --> 00:25:48,929
3.12 and of course you would get

588
00:25:48,929 --> 00:25:52,110
whatever the result of that is but the

589
00:25:52,110 --> 00:25:54,809
star operator in julia is also the

590
00:25:54,809 --> 00:25:57,059
string concatenation operator so for

591
00:25:57,059 --> 00:26:00,510
example hello times world would result

592
00:26:00,510 --> 00:26:03,450
in hello world now let's just say we

593
00:26:03,450 --> 00:26:05,429
were to create a function called F and

594
00:26:05,429 --> 00:26:07,559
it takes a variable or a parameter

595
00:26:07,559 --> 00:26:12,750
argument called X and it returns x times

596
00:26:12,750 --> 00:26:16,230
X and now Julia is a compiled language

597
00:26:16,230 --> 00:26:18,570
but we didn't tell it what the type of X

598
00:26:18,570 --> 00:26:21,539
is so how in the world does it know what

599
00:26:21,539 --> 00:26:24,929
to do with X well watch this this is

600
00:26:24,929 --> 00:26:27,480
almost like a magic trick I can pass it

601
00:26:27,480 --> 00:26:30,870
the number 5 guess what it returns 25 I

602
00:26:30,870 --> 00:26:34,049
can pass it hello

603
00:26:34,049 --> 00:26:37,500
and guess what our turns hello hello I

604
00:26:37,500 --> 00:26:43,620
can pass it 5.67 and it returns 5.67

605
00:26:43,620 --> 00:26:46,279
squared isn't that absolutely

606
00:26:46,279 --> 00:26:47,610
exceptional

607
00:26:47,610 --> 00:26:50,399
but what's super interesting is that we

608
00:26:50,399 --> 00:26:53,070
can take a look at the LLVM code for all

609
00:26:53,070 --> 00:26:55,830
these different compiled versions of the

610
00:26:55,830 --> 00:26:58,860
F function by using a little macro

611
00:26:58,860 --> 00:27:02,730
called at code underscore LLVM I type

612
00:27:02,730 --> 00:27:04,740
that out and I tell it what I'm going to

613
00:27:04,740 --> 00:27:06,389
invoke for example let's just say I'm

614
00:27:06,389 --> 00:27:08,070
passing well let's just say I'm passing

615
00:27:08,070 --> 00:27:10,740
an integer to F then as you can see it

616
00:27:10,740 --> 00:27:13,500
creates LLVM I our code assuming we're

617
00:27:13,500 --> 00:27:15,570
taking an integer 64 and returning an

618
00:27:15,570 --> 00:27:19,169
integer 64 and returning 8 multiplied by

619
00:27:19,169 --> 00:27:19,919
itself

620
00:27:19,919 --> 00:27:23,580
super simple stuff so then how about we

621
00:27:23,580 --> 00:27:25,799
do floats so let's just say I were to

622
00:27:25,799 --> 00:27:29,210
return or let's just say I were to pass

623
00:27:29,210 --> 00:27:32,399
5.67 now as you can see it's looking for

624
00:27:32,399 --> 00:27:34,860
doubles and it's doing a floating point

625
00:27:34,860 --> 00:27:37,679
multiplication but what if I pass in a

626
00:27:37,679 --> 00:27:40,030
string look at this when I pass it

627
00:27:40,030 --> 00:27:42,880
ten a just like that's so much more code

628
00:27:42,880 --> 00:27:45,280
to deal with this string involved so

629
00:27:45,280 --> 00:27:46,810
every time you pass different arguments

630
00:27:46,810 --> 00:27:48,370
Julia is actually going through and

631
00:27:48,370 --> 00:27:50,710
saying hmm does this function make sense

632
00:27:50,710 --> 00:27:53,620
if X is a string or integer or a double

633
00:27:53,620 --> 00:27:55,570
if it does go ahead and compile it to

634
00:27:55,570 --> 00:27:57,880
LLVM and then provide the user with the

635
00:27:57,880 --> 00:28:00,760
result of the execution and what's

636
00:28:00,760 --> 00:28:02,380
interesting is every single time you

637
00:28:02,380 --> 00:28:05,200
actually run a function the first time

638
00:28:05,200 --> 00:28:07,240
it'll compile the LLVM code and optimize

639
00:28:07,240 --> 00:28:09,730
it and the second time and so on and so

640
00:28:09,730 --> 00:28:10,150
forth

641
00:28:10,150 --> 00:28:12,130
it'll use the cache version of that

642
00:28:12,130 --> 00:28:14,080
function so it doesn't keep compiling or

643
00:28:14,080 --> 00:28:16,150
else of course there would be no point

644
00:28:16,150 --> 00:28:17,440
to using the language because it would

645
00:28:17,440 --> 00:28:18,820
be too slow your recompiling the

646
00:28:18,820 --> 00:28:20,650
function every single time you call it

647
00:28:20,650 --> 00:28:24,720
and so that is how julia uses LLVM and

648
00:28:24,720 --> 00:28:28,750
so that is how clang Swift and Julia

649
00:28:28,750 --> 00:28:31,390
used LLVM in their own ways one more

650
00:28:31,390 --> 00:28:32,910
thing I want you to take a look at them

651
00:28:32,910 --> 00:28:36,520
as you can tell we have LLVM ir files

652
00:28:36,520 --> 00:28:39,690
for two different languages swift and C

653
00:28:39,690 --> 00:28:42,310
both of them were created a zooming no

654
00:28:42,310 --> 00:28:44,650
compiler optimizations in mind but let's

655
00:28:44,650 --> 00:28:47,980
redo that this time assuming we do want

656
00:28:47,980 --> 00:28:50,380
compiler optimizations so I'm going to

657
00:28:50,380 --> 00:28:50,710
do

658
00:28:50,710 --> 00:28:53,800
clang test dot C this time gonna pass oh

659
00:28:53,800 --> 00:28:56,110
fast to make it optimize as much as it

660
00:28:56,110 --> 00:28:58,960
can then we're going to do s emit LLVM

661
00:28:58,960 --> 00:29:01,240
and we're going to output to see example

662
00:29:01,240 --> 00:29:03,850
ll and we're gonna do something similar

663
00:29:03,850 --> 00:29:07,930
for Swift now Swift doesn't have levels

664
00:29:07,930 --> 00:29:10,090
of optimizations either you are or you

665
00:29:10,090 --> 00:29:11,860
aren't optimizing or you're optimizing

666
00:29:11,860 --> 00:29:14,290
for binary size instead of speed which I

667
00:29:14,290 --> 00:29:17,380
rarely ever do and so in this case we're

668
00:29:17,380 --> 00:29:18,820
just gonna pass a - oh because that

669
00:29:18,820 --> 00:29:21,910
means optimized for speed from there I'm

670
00:29:21,910 --> 00:29:23,560
going to tell it to admit I are and

671
00:29:23,560 --> 00:29:26,200
we're going to output to Swift example

672
00:29:26,200 --> 00:29:29,290
LL now let's take a look at this C

673
00:29:29,290 --> 00:29:32,860
version of the LLVM ir how simple is

674
00:29:32,860 --> 00:29:35,170
that the square functions literally just

675
00:29:35,170 --> 00:29:37,120
multiply argument against itself in

676
00:29:37,120 --> 00:29:40,000
return and the main function well it's

677
00:29:40,000 --> 00:29:41,710
not even calling the square function

678
00:29:41,710 --> 00:29:43,900
it's just printing out the hard-coded

679
00:29:43,900 --> 00:29:47,350
result of square and of course that is

680
00:29:47,350 --> 00:29:48,880
10,000 because we're looking for the

681
00:29:48,880 --> 00:29:49,930
square of 100

682
00:29:49,930 --> 00:29:53,230
now what's interesting is that while the

683
00:29:53,230 --> 00:29:56,620
Swift IR is still a lot longer

684
00:29:56,620 --> 00:29:59,500
it is doing fundamentally the same thing

685
00:29:59,500 --> 00:30:01,570
take a look at this line of code it's

686
00:30:01,570 --> 00:30:05,410
storing this hard-coded 10,000 inside of

687
00:30:05,410 --> 00:30:08,440
a variable which it then passes over to

688
00:30:08,440 --> 00:30:10,180
print Anakin's print it out onto the

689
00:30:10,180 --> 00:30:13,000
screen so it's actually pretty simple if

690
00:30:13,000 --> 00:30:15,880
you take a look Swift and see both did

691
00:30:15,880 --> 00:30:17,980
constant folding thanks to the same

692
00:30:17,980 --> 00:30:20,440
optimization passes that is absolutely

693
00:30:20,440 --> 00:30:23,980
exceptional stuff code reuse is always

694
00:30:23,980 --> 00:30:25,930
good and the fact that LLVM is open

695
00:30:25,930 --> 00:30:27,250
source being maintained by large

696
00:30:27,250 --> 00:30:29,380
companies at Google and Apple and if so

697
00:30:29,380 --> 00:30:30,730
many developers working towards it you

698
00:30:30,730 --> 00:30:32,680
can be sure that your code is being

699
00:30:32,680 --> 00:30:34,660
optimized as thoroughly as possible that

700
00:30:34,660 --> 00:30:36,700
people are working towards more and more

701
00:30:36,700 --> 00:30:39,340
even companies like IBM are contributing

702
00:30:39,340 --> 00:30:41,140
towards different optimization passes

703
00:30:41,140 --> 00:30:43,510
for example loop optimization paksas

704
00:30:43,510 --> 00:30:46,270
loop merging all sorts of things one

705
00:30:46,270 --> 00:30:48,220
more thing I want to leave you in before

706
00:30:48,220 --> 00:30:50,800
I go as I mentioned Swift doesn't just

707
00:30:50,800 --> 00:30:53,320
compile to I honor it compiles through

708
00:30:53,320 --> 00:30:56,320
another intermediate language called SIL

709
00:30:56,320 --> 00:30:58,600
Swift intermediate language so let's

710
00:30:58,600 --> 00:31:00,610
take a look at some of that shall we now

711
00:31:00,610 --> 00:31:03,180
we can compile in a very similar way

712
00:31:03,180 --> 00:31:05,770
except this time we're gonna admit silk

713
00:31:05,770 --> 00:31:07,990
instead of a MIDI IR and we're going to

714
00:31:07,990 --> 00:31:12,100
save it to a different file so i'm gonna

715
00:31:12,100 --> 00:31:14,550
open to something there we go we got SIL

716
00:31:14,550 --> 00:31:17,740
this looks kind of like if you were to

717
00:31:17,740 --> 00:31:20,800
take swift and LLVM and kind of go in

718
00:31:20,800 --> 00:31:22,450
between but a little bit closer to the

719
00:31:22,450 --> 00:31:25,060
LLVM side whereas LLVM looks as if you

720
00:31:25,060 --> 00:31:27,460
went between C and assembly sort of

721
00:31:27,460 --> 00:31:28,870
right in the middle right so you're

722
00:31:28,870 --> 00:31:31,000
going from Swift to something a little

723
00:31:31,000 --> 00:31:33,250
bit closer to Swift not quite at LLVM

724
00:31:33,250 --> 00:31:35,560
and then you're going to LLVM and then

725
00:31:35,560 --> 00:31:37,210
they're going to assembly and by doing

726
00:31:37,210 --> 00:31:39,850
this at every stage you can introduce

727
00:31:39,850 --> 00:31:42,190
further further lower level

728
00:31:42,190 --> 00:31:43,990
optimizations that you could never

729
00:31:43,990 --> 00:31:46,300
achieve with a simple monolithic

730
00:31:46,300 --> 00:31:48,100
architecture that's the power of the

731
00:31:48,100 --> 00:31:51,250
Swift and generally LLVM compilers

732
00:31:51,250 --> 00:31:53,740
taking a look at this this is all silk

733
00:31:53,740 --> 00:31:56,020
up now because this has optimizations

734
00:31:56,020 --> 00:31:57,730
there's a chance that the hard coding

735
00:31:57,730 --> 00:31:59,230
and the constant folding occurred over

736
00:31:59,230 --> 00:31:59,780
here

737
00:31:59,780 --> 00:32:03,890
let's take a look indeed it has as you

738
00:32:03,890 --> 00:32:05,690
can see the constant folding that was

739
00:32:05,690 --> 00:32:08,390
necessary for swift to say you know what

740
00:32:08,390 --> 00:32:09,860
instead of calling square we'll just

741
00:32:09,860 --> 00:32:11,990
print out 10,000 that actually happened

742
00:32:11,990 --> 00:32:14,210
at the Silph phase so it didn't even

743
00:32:14,210 --> 00:32:17,900
make it to LLVM and this enables LLVM to

744
00:32:17,900 --> 00:32:20,930
apply its optimization passes better now

745
00:32:20,930 --> 00:32:23,090
just you're aware another thing that

746
00:32:23,090 --> 00:32:26,090
LLVM does is called canonicalization

747
00:32:26,090 --> 00:32:29,270
this does things like for example let's

748
00:32:29,270 --> 00:32:30,740
actually take a look at a sample file

749
00:32:30,740 --> 00:32:33,980
here if I were to do something like int

750
00:32:33,980 --> 00:32:39,650
F X and this just returns X plus 1 or we

751
00:32:39,650 --> 00:32:45,490
could say if X is not equal to 5 return

752
00:32:45,490 --> 00:32:51,530
1 otherwise return 0 well in this case

753
00:32:51,530 --> 00:32:54,230
what's happening is if you were to take

754
00:32:54,230 --> 00:32:58,910
a look at the canonicalize or fixing me

755
00:32:58,910 --> 00:33:00,710
to see syntax here if you were to take a

756
00:33:00,710 --> 00:33:03,290
look at the canonicalized LLVM for this

757
00:33:03,290 --> 00:33:06,230
instead of saying if X is not equal to 5

758
00:33:06,230 --> 00:33:08,540
then return 1 otherwise return 0 it'll

759
00:33:08,540 --> 00:33:11,210
flip that around and it'll say if X is

760
00:33:11,210 --> 00:33:12,680
equal to 5

761
00:33:12,680 --> 00:33:15,890
return 0 otherwise or or if it is so

762
00:33:15,890 --> 00:33:17,810
it'll it'll basically switch the true

763
00:33:17,810 --> 00:33:20,270
and false from the else above to the

764
00:33:20,270 --> 00:33:22,820
regular F or for example if it's doing X

765
00:33:22,820 --> 00:33:26,270
minus 1 in central do X plus equals or

766
00:33:26,270 --> 00:33:28,880
plus negative 1 by doing this it

767
00:33:28,880 --> 00:33:30,740
standardizes the format for certain

768
00:33:30,740 --> 00:33:33,290
operations and enables optimization

769
00:33:33,290 --> 00:33:35,750
passes to look at only certain kinds of

770
00:33:35,750 --> 00:33:37,460
operations instead of having to look at

771
00:33:37,460 --> 00:33:39,890
a wide range of different operations and

772
00:33:39,890 --> 00:33:42,500
so I doing that enables optimization

773
00:33:42,500 --> 00:33:46,580
passes to have an easier job and so that

774
00:33:46,580 --> 00:33:50,480
is how LLVM compiler tooling works now

775
00:33:50,480 --> 00:33:53,780
in the next few videos on LLVM we're

776
00:33:53,780 --> 00:33:55,130
going to be taking a look at how you can

777
00:33:55,130 --> 00:33:57,530
actually use the LLVM pass manager to

778
00:33:57,530 --> 00:33:59,930
introduce your own instrumentation into

779
00:33:59,930 --> 00:34:02,030
different functions and from there we're

780
00:34:02,030 --> 00:34:03,530
gonna be taking a look and brand new

781
00:34:03,530 --> 00:34:05,420
stuff in the world of LLVM hopefully

782
00:34:05,420 --> 00:34:08,270
things like MLI are very very soon

783
00:34:08,270 --> 00:34:10,010
but that's all we have for this tutorial

784
00:34:10,010 --> 00:34:11,990
today I really do hope you enjoy if you

785
00:34:11,990 --> 00:34:13,370
have any questions poof or leave them

786
00:34:13,370 --> 00:34:15,050
down in the comment section below email

787
00:34:15,050 --> 00:34:17,149
them to me or tweet them to me act as

788
00:34:17,149 --> 00:34:19,040
you many apart from that if you do enjoy

789
00:34:19,040 --> 00:34:20,480
the content on this channel and you want

790
00:34:20,480 --> 00:34:21,770
to see more of it please do feel free to

791
00:34:21,770 --> 00:34:23,390
subscribe to be notified whenever I

792
00:34:23,390 --> 00:34:25,970
release a new video once again thank you

793
00:34:25,970 --> 00:34:29,710
very much for joining in today good bye
