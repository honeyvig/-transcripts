foreign
Computing boot camp in this boot camp
you will embark on a comprehensive
journey to learn about cloud computing
one of the most transformative
Technologies of our time and also you
will gain the Knowledge and Skills
necessary to navigate the world of cloud
computing with confidence did you know
that the value of the cloud computing
Market was 370 billion dollars in 2020
an estimated to be 830 billion dollars
by the end of 2025. due to this the
market value has set up a high for data
Engineers an average salary of a data
engineer is 114 000 in the US and 8 lakh
in India if you are also aiming to be a
professional data engineer you are at
the right place take a look at a Caltech
cloud computing bootcamp program by
simply learn and Kickstart your journey
towards becoming a data engineer this
education program will help you become
an expert in designing planning and
scaling Cloud implementations for more
information check out the link in the
description box hi guys welcome to the
cloud computing bootcamp by simply learn
throughout this boot camp you will learn
what is cloud computing and its
fundamentals moving forward we will
learn about virtualization next we'll
understand what AWS is and its services
followed by we will go through Azure and
its services next we will learn some
difference between AWS and Azure and at
last we will learn about how to become a
cloud computing engineer now over to our
training experts imagine you're the
owner of a small software development
firm and you want to scale your business
up however a small team size the
unpredictability of demand and limited
resources are roadblocks for this
expansion that's when you hear about
cloud computing but before investing
money into it you decide to draw up the
differences between on-premise and
cloud-based Computing to make a better
decision
when it comes to scalability you pay
more for an on-premise setup and get
lesser options too
once you've scaled up it is difficult to
scale down
and often leads to heavy losses in terms
of infrastructure and maintenance costs
cloud computing on the other hand allows
you to pay only for how much you use
with much easier and faster Provisions
for scaling up or down
next let's talk about server storage
on-premise systems need a lot of space
for their servers notwithstanding the
power and maintenance hassles that come
with them on the other hand cloud
computing Solutions are offered by cloud
service providers who manage and
maintain the servers saving you both
money and space then we have data
security on-premise systems offer less
data security thanks to a complicated
combination of physical and traditional
I.T security measures whereas cloud
computing systems offer much better
security and lets you avoid having to
constantly Monitor and manage security
protocols in the event that a data loss
does occur the chance for data recovery
with on-premise setups are very small in
contrast cloud computing systems have
robust disaster recovery measures in
place to ensure faster and easier data
recovery
finally we have maintenance on-premises
systems also require additional teams
for hardware and software maintenance
loading up the costs by a considerable
degree
cloud computing systems on the other
hand are maintained by the cloud service
providers reducing your costs and
resource allocation substantially
so now thinking that cloud computing is
a better option you decide to take a
closer look at what exactly cloud
computing is
cloud computing refers to the delivery
of on-demand Computing Services over the
internet on a pay-as-you-go basis in
simpler words rather than managing files
and services on a local storage device
you'll be doing the same over the
internet in a cost-efficient manner
cloud computing has two types of models
deployment model and service model
there are three types of deployment
models public private and hybrid Cloud
imagine you're traveling to work you've
got three options to choose from one you
have buses which represent public clouds
in this case the cloud infrastructure is
available to the public over the
internet
these are owned by cloud service
providers
two then you have the option of using
your own car this represents the private
cloud with the private Cloud the cloud
infrastructure is exclusively operated
by a single organization this can be
managed by the organization or a third
party and finally you have the option to
Hell a cab this represents the hybrid
cloud
a hybrid cloud is a combination of the
functionalities of both public and
private clouds
next let's have a look at the service
models there are three major service
models available es pass and SAS
compared to on-premise models where
you'll need to manage and maintain every
component including applications data
virtualization and middleware cloud
computing service models are hassle free
is refers to infrastructure as a service
it is a cloud service model where users
get access to basic Computing
infrastructure they are commonly used by
it administrators if your organization
requires resources like storage or
virtual machines is the model for you
you only have to manage the data runtime
middleware applications and the OS while
the rest is handled by the cloud
providers next we have pass
pass or platform as a service provides
Cloud platforms and runtime environments
for developing testing and managing
applications this service model enables
users to deploy applications without the
need to acquire manage and maintain the
related architecture
if your organization is in need of a
platform for creating software
applications pass is the model for you
pass only requires you to handle the
applications and the data the rest of
the components like runtime middleware
operating systems servers storage and
others are handled by the cloud service
providers and finally we have SAS SAS or
software as a service involves cloud
services for hosting and managing your
software applications
software and Hardware requirements are
satisfied by the vendors so you don't
have to manage any of those aspects of
the solution
if you'd rather not worry about the
hassles of owning any it equipment the
SAS model would be the one to go with
SAS the cloud service provider handles
all components of the solution required
by the organization if you're also
aiming to be a professional data
engineer you are at the right place take
a look at a Caltech cloud computing
bootcamp program by simply learn and
Kickstarter Journey towards becoming a
data engineer this education program
will help you become an expert in
designing planning and scaling Cloud
implementations for more information
check out the link in the description
box I am Samuel a multi-platform cloud
architect and trainer working for simply
learn let's dive deep into the topics
we're going to discuss here why we
needed cloud computing to begin with and
what is cloud computing and different
types of cloud computings available at
the moment and we also are going to talk
about a dominant Cloud providers
available in the Market at the moment
and we will touch a few topics or
scenarios on life cycle of a cloud
computing solution and we will be
talking about how cloud computing is
implemented in AWS and there is nothing
like visually seeing how things work in
the cloud right so we're going to end it
with a demo and we're going to talk
about products or we're actually going
to use products like ec2 and S3 ec2
being in virtual computer in the cloud
and S3 being an object storage in the
cloud let's understand about why Cloud
compute shooting was needed what was the
problem that we had that cloud computing
solved and since then it took over the
market let's understand that first and
that will solve a lot of unanswered
questions about cloud computing or
services that you might have here on the
left we have an owner of a business and
he wants to set up and DZ or have an ID
infrastructure for his company so he
called Paul an I.T educated person in
his company and consulted him about how
to go about setting up an ID
infrastructure now Paul is the kind of
guy who keeps himself updated about
what's happening in the IT industry and
he frequently goes through learnings
about the reason technology so without
missing a beat Paul suggested why not
set up the environment in the cloud but
his manager was not sure about what is
cloud and and more than trying to
understand what cloud is he was curious
about the benefits of cloud over having
an DC locally so Paul started to explain
the very same thing I'm gonna explain to
you now let's start with the expenditure
or the billing model with Cloud the
billing model is pay as you go type
meaning we use less and pay less and we
use more and we pay less per unit on the
other hand in on-premises we can't
expect that we pay everything upfront
and there is an additional operating
cost and it never lets us to dynamically
scale in on-premises a lot of space is
required for seating the servers but in
the cloud not such space requirement is
needed for the organization in
on-premises we also need a dedicated
team to manage the hardware and software
but in the cloud no such dedicated team
is needed for most of the services they
all get managed by the provider and even
if we need to manage them the provider
gives us options to manage them through
the console which is a lot lot simpler
than managing directly from the device
in the on-premises we need to admit the
fact that data security is poor due to
the cost involved in procuring the
hardware and software to provide the
security but in the cloud the security
standards are high due to the
Investments the providers have done to
secure the data and to meet the
compliance in traditional DC there will
generally be less focus on data recovery
and we kind of settle for less when it
comes to data recovery due to the costs
involved and you know the effort
involved in replicating the data and
even if we set up a high performing data
replication a lot more can be done in
the cloud for the same cost the
on-premises environment lacks the
flexibility needed today like if I need
to restructure the ID for the new age
business needs then the on-premises is
not so friendly for such changes but in
the cloud I can easily undo or tear down
an environment or migrate to the new
environment and tear down the old
environment in view button clicks now
looking at the number and the frequency
of the releases that happen scheduling
updates would be an full-time job but
with Cloud the updates happen
automatically in on-premises if I'm
working with the team that is spread
across the globe working with them in
unison and sharing the data is a tedious
work but with the cloud there are a lot
of tools and Technologies put together
that makes it easy to share the data
with other members in the team or with
the new prospective customer in
on-premises if I'm working with a team
that is spread across the globe working
with them in unison and sharing the data
is a tedious work but with a cloud there
are a lot of tools and Technologies put
together that makes it easy to share the
data with other members from the team or
with a New Prospect customer I will be
working with who is present across the
other side of the globe in on-premises
the data will be present inside the DC
or inside the on-premises DC and even a
valid user trying to access the data
from outside the organization is a tough
task but with a cloud as long as someone
has internet providing the person access
is just a few Mouse clicks away talk
about implementation building and
on-premises DC takes time I was working
on a project few years back and the goal
to make a DC go live at that time was
after two years from the date we were
speaking about it but with the cloud we
can bring our DC in the cloud within
weeks after all this explanation and
comparisons and talking about benefits
pulse manager was fully enlightened and
wants to have his ID environment in the
cloud but our Paul is not done yet and
he took his manager through another
level of discussion about the cloud just
like I'm gonna take you now so let's
talk about what is cloud computing now
cloud computing is the ability to
deliver on-demand Computing service over
the internet and that too on a
pay-as-you-go basis now you might think
well what does that mean let me explain
now with Cloud rather than managing
files on a local storage devices cloud
computing makes it possible to save them
over the internet and access them from
on the internet so I can be a mobile
person and I'm moving from place to
place but I can access the storage from
the internet because it's in the
internet and if I want to give access to
somebody else again it's easy for me to
give access to them as long as they have
Internet connection available with them
now let's move further and talk about or
get understanding on the types of cloud
computing we can categorize the
different types of cloud computing based
on two wide categories one being a
deployment model and the other one being
service model let's talk about the
deployment model first deployment model
is categorized into three types first
one is public and then private and then
hybrid cloud in other words public Cloud
private cloud and hybrid Cloud it'll be
easy for me to explain and also it will
be easy for you to understand if I walk
you through this example consider the
different types of vehicles we use to
commute from one place to another for
example if I want to travel I can pick a
bus which is accessible to anyone I I
get in and I pay for the seat that I
occupy and I pay for the time that I
will be traveling in it and I'm done
cost is very less here a similar kind of
thing happens in the public Cloud I pay
only for the resource that I use and I
pay for how long I use it if I use less
I pay less if I use more I pay more for
that month simple on the other hand
private cloud is like buying your own
car and using it for commuting purpose
here I pay a huge amount upfront and it
is all owned only by me I do not pay for
it in an Audi fashion but completely and
all upfront the cost here is very huge
and thirdly if I want the best of both
types like the comfort of the own car
and still don't want to pay all upfront
otherwise one only to pay for the time
that I use the service I can rent a car
similarly I can have it in an hybrid
environment meaning if I already have a
DC I can integrate it with the cloud and
use both the DCS and that would become
an hybrid environment alright so that
was good of in learning let's summarize
the types of cloud based on deployment
models and as we know now about the
public Cloud public cloud is and Cloud
infrastructure that's made available to
the general public over the internet and
it is owned by the cloud provider some
of the major players as Cloud providers
are AWS Microsoft Azure IBM's blue cloud
and Sun Cloud and private Cloud now this
Cloud infrastructure is exclusively
operated by a single organization it can
be managed by organizations or third
party and may exist on-premises or
off-premises doesn't matter but the
point here is this is exclusively
operated for a single organization and
some companies that provide private
Cloud are AWS and VMware and hybrid
Cloud gives the best of both public and
the private Cloud for example the
federal agencies they opt for private
clouds for storing and developing
personal data and they use public Cloud
to share the non-sensitive data with the
general public or with other government
departments now let's talk about
different clouds based on the service
model if we need to categorize them
broadly we can categorize them as
infrastructure as a service IAS or
platform as a service paas or software
as a service SAS they sometimes are
referred to as is and SAS now at this
moment you could be like this guy
thinking Sam I thought you'd done
categorizing the cloud now you're going
to talk about three more categories
which one should I pick well let me
explain if all that you want is just in
VM and you have all the expertise to
install the software on top of it and
make it work then go for is if you only
want a platform or an interfaced program
or an interface to upload a program and
make it run then pick pass or if all
that you want is a finished product
hosted in the cloud and be able to
access it through the Intel internet
then go for SAS here you get a username
and password for an application and you
can begin to customize the application
based on your needs all right let's talk
about is in a bit more detail I as it
gives basic Computing infra it's based
on a pay for what you use model and some
of the cloud providers who are big
players are AWS Azure and Google and
here the users generally will be it
admins in Pas the provider gives you a
platform or a runtime environment for
developing testing and managing
application it's platform ready you buy
the platform you upload a code and you
start working on it and it allows the
software developers to deploy
applications without running the
underlying infrastructure and as you
might have guessed by now the
interesting candidates who would use Paz
is software developers and in SAS
everything is managed by the vendor be
it the hardware or the software it's
managed by the vendor and we pay for the
service and we pay for it through a pay
as you go subscription model and as you
might have guessed the end users here
would be End customer itself all right
let's put together everything in the
same page and compare and contrast the
different types of service models in
this chart it explains the difference
between the four models starting from
on-premises to is and then pass and says
it is self-explanatory that the
resources managed by us are huge in
on-premises and little less in is and
further less or reduced in paths and
nothing to manage when it comes to SAS
let me also explain the different types
of cloud services through an example
like this let's say that you have a
crush on cake and you're planning to
bake one yourself now let's look at the
options you can have you can make all
the ingredients yourself be the floor
butter and you know put together and
bake the whole thing yourself using your
own oven pan you know the needed water
and the rest you get an idea right
everything is yours and that's on
premises all that you use is owned by
you and nothing is managed by the vendor
the other options you can have is buy
the ingredients and mix and bake the
cake yourself now this would be like is
here the infra is managed by the
provider and we get to use it and
customize it the way we want it here the
cloud service isn't shared
responsibility the other options you
still have on hand is simply pick a
phone and order a cake now this is a lot
simpler than the rest we discussed so
far you know it's simply picking the
phone and ordering the cake and pay for
it when it arrives simple and when it
reaches home you will have to arrange
the table garnish the cake if that's
needed and then enjoy the cake it's the
same way with pass just get the platform
in which you would run your code and
upload your code and start running your
application here you and the vendors
still share the responsibility you still
have one more option left that is simply
go out and dine this is a lot lot
simpler that it requires no effort from
us at all you buy the fully finished and
garnished cake and pay for it and walk
out no responsibility on making the cake
it's the same way with SAS we buy the
finished product and pay for the
finished application as next thing let's
talk about the different Cloud providers
Amazon web services AWS is a cloud
computing service provided by Amazon it
provides a mix of infrastructure as a
service is platform as a service pass
and package software as a service called
SAS offerings Microsoft Azure formerly
known as Windows Azure is a cloud
computing service by Microsoft and it
sort of specializes in using Cloud for
building testing deploying and managing
the applications through the service
throughout a Global Network that
Microsoft manages it also provides
software as a service platform as a
service infrastructure as a service and
it supports lots of different
programming languages and tools and
Frameworks including both Microsoft and
third-party software and systems IBM
cloud is a cloud computing service
offered by IBM IBM Cloud includes
infrastructure as a service software as
a service platform as a service now the
difference is here it offers through
public private and hybrid Cloud delivery
models VMware on the other hand is a
subsidiary of Dell Technologies and
provides cloud computing and platform
virtualization software and services it
was the first commercially successful
company to virtualize the x86
architecture Google Cloud platform on
the other hand is offered by Google it's
a suit of Cloud Computing Services that
run on the same infrastructure that
Google uses internally for its end user
products such as the Google search and
the YouTube you're familiar with
alongside a set of managed tools it also
provides cloud services including
Computing Services data storage Services
data analytics and machine learning
services digitalocean on the other hand
is headquartered in New York City with
data centers worldwide digitalocean
provides developers cloud services that
help to deploy and scale applications
that run simultaneously on multiple
computers as of January 2018
digitalocean was the third largest
hosting company in the world in terms of
web facing computers let's talk about
cloud computing in AWS Amazon web
services AWS is a cloud computing
service provided by Amazon and these
services are accessible over the
internet and because AWS provides
infrastructure as a service it's a
flagship offering we can create and
deploy any type of application in the
cloud on top of the is that Amazon
provides and you know the best part here
is the subscriptions are pay as you go
type you use less and pay less and only
for what you have used you use more pay
more but still less per unit for the
service used attractive isn't it if you
are also aiming to be a professional
data engineer you are at the right place
take a look at a Caltech cloud computing
bootcamp program by simply learn and
Kickstart your journey towards becoming
a data engineer this education program
will help you become an expert in
designing planning and scaling Cloud
implementations for more information
check out the link in the description
box now let's talk about the life cycle
of the cloud computing solution the very
first thing in the life cycle of a
solution or a Cloud solution is to get a
proper understanding of the requirement
I didn't say get the requirement but
said get a proper understanding of the
requirement it is very vital because
only then we will be able to properly
pick the right service offered by the
provider getting a sound understanding
the next thing would be to define the
hardware meaning choose the compute
servers that will provide the right
support where you can resize the compute
capacity in the cloud to run application
programs getting a sound understanding
of the requirement helps in picking the
right Hardware one size does not fit all
there are different services and
Hardwares for different needs you might
have like ec2 if you're looking for is
and LA Lambda if you're looking for
serverless computing and ECS that
provides containerized servers so there
are a lot of Hardwares available pick
the right Hardware that suits your
requirements the third thing is to
define the storage choose the
appropriate storage service where you
can backup your data and a separate
storage service where you can archive
your data locally within the cloud or
from the internet and choose the
appropriate storage that is one
separately for backup called S3 and
there is one separately for archival
that's for glaciers so you know you
knowing the difference between them
really helps in picking the right
service for the right kind of need
Define the network Define the network
that securely delivers data video and
applications Define and identify the
Network Services properly for example
VPC for Network Route 53 for DNS and
direct connection for private P2P line
from your office to the AWS data center
set up the right Security Services IM
for authentication and authorization and
KMS for a data encryption at rest so
there are a variety of security products
available we got to pick the right one
that suits our need and there are a
variety of deployment and Automation and
monitoring tools that you can pick from
for example Cloud watch is for
monitoring Auto scaling is for being
elastic and cloud formation is Define
the management process and tools you can
have complete control of your Cloud
environment if you define the management
tools which monitors your AWS resources
and all the custom applications running
on AWS platform there are a variety of
deployment Automation and monitoring
tools you can pick from like cloudwatch
for monitoring Auto scaling for
Automation and the cloud formation for a
deployment so knowing them will help you
in defining the life cycle of the cloud
computing solution properly and
similarly there are a lot of tools for
testing a process like code star and
code build and code pipeline these are
tools with which you can build test and
deploy your code quickly and finally
once everything is said and done click
the analytic service for analyzing and
visualizing the data using the analytics
Services where we can start querying the
data instantly and get a result now if
you want to visually view the happenings
in your environment you can pick Athena
and other tools for analytics or EMR and
which is elastic map produce and Cloud
search all right enough of theory and
let's have a quick look at how two
services in AWS ec2 and S3 work together
and benefits us here are two ID
professionals talking to each other one
says I have an application which takes
lot of storage and works only on Linux
system which I do not have at the moment
and the other one is a smart guy and he
immediately replies that he could use S3
to store data and retrieve data and use
ec2 for all this compute needs and then
the Curious conversation builds up and
the first person wants to know what is
easy to ensure 3 and the second guy
starts to explain that AWS ec2 is a web
service that provides a secure and
resizable compute capacity in their
cloud and ec2 it can also be used to
launch as many virtual servers as we
need and about S3 he explains AWS S3 is
a simple storage service provided by AWS
and about S3 he explains further saying
that using Amazon S3 we can store and
retrieve any amount of data at any time
on the web alright so the very first
thing is to have an AWS account so
create an AWS account and second thing
is to create an AWS S3 bucket and upload
the files there you know the files that
ec2 server is going to pull from will
get stored in S3 as first thing all
right so the first thing is to create an
S3 bucket so let's create an S3 bucket
and let's call it as a website bucket
and these names will have to be unique
so let's say if this bucket name is
available it says bucket name already
taken or already exist so let me top it
up with SL meaning simply learn all
right so we were able to create a bucket
and in that bucket let me upload a
Content that basically is going to be my
index file that's going to go and sit in
my web server so let me also make it
public and view it alright so this is
the content that I have stored in my S3
and this is the content I'm going to
push to my ec2 server right Second Step
create an AWS S3 bucket and upload files
we're done with that third is to create
an ec2 instance that's in other words
create an virtual machine in the cloud
let's go and create it alright the third
thing is to create an ec2 instance so
let's create an ec2 instance it's plain
and it's very simple I'm going to keep
everything as defaults here alright so
I've launched an ec2 instance as you see
it's running I also have an IP address
public IP address here with that I have
logged into this ec2 instance and I'm in
the folder slash War slash www
HTML and as you see there is nothing in
there at the moment and This Server also
has Apache installed in it as you can
see and now I've browse to the IP
address or the ec2 instance and it's
showing a page which is the default
Apache page all right if I had any files
in this folder that would get shown as
the web page instead of the default page
our task is to save files in S3 and move
them to the ec2 instance so S3 is going
to act as a storage or a repository or a
source code control in this example all
right so let's do that all right the
third step is to create your ec2
instance and that's what we have done
and the ec2 instance has no files in it
and the fourth step is to synchronize
the source code bucket with the ec2
instance let's do that the actual
command to do that would be AWS S3 sync
and then the name of the bucket from
which we're going to pull the code and
the folder in which we're going to put
the code or the data all right so it has
downloaded something look at that and
now if we go back to the test page and
do refresh there you go it's showing the
page that it pulled from S3 so here I
can use S3 as the source code control
bucket and any information that I put in
there will get reflected in ec2 instance
once I do a sync every day and that's
how I use S3 as my storage for ec2 all
right finally we were able to
synchronize S3 bucket and the ec2
instance and we were also able to view
the results in the web browser of the
ec2 instance the data was copied from S3
to the ec2 instance and that we were
able to view from the web browser all
right so what did we learn we learned
about what is cloud computing understood
the basics of cloud computing we
understood about the types of cloud
computing based on deployment model
tools and service model and then we
understood how cloud computing is with
AWS and now how AWS is a cloud computing
service provider and the benefits of
using AWS over other providers we also
looked at life cycle of the cloud
computing solution and finally we did a
demo on AWS ec2 and S3 and we saw how
ec2 is dependent on S3 or how we can use
S3 to be dependent on ec2 and sort of
act as an storage for the computer
instances so to understand what exactly
virtualization is let's take a look at
an example so beat Jake he works as a
software developer in an IT firm and he
often has to work on different projects
involving multiple operating systems
according to the requirements of the
project during which you often come
across cases where the managing of data
becomes problematic due to the
compatibility issues with the different
operating systems which makes it hard
for the completion of the project so
what can Jake do to overcome such a
problem well to overcome such a problem
he decided to use the way of
virtualization
but what is virtualization and how does
it help us
well let's take a look
to begin with we'll take a look at what
exactly virtualization is and how it can
help us then we'll understand what
virtual machines are after that we learn
about the role and different types of
hypervisor that are involved during the
process of virtualization after that we
learn what different types of
virtualizations are available and how
differently they affect our systems and
lastly we will see what benefits
virtualization provides us with to begin
with we'll understand what
virtualization is
virtualization is nothing but utilizing
a software to create a virtual layer
over the hardware which allows the
system Hardware to be used more
efficiently and allows appropriate
return for a hardware cost the software
hypervisor also allows the elements of
the system like storage memory processor
and Etc to be distributed among multiple
separate and secure virtual computers
known as virtual machines to understand
the situation of virtualization much
better let's take a look at an example
this is a system installed with the
Windows operating system which is
officially known as the host OS where
the virtualization software known as the
hypervisor will run
and then using the hypervisor software
we can have multiple instances of
different OS including Unix Mac and
Linux which are known as virtual systems
or guest OS
the working of the virtualization is
only possible by using a software known
as a hypervisor and later in the video
we will also learn about the working and
different types of hypervisor involved
now that we have understood what
virtualization is let's take a look at
what a virtual machine is
so as the name suggests virtualization
is nothing but an emulation or a virtual
representation of a physical operating
system on a hardware device
the virtual machines are also known as
guest OS whereas a physical system that
they run on is also known as the host OS
now let's take a look at the software
that makes the virtualization possible
hypervisor is a software layer that
manages the virtual machines
it forms an interface between the
physical system and the virtual machine
which ensures the proper access of the
resources
it also manages the virtual machine so
that they don't interfere with each
other's resources
let's take a look at what different
types of hypervisors are there the first
type of hypervisor is known as the type
1 hypervisor or the bare metal
hypervisor this type of hypervisor
directly interacts with the hardware
system and user resources
the other type of hypervisor is known as
the type 2 hypervisor which runs as an
application on the host operating system
and the hypervisor also coordinates with
the virtual machine for resource
management
let's take a look at the type 1
hypervisor they run directly on top of
the host operating system and utilize
the hardware resources and that is why
they're also known as the bare metal
hypervisor they take up the place of the
host operating system and works as the
own operating system
this is this type of hypervisor Works
directly on the hardware system they are
highly efficient now that we understand
type 1 hypervisor let's take a look at
the type 2 hypervisor this type of
hypervisor doesn't directly work on the
operating system Hardware but instead it
works as an application in the host
operating system where they are suitable
for running individual systems users can
also have different multiple OS
installed in the physical system by
using this type of hypervisor
due to the application-based working of
the type 2 hypervisor they are also
known as virtual machine monitors or in
short vmms
now that we understand what different
types of hypervisors there are let's
take a look at what types of
virtualizations are present
the first type of virtualization is the
desktop virtualization then the network
virtualization storage virtualization
and lastly the application
virtualization let's take a look at them
one by one for desktop virtualization as
the name suggests in this type of
virtualization we can run multiple
operating systems on a single Hardware
system let's take a look at the
different types of desktop
virtualization the first one is virtual
desktop infrastructure or in short vdi
which runs numerous virtual machines on
a central server and then hosted to the
user according to the user's requirement
in this way the user can access any
operating system without having to
physically install the particular
operating system in its Hardware system
the second one is known as local desktop
virtualization as the name suggests it
uses a hypervisor software on a local
system which allows a user to run
multiple operating systems
simultaneously without having to affect
the host operating system
the next type of virtualization is
Network virtualization
in this type of virtualization the
software creates a virtual instance of
the network that can be used to manage
from a single console and it also forms
the abstraction of the hardware
components and functions including
switches routers and Etc which
simplifies the network management
different types of network
virtualization are software-defined
virtualization which virtualizes the
hardware that controls the network
traffic routing and the other one is
Network function virtualization
virtualize is the Hardware Appliances
that provide Network specific functions
easier to configure and manage for
example a firewall let's take a look at
the third type of virtualization known
as the storage virtualization this
virtualization enables all the storage
devices on the system to be accessed and
be managed as a single storage unit the
storage virtualization collects all the
storage into a single pool from which
they can allot another virtual machine
on the same network as required and this
makes it easier to assign storage for
multiple virtual machines with maximum
efficiency and the last virtualization
that we'll discuss is the application
virtualization in this type of
virtualization process the application
runs directly without the need of
installing it into the system as they
run on a virtual environment different
types of application virtualization app
the local application virtualization and
this type of application runs on the
host device but runs in a different
virtual environment but not in the
hardware
the second one is application
virtualization and in this the
application is on the server side and it
sends some of the components to the host
device according to the requirement and
last is the server-based application
virtualization this application runs
directly on the server side and sends
only the interface to the client system
now let's take a look at the benefits of
virtualization the first one is resource
efficiency
as the name suggests before
virtualization each application server
used its own Hardware resources which
were being underused but with having
multiple virtual machines maximum
utilization of the hardware capacity
occurs
then we have minimum downtime which
refers to the crashes of operating
systems and applications which can cause
a halt in the user productivity by using
virtualization the admin can run
multiple similar virtual machines
simultaneously and change over the
working instances in case of a crash
instead of having multiple dedicated
servers
and then we have time management
buying installing and configuring a new
system is not only costly but also a
waste of time
in such a case virtualization can solve
the problem provided that the existing
Hardware resources are sufficient for
running the virtualization software
otherwise it can be configured for the
same meet Rob he runs an online shopping
portal the portal started with a modest
number of users but has recently been
seeing a surge in the number of visitors
on Black Friday and other holidays the
portal saw so many visitors that the
servers were unable to handle the
traffic and crashed is there a way to
improve performance without having to
invest in a new server wondered rob a
way to upscale or downscale capacity
depending on the number of users
visiting the website at any given point
well there is Amazon web services one of
the leaders in the cloud computing
Market before we see how AWS can solve
Rob's problem let's have a look at how
AWS reached the position it is at now
AWS was first introduced in 2002 as a
means to provide tools and services to
developers to incorporate features of
amazon.com to their website in 2006 its
first Cloud Services offering was
introduced in 2016 AWS surpassed its 10
billion Revenue Target
and now AWS offers more than 100 cloud
services that span a wide range of
domains thanks to this the AWS cloud
service platform is now used by more
than 45 of the global market now let's
talk about what is AWS AWS or Amazon web
service is a secure cloud computing
platform that provides computing power
database networking content storage and
much more
the platform also works with a PSU go
pricing model which means you only pay
for how much of the service is offered
by AWS you use
some of the other advantages of AWS are
security AWS provides a secure and
durable platform that offers end-to-end
privacy and security
experience you can benefit from the
infrastructure management practices born
from Amazon's years of experience
flexible it allows users to select the
OS language database and other services
easy to use users can host applications
quickly and securely
scalable depending on user requirements
applications can be scaled up or down
AWS provides a wide range of services
across various domains what if Rob
wanted to create an application for his
online portal AWS provides compute
services that can support the app
development process from start to finish
from developing deploying running to
scaling the application up or down based
on the requirements the popular Services
include ec2 AWS Lambda Amazon light sale
and elastic Beanstalk for storing
website data Rob could use AWS storage
services that would enable him to store
access govern and analyze data to ensure
that costs are reduced agility is
improved and Innovation accelerated
popular services within this domain
include Amazon S3 EBS S3 Glacier and
elastic file storage
Rob can also store the user data in a
database with aw Services which he can
then optimize and manage popular
services in this domain include Amazon
RDS dynamodb and redshift if Rob's
businesses took off and he wanted to
separate his Cloud infrastructure or
scale up his work requests and much more
he would be able to do so with the
networking Services provided by AWS some
of the popular networking Services
include Amazon VPC Amazon Route 53 and
elastic load balancing other domains
that AWS provide services in are
analytics blockchain containers machine
learning internet of things and so on
and there you go that's AWS for you in a
nutshell AWS let me start the session
with this scenario let's imagine how
life would have been without Spotify for
those who are hearing about Spotify for
the first time a Spotify is an online
music service offering and it offers
instant access to over 16 million
licensed songs Spotify now uses AWS
Cloud to store the data and share it
with their customers but prior to AWS
they had some issues imagine using
spotify before AWS let's talk about that
back then users were often getting
errors because Spotify could not keep up
with the increased demand for storage
every new day and that led to users
getting upset and users canceling the
subscription the problem Spotify was
facing at that time was their users were
present globally and were accessing it
from everywhere and they had different
latency in their applications and
Spotify had a demanding situation where
they need to frequently catalog the
songs released yesterday to today and in
the future and this was changing every
new day and the songs coming in rate was
about 20 000 a day and back then they
could not keep up with this requirement
and needless to say they were badly
looking for a way to solve this problem
and that's when they got introduced to
AWS and it was a perfect fit and match
for their problem AWS offered a
dynamically increasing storage and
that's what they needed AWS also offered
tools and techniques like storage life
cycle management and trusted advisor to
properly utilize the resource so we
always get the best out of the resource
used AWS addressed their concerns about
easily being able to scale yes you can
scale the AWS environment very easily
how easily one might ask it's just a few
button clicks and AWS sold spotify's
problem let's talk about how it can help
you with your organization's problem
let's talk about what is AWS first and
then let's bleed into how AWS became so
successful and the different types of
services that AWS provides and what's
the future of cloud and AWS in specific
let's talk about that and finally we'll
talk about a use case where you will see
how easy it is to create a web
application with AWS all right let's
talk about what is AWS AWS or Amazon web
services is a secure cloud service
platform it is also pay as you go type
billing model where there is no upfront
or Capital costs we'll talk about how
soon the service will be available well
the service will be available in a
matter of seconds with AWS you can also
do identity and access management that
is authenticating and authorizing a user
or a program on the Fly and almost all
the services are available on demand and
most of them are available
instantaneously and as we speak Amazon
offers 100 plus services and this list
is growing every new week now that would
make you wonder how AWS became so
successful of course it's their
customers let's talk about the list of
well-known companies that has their ID
environment in AWS Adobe Adobe uses AWS
to provide multi-terabyte operating
environments for its customers by
integrating its system with AWS Cloud
Adobe can focus on deploying and
operating its own software instead of
trying to you know deploy and manage the
infrastructure Airbnb is another company
it's a Community Marketplace that allows
property owners and travelers to connect
each other for the purpose of renting
unique vacation spaces around the world
and the Airbnb Community users
activities are conducted on the website
and through iPhones and Android
applications Airbnb has a huge
infrastructure in AWS and they are
almost using all the services in AWS and
are getting benefited from it another
example would be Autodesk Autodesk
develops software for engineering
designing and entertainment Industries
using services like Amazon RDS or
rational database service and Amazon S3
or Amazon simple storage service
Autodesk can focus on deploying or
developing its machine learning tools
instead of spending that time on
managing the infrastructure AOL or
American online uses AWS and using AWS
they have been able to close data
centers and decommission about 14 000
in-house and co-located servers and move
Mission critical workflow to the cloud
and extend its Global reach and save
millions of dollars on energy resources
bitdefender is an internet security
software firm and their portfolio of
softwares include antivirus and
anti-spyware products bitdefender uses
ec2 and they're currently running few
hundred instances that handle about 5
terabytes of data and they also use
elastic load balancer to load balance
the connection coming in to those
instances across availability zones and
they provide seamless Global delivery of
service because of that the BMW group it
uses AWS for its new connected Car
application that collects sensor data
from BMW 7 Series cars to give drivers
dynamically updated map information
Canon's offers Imaging products division
benefits from faster deployment times
lower cost and Global reach by using AWS
to deliver cloud-based services such as
mobile print the office Imaging products
division uses AWS such as Amazon S3 and
Amazon Route 53 Amazon cloudfront and
Amazon IM for their testing development
and Production Services Comcast it's the
world's largest cable company and the
leading provider of internet service in
the United States Comcast uses AWS in a
hybrid environment out of all the other
Cloud providers Comcast chores AWS for
its flexibility and scalable hybrid
infrastructure Docker is a company
that's helping redefine the way
developers build ship and run
applications this company focuses on
making in use of containers for this
purpose and in AWS the service called
the Amazon ec2 container service is
helping them achieve it the esa or
European Space Agency although much of
esa's work is done by satellites some of
the programs data storage and Computing
infrastructure is built on Amazon web
services Esa shows AWS because of its
economical pay as you go system as well
as its quick startup time the Guardian
newspaper uses AWS and it uses a wide
range of AWS services including Amazon
Kinesis Amazon redshift that power and
analytic dashboard which editors use to
see how stories are trending in real
time Financial Times FD is one of the
world's largest leading business news
organization and they used Amazon
redshift to perform their analysis A
Funny Thing Happened Amazon redshift
performed so quickly that some analysis
thought it was malfunctioning they were
used to running queries overnight and
they they found that the results were
indeed correct just as much faster by
using Amazon redshift FD is supporting
the same business functions with costs
that are 80 percentage lower than what
was before general electric GE is at the
moment as we speak migrating more than
9000 workloads including 300 desperate
Erp systems to AWS while reducing its
data center footprint from 34 to 4 over
the next three years similarly Howard
Medical School HTC IMDb McDonald's NASA
Kellogg's and lot more are using the
services Amazon provides and are getting
benefited from it and this huge success
and customer portfolio is just the tip
of the iceberg and if we think why so
many adapt AWS and if we let AWS answer
that question this is what AWS would say
people are adapting AWS because of the
security and durability of the data an
end-to-end privacy and encryption of the
data and storage experience we can also
rely on a AWS way of doing things by
using the AWS tools and techniques and
suggested best practices built upon the
years of experience it has gained
flexibility there is a greater
flexibility in AWS that allows us to
select the OS language and database easy
to use swiftness in deploying we can
host our applications quickly in AWS be
it a new application or migrating an
existing application into AWS
scalability the application can be
easily scaled up or scaled down
depending on the user requirement cost
saving we only pay for the compute power
storage and other resources you use and
that too without any long-term
commitments now let's talk about the
different types of services that AWS
provides the services that we talk about
fall in any of the following categories
you see like you know compute storage
database Security customer engagement
desktop and streaming machine learning
developers tools stuff like that and if
you do not see the service that you're
looking for it's probably is big because
AWS is creating it as we speak now let's
look at some of them that are very
commonly used within compute Services we
have Amazon ec2 Amazon elastic Beanstalk
Amazon light sale and Amazon Lambda
Amazon ec2 provides compute capacity in
the cloud now this capacity is secure
and it is resizable based on the user's
requirement now look at this the
requirement for the web traffic keeps
changing and behind the scenes in the
cloud ec2 can expand its environment to
three instances and during no load it
can shrink its environment to just one
resource elastic Beanstalk it helps us
to scale and deploy web applications and
it's made with a number of programming
languages elastic Beanstalk is also an
easy to use service for deploying and
scaling web applications and services
deployed a bit in java.net PHP node.js
python Ruby Docker and lot other
familiar services such as Apache
passenger and IIs we can simply upload
our code and elastic Beanstalk
automatically handles the deployment
from capacity provisioning to load
balancing to Auto scaling to application
Health monitoring and Amazon light sale
is a virtual private server which is
easy to launch and easy to manage Amazon
light cell is the easiest way to get
started with AWS for developers who just
need a virtual private server light cell
includes everything you need to launch
your project quickly on a virtual
machine like SSD based storage a virtual
machine tools for data transfer DNS
management and a static IP and that too
for a very low and predictable price AWS
Lambda has taken Cloud Computing
Services to a whole new level it allows
us to pay only for the compute time no
need for provisioning and managing
servers an AWS Lambda is a compute
service that lets us run code without
provisioning or managing service Lambda
executes your code only when needed and
scales automatically from few requests
per day to thousands per second you pay
only for the compute time you consume
there is no charge when your core is not
running let's look at some storage
services that Amazon provides like
Amazon S3 Amazon Glacier Amazon abs and
Amazon elastic file system Amazon S3 is
an object storage that can store and
retrieve data from anywhere websites
mobile apps iot sensors and so on can
easily use Amazon S3 to store and
retrieve data it's an object storage
built to store and Destroy any amount of
data from anywhere with its features
like flexibility in managing data and
the durability it provides and the
security that it provides Amazon simple
storage service or S3 is a storage for
the internet and Glacier Glacier is a
cloud storage service that's used for
archiving data and long-term backups and
this Glacier is an secure durable and
extremely low cost cloud storage service
for data archiving and long-term backups
Amazon EVS Amazon elastic blog store
provides Block store volumes for the
instances of ec2 and this elastic Block
store is highly available and a reliable
storage volume that can be attached to
any running instance that is in the same
availability Zone ABS volumes that are
attached to the ec2 instances are
exposed as storage volumes that persist
and independently from the lifetime of
the instance an Amazon elastic file
system or EFS provides an elastic file
storage which can be used with AWS cloud
service and resources that are on
premises and Amazon elastic file system
it's an simple it's scalable it's an
elastic file storage for use with Amazon
cloud services and for on-premises
resources it's easy to use and offers a
simple interface that allows you to
create and configure file systems
quickly and easily Amazon file system is
built to elastically scale on demand
without disturbing the application
growing and shrinking automatically as
you add and remove files to your
application have the storage they need
and when they need it now let's talk
about databases the two major database
flavors are Amazon RDS and Amazon
redshift Amazon is it really eases the
process involved in setting up operating
and scaling a rational database in the
cloud Amazon RDS provides cost efficient
and resizable capacity while automating
time consuming administrative tasks such
as Hardware provisioning database setup
patching and backups it sort of frees us
from managing the hardware and sort of
helps us to focus on the application
it's also cost effective and resizable
and it's also optimized for memory
performance and input and output
operations not only that it also
automates most of the services like
taking backups you know monitoring stuff
like that it automates most of those
Services Amazon redshift Amazon redshift
is a data warehousing service that
enables users to analyze the data using
SQL and other business intelligent tools
Amazon redshift is an fast and fully
managed data warehouse that makes it
simple and cost effective analyze all
your data using standard SQL and your
existing business intelligent tools it
also allows you to run complex analogy
queries against petabyte of structured
data using sophisticated query
optimizations and most of the results
they generally come back in seconds all
right let's quickly talk about some more
services that AWS offers there are a lot
more services that AWS provides but are
we going to look at some more services
that are widely used AWS application
Discovery Services help Enterprise
customers plan migration projects by
gathering information about their
on-premises data centers in a planning a
data center migration can involve
thousands of workloads they are often
deeply interdependent server utilization
data and dependency mapping are
important early first step in migration
process and this AWS application
Discovery service collects and presents
configuration usage and behavior data
from your servers to help you better
understand your workloads Route 53 it's
a network and content delivery service
it's an highly available and scalable
Cloud domain name system or DNS service
and Amazon Route 53 is fully compliant
with IPv6 as well elastic load balancing
it's also a network and content delivery
service elastic load balancing
automatically distributes incoming
application traffic across multiple
targets such as Amazon ec2 instance
containers and IP addresses it can
handle the varying load of your
application traffic in a single
available zones and also across
availability zones AWS Auto scaling it
monitors your application and
automatically adjusts the capacity to
maintain steady and predictable
performance at a lowest possible cost
using AWS Auto scaling it's easy to set
up application scaling for multiple
resources across multiple services in
minutes Auto scaling can be applied to
web services and also for DB Services
AWS identity and access management it
enables you to manage access to AWS
services and resources securely using IM
you can create and manage AWS users and
groups and use permissions to allow and
deny their access to AWS resources and
moreover it's a free service now let's
talk about the future of AWS well let me
tell you something cloud is here to stay
here's what in store for AWS in the
future as yours pass by we're gonna have
a variety of cloud applications born
like iot artificial intelligence
business intelligence serverless
Computing and so on cloud will also
expand into other markets like
healthcare banking space automated cars
and so on as I was mentioning some time
back lot or greater Focus will be given
to artificial intelligence and
eventually because of the flexibility
and advantage that cloud provides we're
going to see a lot of companies moving
into the cloud all right let's now talk
about how easy it is to deploy an web
application in the cloud so the scenario
here is that our users like a product
and we need to have a mechanism to
receive input from them about their
likes and dislikes and you know give
them the appropriate product as per
their need alright though the setup and
the environment it sort of looks
complicated we don't have to worry
because AWS has tools and Technologies
which can help us to achieve it now
we're going to use services like Route
53 services like Cloud watch ec2 S3 and
lot more and all these put together are
going to give an application that's
fully functionable and an application
that's going to receive the information
like using the services like Route 53
cloudwatch ec2 and S3 we're going to
create an application and that's going
to meet our need so back to our original
requirement all I want is to deploy a
web application for a product that keeps
our users updated about the happenings
and the newcomings in the market and to
fulfill this requirement here is all the
services we would need ec2 here is used
for provisioning the computational power
needed for this application and ec2 has
a vast variety of family and types that
we can pick from for the types of
workloads and also for the intents of
the workloads we're also going to use S3
for storage and S3 provides any
additional storage requirement for the
resources or any additional storage
requirement for the web applications and
we are also going to use cloudwatch for
monitoring the environment and
cloudwatch monitors the application and
the environment and it provides trigger
for scaling in and scaling out the
infrastructure and we're also going to
use Route 53 for DNS and Route 53 helps
us to register the domain name for our
web application and with all the tools
and Technologies together all of them
put together we're going to make an
application a perfect application that
caters our need all right so I'm going
to use elastic Beanstalk for this
project and the name of the application
is going to be as you see GSG sign up
and the environment name is GSG signup
environment one let me also pick a name
let me see if this name is available yes
that's available that's the domain name
so let me pick that and the application
that I have is going to run on node.js
so let me pick that platform and launch
now as you see elastic Beanstalk this is
going to launch an instance it's going
to launch the monitoring setup or the
monitoring environment it's going to
create a load balancer as well and it's
going to take care of all the security
features needed for this application
all right look at that I was able to go
to that URL which is what we gave and
it's now having an default page shown up
meaning all the dependencies for the
software is installed and it's just
waiting for me to upload the code or in
specific the page required so let's do
that
let me upload the code I already have
the code saved here
so that's my code
and that's going to take some time all
right it has done its thing and now if I
go to the same URL look at that I'm
being thrown an advertisement page all
right so if I sign up with my name email
and stuff like that you know it's going
to receive the information and it's
going to send an email to the owner
saying that somebody had subscribed to
your service that's the default feature
of this app look at that email to the
owner saying that somebody had
subscribed to your app and this is their
email address stuff like that not only
that it's also going to create an entry
in the database and dynamodb is the
service that this application uses to
store data there's my dynamodb and if I
go to tables right and go to items I'm
going to see that a user with name
Samuel and email address so and so has
said ok or has shown interest in the
preview of my site or product so this is
where this is how I collect those
information right and some more things
about the infrastructure itself is it is
running behind and load balancer look at
that it had created a load balancer it
had also created an auto scaling group
now that's the feature of elastic load
balancer that we have chosen it has
created an auto scaling group and now
let's put this URL you see this it's
it's not a fancy URL all right it's an
Amazon given URL a dynamic URL so let's
put this URL behind our DNS let's do
that
so go to Services go to Route 53
go to hosted Zone and there we can find
the DNS name right so that's a DNS name
all right
all right let's create an entry
and map that URL to our load balancer
right
and create now technically if I go to
this URL it should take me to that
application all right look at that I
went to my custom URL and now that's
pointed to my application previously my
application was having a random URL and
now it's having a custom URL so what did
we learn we started the session with
what is AWS we looked at features and
tools Technologies products that AWS
provides and we also looked at the how
AWS became very successful again we
looked into the benefits and features of
AWS in depth and we also looked at some
of the services that AWS provides in
random and then we picked particular
services and we talked about them like
ec2 elastic Beanstalk light sail Lambda
storage stuff like that then we also
looked at the future of AWS what AWS
holds in the store for us we looked at
that and then finally we looked at a lab
in which we created an application using
elastic Beanstalk and all that we had to
do was a couple of clicks and boom an
application was there available that was
connected to the database and that was
connected to the simple notification
system that was connected to cloudwatch
that was connected to storage stuff like
that what's in it for you
I would be covering up what is AWS the
Amazon web services
what are the benefits of using AWS as a
cloud and the different AWS services
that would include compute service
storage service database service
networking service Security Service
management tool service developer tool
service likewise and then I would be
covering up demo on those essential AWS
services
let's look into what is AWS
AWS is a broadly adapted Cloud platform
which offers several on-demand
operations like compute power database
storage content delivery Etc and that
helps cooperate scale and grow AWS
Services can be used to create and
deploy any application in the cloud for
example it provides services over the
Internet just like world wide web and
AWS is the largest cloud platform
available that you can use for either
creating the application creating the
databases likewise the other features
also you can use simultaneously now what
are the benefits of AWS
the first is it is easy to use for using
the AWS you require the good internet
connectivity and then you can actually
browse it using the web console and also
you can use the command line interfaces
as well second
flexibility AWS offers you a flexibility
so that you can actually change or tweak
your Solutions whenever you require
reliability so with the help of the
Redundant infrastructure across the
globe the AWS gives you the reliability
that any application or any databases if
you are running on the AWS that would be
basically up all the time and there will
be no or very less downtime then comes
the scalability so scalability is one of
the important features of AWS and in
that case you can actually scale up your
resources
at any time you require so for example
if any of your application is over
utilized and you require more resources
to run your application you can do that
on the Fly then comes cost Effectiveness
so AWS is a very cost effective platform
because here whatever the service that
you use that is charged on a per hour
usage only so you don't have to pay the
complete cost like you do when you
procure the infrastructure in the data
centers you don't have to basically pay
for the complete package or usage of the
service you just have to pay for
whatever time duration that you have
actually used the service and the
associated charges with it and that
makes the AWS a very cost effective
solution then comes this security so AWS
is a secure platform and a lot of
measures have been taken so that the
security can be enhanced and upgraded in
the AWS so from the infrastructure level
the AWS have a very high level of
security that is implemented and from
the application and the solution
perspective it gives you a lot of
features where you can actually apply
the security as per your requirement
onto your applications coming to the AWS
services so essentially AWS services are
compute storage database migration
networking and content delivery
developer tools management tools Media
Services machine learning analytics
security identity and compliance mobile
services
application integration AR and VR which
is augmented reality and virtual reality
customer engagement business
productivity desktop and app streaming
internet offerings which is iot now
let's look into the compute service
which is one of the widely used service
on the AWS and what does the compute
service do these Services help
developers build deploy and scale an
application in the cloud platform that
is ec2
Lambda elastic container service elastic
load balancer light sail and elastic
bean stock these are the services which
lie in the compute service section only
one of the most widely used service
within the compute section is ec2 which
stands for elastic Cloud compute it is a
web service that allows developer to
rent virtual machines and helped to
resize the compute capacity
so here what you can do is you can run
the virtual machines and you have the
Privileges to select the type of
operating system that you want should be
running on your instances or on your
virtual machines and likewise later you
can customize as per your requirement
Lambda is a serverless compute service
it is also responsible to execute code
for a specific application so those who
are from the development background they
can focus more on creation of a code
they don't have to create a server
manage it instead they can use a Lambda
where you they can deploy their code
directly onto the Lambda server then
comes this storage service now couple of
storage services are S3 Glacier EBS
which is elastic block Storage storage
Gateway now AWS provides web data
storage service for archiving data also
its main advantage is disaster data
recovery with high durability let's look
into some of the essential storage
services and one of the most widely used
storage Services S3 which stands for
simple storage service in the simple
storage service what you need to do is
you have to create a bucket and in that
bucket you have to put the files in it
so S3 gives open cloud-based storage
service which is utilized for online
data backup then comes the EBS which is
an elastic block storage now you can
understand EBS as a virtual hard drive
also which attaches with the ec2 and it
provides High availability storage
volume for persistent data it is mainly
used by Amazon ec2 instances then you
have the database Services AWS database
domain service offers cost efficient
highly secure and scalable database
instances in the cloud and some of the
database services are RDS which is a
relational database service
dynamodb the non-relational or nosql or
no SQL database service elastic cache
and Amazon redshift now one of the
essential database service is the
dynamodb it is a flexible nosql database
service us which offers fast and
reliable performance with no scalability
issues
it is fast reliable highly scalable and
suitable for small scale applications
like mobile applications gaming
applications or anything with respect to
the Internet of Things devices there the
dynamodb is most widely used or suitable
then comes the relational database
service that is the RDS which is a
structured database service
it is a managed distributed relational
database cloud service that helps
developers to operate and scale database
in a simple manner so RDS has different
vendors platform with respect to the
database usage and that includes the
postgresql MySQL then you have Oracle
Microsoft or Ms SQL and they have their
own
customize
database as well that is called as the
Amazon Aurora
along with that they have a Maria
database or Maria DB as well
so these are couple of vendors that give
their database engines that you can use
on the RDS now coming to the networking
Services it offers a highly secure Cloud
platform and helps in connecting your
physical Network to your private virtual
network with high transfer speed
now some of the services in the
networking and content delivery are VPC
which is a virtual private Cloud a very
important service in order to make your
applications or Services more secure
Route 53 which is a DNS mapping Service
Direct Connect which directly connects
with the AWS services and with your data
centers and the cloud front that is
basically a Content delivery service now
coming to the VPC or a virtual private
Cloud it helps a developer to deploy AWS
resources such as Amazon ec2 instances
in a private virtual Cloud so that you
can actually make your ec2 isolated or
make it more secure and even you can
make it for a public access also depends
on the administrator that how they want
to customize it so the complete control
of a VPC and its networking is with the
admins then comes the Route 53 service
it is a web service with highly
available domain name system or the DNS
that helps user to Route software by
translating text into IP address and
that is why it is called as a DNS
mapping service and that helps you to
use your domains or the external domains
pointed to the AWS services in case if
you use AWS for hosting your websites or
the applications note DNS translates
text into the IP address now coming to
the developer tool services it helps a
user build deploy and run an application
source code automatically it also
updates the server and instance on the
workload so first is the code star code
build code deploy code pipeline so code
star it is a service designed to manage
application development at a single
place
here developers can quickly develop
build and deploy applications on AWS
so all the manage app development can be
done with the code star code build
removes the hassle of managing physical
servers and helps developer build and
test code with continuous scaling so
security identity and compliance
services
helps in monitoring a safe environment
for your AWS Resources by providing
limited access to specific users so in
case let's assume that you have to give
an access to someone but with limited
privileges you can primarily use IIM in
that case and if you want to make your
applications or
deployments more secure then you can use
these services like KMS IM Cognito
Waf which acts as a firewall now the IM
service which is the identity access
management is a framework that helps in
maintaining access to AWS services in a
secure way so what happens is that the
admin who has the complete access of the
AWS console provide access to users and
there can be different users and they
would have the privileged accesses
defined by the Admin so what type of
permissions the admin gives them they
would have those limited access on the
AWS console KMS enables users to create
and manage the encryption keys that are
used for encrypting data coming to
management tool services with the help
of management tools using the service an
individual can optimize cost minimize
risk and automate all the resources
running on the AWS infrastructure
efficiently so with the management tools
you can
monitor the resources application it's
its tools and the utilizations and along
with that you can scale up scale down
the resources likewise with the help of
the management tools you can also do the
auditing task so one of the essential
service in the management tool services
the cloud watch
it is a monitoring tool for AWS
resources and customer applications
running on AWS platform so let's assume
that you have used ec2 dynamodb S3 RDS
and you want to monitor those resources
you can use the cloud watch that can
give you the results coming to the cloud
formation
this service helps you in monitoring all
your AWS resources at one place so that
you can spend minimum time in managing
those resources and maximum time on
developing the application so with the
help of the cloud formation you can
deploy the entire solution with the help
of creation of a template you just need
to create one template and you have to
deploy it the rest of the things will be
done by the AWS and hence it is a kind
of an automation task only now let's
look into the demo of some of the
essential services
so we'll start with the ec2 and I have
already logged in into my AWS account so
where exactly you can find the ec2 just
click on the services
under the compute section you can find
the ec2 ec2 stands for elastic Cloud
compute service
primarily used for creating the virtual
machines
so I'll click on the service and quickly
I'll show you how the virtual machine is
created and how we can basically access
it
so I would be creating one virtual
machine or an instance with the Windows
operating system
so here you can see there are three
instances which are already running let
me create another one
we have to click on launch instances
and here you have to select some
configuration details
so most of the configuration details
I'll be taking as default
and wherever it is necessary I'll be
making the changes
so first of all you have to select the
operating system in the form of Ami and
I would be looking for Windows
2016 and then you have to select the
type of instance with respect to
the CPUs number of CPUs and the memory
capacity so I'll go with t2.micro which
is a free tier eligible instance
in the configure instance details the
rest of the things we'll keep it as
default as of now
click on add storage
this is a basically
the virtual hard drive or the EVS the
elastic block storage that is attached
with the ec2 instance
so primarily it is giving us 30 GB of
space without any additional cost
we can leave the tags as blank
click on configure security groups and
here you can see that the RDP Port is by
default open
which will actually allow us to RDP or
to have a remote connectivity of our
instance
click on review and launch
now to give an authentication or to
provide an authentication we should have
a key pair with us so that the AWS scan
understand or can tally the key pair and
give us the access
so I already have a key pair created
what I'll do is I'll create a new key
pair for this instance and put a random
name let's say I put it something like
demo
download the key pair
and make sure that you keep your key
pair in a safe and secure place
click on launch instances
now you will see that there is an
instance ID that has been created which
is a number alphanumeric number that is
randomly given by the AWS
you can name your instances
so let's assume let's say we name our
instance as
windows 2016.
click on Save
and
the AWS deploys our instance on a
respective infrastructure
it gives us the IP addresses the public
IP and the private IP which is an
internal IP and we have to access the
instance from the public IP only so now
to access that instance we have to open
up the RDP
put the public IP
click on connect
and when it asks you for the
Authentication
you put a username as administrator
and the password you have to generate by
providing the keep so click on connect
and then you have to click on RDP client
here you have to get a password so click
on get password
browse and when you click on browse you
have to provide demo dot pem file so it
should be in the download section here
itself
just provide that key pair and it is
going to give you the password in the
encrypted format decrypt your password
copy that
and then provide those details
to the RDP client click on OK
and now it should allow you to login to
the instance let's wait for the windows
to appear so here you can see that we
have
logged in into the windows instance the
windows 2016 screen is available in
front of us if getting your learning
started is half the battle what if you
could do that for free visit scale up by
simply learn click on the link in the
description to know more
in this particular demonstration I would
be explaining you about
how to use a storage service
specifically the S3 service which is
most widely used service under the
storage section
now the S3 stands for simple storage
service primarily used for storing the
objects and the files
and what we need to do is we just have
to click on the S3 service under the
storage section
so when you click on S3 service you have
to create the buckets inside the S3
and the buckets are the places where you
keep your folders or you upload the
files that are available on your systems
so
here if you'll notice that the S3
service is a global Service that means
it is irrespective of the region
and the buckets when you create they are
created in a specific region now what is
the benefit
the benefit is that if you create a
bucket in different regions all those
buckets in different regions can be
viewed from a single dashboard
and you don't have to change the region
again and again to view the S3 buckets
so what you need to do is you have to
click on create bucket
and here you have to specify the name of
the bucket so let's say I put something
like demo AWS
and uh
that's the bucket name I'm going to
select now make sure that the bucket
name starts with the lower case and it
should be always unique now why it
should be unique because since S3 is a
global Service so it may be that
somebody else could be using your
the name that you have provided so it
should be always unique otherwise it
will not be allocated
now you have to select a region and that
would be let's say I go with
the Ohio region
and in the bucket settings
you can basically change and configure
these settings according to your
requirement by default when you create a
bucket
it blocks all the public access from the
bucket so when you have all public
access blocked
no object can be viewed from the S3
Bucket from a public network or from or
by anyone else
and hence uh in order to
view the objects or the other files in
the bucket you have to unblock or
uncheck this option so that first of all
you make the bucket accessible from the
public network likewise you can
customize as per the requirement and
then click on acknowledgment the rest of
the things will keep it as default and
click on create bucket now it says that
the bucket with the same name already
exists so that means it is not a unique
name somebody else might have been using
this name so I'll try to keep it more
unique and I'll try to assign some
number so let's say I put something like
987
and it says it is already existed let's
say 9876
and then click on create bucket now if
it creates a bucket that means we have
been allocated with that bucket name so
let's wait for
wait for a minute to get that bucket
created
so that happens quickly and you can see
there are a couple of buckets already
created here and these buckets can be
viewed in a single dashboard
so some of the buckets are in Mumbai
region some of the buckets are in Ohio
region but they are available in the
same or a single dashboard so I'll open
up the bucket that I have recently
created and I'll try to upload some
documents now what you can do is you can
create a folder also inside the S3 and
when you create a folder you can upload
the objects accordingly otherwise you
can directly also upload the objects so
click on upload and we will upload any
random file from my system onto the sket
so I'll basically file
and then click on upload
now it is uploading my object from my
system onto the S3 bucket
and now it has successfully done so it
says the messages successful now in
order to validate I will click on the
bucket from the S3 service and view this
object
now you can see here is my bucket so
I'll just open up this bucket and these
dnsrecords.csv file is available with us
now the S3 is not only limited till
storing the objects or the files it has
many other functionalities and the
features also
like you can enable versioning you can
host a static website on the S3
along with that you can have a cross
region replication enabled so that you
can have a high availability of your
objects or you can have a redundancy of
your critical objects in different
regions so likewise there are more
features that would be covered up in the
details section of an S3 service now
coming to another
section of the essential services that
is the database
now here you can see I have a database
section in the AWS and it has multiple
service within
the RDS is there dynamodb is their
elastication the other database services
are there
so I would be showing a demo on the
dynamodbeam which is a no SQL database
now
when we say it is a nosql database that
means it is a non-relational database
service where we can create a database
table directly from the web console we
don't require a separate database engine
like in the case of RDS
and in the tables you can insert the
values and view those values directly
from the AWS dashboard itself
so it says Amazon dynamodb is a fast and
flexible nosql database service
primarily suitable for iot and web
gaming and other mobile applications so
what you need to do is it is a
straightforward database service which
is which can be accessed
while creating a table itself and it's a
compute based database service that is
the reason that it is more fast
so click on create table
and what you need to do is you just have
to put a table name so I'll just put
something like test
and
in the partition key so these partition
keys are unique entities so what you
need to do is you have to specify a
partition key so I'll put something like
ID
and the string instead of string I'll
use a number
likewise I can add sort Keys Also let's
say I put a name
and the name should be in the string
format
now these are the unique entries these
are the fixed entries in the table and
after that we are going to put the
attributes and in the attributes the
data will be inserted so what you need
to do is rest of the things will keep it
as default as of now click on create
and
here you can see the table has been
created the test table has been created
now if I click on the items so you would
see that it has the sort Keys available
the ID and the sort key associated with
that that is the name but it does not
have any entry because we have not added
any value or the attributes so how we
can add or insert the values in this
table that can be done many ways
you can enter manually you can use the
help of CLI to enter the large chunk of
data directly upload it onto the
dynamodb table and also you can use the
apis also in order to insert the data
inside the table so what you will do is
we will click on create item
and in the ID we will put some value
let's say number one string let's say we
put something like
we will go with a random name so instead
of putting any name we'll put a value
like ABCD that should be fine and then
we will insert some attributes
so let's say I put
string as Rank and I'll put something
like rank 2.
and
then click on Save
so here you will see
just refresh the database table
close it and open it up again
click on the items
now here you can see the id1 name is
ABCD got the rank two likewise you can
click on create items let's say the
serial number or the id2 name let's say
we put something like we can go with XYZ
any random thing put it up as
number rank
and let's say this particular value got
a rank 3
likewise you can add some more items
string let's say you put something like
hjk
and
you put a rank let's say it's a rank
number one holder rank one holder
right so likewise uh this is just an
example likewise you can add the
attributes as per your need and the
table can be filtered out based on the
attributes also so if you have to search
some values in the dynamodb table so you
can always use filters uh to basically
search the values inside the table apart
from that the dynamodb table has lot of
other functionalities
it can be basically you can have a
backup
of a table created in the dynamodb table
in the Dynamo database and then you can
retrieve or recover the data by
restoring the backups from the dynamodb
this database can be created in the
cluster format also
so these are couple of features that you
can use with the dynamodb
now let's move into the next section
now coming to the networking services so
there are
some of the networking Services which
are very useful and that includes a VPC
which is a virtual private cloud cloud
front root 53 API Gateway Etc
now I will basically demonstrate about
the Route 53 service in this demo so in
the root 53 is basically a DNS mapping
service so what you can do is let's
assume that you are hosting any web
application on the server and you want
to Route the domain traffic onto those
servers you need to have the help of
Route 53 to do that
so what you need to do is you just have
to click on Route 53 service
and from this service you can register
your domains also otherwise if you have
domains purchased from any external site
you can point them to the Route 53 name
servers also so first of all
in the Route 53 you have to create a
hosted zone so there is already one
hosted Zone all created
now when you create a hosted Zone you
have to specify the domain name
so let me show you I have one dummy
domain
this is the domain that has been defined
so what you have to do is when you click
on create hosted Zone you have to put a
domain here you can see example.com
likewise you have to put your own domain
and uh
click on the public hosted Zone
click on create hosted Zone and it is
going to give you four name server now
those four name servers have to be
updated
on
the platform from where you have
purchased the domain
so that is mandatory in order to Route
the traffic to the Route 53 service
right so here you can see I already have
a hosted Zone created for a domain
and it has given me
four name servers
these are the name servers and these
name servers have been updated
in a record set
from where the domain has been purchased
right
once it is done then you have to
route the domain traffic to a server so
what you have to do is you have to click
on create record
and in the create record you have to
specify
the IP address or you can use the Alias
also where the traffic should be routed
to where your application is hosted at
so ideally it is a server details
and it exists with certain
policies also
so you can see some view existing
records so here you can see
this particular domain
is routed to a DNS value which is hosted
in the elastic Beanstalk instead of that
you can put an IP address of the ec2
instance also you can use the S3 URL
also you can use the cloudfront URL also
so likewise what would happen is that
the domain traffic will be routed to the
server where actually the application or
a web application is hosted at
now I am using a routing policy as
simple routing policy that means all the
traffic should be routed to that
particular domain
whereas there are other routing policies
also in the Route 53 that includes the
weighted routing policy which acts as a
kind of a load balancing geolocation
routing policy multi-value answer
routing policy and then you have a
redundancy based routing policy which is
a failover one so likewise you can
select as per your requirement
so what you need to do is you just have
to click on create records uh you have
to specify you have the domain so you
have to specify any uh particular info
you want to put before the domain
otherwise you can leave it as blank and
in the record type let's assume that you
are using an IP address of a server
where your web application is hosted at
so you can basically use a routes
traffic to an ipv for address and put an
IP address make sure that you put a
public IP address or the elastic IP
address attached to your instance in
case if you are not using any particular
IP address or the URL you can use the
Alias also so likewise the records can
be created along with that the Route 53
Services used for domain verifications
also like if you want the email services
on onto your web application then you
can basically verify your domain
directly from the root 53 service you
can get the verification done for the
SSL certificate creation for that also
the records will be directly created
from the root 53 service because it is
actually managing or hosting your domain
now with respect to the security
services
the most widely used service is the IM
which is identity access management
that lies under security identity and
compliance so in from the IM you can
create the users whom you want to give
an access to your AWS console you can
create groups and you can add multiple
users in that group give them the
permissions you can create the rules
also so that multiple Services can
interact or integrate it together
so how the IM is used we click on the IM
service
and I'll show you how a particular user
can be created
and how the user is basically uses the
credentials to access the AWS console
now the IM dashboard is open and when
you open up the IM dashboard it gives
you the URL so this is the URL through
which the user has to actually
access the AWS console by providing the
user credentials now how the users are
created just click on the users
and
here you just have to click on add user
so I'll create one sample user let's say
I put something like sample user
and what type of an access you want to
give that particular user do you want to
give a programmatic access which is a
primarily or the CLI access or you want
to give the AWS Management console so
right now we'll go with the AWS
Management console access
now do you want an auto generation of
the password or do you want to customize
the password so let's assume that we
customize the password so put any value
make sure the password meets all the
criterias
and uh
then click on next permissions now what
kind of permissions you want to give to
that user let's assume that you want to
give an access of a particular service
only to that user so you have to
actually search you have to actually
search a policy for that particular
service that can be given an access to a
user otherwise if you want to give an
admin policy or the admin access to that
user you can search an admin policy
there so the permissions are important
otherwise the user would not have
privileges to access
the AWS console
so
we'll attach the existing policies
directly so click on it
and here let's assume that I want to
give an admin access to that user so
I'll just click on the admin access now
to a particular user you can give
multiple policies also it is not
necessary that you have to give only a
single policy
so you can provide a multiple policies
to the users also now click on next tags
let let's make the tags blank click on
review and create a user
now you'll see that our sample user
would be created and to access the
console we'll just copy this URL which
has the account information as well that
is the account number
so copy the link or you can copy the
complete URL log out from the root
account
and then
paste the URL that was copied from the
console
and then we have to give the user
credentials
so we'll put sample user as the username
and the password that we provided while
creating the user
click on sign in and if it is correct
then it should allow us to login into
the AWS console while asking the
password change
so we'll change the password
confirm password change
and now it should allow us to login into
the root accounts AWS console with the
admin privileges
now the next service is the monitoring
services and under the monitoring
Services primarily the cloud watch the
cloud trail the cloud formation these
are some of the services that are most
widely used
now the cloud watch is a service which
is primarily used for monitoring the
metrics primarily of the servers like
for example if you create an ec2
instance and you want to basically
watch out for the
metrics associated with the CPU
utilization or the storage utilization
the network in network out all those
information you can get it from the
cloud watch
now cloudwatch is not only
related to monitoring the metrics it can
generate the alarms also and here you
can get the events also generated which
or the events that can be created which
can trigger the Lambda function as well
so what you have to do is you just have
to
click on a dashboard so I'll centering
metrics are viewed uh with the help of
the cloud watch so first of all you have
to create a dashboard
now you have to put a dashboard name
let's say I put something like
monitoring
ec2
click on create dashboard now how do you
want the reports to be published you
have to actually select a widget I want
that okay the report should be visible
in the numeric form so I'll select a
number
now click on the dashboard that was
created and uh
so again add the widget
and here we'll select the metrics
primarily for the ec2
for instance metric so we have one
single instance running now there are 14
metrics available for that particular
instance now I would be looking for the
CPU utilization for this particular
instance so I'll just select for the CPU
utilization and it is going to give me
some information about what is the
current CPU utilization of that
particular instance so that is somewhere
around 29.3 percent
uh the CPU utilization has been done for
the single instance that is running in
my ec2 dashboard so likewise you can add
some more metrics and view them in this
particular dashboard and the cloud watch
will keep on publishing the data at a
refresh interval of five minutes that is
uh the default value if you are also
aiming to be a professional data
engineer you are at the right place take
a look at a Caltech cloud computing
bootcamp program by simply learn and
Kickstart your journey towards becoming
a data engineer this education program
will help you become an expert in
designing planning and scaling Cloud
implementations for more information
check out the link in the description
box software's job now before we begin
let's talk about what we'll be covering
in this video first we'll talk about why
you should be interested in cloud
computing what exactly is cloud
computing what is Microsoft Azure some
of its services and the users of azure
now let's start with why you should be
interested in cloud computing now let's
say you have an idea for a revolutionary
application an idea that ticks both the
boxes when it comes to good applications
one it has great user experience and two
it will be highly profitable now for it
to be successful you'll have to release
it on the internet people need to use it
they need to spread the word and then
it'll become truly famous however for
that you're going to need servers
storage developers a dedicated Network
an application security to ensure your
application works the way it does now
these are a lot of comp components and
that's where the problem lies there are
two major disadvantages to this approach
the initial setup is very expensive and
risky which means this requires a huge
amount of capital upfront to ensure that
it works properly and the downside is if
your application does not become famous
or it doesn't return as much as you
expect it to you're probably not going
to get the money back which means it
provides a huge amount of risk and then
on the flip side if it does become
famous your number of users have
increased which means that you'll have
to buy more servers and storage systems
to keep up with your demand and this
problem can be solved with the help of
cloud computing now that you know why
you should be interested in cloud
computing let's go into the details of
what exactly is cloud computing now
cloud computing is basically a platform
that gives you access to a number of
computing resources and this is possible
with the help of the internet now as a
user all you need to do is go to a cloud
service provider through your laptop or
your computer through the internet of
course connect to that cloud service
provider and then there you go you have
access to Computing the sources now
Computing resources may include you know
serverless Computing virtual machines
storage and so much more now let's dig a
Little Deeper now basically these cloud
service providers actually have massive
data centers now in these data centers
what you have are hundreds of servers
also included are storage systems and
mainly several organizations critical
components so these are very secure safe
locations where a large amount of data
is stored hence the name data centers
now it is to these data centers that
users actually connect to collect their
data or use it so actually users can
access any service based on their
requirement now like I told you there's
a number of services the user can use
for example now if you want a
notification every time someone sends
you a message or perhaps once you get an
email you need a copy of it created now
for all of this there are services and
most importantly almost every cloud
service provider has this option where
users only pay for the service that they
use so there's no charge up front where
they tell you that you need to pay x
amount of money so that you can use our
services you're only paying for the
amount of time that you're using these
Services now cloud computing is used for
a wide variety of reasons firstly
there's machine learning and data
analysis now basically there are
services that analyze your data and tell
you how you can work with this data
better then there's data storage and
backup streaming media content for
example did you know that the shows that
you watch on Netflix actually all of
them are in the cloud so you're
connected to the internet and you browse
through Netflix and you get access to
the videos these are possible with the
help of cloud service providers this
creating and testing applications
automating software delivery which is a
component in devops and hosting blogs
and applications so now what is azure
what's the big cloud service provider
all about so Azure is a cloud computing
platform provided by Microsoft now it's
basically an online portal through which
you can access and manage resources and
services now resources and services are
nothing but you know you can store your
data and you can transform the data
using services that Microsoft provides
again all you need is the internet and
being able to connect to the Azure
portal then you get access to all of the
resources and their services in case you
want to know more about how it's
different from its rival which is AWS I
suggest you click on the top right
corner and watch the AWS versus Azure
video so that you can clearly tell how
both these cloud service providers are
different from each other now here are
some things that you need to know about
Azure it was launched in February 1st
2010 which is significantly later than
when AWS was launched it's free to start
and has a pay-per-use model which means
like I said before you need to pay for
the services you use through Azure and
one of the most important selling points
is that 80 percent of Fortune 500
companies use Azure Services which means
that most of the bigger company of the
world actually recommend using Azure and
then Azure supports a wide variety of
programming languages the C sharp
node.js Java and so much more another
very important selling point of azure is
the amount of data centers it has across
the world now it's important for a cloud
service provider to have many data
centers around the world because it
means that they can provide their
services to a wider audience now Azure
has 42 which is more than any cloud
service provider has at the moment it
expects to have 12 more in a period of
time which brings its total number of
regions it covers to 54. now let's talk
about Azure Services now Azure Services
have 18 categories and more than 200
services so we clearly can't go through
all of them it has services that cover
compute air and machine learning
integration management tools identity
devops web and so much more you're going
to have a hard time trying to find a
domain that Azure doesn't cover and if
it doesn't cover it now you you can be
certain they're working on it as we
speak so first let's start with the
compute Services first virtual machine
with this service what you're getting to
do is to create a virtual machine of
Linux or Windows operating system it's
easily configurable you can add RAM you
can decrease RAM you can add storage
remove it all of it is possible in a
matter of seconds now let's talk about
the second service cloud service now
with this you can create a application
within the cloud and all of the work
after you deploy it deploying the
application that is is taken care of by
Azure which includes you know
provisioning the application load
balancing ensuring that the application
is in good health and all of the other
things are handled by Azure next up
let's talk about service fabric now with
service fabric the process of developing
a micro service is greatly simplified so
you might be wondering what exactly is a
micro service now a micro service is
basically an application that consists
of smaller applications coupled together
next up functions now with functions you
can create applications in any
programming language that you want
another very important part is that you
don't have to worry about any hardware
components you don't have to worry what
Ram you require or how much storage you
require all of that is taken care of by
Azure all you need is to provide the
code to Azure and it will execute it and
you don't have to worry about anything
else now let's talk about some
networking Services first up we have
Azure CDN or the content delivery
Network now the Azure CDN service is
basically for delivering web content to
users now this content is of high
bandwidth and can be transferred or can
be delivered to any person across the
world now these are actually a network
of servers that are placed in strategic
positions across the world so that the
customers can obtain this data as fast
as possible next up we have expressr now
with this you can actually connect your
on-premise network onto the Microsoft of
cloud or any of the services that you
want through a private connection so the
only communication that happens is
between your on-premise network and the
service that you want then you have
virtual Network now with virtual Network
you can have any of the Azure Services
communicate with each other in a secure
manner in a private manner next we have
Azure DNS so Azure DNS is a hosting
service which allows you to host their
DNS or domain name system domains in
Azure so you can host your application
using Azure DNS now for these storage
Services first up we have disk storage
with this storage you are given a cost
effective option of choosing HDD or
solid state drives to go along with your
virtual machines based on your
requirements then you have blob storage
now this is actually optimized to ensure
that they can store massive amounts of
unstructured data which can include Text
data or even binary data next you have
file storage which is a manage file
storage and can be accessible via the
SMB protocol or the server message block
protocol and finally you have queue
storage now with queue storage you can
provide durable message queuing for an
extremely large workload and the most
important part is that this can be
accessed from anywhere in the world now
let's talk about how Azure can be used
firstly for application development it
should be any application mostly web
applications then you can test the
application see how well it works you
can host the application on the internet
you can create virtual machines like I
mentioned before with the service you
can create these virtual Machines of any
size or Ram that you want you can
integrate and Sync features you can
collect and store matrices for example
how the data Works how the current data
is how you can improve upon it all of
that is possible with these services and
your virtual hard drives which is an
extension of the virtual machines where
these services are able to provide you a
large amount of storage where data can
be stored in a city not so far away as
CEO had plans to expand his company
globally and called one of his ID
Personnel for an I.T opinion and this
guy has been in the company for a long
time and is very seasoned with the
company's infra and he nicely answered
the questions with what he foresaw and
he said I have a good news and a bad
news for us to go Global and he starts
with the good news he said sir we're
well on our way to become one of the
world's largest shipping company and the
bad news is however our data centers
have almost run out of space and setting
up new ones around the world would be
too expensive and very time consuming
now the IT personnel let's call him Mike
now he explains the situation from how
he saw it but the CEO had done some
homework about how he was going to do it
and he answered Mike saying don't worry
about that Mike I've come up with a
solution for a problem and it's called
Microsoft azure well Mike is an
hard-working and honest I.T professional
working for that company but he did not
spend time on learning the latest
Technologies and he asked this question
very honestly oh how does it solve a
problem and the CEO begins to explain
Azure to Mike and he starts with what is
cloud computing and then he goes on and
talks about Azure and the service is
offered by Azure and why Azure is better
than the other Cloud providers and what
are the great companies that uses Azure
and how they got benefited out of it and
then he winds it all up with the use
cases of azure so he begins his
explanation saying Microsoft Azure is
known as the cloud service provider and
it works on the basis of cloud computing
now Microsoft Azure is formerly known as
Windows Azure and it's a Microsoft's
public cloud computing platform it also
provides a range of cloud services
including some of them are compute
analytics storage and networking we can
always pick and choose from these
services to develop and scale our
applications or even plan on running
existing applications in the public
Cloud Microsoft Azure is both a platform
as a service and infrastructure as a
service let's now fit their conversation
out and let's talk about what is cloud
computing Azure services offered by
Azure how is azure leading when compared
to other cloud service providers and
what are the companies that are using
Azure let's talk about that in simple
terms cloud computing is being able to
access compute services like servers
storage database networking software
analytics intelligence and lot more over
the Internet which is the cloud with the
the flexibility of the resources that we
use like anytime I wanted results I can
use one and it becomes available
immediately and anytime if I want to
retire in there's those I can simply
retire at resource and not pay for it
and we also typically pay only for the
services that we use and this helps
greatly with our operating cost to run
our infrastructure more efficiently and
scale our environment up or down
depending on the business needs and
changes and all the servers and storages
and databases and networking all that
are accessed through the network of
remote systems or remote computers
hosted in the internet typically in the
provider's data center which is azure in
this case now we don't use any physical
server or an on-premises server here
well we still use physical servers and
VMS you know hosted on a hardware or a
physical server but they're all in the
provider's environment and none of them
sit on premises or in our data center we
only access them remotely it looks and
feels the same except for the fact that
they are in a remote location we access
them remotely do all the work remotely
and when we're done we can shut it down
and not pay for them so some of the use
cases some of the use cases of cloud
computing are creating applications and
services the other use cases are storing
or using Cloud for storage alone if
there is one thing that ever grows in an
organization is the storage every new
day there is a new storage requirement
and it's very Dynamic it's very hard to
predict and if we go out and buy a big
storage capacity up front until we use
the storage capacity fully the empty
storage is you know we're wasting money
on them so instead I can go for a
storage with scales dynamically that's
in the cloud put storage or put data in
the cloud and pay only for what you are
storing and for the next month if you
have deleted or flushed out some files
or data pay less for it so it's a very
Dynamic storage in the cloud and a lot
of companies are getting benefited from
storing data in the cloud because of its
a dynamic in nature and the cost that
comes along with it the cheap cost that
comes along with it and also they give a
lot of the providers like Azure they
give a data application for free they
promise an SLA along with the data we
store in the cloud so there's an SLA
attached to it and they also provide
data recoveries as well if in case
something goes wrong with the physical
disk where our data is stored Azure
automatically makes our data available
from the Redundant or other places where
it had stored our data because of the
SLA they wanted to keep the other use
case for Azure is hosting websites and
running blogs using the compute service
be it storing music and letting your
users stream the music Azure is a good
place to store music and stream the
music with the best benefit of CDN
content delivery Network which allows us
to stream a video or audio files with
great speed now with that with Azure our
audio or video application works
seamlessly because they are provided to
the client with very low latency and
that improves the customer experience
for our application Azure compute
service is a good place for delivering
software on demand there are a lot of
softwares embedded softwares that we can
buy using Azure and everything on a pay
as you go service model so anytime we
need a software we can go out and
immediately buy the software for the
next one hour or two hours let's say and
use them and then return it back we're
not bound to any yearly licensing cost
by that Azure Computing Services has
analytics available for us with which we
can analyze get a good visualization of
what's going on in a network be it logs
be it the performance beat the metrics
you know instead of looking at logs and
searching logs and trying to do manual
things over the heaps and heaps of logs
that we have saved Azure analytics
Services helps us to get a good visual
of what's going on in the network where
have we dropped where have we increased
or what's causing what's the major
driver what is the top 10 errors that we
get in the server in the application
stuff like that those can be easily
gathered from the Azure analytic
Services now cloud is really a very cool
term for the internet a good analogy
would be looking back anytime we look at
a diagram when we do not know how things
are transferred we simply draw a cloud
right for example m mail gets sent from
a person in one country to a person in
the other country a lot of things
happening in between from the time you
hit the send button and the time the
other person hits the read button right
and we let the simple and the easiest
way of putting it in a picture is simply
draw a cloud and on the one end one
person will be sending the email and on
the other end the other person will be
reading the email so a cloud is a really
cool term for the internet now that's
some Basics about cloud computing now
that we've understood about cloud
computing in general let's talk about
Microsoft Azure as a cloud service now
Microsoft Azure is a set of cloud
services to build manage and deploy
applications on a network with the help
of Microsoft azure's Frameworks now
Microsoft Azure is a Computing service
created by Microsoft basically for
building testing deploying and managing
applications and services through a
Global Network of Microsoft managed data
centers now Microsoft Azure provides SAS
which is software as a service and pass
which is platform as a service and IAS
infrastructure as a service and they
support many different programming
languages tools and framework and those
tools and framework include both
Microsoft specific and third-party
software now let me pick and talk about
a specific service for example
management Azure automation provides a
way for us to automate the manual long
running and frequently repeated tasks
that are commonly performed tasks both
in cloud and Enterprise environment it
saves us a lot of time and increases the
reliability and it kind of gives a good
administrative control and even
schedules the task automatically to be
performed formed on a regular basis
to give you a quick history of Microsoft
Azure it was launched on 1st February
2010 and it was awarded or it was called
an industry leader for infrastructure
and platform as a service by Gartner now
Gartner is the world's leading research
and advisory company this Microsoft
Azure supports a number of programming
languages like c-sharp Java and python
all these School Services we get to use
and pay only for how much we use for
example if we use for an R we only get
to pay for an R even the cost list
system available if you use them for an
R we only pay for that particular R and
then we done no more billing on the
resource that we have used a Microsoft
Azure has spread itself more than 50
regions around the world so it's quite
easy for us to pick a region and you
know Start program positioning and
running our applications probably from
day one because the infrastructure and
the tools and Technologies needed to run
a replication are already available all
that we have to do is comment the code
in that particular region or build an
application or launch it in that
particular region and they become live
starting day one now because we have 50
regions around the world we can very
carefully design our environment to
provide low latency services to our
customers all right instead of In
traditional data center let's say you
know customers will have to or their
requests will have to travel all the way
around the globe to reach a data center
which lives in the other side of the
planet and this adds more latency to it
and it is really not feasible to build a
data center near each customer location
because of the cost involved but with
Azure it's possible Azure already has
data centers around the world and all
that we have to do is just pick a data
center build an environment there
they're available starting day one
number one and also the cost is
considerably saved because we are using
a public Cloud instead of an physical
infrastructure to serve those customers
from a very local location and these
services that Azure is offering is ever
increasing as of now as we speak we have
like 200 plus services offered and they
span through different domain or
different platform or different
Technologies available within the Azure
console portal now we're going to talk
about that later in this section so hold
your breath till we talk about it but
for now just know that we have like 200
plus services offered by azure let's now
talk about different services and Azure
starting with artificial intelligence
plus machine learning where we have a
lot of tools and Technologies
so the wide variety of services
available in Azure includes artificial
intelligence plus machine learning plus
analytic services to get and or to give
us a good visual of how the data or how
the application is performing or the
type of the category of data stored and
to read from the logs and variety of
compute Services different VMS with
different size and different operating
systems different containers available
different type of databases available a
lot of developer tools that are
available for us and identity service to
manage our users in the Azure cloud and
those users can be integrated or
Federated with let's say Google Facebook
you know LinkedIn so there are some
external Federation Services they can be
used to integrate with our identity
system iot's iot Services iot tools and
Technologies available model and
management tools to manage the users you
know creating identities one and then
managing them on top of it is a totally
different thing and we have tools
Technologies to manage the users cool
services for a data migration data
migration is now made simple tools and
Technologies available for mobile
application a development and I can plan
my own network in the cloud with the
networking Services I can Implement my
own security both Azure provider and
third-party Security Services on Azure
Cloud that's now possible and a lot of
storage options available in the cloud
so these are just a glimpse of the big
list of services available in Azure
Cloud so that was a glimpse of what's
available in the cloud let's talk about
the services in a specific let's say
compute for example you know whenever
we're building a new application or
deploying existing ones the Azure
compute service provides the
infrastructure we need to run and
maintain our application we can easily
tap in the capacity that Azure cloud
service has and we can scale our compute
requirement on demand we can also
containerize our application we have the
option of choosing windows or Linux via
machine and take the advantage of the
flexible options Azure provides for us
to migrate our VMS to Azure and lot more
and these compute Services also include
a full-fledged identity solution meaning
integration with active directory in the
cloud or an on-premises and lot more
let's look at some of the services that
this compute domain provides
some of the services the compute domain
provides are virtual machines and this
Azure virtual machines gives us the
ability to develop and manage a virtual
computer environment or a virtualized
environment inside azure's Cloud
environment that too in a virtual
private Network now we will talk about
virtual private Network at a later point
but as of now just know that there are a
lot of services available in Azure
compute service that we can get
benefited from we can always choose from
a very wide range of compute options for
example you know we have an option to
choose the operating system we have the
option to choose whether the system
should be in on premises or in the cloud
or do we want to maintain the
environment both in on-premises and in
the cloud we have the option of choosing
the operating system whether we want to
use our own operating system with some
soft software attached to it or do we
want to go and buy the operating system
from the cloud from Azure Marketplace
and these are just a few of the options
available for us when we want to buy the
compute environment and these complete
environments are easily scalable meaning
we can easily scale our VM instances
from one instance to thousands of
virtual machines in a matter of minutes
or simply put in a couple of button
clicks and all these services are
available on a pair for what we use
model meaning there is no upfront cost
we use the service and then pay for the
services that we have used there's no
literal or long term commitment when it
comes to using virtual machines in the
cloud and these most of the services are
built on a paper minute billing basis
all right and at no point because of the
paper minute selling model at no point
we will be overpaying for any of the
services that's that's attractive isn't
it now let's talk about batch service
now bad service is always independent
regardless of whether you choose windows
or Linux it's going to run fairly well
and with bad service we can take
advantage of the environment's unique
features and not only that in short the
batch service helps us to manage the
whole batch environment and also it
helps to schedule the jobs now this
Azure batch service is actually runs on
a large scale parallel and high
performance Computing because of that
batch jobs are highly efficient in Azure
and when we run batch services this
Azure batch creates a pool of computer
nodes and installs the needed
applications that we want to run and
then it schedules jobs to those
individual nodes in those pools as a
customer there is no need for us to
install a cluster or there is no need
for us to install a software that
actually can use the jobs or even to
manage or even to scale those
infrastructure or the software because
everything is managed by Azure and this
batch service is a platform as a service
there is no additional charge for using
this batch service except for I mean the
only charges that we'll be paying is for
the virtual machines that the service
uses and the storage that we will be
using of course and the networking
services that we would be using for this
batch service let's summarize this batch
service we have a choice of operating
system that we can pick and use and it
scales by itself now the alternative for
the batch would be cues but in queues
we'll have to pre-provision and pay for
the infrastructure even if we're not
using it but with a batch we only pay
for what we use and this bad service
helps us to manage the application
manage the scheduling as a whole as if
they are just one thing as next thing in
compute domain let's talk about this
fabric service now this fabric service
is actually a distributed system
platform that helps us to package deploy
and manage a scalable and a very
reliable microservice and containers and
what does it help this Azure fabric
service helps us or it helps the
developers and administrators so they
can avoid the complex infrastructure
problems and they can focus only on
implementing workloads or taking care of
their development taking care of their
application instead of spending time on
infrastructure so what service fabric
service fabric it provides runtime
capabilities and life cycle management
to applications that are composed of
microservices no infrastructure
management at all and with service
fabric we can easily scale the
application to tens or hundreds or even
to thousands of machines here machines
represent containers as next thing in
compute domain let's talk about virtual
machine scale set now this virtual
machine scales that it lets us to create
a group of identical load balanced VMS I
just want to mention it again it helps
us to manage a group identical and load
balanced VMS the number of instances or
the number of VM instances in an in a
scale set can increase or decrease in
response to the demand or in response to
a schedule that we Define you know the
resources needed on a Monday morning is
not the same as that would be required
on a Saturday or a Sunday morning all
right and even within the day the
resources that would be needed in the
beginning of the business hour is not
the resources that would be needed now
at noon or you know after eight or nine
in the evening so the demands could
actually vary in environment and this
skill set helps us to take care of the
varying demand or take care of the
different infrastructure requirement at
a different schedule throughout the day
throughout the week throughout the month
or could be throughout the year as well
the skill set also allows us to provide
High availability to our applications
and it helps us to centrally manage
configure and update a large number of
VMS as if they they are just one thing
now you might ask well virtual machines
are enough why would we need a virtual
machine skill set just like I said this
virtual machine skill set helps us with
a greater redundancy and improved
performance for our applications and
those applications can be accessed
through a load balancer that actually
distributes other requests to the
application instances so in a nutshell
this virtual machine scale set it helps
us to create a large number of identical
virtual machines number one and with
scale set we can increase or decrease
the virtual machine with virtual machine
scale said we can centrally manage and
configure and update a big group of VMS
and it's a great use case when it comes
to Big Data or container workloads as
next thing in compute domain let's talk
about cloud services now this Azure
cloud service is actually a platform as
a service and it's very friendly in fact
it is designed for applications that
support scalability or an application
that requires scalability or reliability
and and on top of it you want them to be
very inexpensive to operate so Azure
cloud service provides all these so
where would this cloud service run well
it runs on a VM but it's a platform as a
service VMS are infrastructure as a
service and when we run applications on
VM through cloud service it becomes
platformed as a service so here is how
you got to be thinking with
infrastructure as a service like VMS we
first create and configure the
environment and then we run applications
on top of it let's go got the
responsibility the responsibility for us
in VM is that we manage everything end
to end like you know deploying new
patches picking the versions of the
operating system and making sure they
are intact and all that stuff it's all
managed by us but on the contrary with
platform as a service it's I mean it's
as if the environment is already ready
all that you have to do is deploy your
application in it and manage the
platform I mean manage the platform not
as an administrator because all the
administration is taken care by Azure
like you know deploying new versions of
the operating system it's all handled by
the Azure so we deploy the application
and we manage the application that's it
infrastructure management is handled by
Azure so what does cloud service provide
this cloud service provides a platform
where we can write the application code
and we don't have to worry about
Hardware simply hand over the code and
cloud service takes care of it so no
worry on the hardware at all so
responsibilities like patching what do
we do if something crashes how do I
update the infrastructure how do I
manage the maintenance or the downtime
in the underlying infrastructure all
that the dashboard we can benefit from
when we use Azure cloud services and
that shows the key statistics all in one
place and we can also set up real-time
alerts to one when a service
availability or a certain metrics that
we are concerned about D grades as next
thing in compute domain let's talk about
functions now functions are serverless
Computing you know many times if you
heard about Azure being serverless a lot
of time they are referencing or the
person who's talking to you is
referencing to serverless Computing or
Azure functions which is a serverless
Computing service hosted on Microsoft
Azure the main motive of a function is
to accelerate and simplify application
develop development functions helps us
to run code on demand without we need to
pre-provision or manage any Azure
infrastructure so Azure functions are
script or a piece of code that gets run
in response to an event that you want to
handle so in short we can just write a
code that you need for a problem at hand
without actually worrying about the
whole application or the infrastructure
that will be running that code and the
best of all the best is when we use
functions we only pay for the time that
our code runs so what does functions
provide or what is azure functions
provide Azure functions allow users to
build applications using serverless
simple functions with a programming
language of our choice so the current
programming languages that are supporter
is C Sharp F sharp node.js Java and PHP
so here we really don't have to worry
about provisioning or maintaining
servers if a code requires more resource
you yes Azure functions handles or it
provides the additional resources needed
by the code and the best part is we only
pay for the amount of time the functions
are running not the resources but the
amount of time the function is running
as next thing and moving to the new
domain let's talk about the container
domain in Azure now the container domain
or the container service it allows us to
quickly deploy a production ready
kubernetes or a Docker swarm cluster now
what's a container a container is a
standard unit of software that packages
of code and all its dependencies so the
applications run quickly and reliably
from one Computing environment to
another it could be a testing to staging
to developing development environment to
staging to production or from one
production to another production or on
premises to cloud or one Cloud to
another Cloud vice versa now imagine we
had an option not to worry about the VM
and just focus on the application well
that's exactly what containers helps us
achieve so these container instances
enable us to focus on applications and
not worrying about managing VMS or not
worrying about the loading the new tools
required to manage the VMS or even the
deployment and our applications that we
create they run in a container running
in a container is what helps us to
achieve all these not being able to
manage or not needing to manage the
virtual machines so these containers
they can be deployed into the cloud
using a single command if you're using
command line interface and a couple of
button clicks if we are using the Azure
portal and these containers are kept
lightweight but they are equally secure
as virtual machines let's talk about
container services next thing the
container service or sometimes called as
azure kubernetes service it helps us to
manage the containers containers one
thing and a service that's used to
manage the container is another thing
now this kubernetes service or ACS it
helps us to manage the containers so
let's expand on this a bit so this Azure
container service or ACS it actually
provides a way to simplify the creation
configuration and management of a
cluster of virtual machines that are
pre-configured to run containerized
applications on top of them now
deploying them deploying these
containers might take like 15 to 20
minutes or deploying the virtual
machines that run containers in it might
take 15 to 20 minutes and once they are
provisioned we can actually manage them
by using simple SSH tunnel into them and
this ACS when it runs application it
runs applications from Docker images
what does that mean a Docker images
makes sure that the applications the
container runs or fully portable images
are portable and ACS also helps us to
orchestrate the container environment
not only that it also helps us to ensure
that these applications that we run in
containers can be scaled to thousands or
even tens of thousands of containers so
in a nutshell managing an existing
application into a container and running
it using AKs or ACS is really easy or
that's what it is all about to make the
application management or migration easy
now managing the container based
architecture and we discussed that a
containers could be tens or even tens of
thousands of containers so managing them
is Made Simple using this container
services and even training of model
using a large data set in a complex and
resource intensive environment this AKs
helps us to simplify that environment
all right as next thing in container
domain let's talk about container
registry we we spoke about registry a
little bit when we spoke about Docker
images so container registry is a single
place where we can store our images
which are Docker images when we use when
we use containers it's it's Docker
images that we use for our image
purposes so these container images are a
central registry that can be used to
ease container development by easing the
storage and management of container
images so there we can store all kind of
images like Docker swamp are the images
used in Docker swarm or in kubernetes
everything can be stored in container
registry in Azure now anytime we store a
container image it provides us an option
for geo replication what that means is
that we can efficiently manage a single
registry replicated across multiple
regions now these Geo replication it
actually enables us to manage global
deployments assuming we are having an
environment that requires a global
deployment so it helps us to manage
Global deployments as one entity because
we are geo-replicating we would be
updating we would be editing one image
and that image gets replicated
throughout the global replication
centers we would have set up and so just
one editing would have actually edited
the global images and those global
images will have provisioned at the
global application so one edit
replication and then posting of the
applications Global wide and this
replication also helps us to helps us
Network latency because you know anytime
an application needs to deploy it does
not have to rely on a single source
which which can be reached only through
high latency Network because we have
Global replications around the world
anytime the application wants to check
back it will check back the application
which is in a very nearby location for
the application itself Global
replication means that we are managing
it as a single entity that's being
replicated across the multiple regions
in the globe as next thing in a learning
let's talk about Azure databases now
this Azure databases are a rational in
fact they have many flavors in them
we're going to look at different flavors
or SQL nosql cache type of database that
Azure offers so we're going to learn one
at a time or we're going to learn one by
one so this Azure SQL database is a
rational database in fact it's a
rational database as a service it's
managed by Azure we don't get to do a
lot of management in it so it's a
rational database as a service based on
Microsoft SQL Server database engine and
this database is a high performance
database it is very reliable and it's
very secure as well and this High
reliability high performance and for
this high security you really don't have
to do anything it comes along with it
and it's managed by Azure and there are
two things that I definitely need to
mention about Azure SQL database that is
it's an intelligent service number one
it's fully managed by Azure and it also
has this one good thing which is it has
built-in intelligence that learns app
patterns and adapts to maximize
performance and reliability and data
protection of the application that's
something that's not found in many of
the other Cloud providers that I'm aware
of so I thought I'll mention it so it
uses built-in intelligence to learn
about the user's database patterns and
helps improve performance and protection
and migration or importing data is very
easy when it comes to Azure SQL database
so it can be readily or immediately used
for analytic reporting and intelligent
applications in Azure as next thing
let's talk about Azure Cosmo DB now
Azure Cosmo DB is a database service
that is for nosql type and it's it's
created to provide low latency and an
application that scales dynamically or
that scales rapidly now this Azure Cosmo
DB is an a globally distributed service
and it's a multi-modal database this can
be provisioned in a click of a button
that's all we got to do if we need to
provision and Azure Cosmo DB in the
Azure it helps with scaling the database
now we can elastically and independently
scale throughput and storage across this
database and in any of the Azure
geographic regions it provides a good
throughput it provides good latency it
provides good availability and it
provides our Azure promises a
comprehensive SLA that no other database
can offer that's the best part about
cosmodb so this Cosmo DB was built with
a global distribution in mind and it's
built with the horizontal scale in mind
and all this we can use by only paying
for what we have used and remember the
difference between Azure Cosmo DB and
the SQL database is that Azure Cosmo DB
supports nosql whereas SQL doesn't all
right few other things about Azure Cosmo
DB is it allows users to use key value
graph column family and document data it
also gives users a number of AP options
like SQL JavaScript mongodb and and few
others that you might want to check in
the document at the time of reading and
the best part here is that all that we
mentioned we get to use only by paying
for the amount of storage and throughput
that are required and the storage and
the throughput can be elastically scaled
based on the requirement of that R
alright let's talk about redis cache
discussion about Azure database won't be
complete without we talking about
release cache now redis cache is a
secure data cache it's also called it's
also sometimes called as messaging
broker that provides high throughput and
low latency access to data for the
applications now redis cache is based on
an popular open source caching product
which is redis sometimes called as there
is cash now what's the use case it's
typically used to Cache to improve the
performance and scalability of a system
that rely heavily on back-end data
stores now performance when we use redis
cache is improved by temporarily copying
the frequently accessed data to a fast
storage located very close to the
application now with redis cache this
fast storage is located in memory with
redis cache instead of being loaded from
the actual disk in the database itself
now this redis Cache can also be used as
an in-memory data structure store not
only that it can be used as a
distributed non-relational database and
a message broker so there are variety of
use cases for this various cache and by
using various cache the application
performance is improved by taking
advantage of the low latency and the
height throughput performance that this
redis cache engine provides so to
summarize this redis cache when we use
redis cache data is stored in the memory
instead of the disk to ensure that there
is high throughput and low latency when
the application needs to read the data
it provides various levels of scaling
without any downtime or interference now
this various cache is actually backed by
reduce server and it supports a string
hashes linked list and various other
data structures now let's talk about
security and identity Services now
identity management in specific is a
process of authenticating first and then
authorizing using security principles
now not only that identity management
involves controlling information about
those principal identities you might ask
now what's a principal identity now
Identity or principal identity are
Services applications users groups and a
lot more the specialty about this
identity management is that it not only
helps authenticate and authorize
principles in Cloud it also helps
authenticate and authorize principles or
resources on premises especially when
you run an hybrid Cloud environment so
all these services and features that
this identity management helps us to get
additional level of validation like
identity management can provide
multi-factor authentication it can
provide access policies based on
condition a permit or deny based on
condition it can also monitor suspicious
activity and not only that it can also
report it it can also help generate
alerts for potential security issues and
in a way to mitigate it can send us an
alert so we can get involved and prevent
and security accident from happening so
let's talk more about identity
management so some of the services under
security and identity G management or
Azure security center now this Azure
security Center provides Security
Management and threat protection across
the workloads in both cloud and in the
hybrid environment it helps control user
access and application control to stop
any malicious activity if present it
helps us to find and fix vulnerabilities
before they can be even exploited it
integrates very well with analytic
methods that helps us to identify or it
gives us the intelligent to identify or
deduct attacks and prevent them before
it can actually happen and it also works
seamlessly with hybrid environments so
you don't have to have one policy for
on-premises and one policy for the cloud
it's now a Unified Service both for
on-premises and the cloud the next
service in security and identity would
be keyboard now a key vault is a service
or a feature that help Safeguard the
cryptographic keys and any other Secrets
used by the cloud applications and the
services in other words this Azure key
vault is a tool for securely storing and
accessing the secrets of the environment
I mean the secret Keys now a secret is
anything that you really want to have a
very tight control access like the
certificates like the passwords stuff
like that now if I tell you what keyword
actually solves that would actually
explain what keyword is now key vault is
used in Secrets management it's helped
in securely storing The Tokens The
passwords the certificates it helps in
Key Management you know it really helps
in creating and controlling the
encryption keys that we would use to
encrypt data it helps in certificate
management talking about the
certification management it helps us to
easily provision manage and deploy pop
public and private SSL TLS certificates
in Azure and lot more so in a nutshell
this key wall it provides users the
ability to provision new walls and keys
in just a matter of minutes all that in
a single command or all that in a couple
of button clicks it also helps users to
centrally manage their Keys Secrets and
policies next in the list let's talk
about Azure active directory now Azure
active directory it helps us to create
intelligent driven access policies to
limit resource usage and manage user
identities but what does that mean now
this Azure active directory is a cloud
based active directory and identity
management service now Azure active
directory combines and it's actually a
combination of the core directory
Services Plus application access
management plus identity protection and
and one good thing about this Azure in
fact there are a lot of good things but
especially when you're running hybrid
environments you might wonder well how
does Azure active directory is going to
behave now this Azure active directory
is built to work on on-premises and
Cloud environment as well not only that
it also works seamlessly with mobile
applications as well so in a nutshell
this Azure active directory it acts as
an central point of identity and access
management for our Cloud environment it
also provides good Security Solutions
that protect against unauthorized access
of our app and the data now that we have
discussed about security and identity
let's talk about the management tools
that Azure has to offer Azure provides
built-in management and account
governance tools that helps
administrators and developers that helps
them to keep their resources secure and
very compliant and again it helps both
in on-premises and in the cloud
environment and these management tools
help us to monitor the infrastructure
monitor the applications it also helps
in provisioning and configuring
resources it also helps in updating apps
it helps in analyzing threats taking
backup of the resources build a disaster
recoveries it also helps in applying
policies and conditions to automate our
environment we use Azure management
tools and it's also used in cost control
methods so this Azure management plays a
wide role across the Azure services and
in the management tools first comes the
Azure advisor now this Azure advisor it
acts as a guide to educate us about
Azure best practices it throws
recommendations that we can select on
the basis of the category of service and
it also provides the impact it can have
or the impact that would happen in our
environment if we follow the
recommendations given and
recommendations or first one is the
recommendations are kind of templatized
and it throws the templatized
recommendations not only that it also
provides customized recommendations on
the basis of the configuration on the
basis of our usage patterns and these
recommendations are not Parts it's not
like something that it recommends and
then just leaves us hanging there these
recommendations provided are very easy
to follow very easy to implement and see
results you can think of azure advisor
as an a Very personalized Cloud
consultant that helps you to follow best
practices to optimize our deployments it
kind of analyzes our resources our
configurations our usage and then it
recommends a solution for us that really
helps in improving the cost
Effectiveness improving the performance
improving High availability and
improving Security in our Azure
environment so with this Azure advisor
we can get a proactive actionable and
personalized best practice
recommendations now you don't have to be
an expert just follow the Azure advisor
and your environment is going to be good
it also helps in improve the performance
security High availability of our
environment and also it helps in
bringing down the overall Azure spend
and the best part is it's a free service
that analyzes our Azure use agent
provides recommendations how we can
optimize our Azure resource to reduce
cost and reduce cost at the same time
boost the performance helps in
strengthening the security and improve
the overall reliability of our
environment and next in the list would
be Network Watcher now this network
Watcher helps users identify and gain
insights in the overall Network
performance and the health of the
overall environment now these Azure
Watchers provides enough tools to
monitor to diagnose to view the metrics
and to enable or disable logs which
means it will generate and collect the
logs for resources in the Azure virtual
Network so with network Watcher can
monitor and diagnose issues in
networking without even logging into the
virtual machines with just the logs
which are real time we can actually come
to a conclusion what could be wrong in a
certain resource in a VM or in a
database you know but just looking at
the logs and not only that it's used for
analytic or to gain some intelligence of
what's happening in our Network we can
again lot of insight to the current
Network traffic pattern using the
security group flow logs that this
network Watcher offers it also helps in
investigating VPN connectivity issues
using detailed logs now you might or
might not know that you know VPN
troubleshooting requires both parties or
it involves two parties another person
the network administrator on this side
and the network administrator on the
other side and they will have to check
logs in their end and we'll have to
check logs and over and stuff like that
but with the network Watcher it kind of
takes it to the next level the logs
itself we could easily identify which
side is having the issue and suggest an
appropriate fix and the next in the list
would be Microsoft Azure portal now this
Microsoft Azure portal it provides a
single unified console to perform
various number of activities like
building not only building managing and
monitoring the web applications that we
build now this portal can be used to
organize our environment or the
appearance of the environment or the
visual of the environment based on our
work style and using Azure portal users
can control who gets to manage or access
the resources all from the Azure portal
and this Azure portal gives a very good
visibility on the spends that happen on
each resource right and if we can
customize it we can also identify spends
based on teams spends based on days
spends based on Department stuff like
that so it kind of gives us a good
visual offer where the money is spending
or whereas the bill consumed within the
Azure environment next in the list would
be Azure a resource manager now Azure
resource manager enables us to manage
the usage of the application resources
now we use resource manager to deploy
Monitor and manage solution resources as
a group as if it's one single entity now
the infrastructure of our application is
typically made of various components
which includes virtual machine storage
virtual Network web app database servers
some other third-party services that we
might use in our environment and they
are by nature separate services but with
Azure resource manager we don't see them
as different components or different
entities instead we see them as related
services in a group that supports an
application now we kind of get the
relation between them instead of you
know letting them spread Azure results
manager identifies the relation between
them and helps us to visually see them
all as one or single entity not only
that Azure resource manager helps or it
ensures that the resources that we
provision or deploy at a constant rate
along with the other application it also
helps users to visually see their
resources and how they are connected and
that helps in managing the resources a
lot better resource Group also is used
to control who can access the resources
within the user's organization kind of
gives you the fine grained control over
who gets to access and who does not get
access and the last one in the
management tools will be Automation and
this automation gives us the ability to
automate configure and install upgrades
across hybrid environments it provides a
cloud-based Automation and configuration
service not only that this can be
applied for non-azure environments as
well which is on-premises so some of the
automation we could do is process
automation update management automation
configuration features automation stuff
like that and this Azure automation
provides complete control during the
deployment operation and also during the
decommissioning of the workloads and
resources with automation we can
actually automate a time consuming or
mundane or any task that's error prone
because of human errors those things can
be automated so irrespective of how many
times you run it it's going to run the
same way and that really helps in
reducing the overall time and also the
overhead cost because a lot of the
things are automated which means it's
human error-free which means the
application is not going to break and
keep running for a longer time with
automation we can actually build a good
inventory of operating system resources
and configuration items all in one place
with ease and this really helps in
tracking the changes and investigating
the issue let's say something happened
because we have automation because it's
logging the configuration changes it's
easy to track easy to identify easy to
identify what has changed lately that
has broken the environment go back and
fix it or kind of roll it back that
solves the problem and that actually
summarizes the Azure management tools or
Management Services now let's talk about
the networking tools or the networking
services available in Azure there are
variety of services especially
networking services that Azure offers
and I'm sure it's going to be an
interesting one let's begin our
discussion with content delivery Network
now the content delivery Network in
short CDN it allows us to perform secure
and a very reliable content delivery not
only that it also helps in accelerating
the delivery time or in other words
reducing the delivery time also called
as low times it also helps in Saving
bandwidth and increases in
responsiveness to the application let's
expand on this the content delivery
network is actually a distributed
network of servers that can efficiently
deliver web content to users now cdns
are we going to use the word CDN here
cdns store cached content on global Edge
servers also called as pops point of
presence locations that are very close
to the end users so the latency is
minimized it's like taking a copy of the
data or taking multiple copy of the data
and storing it in different parts of the
world and whoever is requesting it the
data gets delivered to them from a
server which is very locally to them so
this CDN offers developers a global
solution for rapidly delivering high
bandwidth content to users by caching
the content in a strategically placed
location which is very near to them so
these content delivery networks it
really helps in handling that's one
advantage you get for Content delivery
Network that's we can handle spikes and
heavy loads very efficiently and we can
also run analytic against the logs that
gets generated in content delivery
Network which helps in gaining good
Insight on the workflow and what would
be the future business need for that
application and this just like a lot of
other services this is on a pay as you
go type so you use the results first and
then you only pay for what you have used
the next one in networking would be
expressed route now express route is
actually circuit or a link that provides
an a direct private connection to Azure
and because it's direct it gives low
latency link to Azure it gives good
speed and reliability for the Azure data
transfer it could be on premises to
Azure so it gives very good speed it
gives increased reliability and low
latency for that connection let's expand
on this a bit now this express route is
in service that actually provides a
private connection between Microsoft
Data Center and the infrastructure in
our premises or in a different
co-location facility that we might have
now these Express routes do not go over
the public internet and because they
don't go over the public internet they
offer a high security reliability and
speed and low latency compared to the
connections which are in the the
internet because it's fast because it's
reliable because it has low latency it
can be used as an extension of our
existing data center you know users are
not going to feel the difference whether
they are accessing services from an
on-premises or in the cloud environment
because latency is minimized as much as
possible users are really not going to
see the difference and because it's a
private line and not an public internet
line it can be used to build hybrid
applications without compromising a
privacy or at the performance now these
virtual private Cloud these expressed
routes can be used for taking backups if
assume a backup going through the
internet that would be a nightmare if
you use express route for backups that's
going to be fast and imagine recovering
a data through the internet from the
cloud through the internet to the
on-premises in a time of disaster that
would be the worst nightmare so these
Express routes can be used not only to
backup but also recover the data because
it provides good speed low latency
recovering the data is going to be a lot
sooner the next product or service we're
gonna discuss in networking is azure DNS
now Azure DNS allows us to host domain
name in Azure and these domain names
come with an exceptional performance and
availability now Azure DNS is used to
set up and manage DNS zones and records
for our domain name in the cloud now
this Azure DNS is a service for DNS just
like the name says and it provides name
resolution by using azure's
infrastructure and by using this domain
we can actually manage the DNS our cells
through the Azure portal with the same
credential imagine having a DNS provider
which does not even belong in RIT
imagine that environment you know we
would have a separate portal to manage
the DNS environment now those are gone
and now we can actually manage the DNS
in the very same Azure portal where we
use the rest of the other services and
this Azure DNS very much integrates with
other DNA service providers it uses a
Global Network of name servers to
provide fast response to DNS queries and
these domains are having additional
availability compared to the other
domain service providers availability
promises these are going to have more
availability than the rest because most
of the servers are maintained by a
Microsoft and it helps resolve sooner it
helps resyncing let's say a server fails
it kind of helps resyncing with the rest
of the servers so all the Microsoft's
environment all the Microsoft Global
Network of name servers can kind of
ensures that our domain names are
resolved properly not only properly but
also are available most of the time all
right next in the list in networking
Services is virtual Network I'm sure
this is going to be very interesting and
I'm sure you're gonna like it so this
networking or virtual networking in
Azure it actually allows us to set up
our own private cloud in the public
Cloud it gives us an isolated and highly
secure environment for our application
let's expand on this then this Azure
virtual Network helps us to provision
Azure virtual machines and it helps us
to securely communicate with other
on-premises and internet networks it
also helps in controlling the traffic
that flows through or Flows In and Out
of This virtual Network to other virtual
networks and to the internet now this
Azure virtual Network sometimes called
as v-net is actually a representation of
our own network in the cloud it's
actually a logical isolation of the
Azure Cloud dedicated to our
subscription all our environments of
provision in a v-net that is separate
from another customer's witness that way
we have that logical separation there so
this virtual Network can also be used to
provision our vpns in the cloud so we
can connect the cloud and the
on-premises infrastructure and lot more
especially in a environment where we
have hybrid environment surely we will
be using virtual Network because that's
going to require VPN for secure data
transfer in and out of the cloud and in
and out of the on-premises environment
all right so it kind of gives us an
boundary for all the resources so all
the traffic between the Azure resources
the kind of logically stay in between or
logically stay within the Azure virtual
Network and here we can design the
network is given over to us you know you
can pick the IP you can pick the routing
you can pick the subnet and a lot of
freedom is given or I would say a lot of
control on how the network is designed
it's not like something that's already
cooked and we only get to use it no we
can actually build the network from the
scratch we can pick the IP address that
we like we can pick you know which
subnet needs to communicate with the
other subnets stuff like that and like I
said if you are using hybrid environment
you definitely would be requiring a
virtual Network because it helps connect
the on-premises and the cloud in a
secure fashion using VPN the last
product we're going to discuss and
networking is a load balancer this load
balancer actually provides application a
good availability and a good Network
performance so how does it work it
actually works by load balancing the
traffic to and from the virtual machine
and the cloud resources not only that it
also load balances between cloud and
cross premises virtual networks with
Azure load balancer we can actually
scale our application and create high
availability for our services which
means Our obligation will be available
most of the time if any of the server
goes dead the server does not get
traffic what happens if the server gets
traffic user is going to experience
downtime what happens if the server does
not get traffic user won't experience
any downtime the connection is shifted
to an healthy service so the user
experiences uptime all the time so this
load balancer supports inbound and
outbound scenarios and it provides low
latency it gives high throughput of the
data transfer and we can actually scale
up the flow of the TCP and UDP
connections from hundreds to thousands
to even Millions because we have a load
balancer now in between the user and the
application so how does it operate this
load balancer actually receives the
traffic and it load balances the traffic
to the back end pool of instances
connected to it according to the rule
and the health probe that we set that's
how it maintains High availability so
what does load balancer help it helps in
creation of high available scalable
application in the cloud in minutes it
can be used to automatically scale the
environment with the increasing
application traffic and one feature of
load balancer is to check the health of
the user's application instance and it
removes or it stops sending the request
to the unhealthy instance and kind of
shifts that connection to the healthy
instance that way a user or a connection
does not get stuck with an instance
That's not healthy that's all that you
need to know about the networking
Services now let's talk about the
storage services or the storage domain
in Azure now Azure storage in general is
a Microsoft manage service providing
cloud storage which basically is highly
available secure durable scalable and
redundant because it's all managed by
Azure we don't get to manage a lot of it
and these Azure storages are a group of
storage Services they cater different
needs and the storage products include
Azure blobs which is actually an object
storage it includes Azure data Lake it
includes Azure files as you see it it
includes Azure queues it includes Azure
tables and lot more but let's start our
discussion with Azure store simple Azure
store simple is an hybrid cloud storage
solution that actually lowers the cost
of storage to nearly 60 percent of how
much you would be actually spending
without using it so Azure simple storage
or store simple is an integrated storage
solution that manages the storage task
between on-premises and the cloud
storage what I really like about Azure
is that it's built around the hybrid
environment in mind there are a lot of
other Cloud providers that are there
where running and hybrid environment is
a big challenge you know it has some
compatibility you won't be able to find
an hybrid or a on-premises and Cloud
solution for your need stuff like that
but with Azure especially when it comes
to storage a lot of the things that
we're going to see it clearly is
designed with hybrid environment in mind
all right so let's come back and talk
about store simple so store simple is an
very efficient cost effective and a very
easily manageable sand storage area
networking solution in the cloud I
thought I'll throw in this information
the reason why it got store simple is
really because it uses store simple 8000
series devices which are used in Azure
Data Center and this store simple or
simple storage it comes along with
storage sharing to manage the stored
data across the various storage media so
the current the very current data is
actually stored in on-premises on solid
state drives and data that is used less
frequently is stored in hdds or hard
disk drives and the data that requires
archived or that needs to be archived
very old data let's say less frequently
use data candidate for archive they are
actually pushed to the cloud so you see
how this storage tearing automatically
happens in store simple and one another
cool feature of store simple is that it
enables us to create an on-demand and
scheduled backups of data and and then
store the data locally or in the cloud
and these backups are actually taken in
the form of of incremental snapshot
which means that they can be created and
restored quickly it's not a complete
backup it's an incremental backup and
these Cloud snapshots they can be
critically important when there is a
disaster and when there is a disaster
recovery scenario because these
snapshots can be called in and they can
be put on storage systems and then they
become the actual data so recovering is
faster if you have proper scheduled
backups or if you have frequent backups
and this storage simple it really helps
in easing our backup mechanism which
means it kind of eases our Disaster
Recovery steps or procedures as well so
the store simple it can be used to
automate data management data migration
data movement data tearing across the
Enterprise both in cloud and on-premises
it actually improves the compliance and
accelerates the disaster recovery for
our environment and if there is one
thing that's increasing every new day in
our environment that will be storage and
this stores simple addresses that need
and we really don't have to pre-plan or
think in deep or having a proper storage
because now we have a simple storage
available in the cloud and moreover it's
on a pay-as-you-go type so not much free
planning on storage is needed yes there
will be a need but not as much as I
would without the cloud or without the
simple storage and the next service
under storage that we would like to
discuss is the data Lake store this data
Lake store or storage it's a cost
effective solution for big data
analytics in specific so let's expand
this so this is data Lake storage is an
enterprise-wide repository for big data
analytic workload now that's the major
service that's dependent on this data
Lake store and this data Lake enables us
to capture data of any size of any type
and other any injection speed and it
kind of collects them in one single
space or in one single place for
operational efficiency I mean
operational efficiency and for analytic
purpose Hadoop in Azure is very
dependent on this data Lake storage and
this data Lake store is designed with
performance for analytics in mind so
anytime you think of or anytime you're
using analytic in the cloud or anytime
you're using Hadoop in the cloud in
Azure we are definitely using or we will
be to the most part or the normal
procedure or the Right Storage to pick
would be data Lake store in Azure it's
designed with security in mind so
anytime we use Azure storage we can be
rest assured that we are using storage
from within a data center which has or
which was built with security in mind so
this data store also uses Azure blob
storage behind the scenes for or global
scale durability and for performance
let's talk about blob storage now blob
storage provides large amount of storage
and scalability now this blob storage is
the object storage solution for Azure
Cloud let's expand a bit on blob storage
Azure blob storage is Microsoft offering
for object storage now this blob storage
is optimized for storing massive amount
of unstructured data which could be text
or binary data it's designed and it's
optimized for Rapid reads if I explain
to you on what scenarios we would be
using blob storage that might help you
get a good understanding of what blob
storage is so it's help or its design as
of now it's being used in many ID
environments to serve images or
documents directly to the browser it
helps in storing files for distributed
access a lot of Fetchers can fetch data
from Azure blob storage and it currently
helping users stream video and audio
it's currently being used for writing
log files it's currently being used to
store data as backup and restore at a
later point in times of Disaster
Recovery it also is used as an archiving
storage in a lot of cloud ID
environments it's widely used in storing
analytic data not only storing but also
running analytic query against the data
stored in it so that's a wide use case
for blob storage not only that in
addition to all that we mentioned it
also supports versioning so anytime
somebody updates an data a new version
gets created which means at any point I
can roll back as and when needed and it
provides a lot of flexibility on
optimizing the user's storage need it
also supports tearing of the data So
based on need when I actually explore I
would find a lot of options I can pick
from that you know suits to my unique
storage environment or unique storage
need and like I said it stores
unstructured data and this unstructured
data is available for customers through
rest based object storage environment
the next product and storage service
would be queue storage now queue storage
provides durable queues for large volume
cloud services it's a very simple and a
cost effective durable messaging queue
for large workloads let's expand this
queue storage for a moment now this Q
storage is a service for storing large
amount of messages that can be accessed
from anywhere in the world through HTTP
and https calls a single queue or a
single Cube message can be up to like 24
KB in size and a single queue can
contain millions of such 24 KB in size
messages and how much can it hold it can
hold up to the total capacity of the
storage account account itself so that's
kind of easy to translate How much would
it hold and this Azure queue storage it
provides an messaging solution between
applications and components in the cloud
what does it help it helps in designing
an application for scale it helps in
decoupling in the application so you
know it's not very dependent or
sometimes it's not at all dependent on
the other application because now we
have a queue in between which kind of
translates or which kind of connects or
which kind of decouples both the
environment now we have a queue in
between both the environment can scale
up or scale down independently the next
in the storage service would be file
storage let's talk about file storage
now these Azure files provide secure
simple and managed Cloud file shares now
with file share in the cloud it actually
extends the user servers on-premises
performance and capacity and a lot of
familiar tools for the cloud file share
management can be used along with the
file storage that we're talking about so
let's expand a bit on file storage now
this Azure files or Azure file storage
offers a fully managed file shares in
the cloud that can be accessed via the
SMB protocol server message block
protocol now this Azure file shares can
be mounted concurrently by cloud or in
on-premises deployments a lot of
operating systems are compatible with it
windows are compatible Linux is
compatible Mac OS is compatible in an
addition to all this being able to run
on on-premises and on the cloud or being
able to access from on-premises and on
the cloud it can also offer cash for
caching the data and keeping it locally
so it's immediately available when
needed so that's some additional feature
I would say that some Advanced feature
that it offers compared to the other
file shares available in the market
let's talk about table storage let's
talk about table storage now table
storage is a nosql key value pair
storage for quick deployments with the
large semi-structured data sets the
difference between one important thing
to note with table storage is that it
has a flexible data schema and also it's
highly available let's expand a bit on
table storage so anytime you want to
pick a schema less a nosql type table
storage is the one we'll end up picking
it provides an key pair attribute
storage with a schema less design this
table storage is very fast and very cost
effective for many of the applications
and for the same amount of data it's a
lot cheaper when you compare it with the
traditional SQL data or data storage so
some of the things that we can store in
the table storage are are of course
they're going to be flexible data sheets
such as user data for web application
address books device information and
other types of metadata for our service
requirements and it can have any number
of tables up to the capacity limit of
the storage account now this is not
possible with SQL this is only possible
with nosql especially with table storage
in Azure explanation of storage really
concluded the length and breadth of the
explanation this CEO was giving his ID
personal but this ID personal is not
done with it yet he still has a question
even after this lengthy discussion and
his question was well there are a lot of
other Cloud providers available what
made you specifically choose Azure I
mean from the kind of question that he
asked we can say that he is very curious
and he definitely had asked and very
thoughtful question so his CEO went on
and started to explain about the other
capabilities of azure or how it kind of
outruns the rest of the cloud providers
so he started or he again started his
discussion but from a different angle
now so he started to explain what are
the capabilities or how Azure is better
than the competitor so he started with
explaining the platform as a service
capabilities and I'm going to tell you
what the CEO told his ID person so this
platform as a service or in platform as
a service the infrastructure management
is completely taken care by Microsoft
allowing users to focus completely on
the innovation no more infrastructure
management responsibilities go and focus
on Innovation that's that's a fancy way
of saying it when we buy platform as a
service that's what we get we can
contribute our time on Innovation and
not just maintaining the infrastructure
and azure especially is dotnet friendly
Azure supports the dotnet programming
language and it has or it is built or
designed or it is optimized to work with
old and new applications deployed
using.net programming framework so if
your application is dot net most of the
time you would end up picking Azure I
mean if you try to compare most of the
time you would end up picking Azure as
your cloud service provider and the
security offerings that Azure offers is
it's designed based on the security
development life cycle which is an
industry leading Assurance process when
we buy services from Azure it assures
that the environment is designed based
on security development life cycle and
like I mentioned many times in the past
and I would like to mention it again
Azure has well thought about the hybrid
environments which a lot of the cloud
providers have failed so it's very easy
to set up an hybrid environment to
migrate the data or not to migrate the
data and still run a hybrid environment
they work seamlessly with Azure because
Azure provides seamless connection
across on-premises data centers and the
public Cloud it also has a very gentle
learning curve if you look at the
documentation it's picture rich and the
documentations are neat and clear with
really it would encourage you to learn
more it would encourage you to think and
imagine and try easily get a grasp of
how Services work so it has a very
gentle learning curve Azure allows the
utilization of technologies that several
business have used for years so that is
a big history behind it it has a very
gentle learning curve the certifications
the documentations the stage by stage
certification levels it's all very
gentle learning curve which is generally
missing in other clouds service
providers now this would really impress
the ctOS or people working in finance
and budgeting if an organization is
already using Microsoft software they
can definitely go and Avail or be bold
and ask for a discount that can reduce
the overall Azure spending in other
words overall a pricing of the Azure so
that's what helped or they are the
information that helped the CEO pick
Azure as his cloud service provider and
then the CEO goes on and talks about the
different companies that are currently
using Azure and they are definitely
using Azure for a reason like Pixar
Boeing Samsung EasyJet Xerox BMW 3M they
are major multinational multi-billion
companies they rely run operate their ID
in Azure and this CEO has a thought that
his it person is still not very
convinced unless and until he shows him
a visual of how easy things are in Azure
so he goes on and explains about a
practical application of azure which is
what exactly I'm going to show you as
well all right a quick project on
building an Azure app using or building
a dotnet application in Azure web app
and making it connect to an SQL database
will solidify all the knowledge that we
have gained so far so this is what we're
gonna do I have an Azure account open as
you see logged in and everything is
fresh here let me go to Resource Group
there's nothing in there it's it's kind
of fresh all right I'm logged in and
this is what we're gonna do so we're
going to create an application like this
which is nothing but an to-do
application a to-do list application
we're just going to run from the web app
get information from us and save it in
the database that's connected to it so
you can already see it's a two-tier
application web and DB all right so let
me go back to my Azure account the first
thing is to create and Resource Group
let's give it an a meaningful name let's
call it Azure simply learn all right and
it's going to be a free trial and the
location pick one that's nearest to you
or you know wherever you want to launch
your application now for this use case
I'm going to pick Central us and create
it's going to take a while to get
created there you go it's created it's
called Azure simply learn now what do we
need we need an web app and and a
separate SQL database let's first get
our web app running so go to app
services and then click on ADD it's not
the web app plus SQL that we want we
want web app alone for this example so
let's create a web app give it a quick
name let's call it azure
simply learn
the subscription is free trial and I'm
going to use my existing Resource Group
a resource Group that we created some
time back it's going to run out of
Windows and we're going to publish the
code all set we can create it all right
while this is running let me create my
database
right SQL database create a database
give it a name let's call it Azure
simply learn DB
put it in our existing Resource Group
that we created it's going to be a blank
database all right and it's going to
require some settings like the name of
the server and the admin login the
password that goes along and in which
location this is going to be created the
server name is going to be Azure simply
learn DB that's the server name and the
admin login can be what can be the admin
login name let's see
so let's call it simply learn that's my
admin login name
and let me pick a password
click on create so what have we done so
far we have created an web app and we
have created an a database in the
resource Group that we have created so
if I go to Resource Group it's going to
take some time before things show up so
if I go to my Resource Group I only have
one Resource Group as of now Azure
simply learn and there I have a bunch of
resources being created and I'll still
being created all right in the meantime
I have my application right here that's
running out of uh or that's in Visual
Studio as of now right so once the
infrastructure is set and ready in the
Azure console we're gonna go back to
visual studio feed these inputs in the
visual studio so the code knows what the
database is the the credentials to log
into the database and stuff like that so
we're going to feed those information in
Visual Studio by that we're actually
feeding it into the application and then
we're going to run it from there
deploying this application takes quite a
while we really got to be patient right
now we have all the resources that we
need for the application to run here is
my database and here is my app service
there's one more thing we need to do
that is create and firewall exception
rule so one more thing needed is to
create a firewall exception rule right
so the application is going to run from
my local desktop and it's going to
connect to the database right so let's
add an exception rule by simply adding
the client type B it's going to pick my
IP the IP of the laptop I'm using as of
now and it's going to create an
exception to access the database so
that's done now we can go back to our
Visual Studio I already have a couple of
apps running or couple of configurations
pushed from a visual studio I'm going to
clean that up if you're doing it for the
first time you you may not need to do
this
all right so let's start from the
scratch
this is very similar to how you would be
doing in your environment right so we're
gonna select an existing Azure app
service now before that I have logged in
as you can see I have logged in with my
credentials so it's going to pull few
things automatically from my Azure
account so in this case I'm going to use
an existing Azure app so select existing
and then click on publish
all right if you recall these are the
very same resources that we created a
while back
all right we have clicked on Save and
it's running kind of validating the code
and it's going to come up with an URL
now initially the URL is not going to
work because we haven't mapped the
application to the database that would
be the next thing
all right so the app has been published
and it's running from my web app as of
now
it's going to throw an error like you
see it's throwing an error that's
because we haven't mapped the app and
the DB together so let's do that
all right let's do that so let's go to
server Explorer this is where we're
going to see our
databases that we have created now let's
quickly verify that
go back to
the resource Group right appropriate
Resource Group
which is right here
and here I have my database azure
simply learn database
all right it has some issues connecting
to my database give me a quick moment
let's fix it
all right so we'll have to map the
database into this application
right so let's go to the solution
Explorer click on publish
and a page like this gets shown and from
here we can go to configure
here is our web app all right with all
its credentials let's validate the
connection number one
all right and then click on next
this is my DB connection string right
which the app is going to use to connect
to my DB now if you recall rdb was
Azure simply learned DB and that's not
being shown here so let's fix that
right so let's fix that
click on configure and here let's put
our DB servers URL now before that let's
change this to SQL Server
all right and then in here I'll put the
DBS URL so go back to azure
here is my DB or server's name
put that here
all right the username to connect to the
server that's right here
put that in
and the password
to connect to the server let's put that
in
all right it's trying to connect to our
azure
portal or the Azure infrastructure and
here is my database if you recall it's
azure
sldb that's the name of the database
Let's test the connection
connection is good click on OK
so now it's showing up correctly Azure
simply learn DB that's the name of the
database that we created now it's
configured
all right let's modify the data
connections
right let's map it to the appropriate
database again all right so our name of
the database is azure simply learn DB
and then it's going to be
SQL Server that's the data source
the
username is simply learn
and the password is
what we have given in the beginning
all right let's validate the connection
it's good click ok
now we're all set
and ready to publish our application
again now the application knows how to
connect to the database we have educated
it with the uh the correct connection
strings the DNS name the username and
the password for the application to
connect to the database
so visual studio is building this
project and once it is up and running
will be prompted with an URL to connect
and anytime we put or we give inputs to
the URL that's going to receive the
input and save it in the database
all right so here is my to-do list app
and I can start creating to-do list for
myself all right so I have items already
listed I can create an entry and these
entries get stored in the uh in the
database I can create another entry
and I'll take the dog for a walk that's
gonna get stored I can create another
entry uh book tickets for a scientific
exhibition
and that's going to receive and put that
in the database and that concludes our
session so through this session we saw
how I can use Azure services to create
web app and connect that to the DB
instance and how those two Services
which are decoupled by default which are
separate by default how I can you know
use the connection strings to make
connection between the app server and
the database and be able to create an
working app I strongly believe you
enjoyed me walking you through this
session let's ask the question what is
Microsoft Azure Microsoft Azure is
actually a cloud service platform that
allows users to build manage scale and
deploy applications by giving them
access to cloud services now these cloud
services range from creating virtual
machines to creating functions that run
themselves without having to worry about
Hardware now all of this is made
possible only through the internet now
here are some things that you need to
know about Azure firstly you was
launched on the 1st of February 2010 it
has data centers in more than 42 regions
across the world they also say the 12
more data centers are in the making
which helps them say they're the only
cloud service provider that covers these
many regions next Azure is preferred by
eighty percent of the Fortune 500
companies which means that the best of
the best in the market only choose to
work with this job and finally Azure is
the second largest cloud service
provider in the market right now let's
talk about Azure Services as I told you
Azure provides services for a wide range
of domains now let's have a look at some
of these domains there's Ai and machine
learning compute containers database
identity management tools networking
Security Storage and so much more now
let's have a look at some of the
individual services within these domains
firstly you have Azure virtual machines
with Azure virtual machines what you get
is the opportunity to create Windows or
Linux virtual machines now all of this
is possible in a matter of seconds with
a large amount of customization now
let's have a look at some of its
features firstly you can choose from a
wide variety of virtual machine options
then you have a large amount of
optimization available to you for
example what size of operating system do
you want how much size do you want to
locate it to it what version of the
system is it and so much more then it
provides low cost and per minute billing
now Azure provides you per minute
billing which means that you're only
charged for how much time you use the
service and finally you have enhanced
security and protection for your virtual
machines next we have service fabric now
with service fabric you have platform
which enables you to create micro
Services now this also makes the process
of application lifecycle management a
whole lot easier as a direct result you
can create applications with a faster
time to Market it supports Windows Linux
on-premises or other clouds and it
enables you to do a tremendous amount of
scaling up depending on your requirement
and finally we have functions now with
functions you can build applications
with the help of serverless computing
here the users only pay for the amount
of resources that they've used you can
create applications in any language that
you want and the only thing you need to
worry about is the code of the
application everything other than that
that is the hardware requirements are
taken care of by Azure now let's have a
look at the networking Services firstly
we have the Azure CDN or the content
delivery network with Azure CDN what you
get is the ability to deliver your
content with reduced load times fast
responsiveness and less bandwidth now
CDN can be integrated with several other
Azure services so that the process can
move at a faster rate it can handle
heavy loads and traffic spikes with ease
it also provides a robust security
system now with the content that's
delivered you can get Advanced analytic
data with which you can understand how
customers are using your content next we
have express route with express route
you can connect your on-premises network
to Azure through a private Network Now
by default this lowers latency it
increases the emphasis on reliability
and speed and it can be of great use
when you have to transfer large amounts
of data between networks now another way
this can be useful is if it's used to
add compute or storage capacity to Data
Centers next we have Azure DNS domain
name service or Azure DNS can be used to
host your domains on Azure this provides
High availability and great performance
it provides fast responses to DNS
queries by taking advantage of
Microsoft's Global Network it also
provides High availability next we have
virtual Network Azure virtual Network
allows the Azure resources to
communicate with each other or other
on-premise networks via the Internet and
all of this is kept extremely secure now
with this users can create their own
private Network for communication it
provides users with an isolated and
extremely secure environment for their
applications to run now all of the
traffic stays entirely within the Azure
Network and it also allows users to
design their own networks next we have
traffic manager now with traffic manager
you can route incoming traffic to
improve your performance and
availability now one thing it provides
is multiple failover options so if a
particular situation goes wrong there's
always an option to consider to salvage
the situation it helps reduce
application runtime and enables the
distribution of user traffic across
multiple locations it also helps the
people who are using it to know where
the customers connecting from across the
world next we have load balancer with
this you have provided the ability to
instantly scale applications at the same
time providing High availability and
improved Network performance for users
applications it can be integrated into
virtual machines and cloud services it
provides highly reliable applications it
also allows users to secure and
integrate security groups finally we
have Azure VPN Gateway now this allows
users to connect their on-premise
networks to Azure using a side-to-site
VPN now this allows users to connect
their virtual machine to anywhere in the
world through a point to site VPN and
also it's very easy to manage and is
highly available now let's talk about
the storage Services first we have data
Lake storage now with this what you get
is a scalable data storage with an
emphasis on cost Effectiveness and
scalability now it comes with maximum
use when you integrate it with other
services so that you can get analytics
on how the data is being used it is also
integrated with other services like the
Azure blob storage now it is also
optimized for Big Data analysis tools
like battery spark and Hadoop next up we
have blob storage The Blob storage
provides a storage capacity for data now
depending on how often a particular data
is used it is classified into different
tiers now all the data that is within
the blob storage is unstructured data
now it has a way of ensuring that the
data Integrity is maintained every time
a particular object is being changed or
the data is being accessed and it also
helps improve app performance and
reduces bandwidth consumption next we
have q storage now with this you have a
message queuing system for large
workloads this allows users to build
flexible applications and separate
functions not to mention with this you
can be sure that your individual
components will not fail it also makes
sure that your application is scalable
Q storage provides queue monitoring
which helps ensure that the customer's
demands are met then we have files
stored now with file storage you can
perform file sharing with the help of
the SMB protocol or the server message
block protocol now this data is
protected by SMB 3.0 and the https
protocol in this case like we mentioned
in functions Azure takes care of all the
hardware needs and the operating system
deployments on its own it also improves
on-premises performance and other
capabilities lastly we have table
storage with table storage you can
deploy semi-structured data sets and
nosql key value store now this is used
for creating applications which have a
flexible data schema and also
considering how it has a very strong
consistency model it's mainly aimed for
end prices next let's have a look at
some web and mobile services first we
have the Azure search now with Azure
search you get a cloud search service
which is powered by artificial
intelligence with this you can develop
web application as well as mobile
applications now one big Advantage is
that you don't have to set up or manage
your search indices Azure takes care of
that and by extension it increases your
development speed the artificial
intelligence also will provide insights
and structured information that you can
use to improve the search as structured
information next we have logic apps now
with this you can create integration
Solutions which can connect applications
that are important to your business now
with this you can visually create
business processes and workflows you can
integrate SAS or software as a service
applications and Enterprise applications
and more importantly it allows you to
unlock data within a firewall and
securely connect to services next we
have web applications now with web apps
you can create deploy and scale web
applications according to business
requirements now it supports both
windows and Linux platforms and it helps
with continuous integration or
deployment abilities another very
important aspect of this is that the
data can be deployed and hosted across
multiple locations in the world and
finally we have mobile apps with mobile
apps you can create applications for iOS
Android and Windows platforms one
advantage is that it automatically
scales Up and Down based on your
requirements now in situations where you
have network issues offline data syncing
ensures that your applications work
anyway and you can create cross-platform
applications or native applications for
iOS Android and Windows next let's have
a look at some container services first
let's talk about ACS or Azure container
services it is also known as the Azure
kubernetes Services as it's a fully
managed kubernetes container
orchestration service now what this
means is that it eases the process of
container integration and deployment it
also can be used with other resources
from security like virtual networks
cryptographic keys and so much more to
ensure that your container is kept
secure next we have container instances
now this is similar to functions in a
way just that in this we're using
containers without having to manage
servers now applications can be
developed here without managing virtual
machines or learning new tools all that
is azure's problem to take care of and
it enables building applications without
having to manage the infrastructure that
is all you need to worry about is
running the container next let's have a
look at some database Services first we
have the SQL database now with SQL
database what you get is a relational
Cloud database service now this means
that it helps accelerate your app
development and makes it easier for you
to maintain your application now SQL
database is also used extensively in
migrating workloads to the cloud and
hence saves time and cost it also helps
improve your performance by integrating
machine learning and Adaptive
Technologies into your database next we
have Azure Cosmos DB now this is a
globally distributed multi-mart database
service now what this means is that with
this you can create application with
support nosql it provides a high grade
security system has high availability
and low latency now this is usually used
in situations where you have a diverse
and highly unpredictable workload now
let's have a look at some security and
identity Services firstly we have the
Azure active directory now if you want
to know more about Azure active
directory I suggest you click on the top
right corner and watch our video on the
Azure active directory this is just an
introduction so with this you can manage
user identities and you can make sure
the resources are kept safe with the
help of access policies most of these
are intelligence driven now one of the
main features is that you can have
access to your applications from any
location or device it helps increase
your efficiency and helps down cutting
costs when it comes to having a help
desk it can also help improve security
and can respond to Advanced threats in
real time next you have Azure active
directory b2c it helps provide customer
identity and access management in the
cloud now protecting customer identity
is extremely important for an
organization and that's what Azure adb2c
does now it also enables the application
to be scaled to great amounts even
billions of customers next we have the
Azure security Center this is basically
like a command post with which you get a
complete view of the security across
users on your on-premises and Cloud
workloads so with this you are given
threat protection method that adapts to
situations and helps reduce exposing you
to threads it also has rapid threat
response and makes the process of
finding and fixing vulnerabilities a
whole lot easier next up let's talk
about monitoring and Management Services
so first let's have a look at Azure
advisor now Azure advisor is basically a
guide for the best practices when it
comes to Azure now when you follow these
it improves performance secure security
cost and increases availability now it
also learns from how you use the
services on your configuration and usage
pattern and the adjustments that it
suggests can be implemented very quickly
and easily next we have Network Watcher
now with this you can monitor diagnose
and understand the working of your
network now you can monitor your network
without actually having to login to your
virtual machine now you can also use
something known as network security flow
logs to understand the traffic pattern
how much traffic is coming towards you
how much you are giving and so much more
it also helps diagnose VPN problems that
you might have with detail logs and
finally you have the Azure resource
manager now with this you can ensure
that the resources that you have are
managed and deployed at a consistent
rate now this makes it extremely easy
for you to manage and visualize your
resources that are used in your
applications or some other requirements
and you can control who can access your
resources as well as perform actions on
it today I'm joined by two giants of the
cloud computing industry they'll be
going head to head with each other to
decide who amongst them is better it's
going to be one hell of fight now let's
meet our candidates on my left we have
AWS who's voiced by a picture hi guys
and on my right we have Microsoft Azure
who's voiced by Anjali hey there so
today we'll be deciding who's better on
the basis of their origin and the
features they provide their performance
in the present day and comparing them on
the basis of pricing market share and
options free tier and instance
configuration now let's listen to their
opening statements let's start with AWS
launched in 2006 AWS is one of the most
commonly used cloud computing platforms
across the world companies like Adobe
Netflix Airbnb HTC Pinterest and Spotify
have put their faith in AWS for their
proper functioning it also dominates the
cloud computing domain with almost 40
percent of the entire Market share so
far nobody's even gotten close to
beating that number AWS also provides a
wide range of services that covers a
great number of domains domains like
compute networking storage migration and
so much more now let's see what Azure
has to say about that Azure was launched
in 2010 and is trusted by almost 80
percent of all Fortune 500 companies the
best of the best companies in the world
choose to work only with Azure Azure
also provides its services to more
regions than any other cloud service
provider in the world Azure covers 42
regions already and 12 more are being
planned to be made Azure also provides
more than 100 Services spanning a
variety of domains now that the opening
statements are done let's have a look at
the current market status of each of our
competitors this is the performance
route here we have the stats for the
market share of AWS Azure and other
cloud service providers this is for the
early 2018 period Amazon web services
takes up a whopping 40 percent of the
market share closely followed by sgr at
30 percent and other cloud services
adding 30 this 40 indicates most
organizations clear interest in using
AWS VR number one because of our years
of experience and Trust we've created
among our users sure you're the market
leader but we are not very far behind
let me remind you more than 80 percent
of the Fortune 500 companies trust Azure
with their cloud computing needs so it's
only a match of time before Azure takes
the lead the rest of the 30 percent that
is in AWS or Azure accounts to the other
cloud service providers like Google
Cloud platform Rackspace IBM software
and so on now for our next round the
comparison round first we'll be
comparing pricing we'll be looking at
the cost of a very basic instance which
is a virtual machine of two virtual CPUs
and 8 GBS of RAM for AWS this will cost
you approximately
0.0928 US dollars per hour and for the
same instance in Azure it will cost you
approximately 0.096 US dollars per hour
next up let's compare market share and
options as I mentioned before AWS is the
Undisputed market leader when it comes
to the cloud computing domain taking up
40 of the market share by 2020 AWS is
also expected to produce twice its
current Revenue which comes close to 44
billion dollars not to mention AWS is
constantly expanding its already strong
roaster of more than 100 services to
fulfill the shifting business
requirements of organizations all that
is great really good for you but the
research company Gartner has released a
magic quadrant that you have to see you
see the competition is now neck to neck
between Azure and AWS it's only a match
of time before Azure can increase from
its 30 market share and surpass AWS this
becomes more likely considering how all
companies are migrating from AWS to
Azure to help satisfy their business
needs Azure is not far behind AWS when
this comes to Services as well azure's
service offerings are constantly updated
and improved on to help users satisfy
their cloud computing requirements now
let's compare AWS and azure's free
offerings AWS provides a significant
number of its services for free helping
users get hands-on experience with the
platform products and services the free
tier Services fall under two categories
services that will remain free forever
and the others that are valid only for
one year the always free category offers
more than 20 services for example Amazon
SNS sqs cloudwatch Etc and the valid for
your category offers approximately 20
services for example Amazon S3 ec2
elastic cache Etc both types of services
have limits on the usage for example
storage number of requests compute time
Etc but users are only charged for using
services that fall under the valid for a
year category after a year of their
usage a shop provides a free tier as
well it also provides services that
belong to the categories of free for a
year and always free there are about 25
plus always free services provided by
Azure these include app service
functions container service active
directory and lots more and as of the
valid for a year there are eight
services offered there's Linux or
Windows Virtual machines blob storage
SQL database and few more Azure also
provides the users with credits of 200
US dollars to access all their services
for 30 days now this is a unique feature
that Azure provides where users can use
their credits to utilize any service of
a choice for the entire month now let's
compare instance configuration the
largest instance that AWS offers is that
over whopping 256 GBS of RAM and 16
virtual CPUs the largest that Azure
offers isn't very far behind either 224
GBS of RAM and 16 virtual CPUs and now
for the final round each of our
contestants will be shown facts and they
have to give explanations for these
facts we call it the rapid fire round
first we have features in which AWS is
good and Azure is better AWS does not
cut down on the features it offers its
users however it requires slightly more
Management on the user's part Azure goes
slightly deeper with the services that
fall under certain categories like
platform as a service and infrastructure
as a service
next we have hybrid Cloud where AWS is
good and Azure is better OK although AWS
did not emphasize on hybrid Cloud
earlier they are focusing more on
technology now Azure has always
emphasized on hybrid cloud and has
features supporting it since the days of
its inception for developers AWS is
better and Azure is good of course it's
better because AWS supports integration
with third-party applications well Azure
provides access to data centers that
provide a scalable architecture for
pricing both AWS and Azure are at the
same level it's good for AWS because it
provides a competitive and constantly
decreasing pricing model and in the case
of azure it provides offers that are
constantly experimented upon to provide
its users with the best experience and
that's it our contestants have finished
giving their statements now let's see
who won surprisingly nobody each cloud
computing platform has its own pros and
cons choosing the right one is based
entirely on your organization's
requirements if you are also aiming to
be a professional data engineer you are
at the right place take a look at a
Caltech cloud computing bootcamp program
by simply learn and Kickstart your
journey towards becoming a data engineer
the certification program will help you
become an expert in designing planning
and scaling Cloud implementations for
more information check out the link in
the description box imagine you're the
owner of a small software development
firm and you want to scale your business
up however a small team size the
unpredictability of demand and limited
resources are roadblocks for this
expansion that's when you hear about
cloud computing but before investing
money into it you decide to draw up the
differences between on-premise and
cloud-based Computing to make a better
decision when it comes to scalability
you pay more for an on-premise setup and
get lesser options too
once you've scaled up it is difficult to
scale down
and often leads to heavy losses in terms
of infrastructure and maintenance costs
cloud computing on the other hand allows
you to pay only for how much you use
with much easier and faster Provisions
for scaling up or down
next let's talk about server storage
on-premise systems need a lot of space
for their servers notwithstanding the
power and maintenance hassles that come
with them on the other hand cloud
computing Solutions are offered by cloud
service providers who manage and
maintain the servers saving you both
money and space then we have data
security on-premise systems offer less
data security thanks to a complicated
combination of physical and traditional
I.T security measures whereas cloud
computing systems offer much better
security and lets you avoid having to
constantly Monitor and manage security
protocols in the event that a data loss
does occur the chance for data recovery
with on-premise setups are very small in
contrast cloud computing systems have
robust disaster recovery measures in
place to ensure faster and easier data
recovery
finally we have maintenance on-premises
systems also require additional teams
for hardware and software maintenance
loading up the costs by a considerable
degree
cloud computing systems on the other
hand are maintained by the cloud service
providers reducing your costs and
resource allocation substantially so now
thinking that cloud computing is a
better option you decide to take a
closer look at what exactly cloud
computing is
cloud computing refers to the delivery
of on-demand Computing Services over the
internet on a pay-as-you-go basis in
simpler words rather than managing files
and services on a local storage device
you'll be doing the same over the
internet in a cost efficient manner
cloud computing has two types of models
deployment model and service model
there are three types of deployment
models public private and hybrid Cloud
imagine you're traveling to work you've
got three options to choose from one you
have buses which represent public clouds
in this case the cloud infrastructure is
available to the public over the
internet
these are owned by cloud service
providers two then you have the option
of using your own car this represents
the private cloud with the private Cloud
the cloud infrastructure is exclusively
operated by a single organization this
can be managed by the organization or a
third party and finally you have the
option to Hell a cab this represents the
hybrid cloud
a hybrid cloud is a combination of the
functionalities of both public and
private clouds
next let's have a look at the service
models there are three major service
models available es pass and SAS
compared to on-premise models where
you'll need to manage and maintain every
component including applications data
virtualization and middleware cloud
computing service models are hassle free
is refers to infrastructure as a service
it is a cloud service model where users
get access to basic Computing
infrastructure they are commonly used by
it administrators if your organization
requires resources like storage or
virtual machines is the model for you
you only have to manage the data runtime
middleware applications and the OS while
the rest is handled by the cloud
providers next we have pass
pass or platform as a service provides
Cloud platforms and runtime environments
for developing testing and managing
applications this service model enables
users to deploy applications without the
need to acquire manage and maintain the
related architecture
if your organization is in need of a
platform for creating software
applications pass is the model for you
pass only requires you to handle the
applications and the data the rest of
the components like runtime middleware
operating systems servers storage and
others are handled by the cloud service
providers and finally we have SAS SAS or
software as a service involves cloud
services for hosting and managing your
software applications
software and Hardware requirements are
satisfied by the vendors so you don't
have to manage any of those aspects of
the solution
if you'd rather not worry about the
hassles of owning any it equipment the
SAS model would be the one to go with
SAS the cloud service provider handles
all components of the solution required
by the organization
time for a quiz now in which of the
following deployment models are you as
the business responsible for the
application data and operating system
one is two pass three SAS
4. is and pass let us know your answer
in the comments section Below in this
session we learn about Google Cloud
platform wherein we will learn about
what is cloud computing why Google Cloud
platform what is gcp that is Google
Cloud platform Google Cloud platform
domains about a use case that is Ferrero
use case and also a quick demo on using
services from Google Cloud platform so
when we talk about Google Cloud platform
we also need to know what is cloud
computing so cloud computing is the use
of hardware and software components to
deliver a service to a network users can
access these files and applications
and services provided by a cloud
provider from any device that has access
to Internet in short cloud computing is
a way where cloud provider provides
access to different services such as
resources and when we talk about
resources here we talk about Computing
we talk about memory we talk about
processing power we talk about storage
and we also talk about different
Services which Cloud providers make
available for the users now that allows
us for automatic software integration
backup and restoring data unlimited
storage capacity having a reliable use
of different services and having a cost
efficient solution now we know that
cloud computing models there are
different service models so you have
platform as a service you have
infrastructure as a service and you have
software as a service and these are the
prominent models which are offered by
different Cloud providers such as Google
Cloud such as Google you have Amazon you
have Azure and also some organizations
build their own private clouds using
open source openstack let's focus more
on Google Cloud platform and what it has
to offer and how it is gaining
popularity in the market with different
organizations which would want to work
on a cloud platform or which would want
want to work on an infrastructure which
is modernized so when we talk about
cloud computing this is one of the
approach which organizations can take to
instantaneously benefit from
modernization using different Services
different platforms and also newer
Technologies for their various
requirements such as scalability or
dynamic businesses
before we get into Google Cloud platform
it is also good to understand where you
can find some useful resources about
Google Cloud platform and here you have
a website which is from your Google
Cloud so this is cloudacademy.com
Library slash Google and here you can
create a free account now that would
give you just seven days trial but that
has a lot of videos which talk about
your Google Cloud platform and
Essentials and it has various
certification related videos which you
can access and then after seven days
after you have tried you can obviously
go for a paid account where you can take
detailed learning from here
now this is your training Library which
shows you a different Cloud providers
such as Amazon Microsoft SEO gcp and
then you have various other topics which
are specifics to organization you can
obviously look at the pricing and you
can also look at resources which will
give you a good experience in learning
from these videos
you can also create a free account which
I will walk you through later so you can
create a free account on
cloud.google.com now when I say free
account that basically means it allows
you to create an account and every user
who creates an account gets a 300 free
credit which can be used to practice
brush up your skills and also explore
and learn about different Google Cloud
products which are offered by Google
now coming back to our Google Cloud
platform let's understand why Google
Cloud platform so Google Cloud platform
is popular for many reasons now let us
see few of most important reasons why it
stands out
when you talk about pricing pricing is
one of the significant factors that make
Google Cloud Stand Out Among the other
Cloud providers
it offers a monthly pricing plan which
is billed according to monthly usage and
when we talk about billing here the
billing can be in hours it can be in
minutes and it can also be in seconds
there are different options when you
talk about your pricing which can be
found from your Google Cloud web page
now pricing could be based on preemptive
machines pricing could be based on
reserved instances or reserved resources
I'll show you the link where you can
find more details on pricing part of it
so Google Cloud really has various
pricing options which help customers in
their different requirements whether
they would go for any of the service
models such as infrastructure as a
service platform as a service or even
software as a service one more
attractive thing about Google Cloud
pricing is that it provides committed
use discounts
for example under this scheme you can
purchase a specific amount of virtual
CPU course and memory for up to 57
discount off regular prices if you
commit usage for either one or three
years now this is just one option there
are various such options which you can
learn about from the Google clouds page
and that really suits different
customers for their different
requirements
now when we talk about speed we don't
need to really challenge this aspect
when it comes to Google services so
Google provides its Google cloud and
Google app customer speed up to 10
terabytes because of its faster cable
system there are different kind of
machines which can be used if you are
talking about computation if you are
talking about memory hungry applications
or even storage intensive workloads okay
all in all speed is one of the defining
characteristics of Google cloud services
the cable has connections over us West
Coast main cities in Japan and even
major hubs in Asia this speed enhances
performances and leads to customer
satisfaction now when we talk about
customers any or every customer would
prefer to have low latency High
throughput Based Services they would
want to use higher speeds to process
their data in as less time as possible
Google provides a low latency Network
infrastructure in fact you can say that
when you are using Google cloud services
you are using the services from the same
infrastructure which Google uses for its
popular services such as Google search
or even YouTube which is one of the
second largest repository which can be
accessed for videos now when we talk
about Big Data big data is data which is
very complex has lot of other
characteristics such as your volume you
have velocity you have variety you have
veracity validity volatility virility
and so on so if an organization has is
working on Big Data Google Cloud can be
a better choice because Google has many
Innovative tools for cloud warehousing
for example such as bigquery and even
real-time data processing tools such as
data flow bigquery is a data warehouse
that allows massive processing of data
at high speeds basically working on your
structured data Google also has launched
some new machine learning from
artificial intelligence tools now there
are various other services which we can
which we can use from Google Cloud
platform but let's understand what is
Google Cloud platform and what are some
of the services even the services which
are not less listed here can be found in
your console from Google Cloud so what
is Google Cloud platform gcp it is a set
of Cloud Computing Services provided by
Google that runs on the same
infrastructure as I mentioned that
Google uses for its end user products
like YouTube Gmail and even Google
search the various set of services
offered by Google Cloud platform are so
you have Services which are specific to
Computing requirements and again in
Computing you have various different
options available you have machines
which are compute optimized machines
which are memory optimized machines
which are storage optimized and also we
have certain machines such as preemptif
which basically means that you could get
a machine to work on at a far lesser
price than any other machine but when we
talk about preemptive these are the
machines which can be requested on
demand and they can be taken back by
Google at any time you have networking
related Services which can be very
useful when you are setting up your
applications or your services across
Globe you also have different Services
which are specific to machine learning
and organizations which would be
interested in working on machine
learning or artificial intelligence
would be really interested in using
these Services there are also innovative
solutions to work on big data and Big
Data related Technologies now when we
talk about Google Cloud platform domains
so we can break down these Services into
specifics such as you have compute now
the compute service allows for computing
and hosting the cloud
now when you talk about Computing here
there are different services such as app
engine you have compute engine you have
kubernetes you have Cloud functions and
Cloud run when you talk about storage
and database so the storage and database
service allows application to store
media files backups or other file like
objects now various Services Under This
are as follows you have cloud storage
Cloud SQL Cloud bigtable for
unstructured data you have Cloud spanner
cloud data store persistent disks and
Cloud memory store when we talk about
networking the networking service allows
us to load balanced traffic across
resources now as I mentioned earlier
resources could be your different
resources which you would be using from
a cloud platform such as your devices
your instances memory optimize or CPU
optimized instances us or other
resources creating DNS records and much
more so various Services Under This are
VPC that stands for virtual private
Cloud you have Cloud load balancing
Cloud armor Cloud CDN you have Cloud
interconnect DNS and network service
tiers when we talk about the big data
service this allows us to process and
query big data in Cloud now various
Services under these are as follows you
have bigquery cloud cloud data proc
Cloud composer cloud data lab cloud data
prep Cloud Pub sub which is publishing
subscribing system you have cloud data
studio now you also have the developer
tools and developer Tools service
includes tools related to development of
an application now various Services
under these are as follows that is you
have Cloud SDK software development kit
you have deployment manager Cloud Source
Repository and Cloud test lab when we
talk about identity and security which
is one of the primary concerns for any
organization or any user who would be
interested in using a cloud platform
Google Cloud really has taken care of
this so when you talk about identity and
security domain this deals with Security
Services now various Services here are
Cloud identity you have identity and
access management that is cloud IAM you
have identity aware proxies you have
cloud data loss prevention API security
key enforcement Key Management Service
and many more
you also have cloud services which are
related to internet of things so very
much would be used by organizations who
would be working on iot devices or the
data generated by these devices so
various Services here are Cloud iot Core
you have Edge TPU and Cloud iot also
when we talk about Cloud AI that is
artificial intelligence this comprises
of services related to machine learning
and much more so you have Cloud Auto ml
Cloud TPU Cloud machine learning engine
job Discovery dialogue flow Enterprise
natural language Cloud text to speech
and much more
if you would be interested in Services
related to API platform then there are
different Services Under This category
or this domain so you have Maps platform
you have APG API platform monetization
developer portal analytics that is API
analytics APG sends Cloud endpoints and
service infrastructure so these are some
of the listing of services under each
Cloud platform domain now let's look at
Ferrero use case and let's also
understand what was done here so Ferrero
is one of the famous chocolate and ranks
third among worldwide chocolate and
confectionary producers it was found in
1946 in Italy I'm sure you would have
seen the Ferrero chocolates when you
would have gone out to buy some
chocolates so the challenges here was
that Ferrero as we know is sold in every
supermarket and is known for its quality
once the prisoners grew some issues
arose right and that's what happens when
the business grows you have issues
popping up which could be related to the
volume of data the speed with which the
data is getting generated the variety of
data and also looking at your platforms
which support different Dynamic
applications or your scalability
requirements performance requirements
and so on
so it needed data storage processing and
Analysis system for a wide customer
database
there was a huge gap between the company
and the people who bought its goods
because the company relied on data given
sales outlets now that's one of the
challenge Ferrero wanted to create a
digital ecosystem where there was a
point of contact with its customers and
also a foundation for an Innovative
data-driven marketing strategy what was
the solution here so one of the service
of cloud platforms or Google Cloud
platform is bigquery and this was an
answer to ferrero's challenges since it
was capable of hyper fast and efficient
data analysis as a solution now as I
mentioned bigquery is a data warehouse
which allows you to store structured
data now this could directly be used as
a service where you could store in any
amount of data and you would not be
paying for storage so there are
different pricing models and for data up
to one terabytes you would not be
charged anything and if you would be
accessing the data that is reading the
data or processing the data from
bigquery that's where the pricing model
kicks in
Now using Google Cloud's bigquery
business analysts of Ferrero were able
to store and analyze massive data sets
in a very reliable fast and affordable
manner
consumer behavior and sales pattern data
reports were easy to build and automate
and the analysis also followed Ferrero
to adopt advertising across various
marketing channels to serve the customer
needs in a better way what was the
result
they could divide their database into
real-time actionable consumer clusters
to generate more accurate user profiles
Ferrero was also able to personalize its
marketing strategies to match the user
needs
now Google Cloud platform completely
tailored the website mobile content and
advertising and created a very cost
effective media by strategy now these
were some Basics on Google Cloud now as
I said you can always find a lot of
details about pricing about services and
also all the services are accessible in
your free trial account now let me just
walk you through here so one is you
could always find details on
documentation on each of these services
so if I would click on getting started
you have quick start which basically
shows you short tutorials you have
trainings and you have also
certifications now if we click on quick
start now that takes me to this page
which shows me
quick starts or if you would want to
understand about different projects if
you would want to look into the
documentation of creating a Linux
virtual machine or storing a file and
sharing it deploying a container Docker
container image and so on so you have a
lot of quick starts here you can also
look at Cloud minute
on the same page on the right side you
have docs and once you click on that it
takes you to these links now this shows
you build Solutions which shows your top
use cases best practices all the
solutions it's always good to learn from
these use cases which are available and
here you have different feature products
and all the different Services which
Google Cloud offers now you can click on
featured products and that basically
shows you a list of these products now
here we have all the solutions which you
can look at architecture database
Enterprise level big data and Analysis
gaming related internet of things and so
on now if you go down here it shows you
featured products and that shows you
some of the important products such as
compute engine which is belonging to the
compute domain you have Cloud run you
have anthos which is for migration and
basically Cloud adoption when
organizations would want to move from
on-premise to cloud-based Solutions you
have Vision AI you have cloud storage
now that basically allows you to store
any kind of data whether that's an
object so this is acting as an object
storage you have Cloud SQL which is
basically a ready to use service where
you would be using MySQL postgres or any
other SQL Server database Services you
have bigquery which is a data warehouse
which basically allows you to store your
structured data and then you have your
AI and machine learning related products
so you have automl Vision AI video AI
text to speech speech to text and so on
now you also have different platform
accelerators which can be used and in
any of these cases for example if I
would click on compute engine which is a
featured product from Google Cloud now
that shows you basically your quick
starts using your Linux machines how-to
guides which tells you completely
working on a VM instance
or working on storage working on
persistent disks and so on and it shows
you the documentation here now you also
have products and pricing option which
you can see for GCB pricing and you
could straight away go to the pricing
you could be looking at Solutions which
talks about infrastructure modernization
now this is something which
organizations are interested in when
they would want to move from their
on-premise solution to your Google Cloud
now here I can say for example I click
on infrastructure modernization you can
always find some case studies what are
the different solutions we have here
right when you talk about Google Cloud
so you can always click on see Solutions
and you can look at VM migration or sap
Cloud right why Google Cloud what it can
be used for VMware as a service or HPC
that is high performance Computing and
about these services we will learn in
detail later now I can go back on the
same page where I was clicking on the
services so you have quick starts you
have how-to guides you have deep
understanding of different concepts
right and here if I click on all how to
guides so that shows me what are the
different ways in which you can work
with compute engine and working with
different instances although it's quite
exhaustive content but then if you
follow steadily then you can learn a lot
about Google Cloud now here I can just
go back so this is just giving you some
idea on the different products which are
available from Google Cloud looking into
different sections finding right
documentation here right and you can
always look into each one of these in
detail for each product which Google
Cloud offers
now if we scroll down we could see all
the options or all the domains which we
see here right let me just go back
because we got into Solutions now we
have quick starts right and then you can
basically scroll all the way down to
look at Cloud SDK which can be set up on
your Windows machine like I have set it
up on my Windows machine plus when you
use Google console you have a GUI which
I'll show you in a couple of minutes and
also a cloud shell where you can use
your command line options to work with
Google Cloud platform you have Cloud
console which is nothing but your GUI to
access your resources now you can also
look at in-depth tutorials pricing and
you have different other options so
let's just click on pricing here and
then we have your price list which
basically gives you details of different
services what are available and what are
the services or what are the prices so
for example if I click on compute engine
right and this shows me the pricing
aspect of compute engine which belongs
to compute domain and here you can see
you have VM instance pricing you have
networking pricing sold tenant nodes
which are specific to particular
organizations or if organizations would
want to have dedicated nodes you have
GPU based pricing right so General
processing units you have disk and image
pricing and you can click on any of the
links and you can see pricing which also
shows you your different kind of machine
types so here you have different kind of
machine types which says N1 N2 n2d E2
you have memory optimized machine types
you have compute optimized you have
premium images and you can basically
look at all the categories you can look
at disk pricing which involves your
persistent disk pricing for ssds or sdds
what are the kind of images what are the
different network Services right and you
can always look at your machine types
you can choose a particular region right
there is the concept of region and
availability zones here and as per
region you could look at the prices
you can also look at standard prices you
could be looking for what are the free
tier machines if I'm specifically
looking for VM instance pricing I can
click on this one and that takes me to
the VM instance pricing what is the
billing module what is the instance
uptime what is the resource base pricing
and then you can also look at different
kind of discounts such as sustained use
discounts committed use discounts
discounts from preemptable VM instances
and so on and this is how you can be
looking at pricing for all different
resources and you can choose the
resource which you are interested in and
then look for the pricing benchmarks
reservations if you would want to use
and you would want to benefit if you
would want to look at what are the
quotas and limits and so on so please
explore this link and you can find lot
of information when it comes to
technical options looking at different
Google Cloud products which we briefly
discussed when it comes to domains and
what each product can be used for you
can always come back to the main page
where I was showing you different
Services we went into pricing straight
away right now you can always come back
to this page on your cloud.google.com
and then you have your Solutions
which talks about different products
right and you can click on these or you
can look into technical documentation so
this talks about your different featured
Solutions infrastructure Solutions you
have data center migration related and
so on so I could be talking more and
more about Google Cloud platform it's a
ocean it's a huge chunk of different
services for different organizational
requirements so look into this link and
also what you can do is create a account
on Gmail I mean you could create a free
account or you could go to
cloud.google.com and then you could
create a free account like I have
created here and I can just click on
Console now that's my GUI or Google
Cloud console which basically allows me
to work with Google Cloud now there are
a lot of options here by default when
you create an account now in my case on
the top it says it's a free trial
account I have three hundred dollars
credit and out of that 251 dollars is
left and 237 days out of a year are left
for my account now here I can basically
see the project right and by default we
can create an project or by default
there is a project existing for any user
so when you log in it creates a
particular project and you could create
a new project and project would be to
dedicate your different services or
different resources per different
project so this is your dashboard which
basically shows your project which shows
you a project number and a project ID
which is always unique now you can click
on this and this if you would want you
can hide this information you can also
look into the documentation part of it
then it shows you the different services
or a graphical information of services
which you might have used in past so you
have compute engine which shows you how
how much percentage of CPU was used you
can always go to compute engine as a
service you can look at your Google
route platform status and look at the
Google Cloud status now this is billing
now since this shows me the billing
period for April month and I can always
look at detailed charges I can look at
reporting I can look at different apis
which Google offers and for your
different kind of work you can always go
to the API overview or the API link and
enable or disable any API now once you
enable or disable any API then you can
use that so you have new section you
have documentation and you have getting
started guides which tells you how to
work or enable different apis if you
would want to deploy a pre-built
solution at Dynamic logging monitoring
errors deploying a Hello World app and
so on now this is your dashboard I can
click on activity and that that would
show me what kind of activity I would
have done in my cloud platform I can
always choose the kind of activities by
saying activity type I can choose the
resources now it shows me that I created
some VM instances I deleted them I
updated some metadata I basically worked
on instances I changed some firewall
rules here I have then also worked on
some other services or apis so I created
some buckets which is for object storage
and again I have been working with some
instances and creating some firewall
rules here I have granted some
permissions I am setting up a policy
right so this activity gives me a
history of what things I have done over
past couple of months while working on
Google Cloud platform now
on the top left corner you have the
hamburger menu which you can click on
this so that's your navigation menu and
when you click on this this shows you
home it takes you to the marketplace it
specifically takes you to billing you
can always look at apis and services so
here in API Services I can pretty much
go to a dashboard and I can see a report
on the traffic or errors or latency and
the kind of apis which are available so
you have compute engine API you have
bigquery API bigquery data transfer API
bigquery storage cloud data proc so
these are some of the apis or Services
I've used in past might be I was
evaluating a product might be I was
using a particular product so you have
whenever you would want to use a
particular service from Google Cloud
platform you would be enabling these
apis so here we see some apis for data
proc you have logging monitoring you
have have resource manager API you have
Cloud SQL which allows you to directly
use MySQL or postgres you have cloud
storage right and so many apis so if I
would want to enable a particular API
which is not right now required but then
it's good to know you can always click
on this one you can search for an API so
for example if I would say data proc
right and that shows me the cloud data
proc API which manages Hadoop based
clusters and jobs on Google Cloud
platform so I can spin up a Hadoop
cluster and I can start running some
jobs on a Hadoop cluster on demand and
as I'm done with it I can just get rid
of it so this is an API which I would
have to enable and then for every
particular service you also have an
admin API which you would enable
now going back so coming out from this
API Library I got into API and services
now there is you can look into the
library you can look at credentials and
you can also look at different time
intervals for which you can see the
usage of your different apis now going
back to the menu you have support
wherein you can always reach out to the
Google support team if you are using a
paid version even with free trial you
can try to reach out and you will find
someone to help but it is always good
when you have a billing cycle reaching
out the customer care you have identity
access management and admin and this is
required when you're working with
different apis or Services when you
would want to have relevant access you
have getting started you have security
related options you have anthos which is
mainly for migration now here you can
look at your different domains such as
which we discussed so you have of
compute and in compute you have
different services so you have app
engine you have compute engine
kubernetes you have Cloud functions and
Cloud run you can look into the storage
aspect which shows you bit table which
is usually and mainly for your
unstructured data big table which is
something which gave rise to popular
nosql databases like edgebase and
Cassandra you have data store which can
be used you have firestore file store
storage which can be used to put in data
of any kinds you have SQL for structured
data you have spanner as a service you
have memory store and you have data
transfer now when it comes to the
networking domain you have all these
services such as VPC virtual private
network network related services for
your load balancing for using a
cloud-based DNS or Cloud defined Network
you have hybrid connectivity network
service TS security and intelligence
then you have other options for your
operations which can be used and here
you have different other tools which can
be used such as Cloud build you have
Cloud tasks containers registry
deployment manager and many more big
data specific you have the services here
so you have data proc which can be used
to spin up your clusters you have
published subscribe messaging systems
such as now Kafka which you might have
heard of originates its idea from here
so Pub sub you have data flow you have
iot core bigquery which is a real
Warehouse package or data warehousing
solution from Google Cloud now then you
have your artificial intelligence
related Services another Google
Solutions
so you can always find a huge list of
services or you can say at high level
Solutions offered by Google cloud and we
can use these to basically test some of
the solutions use them and work on them
so I'll give you a quick demo on
different Services which can be used
here from your Google Cloud platform now
this is your Google Cloud platform and
this is your console now this also gives
you a cloud shell which can be activated
so that you can work from command line
and you can always find a lot of
documentation on that so you can also
set up your Cloud shell that is SDK on
your Windows machine and if you have set
it up then basically you could be doing
something like gcloud right if the cloud
has been set up so in my case I had set
up the cloud SDK and basically I can get
into that by looking at what path I have
set up so Cloud SDK and then I can be
using it from my Windows machine as per
my comfort I can also activate the cloud
shell here which will basically open up
a terminal and at any point of time you
can open up this one Cloud cell in a
different window it is preparing the
cloud shell where it will by default set
up your project it will set up the
metadata and now I am logged into my
Google Cloud account from command line
and here I can basically use gcloud
right and that basically shows you the
different options which are available
which you can be using so if you would
want to use a particular service you can
also try giving a help and that shows
you how do you manage your Google Cloud
platform right so you have different
options for billing to work with your
different services and basically you
could be working on Google Cloud using
this Cloud shell from your command line
usually for people who are learning old
cloud in the beginning it is always good
to go for console and use your different
services from here in an easier way but
as I said you can always use the command
line for example if I would just go
ahead and type gcloud create instances
and that will directly take me to the
cloud console documentation which shows
you different options which you can use
to work with instances so I could do a
gcloud compute instances create and then
I can give my instance name and so on
and I'll show you some examples on that
so you can be using your Cloud console
right that is your Cloud shell and you
can straight away start working from
command line however I would suggest
using console in the beginning and when
you are well experienced then you can
start using Cloud cell to do things from
command line and when you are fully
experienced you can always switch and
certain things are usually useful or
easier when done from command line and
some are easier when you do it from the
console and you can use any one of these
options now we can go to Google Cloud
console now as of now I can close this
one I still have my cloud cell open if I
would want to look into it I can click
on this one and I can straight away go
to compute end engine where I would want
to work on creating some instances on
Google Cloud platform using the compute
engine service and then basically
connecting to those instances and
basically trying out some basic things
so you can click on VM instances and
then once this comes up I can always
create some instances now if you see
here I have some instances already
created right and I can continue working
on those I can create new instances I
can use different options while creating
instances and I'll show you that in a
demo in quick seconds so let's have a
quick demo on setting up gcp instances
now before that let's have a quick recap
so when you talk about instance or a
virtual machine it is hosted on Google's
infrastructure right and you can create
your Google Cloud instance using this
Google Cloud console that is by clicking
on this and then going to compute engine
and clicking on VM instances now you can
also do that from Google Cloud command
line tool that is cloud shell and you
can be doing that using compute engine
API so compute engine instances can run
the public images for Linux or Windows
servers that Google provides you also
have option of creating or using custom
images that you can create and import
from your existing systems you can
deploy Docker containers which are
automatically launched on instance
running containers optimized OS now when
you talk about instances and projects
always remember that in each instance
belongs to a Google Cloud console
project and a project can have one or
more instances
when you talk about instances and
storage options each instance has a
small boot persistent disk which I will
show you in for this queens that
contains the OS you can add more storage
space if needed
and when you talk about instances and
network a project can have up to five
VPC networks so VPC network is virtual
private networks wherein you can virtual
private Cloud networks where you can
have your resources within your own
subnet and each instance belongs to one
VPC Network
now instances in same network can
communicate with each other through
local area network protocols an instance
uses internet to communicate within any
machine so that could be virtual
physical or outside its own network when
you talk about instances and containers
you should remember that compute engine
instances support a declarative method
for launching your application using
containers now you can create a VM
instance or a VM instance template you
can provide a Docker image and launch
the configuration
so there are different ways in which you
can create these instances and once you
create these instances you can say for
example you're creating a Linux instance
you can associate SSH keys with your
Google account or your G Suite account
and then manage your admin non-admin
access to the instance using IM roles if
you connect to your instance using
gcloud or SSH from console which we will
see later compute engine can generate
SSH keys for you and apply that to your
Google cloud or G Suite account now what
we can do is we can see how we can
create your Google Cloud instances from
your console or from the command line
let's have a look in creating instances
using gcp console now that we have
learned on some basics of Google Cloud
platform what are the different Services
what are different domains basically
looking at your Google Cloud console or
even Cloud Shell let's go ahead and
create some VM instances now that's from
your compute engine service and let's
try connecting to these instances and
see how this works let's also see what
are the different options which are
available when you would want to create
the virtual machine instances here so
when you click on your drop down from
the top left and choose compute engine
so it brings you to this page so I can
show that again so you can click on
compute engine click on VM instances and
that basically brings you to this page
now here it tells you compute engine
lets you use Virtual machines that run
on Google's infrastructure so we can
create micro VMS or large instances
running different distributions of Linux
or Windows using standard images that is
public images and you can also have your
own image so let's create a VM instance
by clicking on create
now that's basically helping me to
create an instance here so it shows me
the instance name I can give it
something so let me say C1 now I can add
labels so what is label it basically
allows you to organize your project add
arbitrary labels as key value pairs to
your resources this so this is basically
categorizing your labels and projects if
you have multiple projects now remember
if you have your Cloud console and if
you have created your free trial account
it will allow you to do these things if
not you may have to go back to the
billing section and see if the billing
is enabled which also means that when
you are creating your Google Cloud
account it will ask you to clean your
credit card details but they do not
charge anything or they might charge
might be one dollar or one rupee
depending on your location and that's
also refunded but that's just to verify
your card now once I've given the name I
can choose a region so I would basically
choose Europe since I'm in Europe I
would be clicking on Europe West 3 and
here I can choose an availability Zone
availability zone is basically to make
your services or instances or any other
resources highly available so you can
choose one of the availability zones now
I would choose save S3 now this one we
can scroll down and here it says machine
configurations you have general purpose
machines you have memory optimized
machines which is M1 series and you can
always go back to the Google Cloud page
and see what a particular kind of
machine specializes in so I would click
on General's purpose and in general
purpose you have different categories so
you have N1 which is powered by Intel
Skylake CPU platform or you have E2
which is CPU platform selected selection
based on availability so let's have N1
selected now this one shows me the
machine type and if you are using your
free to your account then you can start
with correcting a micro machine which is
one virtual CPU core you can go for a G1
small which is one virtual CPU code and
1.7 GB Ram you can even go up to a
high-end machine and then you can
basically see if you are using a free
account how many of these machines you
can use if I would be selecting eight
virtual CPU cores and 32 gigabyte of
memory then it would allow me to create
at least two instances by this
configuration we will use N1 standard
which is one virtual CPU core 3.75 GB
memory now then we can also deploy a
container image to this VM instance if
you would be interested in deploying a
container image let's not get into that
right now here it shows you the port
disk and it shows you dbn gnu 9 then X9
what I would do is I can go for this
distribution or I can choose a Linux
distribution of my choice so here you
have public images you have custom
images you also have snapshots if you
have created backup of your previous
images here I can choose for example
Ubuntu and then I can choose a
particular version so let's go for
Ubuntu 18.04 you can go for the latest
one also 18.04 would be good enough and
here it tells me what is a boot disk so
you have ssds or you have standard
persistent disks now ssds are little
expensive in comparison to your standard
persistent disks or your sdds but then
ssds are faster so as of now we can
choose standard persistent disk as it is
and we can let the gigabyte be 10 now
depending on your requirement you can
increase this you can even add disks
later that's not a problem click on
select now here I have access Scopes so
here I will say allow default access you
can also set access for each API or you
can give full access to all Cloud apis
so that based on your requirement you
can any time change later also we will
also say allow HTTP traffic and we can
also choose allow https traffic that
basically allows me to access this
machine or Services which are HTTP based
accessible from this machine now I can
just click on create however it would be
good to basically enable connectivity to
this machine now we can do that in
different ways one is when you bring up
your machine it will have an SSH access
which you can log in from the cloud
platform here itself or what you can do
is you can create a private and a public
key using some softwares like putty or
puttygen so for example if you do not
have that on your machine you can
download you can just type in download
putty that takes you to the putty.org
page and here you can click on download
putty and scroll down which shows you
for your 64-bit machine which I have in
my case you can download putty.exe which
is basically your SSH internet client to
connect to your machines you can also
use putty gen which will be allowing you
to create a private and a public key
which I have done in my case let me show
you how so what you can do is you can go
to puttygen to begin with and here you
can click on generate now then to have
this key generated just move your cursor
on the top here in the empty space and
that creates your key you can give it a
name so for example let's give a
username I would give hdu now I can give
a password for this one so let me give a
simple password
and what I can also do is I can copy
this public key from here and for my
later usage I can just keep it in my
notepad file which I can use later and
I'll show you when so now we can save
this private key and this will basically
allow me to save my private key I can
choose desktop and I can give it a name
so let's say new key new key and that
will be getting saved in a DOT PPK file
so let's save it and that's done so we
also have our public key and we have
saved our private key now we know that
when you would want to connect using SSH
you need your private keys to the client
and public key also has to be existing
so let's take this public key so let's
do a control a I'm going to copy this
and I'm going to come back to my Google
Cloud console and here you can click on
security so you can click on the
security tab here here scroll down and
just give your public key once you give
that it resolves and shows you the name
and this is good enough so that I can
use my SSH client to connect to this
machine I can click on Create and this
will basically create my VM instance it
will take some time and then your
instance will have an internal IP which
will show up here external IP and it
will also show you options to connect to
these machines so this is my internal IP
this is my external IP which I can use
to connect from a client I can easily
connect from the option here which says
SSH and I can say open in a browser
window I can even open this in a custom
Port I can look at the gcloud command
which you can give from cloud shell or
you can use another SSH so let's first
do a open in browser window and let's
see if this connects so we can easily
connect to our instance in the Ubuntu 18
instance which I just set up here easily
in couple of seconds now this is trying
to establish a connection using your SSH
keys and when you do that it also
basically brings up this web browser so
I'm already connected it shows my
username which is my cloud account
username and I have been connected to
this machine here using SSH it did not
ask me for any password and basically
now I can just check what do I have in
my Linux file system right and I can
anytime login as root by doing a sudo Su
for example let's try installing a
package and I can say aptkit install Vim
or app get installed wget or aptkit
install open SSH and all these packages
are already existing so not an issue now
I can start using this instance I can
just look at the disk what is available
okay now we gave an 10 gigabyte out of
which we see 8.3 gigabyte here for the
dev sda1 and then 1.8 gigabyte available
and you can continue using this machine
this was the easiest way of connecting
to a VM instance using SSH
now what we can also do is I can just
leave this and I will now try to connect
using an external SSH client right and
here you can copy the public IP so when
you want to connect to an instance you
will have to get the public IP also
remember that if you select and stop
this machine which will stop your
billing counter and if you start it
again the internal IP will remain same
but the external IP is the one which
will change
I can obviously select this machine
anytime and I can do a cleanup and I can
delete it I can do a start of the
machine if it is stopped and I can even
import the virtual machine to be used
later so there are different options
which you can always use so this is my
instance and if you would want to look
at the details click on this one C1 and
that should basically allow you to look
at the details so it shows you what is
the instance ID what is the machine type
is it reservation specific what is the
CPU platform what's the zone and all the
other details
at any point of time if you would want
to edit you can always click on edit and
you can change the details as you need
now you can also look at the equivalent
rest command to basically use the rest
API to connect to this instance for now
I have copied the public IP and I would
want to connect it using putty so let's
go in here and let's give the host name
so I can give Ubuntu I can give my IP
address so that's in my session now I
will click on SSH I would go into
authentication I'll click on browse and
this is where I need to choose the PPK
file so this is the one which we created
new key let's select this
and then I can come back to session I
can even save this and I can call it as
my instance one let's save it and you
can create any number of instances so
you see I have created different
instances here for my Google cloud or
Amazon related instances and I can click
on open it says the service host key is
not cached in the registry that's fine
just click on yes
and basically it says no authentication
method supported now this could be
because we have not enabled your SSH
access so let's look at that so now
let's see if we were trying to connect
using putty what was the issue here so
if I go back to my putty select my
instance load it it says Port 22 I am
giving the username which is Ubuntu or
sorry that's the wrong username we gave
and that might be the reason we had set
up the user as sdu so let's save this
again and now let's try connecting to
this one and it asks for my password and
you are able to connect this right now
if there was any other issue related to
network connectivity then we could look
at the rules the inbound and outbound
rules which allow us to look into the
machine now we are connected to our
machine here using hdu user I can log in
as root and I can continue working so
not only from the SSH within the cloud
console but you can use an external SSH
client and connect to your machine so
this is your Ubuntu machine and we can
basically look at the space and that
basically confirms we are connecting to
the same machine which shows 8.3
gigabytes here and 1.8 gigabytes here
which we were seeing from the ssh in the
browser now let's close this and let's
go back to our instance page now here
you can always look at the network
details and this will show you your
different kind of rules that is ingress
or egress rules which basically allows
to connect to this machine from an
external network or for this machine to
connect to an external network so here
we have different firewall rules which
shows default allow HTTP that's your
Ingress Rule and it tells you apply to
all it shows me what are the IP ranges
where I can specifically give the ipf my
machine it shows the protocols it shows
what are the different ports which you
have used for these services for example
RDP or SSH which shows 22 you have icmp
HTTP and https now anytime if you would
want to make a change to these rules
that can be done by going into your
network details and say for example you
would want to work on firewall rules so
we have these firewall rules here you
can click on this one so right now we
are looking into the network domain and
we are looking into VPC Network right
and this shows me what are the different
rules we have now if I would want to
create a different firewall rule for a
different protocol I can always click on
create firewall rule I can give it a
name okay I can say what if you would
want to turn on the firewall logs you
can basically say what is the kind of
traffic so Ingress applies to incoming
traffic and egress applies to outgoing
traffic and you can then basically
choose what are the IP ranges from where
you want that connection to be coming in
or to going out you can choose a
particular protocol you can give a
protocol here with comma separated
values and you can create a firewall
rule so this might be required depending
on the services which you are running
wherein you might want to enable your
access to your machine from an external
service or to an external service so you
can always go to network details from
here you can then go into firewall rules
create a firewall rule apply that to
your instance and restart your instance
so as of now we don't need to create any
network details here because my Ingress
or egress rules are already available
right now I can basically then have my
instance stopped and removed so I can
just do a stop or since this is running
the ideal wave would be to do a stop I
could also do a reset now what does
reset do reset does not basically delete
the machine what it does is it does a
cleanup of the machine and it brings it
to the initial state so sometimes we
might have installed certain things on
our machine we would want to clean them
up and at that time reset can be useful
I can basically click on delete right
and I can select this and I can do a
cleanup and this is good always when you
are using a free trial account try to
use different Services play around with
them and then you can clean up so that
you do not waste your free billing
credit right and you can use it for
Meaningful stuff now I have clicked on
delete and within few seconds my
instance which I had created will be
deleted also to remember is if you are
creating multiple instances then you can
connect from one machine to other
machine using SSH by using the private
file so for that we can learn in detail
later so this is just a simple example
of using your compute engine creating
your instances connecting to it from an
internal SSH or from an external SSH
client such as putty where you have
already created your private and public
Keys now I can click on the browser here
and then I can basically come out and I
can basically be looking into any
particular service so we just looked
into compute engine right you have
different other options you have
instance groups you have instance
templates for example let's click on
instance templates here and that
basically shows you that you don't have
any instance template and this basically
facilitates say for example you are
working as a admin and you would want to
create an instance template so that
using that you can describe a VM
instance and then you can basically use
this template to create different
instances you can go for soul tenant
nodes you can look for machine images
you can also look at your disks you can
create a snapshots and you can look at
different options here now let's come
back here and let's click on home and
that should take you back to your home
page which basically shows you if a
particular API which you have used
recently which shows me in the graph
here so I can go to the api's overview
right and that basically shows me if
there were any errors if I was using the
compute engine API to basically create a
VM instance and that's why we were
seeing some spike in the graph so this
is a quick demo of using your compute
engine service provided by Google Cloud
wherein you can create VM instances and
use those VM instances for your
application installation for any other
purpose now that we have seen how you
use your Cloud console to create an
instance and also clean it up let's also
understand how you can do using your
command line options and let's see what
it takes or what are the different
commands which you can use to create
your instances
now you can always when when you're
creating an instance you can use compute
engine which Provisions resources to
start the instance so instance basically
has different states which we can see
when we are creating the instance so you
basically start the instance instance
moves into staging that is prepared for
your first boot finally it boots up and
then it moves into running so when you
look at instant states which we will
create instance in C it will basically
have different states such as
provisioning where resources are being
allocated for instance but instances not
yet running then it goes into staging
where resources have been acquired and
instance is being prepared for your
first boot then instance is booting up
and running and if you are stopping an
instance it goes into being stop status
and it would be moved to the terminated
option you can also do a repairing of
instance and finally you can terminate
your instance or clean it up by stopping
and then deleting it now when you say
stopping and resetting an instance you
can stop the instance as I showed
earlier if you no longer need it but if
you need for future use you can just use
the reset option which will basically
wipe the kind contents of instance or
any application State and then finally
you can stop it and have it terminated
now when you would want to do that using
your Cloud console or we have seen the
options now let's also see from the
command line tool how you can do it so
here I have the cloud cell which I
brought up from here and I basically
opened it in a new window so command
line tool enables you to easily manage
your compute engine resources in a
friendlier format than using your
compute engine API now gcloud which is
part of cloud SDK is the main command
here and then you can always auto
complete the different options here so
when you would want to create or work on
gcloud you can just type in gcloud here
and then for example I could just say
help to see different options of gcloud
which will show me different options
which you can use here now we would be
interested in compute instances so I
could also do a gcloud compute
compute instances and then I can
basically say create and then I can do a
help now that should show me different
options which work with gcloud compute
instances create command which is
expecting an instance name so your
Google Cloud SDK which we can set up on
our Windows machine or even on your
Linux machine a set of tools that helps
you to manage resources and applications
hosted on your gcp that is your Google
Cloud platform now here you have options
such as gcloud which I'm showing you
right now you have Gs util and then you
have BQ so that also can be used so you
can set up a Google Cloud compute if
using gcloud now what we can do is if we
are setting up our SDK on our Windows
machine then we would have to do a
gcloud init which basically initializes
your configurations for GE cloud
now here we are using a cloud shell
which was started from the console and
we don't have to basically give your
gcloud init command because it's already
initialized now you can always look at
your default Zone you can look at your
region what is being used all those
things are coming from the metadata
which is being used so for example I
could be looking at the metadata for my
particular project by just doing a g
cloud and then I can say compute and I
would be interested in Project info so I
can just do a project minus info and
then I can do a describe and then I need
my project ID so I can say minus minus
project and I can get my project ID from
here so you can click on this one and
that's my project ID so I can click
click on this one and here I can just do
a right click and if it does not paste
then you can do a control V and then I
can try to look at my project info so
this basically will give me the metadata
which is by default set and we can
always look at what are the regions or
what is the Zone which has been set so
if it has been set so I'm looking at my
details it is showing me my SSH keys and
then it can be using your default region
and your default available zones it also
shows my username and other details so
this is basically to look at the
metadata which is available now at any
point of time I can basically say add
metadata I can basically choose metadata
option and I can say my default region
should be Europe which I was choosing
earlier so I can just bring up this
command again and what I can do is I can
say here where I have gcloud compute
project info where I did a describe
earlier now what I can also do is I can
just say add metadata
and then I can specify what is the
metadata I would be interested in adding
I can then say Google compute
default
region
and then I can basically give a region
for example Europe and then I can say
West 3
and if you are not well experienced you
can always do it from console or you can
be doing it from here so I'm giving
Google Cloud compute Google compute
default region then I can also give a
Google compute default Zone
and then I can pass in a value for
default zone so I can say Europe West 3
and then basically I can give an
availability zone so if it is basically
giving me some error where I'm trying to
pass in these values so I can just give
it this way and then it basically says
that if you can look into particular
help to see what is the command which
you would have to do now I can basically
do a g Cloud init here initial
configuration and this basically says
that it is initializing my default
configuration it says re-initialize this
configuration from cloud shell you want
to create a new configuration so if I
had updated my metadata then basically I
could just do a cloud in it and I could
be re-initializing my default
configuration or properties which I have
passed instant so as of now I will not
activate or change the default region
let's go for a simple way in which you
can create your compute engine so for
example I'll just say one and it is
reinitializing it asks me what is the
username and let's select that it says
what is the project and let's select
that and do you want to configure a
default compute region and zone right
and I will just say Yes And basically
then it shows me different options which
we have here so there are too many
options here and then here we were
interested in Europe West 3 so let's
choose 21 right and then that basically
allows me to choose my region and my
zone so it also gives you some
specification so it says your project
default compute Zone has been set to
Europe West 3A you can change it by
running gcloud config set and you can
give a compute zone right so I can
always give these commands I can get
help information here so I can just say
gcloud config set and I can be
specifying the compute zone so I can say
compute slash Zone and I can give a Zone
I can say compute slash region and I can
give a region name if I would want to do
it or the easier ways like what I did
right now so you can basically do a
command gcloud in it and then basically
it allows you to to change your
configuration or set default things here
you can all the times you can say gcloud
config unset to basically remove a
compute zone or a compute region now
there are different ways so if you were
working on a Linux machine you could
always use an export command something
like this so you could do export compute
sorry Cloud
SDK and then you can say compute
underscore Zone and then give your Zone
name or compute underscore region and
give your region or you could add it in
your bash RC file right now that is when
you have your Cloud SDK set up on your
Linux machine or on Windows machine and
you would want to specifically set a
Zone and a region for all your compute
related resources so we don't need to do
that the default settings are already
given here right and what we can do is
we can start by quickly looking into
gcloud compute instances options so I
can say gcloud compute instances and
then I can just do a list at any point
of time if you would need help you can
just do a gcloud compute and then say
minus minus help or I could just do a
gcloud compute and that shows me
different options which I have here from
which I use instances I can always type
instances and again hit enter and it
shows me different options what you
would want to do so I can initially just
type list which should show me what are
the list or what are the instances
available and as of now we don't have
any instances I can always do a list and
then I can specify minus minus format
and then try to get the information in a
Json format or EML or minus minus format
text
so you can always do a list you can do a
filter so there are different options
with your list and you can you can try
doing a help here and that basically
shows you what are the options so for
example if I do a help and it shows me
with list what are the things you can do
so you can give a name you can give a
regular expression you can say in
particular Zone you can use a minus
filter so there are different commands
which are available and you can always
find all those options here as I showed
you earlier so now what we would be
interested in is basically going for
your compute instances I can always do a
SSH and I can create an instance I can
add and remove metadata right for my
instances by giving a particular Zone by
giving a particular region and if you
would want to do that now here what we
can do is we can can basically create an
instance by just giving a name to that
particular instance and we can then go
back to our console and see what has it
done so I can say here create so that's
an option let's see what does the create
do so it says okay you are giving a
create option but you would have to give
a name so let's say let's call it E1 and
that will be the name of my instance and
this one is an easy command from your
Cloud cell which basically creates an
instance you see the Zone which has been
set it is the standard machine type it
is not preemptable it has an internal IP
and it has an external IP now I have
created an instance and here I can just
go back and then I can just do a Refresh
on this page and that already shows me
the instance which I have created and
then you can use the same method to
connect to it using an SSH so I have an
instance created from my cloud shell and
what I can do is I can basically look
into instances and see what are the
different options with instance so if we
did a create right you have an option
delete we did a create you have an
option delete you can be and deleting
the instance from the command line or
you can use other options so you can do
a list you can do a stop you can start
so I can basically do a stop and let's
say even let's go ahead and do a stop
commands are pretty easy here to
remember or you can always use the help
option and now I'm trying to stop the
instance and then basically I can go
ahead and delete it so this is a simple
way where I created a instance from the
command line or from the console which I
showed earlier and similarly you can be
working with other options so now I have
created stop the instance let's do a
listing to see if my instance shows up
it shows up right and it says the status
is terminated so you have stopped it
it's in the terminated status and now
what I can do is I can go ahead and
delete it
so it says this will be lost are you
sure you would want to continue just say
yes and that should take care of
deleting your instance
so this is a quick demo on creating your
instance we have already seen how you
can connect to these instances using SSH
now that we have created instances let's
also see how to use Google Cloud's
storage service which can be used to
load data or upload data so for this we
will have to look into your Google cloud
storage options and here you can look in
cloud storage so let's go back here on
the top which shows me different
Services which we have here and let's
look into storage so this one shows me
your storage option now you can click on
browser and that basically shows me your
storage browser which shows me on the
top you have options for creating a
bucket now Google Cloud Storage allows
you to store any kind of data here the
easiest and the simplest way would be by
using Cloud console although you can
again use cloud shell and in that you
can use your GS util command and GS util
basically has different options where
you can be using say for example I would
want to work on buckets so I can be
using MB and then I can use my command
line option to create buckets I can put
in data there I can browse it and I can
access the data from command line so
let's create a bucket here let's click
on this let's give it a name so let's
say my data important that's the name
now I can click on continue straight
away I can look into all of these
options if I'm interested in so you can
basically be looking at your monthly
cost estimate in the beginning now I can
click on continue or you can say choose
where to store your data and this one
shows you different options so you have
region specific like
so let's also give the bucket name with
all lower case that's what is required
yeah so coming back to the location type
you can choose multi-region which
basically allows High availability so
your bucket or your storage option will
be accessible across regions you can
also give dual region and high
availability and low latency across two
regions I can also say region specifics
or for our use case we can just keep
region specific which can keep our cost
low but in business use cases you would
be going for multi-region now here you
have location and I would again go for
say Europe and let's choose Europe
Wesley Frankfurt it is always a good
practice that when you create your
instances when you create your storage
or you use different Services try to
have a geographical region Chosen and
then you would try to put things on your
services within the particular region
within a particular Zone unless you
would want to make it accessible and
available across regions now I can then
choose a default storage class so when
you say default storage class there are
different storage class and each one is
for a different use case so you have
standard which is best for short-term
storage and frequently accessed data you
have near line so this is basically best
for backups and data access less than
once a month you can also have code
lines so these are basically like your
cold storage or freezing storage which
you might have heard generically as
terms so you can choose one of these
storage classes depending on what will
be the use case for this particular
storage bucket so let it be standard now
how to control access to objects so you
can basically say specify access to
individual objects by using object level
permissions now you can give permissions
to the bucket you can just say uniform
access to all objects in the bucket by
using only Bucket Level permissions so
you can choose that you can also into
advanced settings and here you can see
different ways in which you can have
configuration set up now you can also
have a retention policy to specify the
minimum duration where that this
bucket's object must be protected from
deletion and you can set a retention
policy will not get into all that we
will just first try creating a bucket so
just click on Create and that should
create your bucket wherein I have my
bucket now I can click on overview to
see the details what is the region which
region it belongs what is the storage
class anytime you can always click on
edit bucket and make some changes here
you can look at the permissions so
bucket uses fine grained access allowing
you to specify access to individual
objects and then you can basically look
at who has access to this so in my case
editors of the project they basically
are the bucket owners owners of project
viewers of the project right and you can
basically choose what kind of access you
need so for this you can always go into
cloud storage and then you can decide
what kind of access you would want to
give whether that's a storage admin it's
an object admin object Creator object
viewer and so on you can always look at
storage Legacy
and for any other services depending on
what apis you have enabled right you can
always control your permissions so right
now it is storage Legacy bucket reader
and that's fine and this one is bucket
owner and then might be I was using some
other services like data proc which uses
cloud storage and that's why I have
given data's proc service agent also so
these are some of the members you can
remove you can view by specific members
you can view by roles so what are the
different roles which have access to
this so it says storage Legacy bucket
owner there are two owners based on this
particular project so these are Auto
controlled but then you can add or
remove machines you can save storage
cost by adding a life cycle rule to
delete objects after the duration of
current retention policy so you can add
different policies and you can basically
control your bucket now my bucket is
already created right so I can go back
and then I see my bucket is already here
I can click on this option and you can
anytime edit the bucket permissions you
can edit the labels the default storage
class you can just go ahead and delete
the bucket you can export it to Cloud
Pub sub so basically if you would want
to have the content from this bucket
being accessible in a message queuing
system you can go for Pub sub you can
process with Cloud functions and you can
scan with cloud data loss prevention so
there are different options which are
available we can always select this
bucket and delete it now I can click on
the bucket and that basically shows me
different ways in which I can upload
some data here so I can just click on
upload files and here then I can choose
some files so for example I'll go in
here I'll go into data sets and I have
different data sets so for example let's
choose this one which is a CSV file and
then I'm just uploading this to my
storage right it's as simple as this so
you can drag and drop your files or you
can just upload your files and my file
is uploaded here now I can basically
edit permissions for this one right so
this is in the bucket so anyone who has
access to this bucket can basically
download this file it can they can copy
move or rename this you can export it
and you can look at the permissions of
this file so let's look at edit
permissions and it says
for this project whoever is the owner it
has access I've also given a specific
user my Gmail ID and I have given access
so at any point of time you can just say
add item and then you can start giving
different kind of accesses so let's
click on cancel here now my data is
already uploaded into this particular
bucket and that's a simple usage of your
cloud storage now what we can also do is
I can basically select this and I can
delete it I can also create specific
folders and then basically load data
into it I can click on this one I can
just do a download and then I can
download it anywhere on my machine so
let's go to desktop and let's download
this file so we not only uploaded some
content in the bucket but we also
downloaded that in a different location
which will be accessible now what I
could have also done is I could have
created a folder here and I could have
specified say for example immediate
immediate data
okay and I'm clicking on this one so
that's my immediate data I can click on
this one and now I can upload my data
specifically to this particular folder
by using the same mechanism you can just
do upload file let's choose air
passengers let's say open and my file
will be uploaded so you can always
choose what is the retention expiry date
for this one so as of now there is
nothing right but you can be deleted
objects can be deleted or modified until
there is a minimum duration you can
control all of that you can basically
download it right you can copy it and
you can move it and rename it so this is
a simple example where I created a
particular bucket right now if for
example you click on this transfer so it
says cloud storage data transfer
products have moved you can now find
storage transfer service on-premise data
and transfer Appliance in new data
transfer section right so you can always
go back
to cloud storage you can also look at
transfer options which are mainly when
you are using your on-premise service
and you would want to upload data in a
Google Cloud right so this is my bucket
here now I can go to Cloud console and
here what I can do is if I would be
interested in working so I can just say
GS util right and then we have for
example let's try a help okay and that
basically shows me my GS util now you
can always go to Quick Start gsutil tool
and this is one more way wherein
basically you can do it from the command
line so working with buckets so you can
do a GS util MB minus B and then on a
particular Zone if you would be
interested in and then you can say GS
colon and give a name so my awesome
bucket this is how you will create a
bucket which will show you it is
creating a bucket and then basically you
can upload an image or some data from
internet you can just do a w get
download the file and then you can just
do a GS util copy command and that
basically will pick up the file from
your Cloud shell location put it in your
bucket once you have done that you can
always do a copy right so here you are
doing a copy from your local machine
that is your Cloud cell machine to your
bucket and you can do the reverse of
that that is you can do a copy and you
can point your bucket and the file and
download it to your desktops so you can
just download that using the command
line and you can copy the object to a
folder in the bucket so that is by
creating a particular folder and you are
pushing the file into a particular
bucket you can list the contents of a
bucket using LS and then give your
bucket name so GS colon so we can just
try this one to be simple and rest you
guys can try so so here you can just do
a GS util you can do a LS GS colon slash
slash and then I need to give my bucket
name so in my case the bucket name was
my data important so let's try that so
let's save my data important and I'm
trying to list the bucket and the
content it has right and then you have a
folder and then you can look into the
folder and look into the files so this
is a simple quick option wherein you can
use your Cloud cell you could be using
your Google Cloud SDK from your local
machine or you can be using Cloud
console to create a bucket upload some
data on it download the data see if the
data is accessible and that basically
shows you the power of cloud storage
where you can easily upload any kind of
data now what we can also do is as
you're using a free account or even a
paid account unless and until you would
want to keep the bucket you can select
it and you can just go ahead and delete
it so this will basically ask you to key
in the bucket name and let's say my data
important you need to confirm your
bucket name click on confirm and you
could have done that using gsutil and a
delete command from the command line
that is from cloud cell so we have now
created a bucket we have uploaded some
data into it we saw how you can download
it or create a folder and upload some
specific data into it and also you can
do the same thing using GS util tools
wherein you can list your bucket create
your buckets delete it create some
folders into it and do everything from
the command line so this is in simple
way you can use your gcp where either
you can spin up your machines or you can
use cloud storage to basically use a
storage or a easy to use instance on
Google Cloud platform AWS versus Azure
versus gcp so let's get started
Amazon web services or AWS is a cloud
computing platform that manages and
maintains hardware and infrastructure
reducing the expense and complexity of
purchasing and running resources on site
for businesses and individuals
these resources are available for free
or for a fee per usage
Microsoft Azure is a cloud computing
service that offers a collection of
Cloud Computing Services for building
testing deploying and managing
applications in the cloud including
remotely hosted and managed versions of
Microsoft Technology
Google Cloud platform offers a variety
of Cloud Computing Services for building
deploying scaling monitoring and
operating a cloud
the services are identical to those that
power Google products such as Google
search Gmail YouTube and Google Drive
now let's move on to the comparison
between AWS Azure and gcp
we will be comparing them based on a few
major parameters like origin
service integration
availability Zone
Cloud tools like compute
storage
networking
market share
pricing
and at last who uses them
now let's move ahead and start with the
first comparison origin
in the year 2006 Amazon web services or
AWS was introduced to the market
and in the year 2010 Azure launched its
services whereas on the other hand gcp
was established in the year 2008.
from the start AWS has been supportive
of the open source concept but the open
source Community has a tense
relationship with azure
on the other hand gcp similar to AWS
provides Google cloud with managed open
source services that are tightly linked
AWS offers services on a large and
complex scale that could be manipulated
but Azure support is comparatively low
quality whereas gcp's monthly support
price is almost a hundred and fifty
dollars for the silver class which is
the most basic of services and is quite
expensive
now let's move on to the service
integration of these Cloud platforms
service integration is a set of tools
and technology that connects different
applications systems repositories and
data and process interchange in real
time
AWS makes it simple for users to combine
services such as Amazon ec2 Amazon S3
Beanstalk and others and on the other
hand Azure allows customers to
effortlessly combine Azure VMS as your
app service SQL databases and other
services whereas users can utilize gcp
to combine services such as compute
engine cloud storage and Cloud SQL now
that we know briefly about all these
Cloud platforms let's have a look at the
availability zones of these platforms
because AWS was the first in the cloud
domain they have had more time to build
and extend their network but Azure and
gcp both have various locations around
the world
but the distinction is in the amount of
availability zones they have AWS now
offers 66 availability zones with an
additional 12 on the pipeline close to
it Azure is available in 140 countries
and is available in 54 regions
throughout the world but Google Cloud
platform is now available in 20 Global
areas with three more on the way
now let's move on to the next important
factor which is tools
now let's move ahead and have a look at
the first feature which is compute
elastic compute cloud or ec2 is aws's
compute service which offers a wide
range of features including a large
number of instances support for both
windows and Linux high performance
Computing and more Azure on the other
hand as virtual machines is Microsoft
azure's core cloud-based compute
solution
it includes Linux Windows server and
other operating systems as well as
better security and Microsoft program
integration
in comparison to its competitors
Google's Computing Services catalog is
somewhat smaller compute engine that
companies principal service offers
custom and pre-defined machine types per
second invoicing Linux and Windows
support and carbon neutral
infrastructure that uses half the energy
of traditional data centers
within the compute category Amazon's
different container services are gaining
prominence it has Docker kubernetes and
it's also fargate service which
automates server and cluster management
when using containers as well as other
alternatives
Azure unlike AWS uses virtual machine
scale sets of two container services
Azure container services is based on
kubernetes and container service uses
Docker Hub and Azure container registry
for management
for Enterprises interested in deploying
containers Google offers the kubernetes
engine and it's also worth noting that
Google was significantly involved in the
kubernetes project providing an
extensive knowledge in this field
now let's move on to the next parameter
of comparison which is storage
simple storage service for object
storage elastic block storage for
persistent block storage and elastic
file system for file storage are among
aws's storage offerings
block storage for rest based object
storage of unstructured data Q storage
for a large volume workload file storage
and disk storage are among Microsoft
Azure core storage services
gcp offers an increasing number of
storage options its unified object
storage service cloud storage also has a
persistent disk option relational
database service or RDS dynamodb no SQL
database elastic and memory data store
redshift data warehouse Neptune graph
database and database migration service
are all SQL compatible databases offered
by Amazon
the database choices in Azure are
specifically wide SQL database mySQL
database and postgre SQL database are
the three SQL based choices
now when it comes to databases gcp
offers the sql-based cloud SQL and Cloud
spanner a relational database built for
Mission critical workloads now the next
parameter is networking
AWS uses Amazon virtual private cloud or
VPC
on the other hand Azure uses Azure
virtual Network or v-net
and gcp uses Cloud virtual Network now
let's move on to another factor which is
market share and pricing
all these cloud services are based on
comparative pricing strategies which
means you need to pay on the basis of
its usage
according to Canalis the worldwide Cloud
Market Rose 35 percent to 41.8 billion
in the first quarter of 2021. AWS
accounts for 32 percent of the market
with Azure accounting for 19 and Google
accounting for seven percent
on one hand Amazon charges on a yearly
basis and on the other hand Microsoft
Azure and Google services charge on a
minute basis and also all of them
provide you a standard price for you to
access these services
AWS charges roughly 69 per month for a
very basic instance with two virtual
CPUs and eight gigabytes of RAM
and AWS largest instance with 3.84 TB of
RAM and 128 vcpus will set you back
roughly
3.97 per hour
but in Azure the same type of instance
one with two vcpus and eight gigabytes
of RAM cost roughly 70 U.S per month and
azure's largest instance has 3.89 TB of
RAM and 128 virtual CPUs and it cost
about
6.79 per hour
compared to AWS gcp will supply you with
the most basic instance which includes
two virtual CPUs and eight gigabytes of
RAM for 25 percent less and as a result
it will set you back roughly 52 dollars
every month and the largest instance
that includes is 3.75 TB of RAM and 160
vcpus and it will cost you about 5.32
cents per hour
Amazon other than this also provides
spot instances reserved instances and
dedicated hosts where you can look for
multiple offers and discounts
but for Azure it provides special prices
to developers based on situations or
even Azure hybrid benefit which benefits
your organization up to 40 percent if it
uses Microsoft software in their data
centers
whereas Google offers quite assorted
pricing to its customer compared to the
other two
it gives you sustained use discounts
which activate if you use the same
instance for a month
the printable instance which is very
similar to Amazon's spot instances but
one thing is common in all three cloud
services which is that they all offer
long-term discounts
now let's have a look at the last
comparison which is the companies that
are using them
because AWS is the oldest player in the
cloud business it has the largest user
base and Community Support as a result
AWS has the largest number of high
profile and well-known clients including
Netflix Airbnb Unilever BMW Samsung
missinga and others
with time Azure is getting a large
number of high-profile customers Azure
currently boasts around 80 percent of
Fortune 500 firms as customers Johnson
Controls polycom Fujifilm HP Honeywell
apple and others are among its key
clients
Google Cloud on the other hand uses the
same infrastructure as Google search and
YouTube and as a result many high-end
Enterprises trust Google Cloud HSBC
PayPal 20th Century Fox Bloomberg
Domino's and other are among Google
Cloud's many clients now cloud computing
is one of those Technologies that's
rapidly rising and with any technology
that's growing rapidly it comes with
several job opportunities for the people
who are skilled in it so before we get
into it let's have a brief look at what
is cloud computing cloud computing
refers to services like storage
databases software analytics machine
learning artificial intelligence and so
much more all of which made accessible
via the Internet the cloud tech services
Market is expected to grow 17.3 percent
in the span of 2018 to 19 which means
there's a growth from 175.8 billion
dollars to a whopping 206 billion
dollars in 2019 and as of 2020 it's
expected that ninety percent of all
organizations in the world would be
using cloud services not to mention
several organizations around the world
suggest that using Cloud Computing
Services has enabled their employees to
experiment a lot more with Technologies
like machine learning and artificial
intelligence so here's what we'll be
going through today firstly we'll be
talking about who is a cloud computing
engineer the steps you need to take to
become a cloud computing engineer and
the cloud computing engineer's salaries
so first off who is a cloud computing
engineer now a cloud computing engineer
is an ID professional who takes care of
all the technical aspects of cloud
computing now be a design planning
maintenance and support now a cloud
computing engineer can take up a number
of different career paths this could be
that of a cloud developer security
engineer a full stack developer sysops
administrator Solutions architect Cloud
architect and so much more now let's
have a look at some of the major cloud
computing roles first off we have
Solutions architect now these are
individuals who are responsible for
analyzing the technical environment in
which they are going to produce the
solutions the requirements and the
specifications secondly they are
required to select an appropriate
technology that satisfies set
requirements they need to estimate and
manage the usage and the operational
costs of the solutions they provide and
they need to support project management
as well as solution development next we
have sysops administrators they are
involved in deploying managing and
operating highly scalable and fault
tolerant systems they need to select an
appropriate service based on compute
security or data requirements they need
to estimate and manage usage and
operational costs and they need to be
able to migrate on-premises workloads
onto an appropriate cloud computing
platform so among both of these roles
there are certain requirements that are
remaining constant now let's have a look
at the steps you need to take to become
a cloud computing engineer your first
step is to gain Proficiency in a cloud
computing platform now the first step is
to become proficient in a at least one
of the three major cloud computing
platforms be it AWS Azure or the Google
Cloud platform now there are a huge
number of resources that you can find on
the internet it could be YouTube videos
articles virtual or physical classrooms
and so much more now after you're done
learning you can get certified by
Microsoft Azure AWS or the Google Cloud
platform now for AWS you have a number
of different certifications which can be
divided into three categories which are
the foundational which is just the
basics the associate level
certifications the professional level
certifications and the specialty
certifications similarly with Microsoft
Azure you have certifications that
enable you to become an Azure developer
associate and as your administrator
associate and Azure architect
professional and a devops engineer now
most cloud computing platforms have a
free tier that you can take advantage of
these provide a number of free services
for a period of time some of which are
free forever so you can use these
platforms to your advantage and do as as
much practice as you can on them now if
you want to learn more about cloud
computing you can also check out Simply
learns YouTube channel then you can go
on to the playlist section right here
and you can find comprehensive videos on
a number of different cloud computing
platforms AWS and Microsoft Azure our
AWS tutorial videos talk about what
exactly is AWS how you can become an AWS
Solutions architect Amazon ec2 S3 some
of the other services and so much more
we also have detailed tutorials on Azure
which talks about what exactly is azure
the certifications provided by Azure
some of the services like machine
learning as your active directory and so
much more and now we're at Step 2 being
experienced in at least one programming
language unlike general purpose
programming languages like C C plus plus
C sharp and so on cloud computing
requires ones there are a lot more data
oriented now some of the major
programming languages that are used in
cloud computing are go Python clature
and Java now as I said before there is a
wealth of resources that you can learn
from there are free websites that you
can practice your code on like quick
code code academy and several others
there's also resources like YouTube
videos as well as there's the option of
online or offline classes now we're at
step three specialization you'll also
need to be well versed with a number of
key Concepts these are storage and
networking now with storage you need to
know how data can be stored and where it
can be accessed from you need to know
how it can be accessed from multiple
different resources you'll also need to
have some experience with the services
provided by Azure and AWS like the
Amazon S3 in AWS and the appropriately
named Azure storage from Microsoft Azure
with networking you need to have a
strong understanding of the networking
fundamentals as well as virtual networks
next up we have virtualization and
operating systems with virtualization
you need to know how virtual networks
which is just a combination of different
virtual machines can be used to emulate
different components in a particular
system with operating systems you need
to have a very strong understanding
operating systems like Windows and Linux
next up we have security and Disaster
Recovery now you need to understand how
data application as well as
infrastructure can be protected from
malicious attacks With Disaster Recovery
you need to be prepared for any
unexpected circumstance by making sure
your systems are always safe and are
regularly backed up to prevent any sort
of loss of data then we have web
services and devops now you need to have
a strong understanding of apis or
application program interfaces and web
services some amount of experience with
web design also can be of great help
with devops you need to have a strong
understanding of how cloud computing is
able to provide a centralized platform
on which you can perform testing
deployment and production for devops
automation moreover with devops you
understand the Synergy that the
operations as well as the developer
teams have with each other and for the
success of any project and finally
you're a cloud computing engineer now
let's have a look at the salaries of
cloud computing engineers in the United
States cloud computing Engineers earn
around 116 000 dollars per annum in
India a cloud computing engineer is paid
approximately 6 lakhs 66 000 rupees per
annum now how can simply learn help you
become a cloud computing engineer if
you're also aiming to be a professional
data engineer you are at the right place
take a look at a Caltech cloud computing
bootcamp program by simply learn and
Kickstart your journey towards becoming
a data engineer this education program
will help you become an expert in
designing planning and scaling Cloud
implementations for more information
check out the link in the description
box so with this we have reached the end
of this cloud computing bootcamp I hope
this session was interesting and
informative if you have any questions
regarding any topic discussed in the
boot camp feel free to reach out to us a
team of experts will be happy to help
you out thank you and keep learning
hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos turn it up and get certified
click here
foreign