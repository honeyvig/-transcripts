foreign
Welcome to our Advanced mongodb full
course by simply learn in this
comprehensive full course we will dwell
into the types of mongodb a powerful
nosql database and explore its Advanced
features and functionalities whether
you're a seasoned developer or a curious
learner this will cause its design to
equip you with the skills to master
complex data modeling Advanced querying
in texting sharding aggregation and much
more the course will contain the mongodb
basics regular expressions in mongodb
aggregation and mongodb sharing
relationships grid fs mapreduce and
mongodb projection mongodb replica set
database references python mongodb
indexing in mongodb cluster operations
in mongodb and finally Java connectivity
using mongodb so without further Ado
let's get started if these are the type
of videos you'd like to watch then hit
the Subscribe button like and press on
the Bell icon to never miss on our
future content also if you're an
aspiring data engineer looking for
online training and graduating from the
best universities or a professional who
likes to switch careers with data
engineering by learning from the experts
then try giving a short to Simply launch
postgraduate program in data engineering
from Toyota University in collaboration
with IBM the link in the description box
and the comment section should navigate
you to the homepage where you can find
the complete overview of the program
being offered now over to our training
experts all right so what is data
modeling in on the DB now basically data
modeling is a process of taking
unstructured data that is generated from
The Real World scenario and introducing
it to the data server and then
structuring it into a logical data model
in our database so it is basically a
process of determining how data is
stored and what connection exists
between various entities in a
relationship now you don't have to
create a schema before inserting data
because nosql is flexible this is so
that mongodb can support a dynamic
database schema that makes it
unnecessary to create your schema in
advance instead you can now store your
information and make changes in
accordance with your data now consider
data modeling in mongodb as a
relationship now there is no particular
relationship just like SQL where we use
Now mongodb relationships are the
representations of how multiple
documents are logically connected to
each other in mongodb now since mongodb
is a doc document database any document
within the same collection is not
mandatory to have same set of fields or
structure you can store different types
in a collections given field and can
even add new Fields update fields and
delete existing Fields as well now for
example consider an online shopping
store where we have like thousands of
customers arriving daily and purchasing
new products from the website now we get
a lot of unstructured data that is the
name of the customer the details and all
which is basically unstructured data now
in order to convert into a proper
structured data we need to model them
into a particular way which this is
where data modeling comes into a picture
where we store the data based upon our
requirement now the main challenge in
data modeling is balancing the
application needs guys now the database
engines performance characteristics and
also the data retrieving patterns
all right let us now move ahead and
understand why we use data modeling
now data model basically helps us to
create a simplified and optimized
logical database that eliminates
redundancy red is a storage requirements
and enables efficient retrieval from the
database now data modeling may appear to
be a complex process wherein you have to
make adjustments to your database unlike
SQL value predefine your schema and
create a new table and then store the
data now while in mongodb data modeling
helps us to analyze and understand what
type of data and how much data has to be
inserted into a database data modeling
is necessary foundational work that
allows data to be stored more easily in
the database and has a positive positive
impact on data analytics as well now let
us understand why exactly we use now
data modeling now data quality is
Paramount for any organization and to
ensure that we need higher data quality
when we are showing unstructured data in
large amounts now the visual
representation of requirements and the
business rules enables to anticipate
what could lead to a large-scale data
corruption before it occurs so data
model enables the developers in
hindsight to Define rules that monitor
the data quality and ensuring that there
is no possibility of errors
now it is also important to understand
how the data is Flowing within the
database and the characteristics of that
creating data models forces the business
to Define how data is generated and move
across the application development and
maintenance data modeling exposes errors
and inconsistencies early in the process
making is it making it easier and less
expensive to fix so in order to maintain
a database that is a mongodb database
which is basically a unstructured one it
is important that we try to develop and
maintain it in a regular basis
and finally performance is another
reason why we use data modeling now an
organized database is one that is more
efficiently operated and data modeling
prevents the schema from endless
searching and returns results more
quickly those were some of the reasons
on why we use data modeling guys
all right let us now move and discuss
how data modeling Works in mongodb
now unlike SQL databases where you must
determine and declare a table schema
before inserting data or perform any
operations we need to basically provide
a schema for that now mongodb's
collection by default do not require the
documents to have the same schema now
the documents in a single collection do
not need to have the same set of fields
and the data type of for a field can
differ across documents within a
collection now to change the structure
of the document in a collection such as
adding a new field or removing the
existing field in a document or changing
a field values to a new type or update
the documents to the new structure
now basically the first step is to
basically create and design a schema as
per the requirement and the application
made by the user and then we have to
combine documents now if there is no
scope for multiple documents uh to store
into a single one and ensure that if
there is no other need for a single
document to store in a multiple document
in such way we need to understand what
is our requirement and combine the
documents accordingly so that we can
have performance as well as the
optimization of the database is also
improved now this flexibility
facilitates the mapping of documents to
an entity or an object now each document
can match the data field of a
represented ID entity even if the
document has substantial variation from
other documents in the collection so
this is how basically a data model Works
wherein you have to choose as per the
requirement and understand what type of
documents that are being inserted into
the database
all right let us now understand some
data models that are used in mongodb now
once you've understood the business
requirement and the application on how
it should be as you start modeling your
data you will likely go through various
steps of data analysis now each step
might produce different types of data
models therefore ensuring data models
having the right one can be generally
thought of as being one of the main
aspect of choosing a data model and they
are conceptualized into three categories
based on the level of the detail and the
specificity now that's classified into
three types the first one is conceptual
data model the conceptual data model
explains what the system should contain
with regard to and how it is related
this model is usually built with the
help of the user and the stakeholders it
represents the applications business
logic and is often used as the basis for
one or more following model
next we have the logical data model Now
The Logical data model will describe how
the data will be structured in this
model the relationship between the
entities is established at a high level
you'll also list the attributes for the
entities represented in this model
and finally we have the physical data
model guys the physical data model
represents how the data will be stored
in a specific database now in this case
we have mongodb model where we are using
establishing a primary and a secondary
relationship between the data in a
document that is stored in the database
such as mongodb you will also establish
the data types for each of your fields
that are mentioned this will provide you
with your database schema as well
let's see
now although mongodb has a flexible
schema you need to uh data model or
schema design a good data model means
that you'll establish a strong
foundation for an Ever evolving data
model now mongodb supports multiple ways
to model relationship between the
entities in a data model now the first
one is one to one that is in this type
one value is associated with only one
document that is it will have a single
relationship between the two connected
objects or entities in the database next
we have one to many here one value can
be associated with more than one
document or value at the same time and
finally we have many too many now when
two or more entities within a document
can have multiple relationship that is
basically is many to many relationships
in this type of model multiple documents
can be associated with each other so let
us now quickly understand with an
example now consider the example for one
to one relationship where I have a
student table and contact info table now
for each student ID there is a unique
details or the contact info so it is
basically pointing one value to another
that is student ID which is one to one
relation and similarly we have one too
many relation wherein we have customer
table and Order stable now every
customer has a different ID and a
customer can place multiple orders so it
can generate multiple order IDs so we
have three different IDs like b204 b391
b448 so this is what is one too many
which is basically one entity is being
pointed to three other values I hope you
understood one to one and one too many
so if you understood this let us know in
the comment section below what will be a
good example of many to many
relationship
all right moving ahead let us now
discuss the types of methods to create
the data models now once we are
confirmed with what data model we need
and the relationship that we have chosen
for uh for our documents to store the
data we need a method that is to create
a data model now that is where we have
two different data models that stores
the data in documents that is first one
is embedded data model so in emitted
data model you can embed data in a
single document or structure in mongodb
it is also referred to as the normalized
data model it leverages the full
potential of mongodbs Rich document and
it uses a one to one or one-to-many
relationship guys
next we have the reference data model or
in other words it is known as normalized
data model now they are used to build
one too many as well as many too many
relationship models now while working
with the embedded document models there
will be times when you have to repeat
the data this is where reference data
model comes into picture which basically
tackles their data redundancy
so I know it is bit of confusing so
let's just understand this with an
example here now if you consider the
embedded model if you look at a document
which I have taken here which is the
details of a student named Rohan where
we have a collection uh that is
containing a document has Rohan in this
document we have embedded a document
here that is contact details and his
grade
so embedding uh data model stores
relevant details in the same documents
or the same database record this way you
can minimize queries and update required
to perform common database operation on
the other hand we have a reference data
model or the normalized data model
so if you look at to the reference model
example here we have basically split a
single document into three documents and
since contact details and grade have the
ID from the document that is of rohans
you can call them whenever needed now
normalized data model splits the data
into multiple collections by using
references between the newer collections
you can update or change a single
document which will update other
collections automatically this is an
efficient way of updating data and is
mostly used when your data goes through
frequent changes that is if you're
working on a data that has to be
leveraged or changed on a daily basis
you can consider reference model
that is which is basically one of the
biggest advantages of using normalized
data where you have to model large data
sets that follow a certain hierarchy and
you have to where you have to represent
multiple many to many relationships so
that is where we use uh embedded model
and reference model so what is mongodb
operators operators are basically
special symbols or keywords that tell a
compiler what mathematical or logical
operations to perform the operator
improves mongodb functionality by
enabling the developers and programmers
to construct sophisticated queries to
communicate with data sets that are
appropriate for their application and
perform certain complex tasks to
retrieve the data now in general we use
the find command or method to fetch the
data from collections using the query
operator also we need to use the prefix
which is the dollar sign before the
query operator so let us just quickly
understand the syntax of the operators
in mongodb the syntax is followed as DB
dot name of collection dot find and
within the parenthesis
we have to mention the field name and
mention the semicolon and then we have
to mention the dollar symbol with the
help of the operator that we want to use
mention the value and finally we use the
pretty uh method so let's just quickly
go through all these uh
terminology so that will have a better
idea now the name of the collection is
basically according to the query
operator we used in our query this
parameter is defined as the collection
name from which documents have been
retrieved next we have the find method
now data can be retrieved from
collections using this technique we can
also retrieve particular documents from
mongodb by using the find method with a
query operator next we have this field
name according the query parameter we
used in our query this parameter is
defined as the name of the field from
which we are retrieving data that is
what we are trying to retrieve data from
our collection is basically the field
name next we have the query operator
name which must be used to retrieve the
documents from The Collection accordance
with the query operations next we have
to mention the value the value is
nothing more than the field value that
we used with a query operator to conduct
logical or any mathematical operations
and so on and finally we have an option
well uh tag which is pretty now since
mongodb output is generally is in an
unstructured format so we can display
our output using this technique in a
structure format and this is also
optional guys so if there is a
requirement to show the data in a proper
structure where you can use the 30
statement so that was all about mongodb
operators guys so let us just move ahead
so let us now understand the different
types of operators in mongodb now just
like any operators in other programming
languages mongodb operators are used to
perform specific relational mathematical
or logical operations and produce this
final result operators in mongodb are
you know broadly classified into three
types the first one is query and
projection operator next we have update
operator and then finally we have
aggregation pipeline operator
now in mongodb the default for queries
is to return all the fields in the
matching documents so basically a query
and a projection operator is used to
perform certain calculation wherein a
projection query is used to specify or
restrict the data result returned in
query result Now by specifying a
projection query you can specify the
fields you want to return or exclude now
similarly we have other query operators
which we'll be discussing in a while
which are used to perform certain a
complex calculation on the data that
you're retrieving from the documents
next we have the update operator which
basically updates the value of all the
fields of the documents which is
matching the specified condition and
finally we have the aggregation pipeline
so it basically provides a competent
results as a result of processing the
data requires an document so it is
similar to that of aggregate functions
in SQL wherein it you know Aggregates
all the values within a document and
perform certain aggregation uh operation
like you know some Maximum minimum and
so on so these are some of the main uh
different types of operators in mongodb
so let us now just uh get into detail
and how that further classified into
various types now query and projection
operator further classified into various
other types such as comparison operator
logical operator array operator element
Operator bitwise Operator evaluation
operator and finally we have geospatial
operator now it is time taking to get
into all of this stuff and explain each
and every operator guys so let us just
focus on the main operators that are
frequently used in mongodb
so firstly let us discuss about the
comparison operator guys now the
comparison operators are basically used
to compare two expressions and retrieve
data from the documents that is the
documents that are that we have stored
uh that is the all the data from the
collections which are basically the
group of collections is basically a
document in mongodb that is stored in
the mongodb database now we have several
such comparison operators in mongodb now
as explained earlier we have to use the
dollar sign with the help of operator
that we have been uh mentioning so
basically The Operators uh take the
dollar sign and then we have to mention
the operator that we have taken so let
us just discuss some of the operators
here the first one is EQ which is
basically the equal operator which
matches values that are equal to the
values specified in the query next we
have dollar any which has a full form of
not equal to which is opposite of equal
and matches all the values that are not
equal to the value specified in the
query next we have GT and GT which is
basically greater than and greater than
equals to uh this operator basically
matches the value that are greater than
the value specified in the query or that
are even greater than or equal to the
various value specified in the query
next we have the LT or LTE that is less
than or less than equals to again as the
uh the word course it is similar again
it matches the values that are less than
the value specified in the query or it
matches with the less than or equal
values specified in the query in the
document and finally we have the in and
nin which basically matches any of the
value that is existing or not existing
in an array specified in bigquery I know
it is a bit of confusing so let us just
uh understand this with an example here
so consider this example on your right
hand side where you can see this image
which is basically a format of a
document that is stored in a mongodb
database guys so let us say I have uh
you know a collection named orders of
let's say a stationary item database now
I have further different three different
documents that are present in
uh this collection so basically a group
of documents is basically a collection
in a mongodb database so I hope you've
understood uh what is a collection
document and what is a database so if
you want to know more about it we have a
dedicated video on what is Momo DB where
we've uh explained clearly on all these
terms and how it exactly Works make sure
you check that out uh which will be
quite helpful and I would highly
recommend so as you can see we have
basically three documents here we have a
ID of three different uh people who have
purchased certain products from a
stationary and have different IDs so we
have three customers here Rahul prenup
and kirti now if I say if I want to
perform comparison operation for this uh
let us just understand how equal and not
equal operation performs so basically uh
I'm taking an example here which says
dp.orders DOT fine where payment mode is
equals to card so basically uh the
compiler finds all the documents that is
present in this college action where the
payment mode is made through card which
instead of cash so basically we have
here uh the details of two customers who
have used their payment models card
which is customer Rahul and customer
kirti so in this way it will return
these two following documents and
similarly we have any which is not equal
to and I'm taking another example which
is DB dot orders fine order total is not
equals to 600. now as you can see in the
image we have the third document of
customer care whose order total is 600
right so it basically evaluates this and
Returns the result which has an order
total which is not equals to 600 that is
basically the first two documents that
is it will retrieve the data from this
document of the first uh you know two
documents which is of customer Rahul and
customer prenup whose order total is
basically 2450 and 5800 respectively so
that is basically what is a comparison
operator using EQ and any which is equal
to or not equals to All Right Moving
ahead let us now discuss what is GT and
GTA which basically derived is greater
than and greater than equals to again
let us consider the same uh you know
collection same example that we have
taken earlier now the first query is
basically for GT that is DP dot order
find order total is greater than three
thousand all right so we are basically
performing a search query wherein we
want only uh those documents whose order
total is greater than three thousand now
if you look at the image we have only uh
I guess one document which is of
customer pranav whose order total is
5800 which is more than 3000 and
similarly we have for greater than
equals to which is DB dot orders fine
order total GTE uh 2450. so basically we
should retrieve the document whose order
total is more than 250. again we have
two documents here right now we have a
document of customer Rahul and the
customer pranav whose order total is
2450 which is equals to 2450 for that we
have mentioned in our query so basically
uh the details of the documents of
customer Rahul and customer pranav whose
order total is greater than or equals to
24 500. all right moving ahead let us
now understand what is LT and LT which
is a negation or complete opposite is
greater than greater uh than equals to
now in less than we have taken an
example which is again order total Which
is less than 2000 uh so I guess we have
only one record again here of customer
kirti whose order total is 600 and
similarly less than or equals to 500 now
I guess we have only one document again
of kirti which is order total is 600. oh
I'm sorry are less than or equals to 500
right so we don't have any uh you know
document of the customers Which is less
than or equal to 500 guys sorry uh just
a pardon me for my mistake I didn't
check so we don't have any customers
whose order total is less than or equals
to 500 so it will basically uh you know
retrieve a null value
so that were some examples of comparison
Operator Let us move ahead with logical
operators now so basically logical
operators return data based on the
expression that evaluate the following
condition to either be true or false now
in general we have four different types
of logical operators in mongodb which is
and or not and not which is again
similar uh with any other programming
languages where we use a logical
operator and similar to that of SQL as
well now the basically the and operator
returns all the documents that match the
condition of both the expression
specified and or operator returns all
documents that match the condition of
either expression specified next we have
the nor operator which returns all
documents that do not match the
condition of either expression this is
basically an opposite of or operator and
finally we have the not operator which
basically returns documents that does
not match with the query expression in a
document so again let's just understand
with an example by considering the same
example which is the order collection in
now so for example first example I am
taking and operator which says DB dot
orders fine and address city is either
daily or payment mode is cache now if I
look into the collection here I have
only one such document where
City address city is Delhi and payment
mode is cash that is the details of
customer pranav so it will retrieve only
the document of pranav here next if I
consider the r operator which is DB dot
orders fine or CT Jaipur or order total
is less than or equals 200 so we have
Jaipur
uh City whose uh I think it's of
customer uh Jaipur yeah it's a customer
Rahul so it will retrieve that one and
it will also retrieve those documents
whose order total is less than or equals
two thousand now we have only one
document of K3 whose order total is 600
which is again less than or equals to
100 so basically the first document and
the third document will be retrieved in
our query in a final resultant set and
finally we have the nor operator which
says the city is either is not either
daily or payment mod is cash now other
than City Delhi and the payment mode
cash that is we have a pranav whose
payment mode is cash and also belongs to
Siri so basically it will remove the
document of this person customer printer
and it will fetch the first and third
documents that is uh the I the customer
rahul's and the customer kirti
so those were some of the uh logical
operator examples we have used I hope
you've understood
so moving ahead let us now discuss some
element operators guys the element query
operators are basically used to locate
document I know based uh on the fields
of the document
now what that I mean is so basically
every document has a field right now for
example let's say in the previous
example I've taken ID customer name
order total and so on and so which is
basically a field I know these field
have further values or elements to its
name right so the element operator
basically finds all the documents based
on the fields of the document that you
are trying to search for now we have
basically two uh element operator which
is exists and types exist operator
basically returns documents that have a
specific field now if I let let us take
an example let's say I have an uh you
know collection employees and I want to
find the employee age as a field I want
to find if there is a field called
employees and his age is greater than or
equals to 35 so I have taken this
example which is dbr employees fine
employee age exists true gt35 so if
there is any field in our collection of
employees and this greater than 25 or
greater than 35 it will retrieve those
documents and similarly we have the type
document type operator which returns
document is field is of only a specific
type specified type now if I take an
example here let's say if I'm trying to
find a field uh employee age again and
it is of double uh double integer type
so if I want the particular you know
field data type I can use it type
operator here so this was that was all
about element operator guys and let us
move ahead and finally discuss one of
the main us operator that is array
operators array operators in mongodb are
basically used to query documents that
include a field of arrays now we
basically again have three different
types of operators used in mongodb
the first one is all operator it returns
documents from a collection if it
matches all the values in the specified
array next we have this size operator it
returns documents from The Collection to
match an array with a provided number of
elements in it next and finally we have
LM match which returns those documents
that match specified condition within
each array element now I hope I know it
is bit of confusing so let us just move
ahead and understand with an example
here consider the same uh example again
where we have three documents here now
for first example I have taken the all
operator which is an array operator so
what I'm trying to find is I am trying
to find a element of value which has you
know a notebook and a paper so the query
is followed as DB dot order dot find
orders item all notebook and paper so if
you look into the image I think we have
only uh two documents where we have this
fields are having notebook and a paper
that is the first customer and second
customer if you look into the item name
you have notebook and paper in the first
uh document and second document also we
have item name notebook and paper so it
will retrieve these two documents and
next we have this size so the size
basically retrieved the number of array
elements that you want in your resultant
set now the queries followed as DB dot
order DOT fine where order items is of
size 4. now if you look into three all
the three documents that are present
here we have only one such document
where it has four elements now if you
look at the first document of customer
Rahul order items we have four different
uh you know fields that is he has placed
an order on Notebook play Paper General
and postcard now in contrast if you look
at to the other two uh
documents where we have only notebook
paper and postcard for pranoff and we
have only notebook and postcard for
kirti so which is against or which does
not satisfy the size operator so it
basically retrieves only the first one
which has four elements or Fields so I
think that was all about the array
operators guys I hope you uh understood
about all the query and projection
operators and its different types now
again we have uh several many operators
like geospatiel uh comment operator and
so many but which are not that
significant in its usage but anyways if
you want us to cover uh in our further
tutorials let us know wherein will try
to cover a more uh you know detailed
version of it with a hands-on experience
with the mongodb database as well
and finally let us discuss uh what is
upgrade operator guys and basically
mongodb offers a variety of field update
operators to update the values of the
fields and documents matching the
specified condition so it is basically
similar to that of your DML command
which is an update command which is used
to used to update the values in the
columns now similarly in mongodb there
might be a possibility that you have to
update some values and that is where we
have the update field operators now
there are again various such of update
operators so let us just go in through
one by one we have first one as current
date which is used to set the value of a
field to current date either a date or a
timestamp next we have Inc which is
basically increment it is used to
increment the value of the field by the
specified amount next we have the Min
and Max which is used to update the
field if the specified value is less
than the existing field value or it is
greater than the existing field value
next we have the mul which is uh a full
form of multiply it is used to multiply
the value of the field by the specified
amount and finally we have the rename as
a name suggests this operator is used to
rename a field within a document
so that was all about the operators in
mongodb guys I think we have got most
almost all the important uh operators
that are used frequently on a general
basis I think these are quite enough for
you to perform all the complex operation
that you undertake or to retrieve
certain uh you know documents or values
in your database
now we have moved to something called
very important that is installing
mongodb on Linux this demo will show the
steps to install mongodb on Linux 64.
so what's we gonna do
this command will download the mongodb
from the internet
so this command is gonna antar the
downloaded mongodb which we have done as
you can see we can see the Ben
directory called mongodb
foreign
of the mongodb
to the bashasi file so that I can
execute mongodbend from wherever I want
it's like any one variable setting the
way we do for javafa.net in Windows we
have environment variables similarly in
Linux we have the bash RC files
so that is how the
installation will happen of
mongodb on Linux system and now we will
see how uh the mongodb gets installed on
the windows so this is something which
again I would really uh want all of you
to really focus on
it's again simple the same way as we did
in Linux
so what we do is so we have mongodb
installation going on so what I do okay
so I'm again talking about Windows and
would recommend if all of you also
follow the same so first step is
download
you will get some dot zip version
second step
or rename
it as mongodb so again I'm telling you
the
scenarios so that everyone can go along
and place it under C
place it and the C you can place it
anywhere again for better
let us keep it in the C so now I'm
assuming all of you have your mongodb
under
I'm assuming your mongodb will be over
here this will be a folder
inside this you should be able to see
bin now
and the bin should have all of the
different commands
now what I would recommend is instead of
just double click in mongodb open a
command prompt
open
a command prompt
go to
see
mongodb bin
go to this path
up till the bin and now when you are in
the bin
type
mongod
and put an enter
it means you are saying that start the
 database instance you should see
on the screen you should see on the
screen
waiting
for
connections
to open
on the port
27017
this is what you should see on the
command prompt
fifth step
open
another command prompt
go to
see mongodb
and type
 and put an enter
now what you should see in the current
your current command prompt should tell
should say
connected
to test
and your
previous command prompt
that is on the step four
should now say
one
Connection open
okay so this is what your scenario
should be so please all of you follow
these steps and what are regular
expressions in mongodb regular
expressions are used to match specific
patterns in a document it is basically
nothing but finding strings within a
document now it's possible that you
won't always know the precise field
value to search for when retrieving
documents from a collection so in order
to help with the data retrieval based on
search values that match up specific
pattern instead of the whole word or a
string regular Expressions can be used
it comes with multiple options also so
we can customize our query to check if a
field contains a string or not
now why we use regular Expressions now
there are many reasons but these are
some of the important uh factors on why
we use regular expression just like in
any other languages we use right so even
we discussed regular expressions in SQL
also in our previous tutorial so if you
haven't checked that out make sure you
uh check that out our channel on SQL
playlist now the first reason is obvious
that it provides patterns or a sequence
of characters for matching text and
Define search patterns now like I said
instead of searching the whole uh value
in a particular field you can just write
a simple pattern that you are aiming to
search for
now it retrieves any unidentified field
in a document easily as well and finally
it queries databases to find a smaller
subset of data within a collection so
instead of retrieving all the fields
again in a document you just you can
retrieve only a portion or a part of
data from that collection using the
regular expressions
now this can be achieved with the help
of the regex operator now what is regex
operator the reex operator provides
regular expression capabilities for
pattern matching strings in the queries
so in in simpler terms using this
operator one can search for the given
string in a specific collection so if
the exact field values are known that a
user is looking for in the document this
operator can turn it handy let us now
understand the syntax of the rejects
operator now we have various uh
different types of syntax uh the first
one is a generic syntax where we are
using a delimiter which is uh this index
is followed as DB dot collection name
dot file and within the parenthesis
pressure the field name that you are
using that you want to find a subset of
data or the uh you know a specific
pattern that you are searching for and
then mention the Rex keyword and then
the pattern now if you look at uh the
pattern inside the pattern I have
mentioned it delimiter so
which basically means that you can like
find any pattern of a string value let's
say if I want to find a person's name uh
who has let's say RA in their name so I
can just simply put a delimiter and
inside that I can put a put the two uh
you know strings which is r a so for
example it can match Rahul and and any
such other names uh the same way as well
so in that way you can use the Rex
operator without using any uh without
using actually uh the regex pattern next
we have another uh you know syntax of
the same regex operator which is
mentioned the field and mentioned the
Rex operator using the dollar sign and
let's say if you want to find a specific
character so we use circumflex or to the
power which is a meta character to match
a string at the beginning and we use a
dollar sign at the end to match a
particular string that ends with a
particular value and next we also have
another you know type of Syntax for uh X
operator which is field mention the
field name and the regrets keyword and
mention the pattern it can be anything
it can be a generic one where you can
use delimiters or you can even use the
circumflex or the dollar sign and apart
from that we can mention the options as
well now we have various different
options like s uh I X and F now what the
S option does is it allows the dot
character to match all the characters
including the new line characters that
you are entering in a document now we
use x as an option to ignore all white
space characters in The reacts pattern
next we have I which is used to match
both upper as well as lowercase patterns
in the string and finally we use m in
order to specifically search for the
circumflex and the dollar sign inside
the string so if these are not used
these anchors match in the strings end
or beginning now this is a bit confusion
for you guys so let us understand you'll
understand it in a more better way when
we get into the execution part so I hope
you understood what is Rex operator so
let's just start understand how reget's
operator works with a simple example
here now let's say I have a collection
let's say its name is orders and within
the orders collection I have three
different documents here of three uh
different customers like Rahul pranav
and kirti
now let's say if I want to find uh you
know the customer name who has RA in
their name now it can be at the starting
it can be middle or it can be elsewhere
or the in the end I mean so for that I'm
just using a delimiter uh and I'm
mentioning two uh string values that is
R and A so it will only match Rahul
because we have R A and similarly we
have pranav who is also having R and a
uh strings uh characters in in their
name we also have kirti but she doesn't
have R A so it doesn't match so we only
have we'll get the output of only these
two documents now similarly let's say if
I take another example wherein I am
writing another query which is DB dot
all orders dot find and I mentioned the
field name payment mode and I'm finding
for a particular string here which
starts with C A which is the payment
mode in the document should be it should
start with CA now we have payment board
as card cash and again we also have uh
card and cash are basically the two
types of cable mode so it will basically
retrieve all the three documents
so let us now understand another example
here now let's say I've written a query
which says DB dot orders fine payment
mode
uh sorry uh I think there is a mistake
here uh so let's say if the orders item
uh I'm taking the field as order item
and I mentioned the rate at c word again
and here I'm mentioning dollar okay that
means the item name in the orders item
the item name should end with ok so we
have different item names here like
notebook paper General and postcard now
only one item name which is notebook
which has okay in the ending right so
the dollar symbol basically matches the
string in the end so since it has okay
uh the two uh specific strings in the
end of the uh you know document so it
will only match the notebook so since we
have notebook in all the three documents
again we can retrieve the three uh
documents in our final output so this is
how regex operator basically works so
let us now directly jump into mongodb
shell for execution part and see how it
gets executed with some more different
examples
so as you can see uh the database DB
shell has started so let us just use the
show DBS
in order to display the uh database that
are present so we have this simply code
one which will be using again so I'm
just using simply code one
and let us now see the collections
inside this we have the employer
collection so let us just use that so in
order to find the data that is present
we will use the DB dot correction images
employee DOT sign command
so it will display all the documents
that are present
so firstly let us discuss a simple
example where we'll uh simply use the
delimiter operator in order to find
you know the first name of the employees
in our documents whose name can have l i
okay so then we're just providing a
pattern here which is Li so the query
would be DB Dot
employee dot find
open the brackets square brackets and
within the flower packets mention the
field name that is first name
and then mention the delimiter which is
this and our pattern that we are trying
to find is L I write so mention l i
and again close the brackets
and enter
so all right so we can see some of the
documents have been retrieved let's say
if you take the first document here we
have the first name Valli and his full
name is patabala so you can see we have
characters Li at the end here so
similarly if you take the next document
we have Shelley Sim again we have Li at
the end and if you take this example we
have Julia whose name has a like
characters in The between and next we
also have Williams who has Li in between
again so these are the five documents
that are received so irrespective of
whether
irrespective of the position in which
they are it basically retrieves all the
documents that has Li as a substring in
the uh document so in this way you can
use uh the reex operator also simply
without using the regex uh you know
keyword
so let us now understand another example
guys so let us say uh I'm trying to find
a specific pattern where I want to find
the first name of the employees whose
name starts with s h so in that case
what I'll do I'll write a simple query
as
dot DB dot employee dot find
open the brackets mention the field name
which is first name
and again now we'll write the regex
keyword here
since we are particularly finding a
pattern which says that the name of the
employee the first name of the employee
should start with only S and H
so mentioned the dollar symbol mention
the array X keyword
and semicolon and then within the uh
double quotes mention the words or the
pattern that you're trying to searching
for so I'm keeping it as S and H so let
us close the noted commas let us close
the flower brackets and
and finally the square brackets I think
we need to mention two flower brackets
so I think we are good to go sorry I
just execute the statement all right so
as you can see the resultant set we have
some documents being retrieved so
firstly if you look at the uh document
of this one who's the employee whose
first name is Shelly so it's starting
with SH next we also have uh employee ID
123 who's first image Shanta again
starting with SH and similarly we have
embroidery 2.5 whose first name Shelley
starting with SH again so you can use
the Rex operator in this way to only
find a particular pattern
now let us take another scenario here so
if you look at this previous example now
we are mentioning uh the pattern as
capital S and H so it is case sensitive
right so it is already displaying the
records of those employees whose uh
first name is starting with capital S
and the second letter which is small H
so let's say in in a different scenario
we want uh all the employees name whose
name is having uh let's say capital S as
well as well as Capital H so in that
case you need to use the options uh you
know command so let's say again if I am
trying to find the first name of an
employee uh whose uh first name starts
with ju so it can be capital j or small
U so in that case you'll need to use the
options and the option that we are going
to take is which is basically I
so I'm just going to uh execute this
statement so just follow it with me DB
Dot
employee Dot find
and within the square brackets
open the square brackets and the flower
brackets first name
and open the flower brackets again
mention the dollar sign
mention the regex keyword
again semicolon now the pattern that I
am searching is ju it can be anything so
we are just going for case insensitive
here now for that we have to basically
use the options command here so mention
the dollar sign
options is the keyword
and mention the column
and within the Brack uh inverted quotes
mention I
so what basically this I does is it will
retrieve all the records irrespective of
whether they are in uppercase or
lowercase so
let us just close the follow brackets
again and let us executed
so as you can see we have only uh one uh
record or one document that is being
retrieved which is of Julia Dyer now if
you look at the command that we have
taken as small J and small U but in the
resultant output the uh the the document
is that which has been retrieved is
capital J and small U so in this way you
can use the options uh you know command
you have to find all the documents
irrespective of whether they are in a
smaller case or uppercase so that was
one another scenario guys so finally let
us look into another scenario where you
want to find
you know a specific document starting
with a particular uh substring or sub or
a pattern or a value and ending with the
pro a particular value
so firstly let us take uh an example of
uh you know this document wherein will
search for the job ID which starts with
AC so in that case the following query
would be DB dot employee dot find
mention the flower brackets
so we are taking as job ID which is our
field name
mention the regex keyword again
so the pattern that we are searching for
is so circumflex you have to mention
this uh symbol which is a meta character
and the job ID should start with A and C
so it is must so this condition
basically checks for all the job IDs the
name of java IDs starting with AC
so let us just close this
and enter
all right so in the resultant output we
have two different documents present so
if you look at the first document we
have job ID as AC MGR and next to the
second job ID we have AC accountant
so this was another scenario where we
are using uh you know where we are
finding documents only uh with use with
the help of the regex operator and a
search pattern wherein we are only
finding the job ID of those employees
whose job ID name starts with AC
rogation
tends to simplify application codes and
limit resource requirements following
are the characteristics or aggregation
uses collections of documents as an
input and return results in the form of
one or more documents is based on data
processing pipelines documents passed
through multi-stage pipelines and gets
transformed into an aggregated results
the more basic pipeline state in the
aggregation framework provides filters
that functions like queries
the pipeline operations group and sort
documents by Define field
or fields the pipeline uses native
operations Within mongodb
to allow efficient data aggregation and
is the favored method for data
aggregation so mongodb also would
provide out of box support for mapreduce
as well but again that is not a
favorable or recommended approach by
mongodb to use regretation so they have
the aggregation framework which will
does most of the tasks
this example please understand what is
happening over here
there is a orders collection
and I'm running an aggregate Pipeline on
top of that the orders collection how
does it look like see on the left hand
side you have a customer ID
we have a mount
we have a status
you can see there are two customer IDs
A123
so there are three customizes a one two
three
and there is one customer idb two one
two so a tap on this first of all the
data goes through the match pipeline
the match pipeline
and what is our dollar match the dollar
match is give the status as a
that get me only those records who has
the status as a so we come to know from
looking at the orders collection that
only the first three documents will come
only the first three documents will come
in daily match and that will happen so
we have two documents from A1 to three
and one document for B one to one
after going through the data from the
match pipeline what happens the radar
goes to the group pipeline what happens
the group pipeline I'm grouping by
customer ID and I'm making an alias
called total this total is the key and
what will the total have total will have
a sum of amount and what is the amount
the amount we have a key in the
documents in the orders collection so
see what is happening is the customer ID
is grouped and the amount gets plus the
total we have 750 and again the total we
have 200 there was no irrigation
supposed to be done
so again this is very important from
mongodb's aggregation point of view the
pipeline operators and indexes so
aggregate command and mongodb functions
on a single collection and logically
passes The Collection through the
aggregation pipeline we can use with all
the match dollar limit dollars skip
stages to optimize the aggregate
operations
you may require only a subset of data
from a collection to perform an
aggregation operation therefore use the
dollar match dollar limit and dollar
skip stages to filter the documents once
they are filtered I can actually group
them up the dollar match operation scans
and selects only the matching documents
in a collection when placed at the
beginning of a pipeline placing the
dollar match pipeline stage followed by
a dollar sort stage at the beginning of
the pipeline is equivalent to a single
query with a sort and can use an index
10. Place dollar match operators at the
beginning of the pipeline if possible
because that will make all the sense
dollar matches the way query again I
want all the countries which are India
and again once I've got that I can put a
group operation on top of them to group
things up there are different stages you
know through which it passes again as I
talked about first one is the dollar
project what happens in the dollar
project it's like a view
adds new fields or removes existing
fields and the restructure each document
in the Stream It returns one output
document for each input document
provided
what the dollar match will do dollar
match is like
where filters the documents stream and
allows only matching documents to pass
into the next stage for each input
document it returns one output document
if there is a match or zero if no match
is found dollar group is like the group
by groups document based on a specified
identifier expression and applies logic
known as accumulator expression to
compute the output document
again rearranges the order of the
documents frame using specified sort
Keys provides one output document for
each and per document
so again we have some more as well again
as I told you dollar skip we'll skip the
number of documents and passes the
remaining documents without any
modifications to the pipeline
returns either zero documents for the
first in documents or one document
dollar limit what will the dollar limit
do dollar limit will pass the first n
number of documents without any
modifications of the pipeline returns
either one document for the first 10
documents or zero documents after the
first and document so again the dollar
sort the dollar escape the dollar limit
works exactly the same way how they work
in the find and then we have dollar
unwind if we have an array and we really
want to unwind every element in an array
we use a dollar unwind so that is what
deconstruct an array field in the input
documents to return a document for each
element if I have something called
Hobbies TT badminton so that won't be an
array it'll be three different elements
so different keys that is badminton TT
and volleyball so again the aggregation
example which you see over here so the
aggregation operation given below
returns all the states with total
population greater than 10 million so
that again is the same slide which you
know the the same link which I have sent
you this example is from the same
documentation page so please see in the
slide what is being shown so what I'm
doing so zip codes is a collection I'm
putting an aggregate
Pipeline on top of that I'm grouping in
on the state and what I'm saying you
group it in the state and calculate the
total population and give the sum of the
total population
so again if I remain on the first query
for some more time again be with me I'm
going slow very slow
DB dot zip code dot aggregate zip code
is the collection I put an aggregation
framework on top of that
the array starts in the
around brackets there is an array inside
the array they will come different
pipelines the first pipeline which came
is dollar group in the dollar group I
specify the ID with which I'm gonna
Group by a state and again I give the
aggregating function which is total
population is the key or Alias and I'm
telling total population will be derived
by calculating uh sum of all the
population
to reference the population I'm using
dollar pop and again I'm doing a dollar
match that get me only those states
which are having a total population of
greater than sometime Millions
so very clear this thing should become
that how this query is running so in
this operation the dollar group stage
does the following group the documents
of the ZIP code collection by the state
field calculates the total population
field for each state returns an output
document for each unique state
so the aggregation operation
given below returns usernames sorted by
the month of their joining so again what
we have over here is so db.users dot
aggregate
dollar project one join again it is
dollar month colon dollar joined
and again we have the name as dollar
underscore ID and underscore ID is zero
and again we can just sort it with the
month underscore joint so again both
examples would have cleared you how the
group by actually happens
in mongodb also if you're an aspiring
data engineer looking for online
training and graduating from the best
universities or a professional who likes
to switch careers with data engineering
by learning from the experts then try
giving a short to Simply launch
postgraduate program in data engineering
from Toyota University in collaboration
with IBM the link in the description box
and the comment section should navigate
you to the homepage where you can find
the complete overview of the program
being offered now mongodb projection
helps to return the specific fields from
the query or you can say from The
mongodb Collection Now by these
collection
documents
so as you you know mongodb is a schema
LS database which is a nosql database
and has a different structure to that of
relational database now the tables in
relational database are called as
collection rows are called columns and
we may not want all the records from the
collection but a few of them in the
resultant set so in that case we use
mongodb projection using projection
document which is used to limit the
amount or fields in the data present in
that document so in a nutshell if I
would say rejection means selecting only
then
necessary data
rather than select
in the whole of the data present in the
document now similarly as to that of
where conditional Clause that we use in
SQL because if I have a document which
has 10 fields and you need to solution
and why we use a popular nosql and open
source document oriented database which
allows for highly scalable and flexible
document structure which is faster than
relational database because of its
efficient storage and indexing
techniques and being a nosql database it
is designed to handle large amounts of
data so DB will process a lot of
unnecessary data and you want when you
want to retrieve specific information
from a large number of Records so to
overcome this problem we use projection
query now some of the reasons Now when
using projection to remove unused or any
sales the military server will have to
fetch each document into its memory and
then filter the results to return uh
actually reduce the memory usage but can
save the significant network band for
query results depending on the data
model and the fields projected in your
documents and it only returns index
query results without fetching the full
documents now which is basically the
main use case of projection which
basically eliminates all the fields that
are unnecessary for the user and
particular Fields within the document
then he can use the production area of
operator
now
by default this is return all fields and
matching documents so if all the details
returning
full dominance is going to be more
efficient having a server manipulate the
result projection however then to
reprove performance and that is one of
the main uh consideration when we are
using mongodb projection so these are
some of the reasons on why we use
mongodb projection all right let us now
understand how mongodb projection works
now in general to retrieve the data from
the uh documents we use the find method
uh which retrieves data from all the
fields within a document without any
filtering so let us now understand the
syntax of mongodb projection operator
now the syntax is followed as DB dot
collection name DOT fine and within the
hypothesis mention the field names that
is I'm taking your field one and its
corresponding value field 2 and value 2.
now
the values that I'm talking about is if
field value is as 1 which is a Boolean
expression uh which is equals to us it
will basically show the data in that
field field value is if the Boolean
expected hides the data in the field so
let us say understand this with an
example guys I the only then you will
get a clear understanding of it now I
have let's say a collection of uh
certain documents let's say the
collection name is orders and I have
three such documents here which has
various Fields like ID customer address
payment mode email order total and Order
items now if I want to display all these
documents uh what I'll do I'll basically
write a query using the find method
which is followed as DB dot orders DOT
fine so it will basically retrieve all
the documents without restricting any of
the fields that are present in our
collection
now let's say if I want only particular
CL that I want to display in my
resultant cell now let's say if I have
uh the payment mode and the order total
sealed and I want only them to display
in the resultant set without displaying
all the fields that are present in each
of the document so in that case I'll
write a query as DB dot orders DOT fine
and inside the parenthesis I'll mention
payment mode colon 1 and order total is
one now since I've set the field value
to 1 it will only retrieve those values
and similarly for order total also it
will retrieve only that particular field
value so this will basically be the
output of our resultant set that is it
will show the ID object the payment mode
of the three documents and similarly the
order total of the three documents Now
by default we have the underscore ID
which is a default value which we cannot
change it so if if at all if you want to
override and change it you can mention
it to 0 now let's say uh I'm taking the
same example here now instead of just
writing payment mode to one and order
total to one I'm adding another uh you
know constraint or I'm using I'm
projecting another field which is of ID
and I'm setting it to zero now if you've
seen a result and set we do not have the
ID field so in this way you can use
projection in order to restrict certain
fields from your resultant table set
without actually retrieving all the data
that is present in your documents so let
us now jump into shell and execute
this example and see how it is working
so as you can see uh shell has
been started now I don't want to get
into the details of all of it I will
cover in a separate tutorial where we'll
understand how to create a database and
how to create a collection in mongodb
separately guys stay tuned to the
channel for that so we'll just cover uh
how we'll Implement mongodb uh
projection with certain examples here
now the basically uh in order to
retrieve the databases that are present
in our mongodb we have to use the
command as show DBS so it will list out
all the databases that are present we
have admin config local and simply code
fund now I have already created uh this
simply code one and hindsight before
itself so that they can save a bit of
time and I've also created a collection
in that so before you see the collection
and the documents that are present in it
you have to use uh the simply code
database so for that we'll use the
simply code one as our Command so as you
can see it is saying that switch to DB
simply code now if you want to find all
The Collection that are present in
database you have to uh basically
write as
social collections so it will list out
all the collections in that now as you
can see I have a collection that is of
employee here so for example I will
consider this same collection now I have
this below collection named as employee
with uh let's say certain number of
documents in that now if I query the
collection in the shell if I write
a command to it to return all the
documents or fields from the matching
documents by default it will basically
it will return all your documents so for
that I will use a statement like
pictures of DB
dot mention the collection name that is
employee dot find so file method is used
to list out all the documents so you can
just see that we have a lot of documents
in our resultant Set uh let me just
scroll and go to the top so as you can
see we have different documents a number
of documents and it has different fields
like ID employee ID first name last name
email phone number hiring date job ID
salary manager ID Department ID and so
on so you can see we have a lot of
documents so let's just count how many
documents we have for that you can use
the count statement
so
DB dot employee dot count so you can see
we have a total of 50 documents present
in our employee collection now if you
look at our resultant set after we used
the fine method you can see it has
returned all the fields of the document
from The Collection now but what if I
want to fetch only a particular field
like let's say first name last name
email or even with salary
how will we do that now the answer is
using mongodb projection we will Project
Specific fields to return from the query
now so before proceeding to mongodb
projection guys let's recall how we
fetch certain fields from you know a
traditional SQL database so that we can
have a clear understanding now let's say
suppose The Collection employee is a
table in SQL and let's say all the
fields like employee ID first name last
name so on RX columns now I want to
fetch the only uh the let's say first
name last name
uh from the table so in that case what
we'll write will basically write this
query as select first name
last name from a table that is employed
right I hope I'm clear with this so it
is similar to that in mongodb wherein we
are executing this query as uh using
projection so let us now see how we do
projection here so let's just uh
consider as an example here now let's
say I'm writing a command as DB dot
employee dot find
and let's say if I want to fix all the
documents of all the employees whose
Department ID is 30. so in that case
what I'll do is Department
so it is says a case sensitive guy so
make sure you write in the capitals or
whatever the field is written as
so mention the column and within the
double quotes mention 30.
so close the parenthesis and close the
square brackets as well so it will
basically list out as you can see all
the documents of the employees whose
Department ID is 30. so we can see we
have employee ID of the employee 114 115
116 117 118 and 119 whose all their
department is 30.
now again even if I am returning a
particular field or a condition it is
also you know retrieving all the fields
from all the documents now I don't want
that now I want only a particular field
so what in that case we will project
certain Fields without returning all the
fields from our documents so let us see
how it works so the query is followed as
DB Dot
mention the collection name employee
find
open the square brackets
and let's say uh I want to retrieve only
the first name
first name so I'm setting it as one
as we discussed earlier if you want to
retrieve the particular field you have
to mention one and similarly I want to
mention I want to retrieve the last name
as well
last name
column and one and also let us take
another field let's say a salary
right we have salary also let us just
retrieve that as well as one
all right close the parenthesis and
close the square brackets and enter so
we do not have any output here guys that
is because we haven't mentioned the
parenthesis uh before the find method so
let me just copy paste and we'll see how
it is
so before after the find we'll have to
mention the uh parenthesis again
foreign
so as you can see in a resultant set now
since we have only mentioned the first
name last name and the salary it is only
displaying the results
only those only certain fields that is
the first name last name and salary in a
result and set now by default this ID
object is uh you know retrieved uh with
the command so if you want to eliminate
that as well you can keep the ID to zero
so let us just execute that so let me
just copy this again
paste it and mention another uh criteria
that is
the field now the field should be
the field that is of ID should be 0.
so close the parenthesis
so let us just execute this and we'll
see how it is the output so as you can
see now only we have the first name last
name and salary of all the employees so
we have just basically eliminated the
object idea as well so if you want uh
only uh the first name last name and
salary in your output you can just
mention the field names and mention one
if you want to display a resultant set
and if you want to display if you do not
want to display those certain Fields you
can mention as zero so in this way you
can use the projection query operator in
order to project only certain fields
from all the documents so yes I guess
that was all about the mongodb
projection guys uh now projection query
operator can be quite useful when you
are handling a lot of unstructured data
let's say if the database has like 10
000 or even a million records in such
case if you want to return a specific
number of fields only now a document can
have any number of fields like 10 20 30
40 and so on so in some cases if you
want to retrieve or specify only certain
number of fields in your resultant set
in that case projection operator can be
quite useful and I know it is quite
confusing at the beginning so just you
just need more practice to understand
this in a more better way
so
that brings us to the end of today's
session guys I hope you have understood
all the topics and Concepts covered in
today's session so firstly what is
starting in mongodb now sharding is a
method for Distributing a single data
across multiple databases which can then
be stored on multiple machines this
allows for large data sets to be split
into smaller chunks and stored into
multiple data nodes increasing the total
storage capacity of the system
so for example let's say I have a
database which has you know 2 million
users uh that are running on my database
frequently so the single machine has a
capacity to only uh hold two million
records in that now for instance my
business is growing and with the ever
increasing demand of data the data is
being piled up in in more uh you know
numbers now for example the 2 million
has been raised into 3 million and in
that case the operations on that
database can be quite difficult because
there is a huge traffic of data that can
be uh you know applied on that database
for in that case I can basically split
the data database into two different you
know instances where I can make two
machines or I can basically store the
data into different servers wherein I
can have two different capacities now
let's say I have divided the 2 million
to 1 million and 1 million now I further
can have a total capacity of total 4
million that is 2 million and 2 million
in each database so this is what a
sharding is based upon sharding
basically distributes the process and
stores a single data set into multiple
databases
now the purpose of any database
distribution is to enhance the
scalability of the applications uh and
sharding is an excellent way to keep the
data safe across different resources in
mongodb database shatting is an
achievable by breaking down big data
sets into simple subdivided data sets
across multiple instances now this
single database cannot handle a database
which large data sets right as it
requires large storage and bulk query
operations can use most of the CPU
Cycles which slows down the processing
of the system for six scenarios we need
more powerful system
so now one approach is to add more
capacity to single server such as adding
more memory and processing units or
adding RAM on on the single server then
it is basically known as scaling now we
can do scaling in two ways first one is
we have vertical scaling vertical
scaling basically refers to adding more
resources for example adding a new CPU
or increasing the Ram or or instead
adding a new disk size to your server
based on your demand and next you also
have horizontal scaling horizontal
scaling involves adding more and more
processing units of physical machines to
your server or databases
so it is basically used to divide a
large data set across multiple systems
and serve a data application to query
data from multiple servers this approach
is basically called as horizontal
scaling and mongodb handles horizontal
scaling through sharding thing now let
us now understand why we exactly need
mobodb starting ice now we learned that
in our previous uh tutorial about
replication wherein we learned that
replica sets gave us the ability to hold
data in multiple databases and thus
given as a certain level of fault
tolerance and data duration and however
this approach has certain limitations as
previously mentioned guys all right
operations in replication go to the
primary nodes as you can see here we
have the primary node here it is going
to the uh secondary node and all the
right operations are basically done on
this primary node and all the read
operations are basically processed to
the secondary node which makes it the uh
you know crucial thing of any system
right the this means that if the system
grows this primary node will be overused
so in that case
eventually it will be limited with
Hardware limitations like Ram number of
CPUs and disks and Etc
so in that case it it is quite difficult
you know that a database can be of
efficient way to uh you know address the
demand or process the data within the
database so that is where mongodb
sharding comes into picture
now
since it is a limitation of uh
replication that is where as I said
sharding comes into play when there is
when database must struggle to handle
more and more data and the query traffic
increases in that case you need to
distribute the data into simpler or uh
secondary multiple machines now another
reason is mongodb instance is unable to
manage right operations as I said
earlier uh the database in replication
you know you're basically copying or
duplicating the data from one uh
demography database into another in that
case it becomes difficult for one single
database to manage all the right
operations right so in that case we need
sharding
next memory cannot be outsized enough in
case your La if your data set is large
for example if the Earth the database is
working on large data large data sets in
that case memory cannot be you know over
uh settled or you can incorporate a
memory you know if the data data set is
too large
and finally which also impacts the
database maintenance also and vertical
scaling is nowadays too costly and in
that case mongodb sharding comes into
picture
so that those were some of the reasons
why we need mongodb shading so let us
now move ahead and let us understand how
mongodb sharding works now before
mongodb sharding uh the working of
mongodb sharding we need to understand
the mongodb starting architecture now
implementing the concept of sharding can
be done with the use of clusters so when
I say about clusters sharding clusters
are basically the combination of
multiple shots Mongoose processes and
configuration servers so if you look
into this image we basically have an app
server wherein we have various routers
and we have a mongodb mongoose instance
of mongodb mongos process and we also
have configuration server so config
servers which are basically the replica
sets and we have different shards where
we are basically trying to you know
breakdown uh a single huge uh database
into further uh you know shots or
simpler pieces
now this is done with the help of a
sharing key now on charting a mongodb
data set a short key is automatically
created by default the short key
basically can be in form of an indexed
field or index compound field that will
be used to distribute that data among
the charts generally The Shard key is
used to distribute mongodb collections
document across all the shots where the
key consists of a single field or
multiple fields in every document
so that brings us to the main part which
is how mongodb starting works now now
mongodb sharding works by creating a
cluster of all these mongodb instances
consisting of at least three servers
which we'll be discussing in a while so
the shared cluster or the mongodb
sharding cluster consists of three main
components which is basically shot
mongos and config servers now when I
talk about chart A Shard is basically a
single mongodb instance that holds a
subset of the sharded data charts can be
deployed as a replica set to increase
availability and provide redundancy now
the combination of multiple charts
creates a complete data set for example
if you are trying to break down or let's
say a 5tb data set which can be broken
down further
into four shots each combining of 100 GB
of data from the original data set so
that is what A Shard is all about now
next we have mongos Mongoose acts as a
query router providing a stable
interface between the application and
the sharded cluster the this mongodb
instance is responsible for routing the
client's request to the correct shot and
finally we have the config servers
configuration servers basically restore
the data and the configuration settings
for the whole cluster so if you look at
it look at this diagram we have a router
which is having a mongodb instance and
we have configuration servers wherein we
have primary secondary servers in that
and also we have shards where we are
basically dividing again into primary
and secondary so the application
communicates with the routers which is
basically the mongos about the query to
be executed now the Mongoose instance
consults the config servers to check
which chart contains the required data
set to send the query to that chart and
finally the result of this query will be
returned to the application
so you need to understand that it's
important to remember that the config
servers also work as a replica sets here
that is why we have primary and
secondary uh you know notes here as well
so this is how basically uh how mongodb
sharding works now the idea is to have
basically multiple replica sets with
multiple primaries that will divide data
and load it among themselves and each of
these replica sets is basically called A
Shard but multiple shards are not enough
to achieve the proper functionality of
this kind of system
so and that brings us to the final
component or final uh you know thing to
our session which is basically the
advantages of sharding
so in database sharding the gives a lot
of advantages now one of them is
increased storage capacity so when data
gets distributed across the shards in
the cluster each chart contains a subset
of the total data in the cluster and on
increasing the data volume the
additional shards grow which leads to
expanding the cluster storage capacity
sharding also increases the read and
write throughput in the database also
guys now in mongodb the read and write
workloads are easily distributed across
the shards in the sharded cluster it
allows each chart to process a subset of
the cluster operation so both the read
and write performance can be directly
scaled horizontally across the cluster
by increasing the short count and which
again ultimately results in high
availability of data now with an
Uncharted database an outage in one
database chart has a caliber to their
you know impact the entire application
and lose losing its functionality and
even completely stop it however with a
sharded database if there is complete
unavailability of one or more sharp
replicas only a few parts of the
application or the website which is
available to some users however the
other shots continue their operation
without any concern and finally sharding
facility facilitates horizontal scaling
now one more reason uh you know
developers love database sharding is
that it facilitates horizontal scaling
which also means scaling out your uh
databases this means it allows you to
have parallel backends and carry your
tasks simultaneously without no with no
hassle whether the focus is on writing
or reading operations scaling out can
add big advantage to enhance the
performance and also eliminate
complexities so these were some of the
main advantages of sharding guys so that
brings us to the end of today's session
now you might wonder how sharding and
replication are different from each
other so whenever you're thinking about
sharding or replication you need to
think in the context of you know the
write and the update operations that
you're performing on your database so if
you don't need to scale right or write
processes then applique then replication
as it's fairly simple is a good choice
for you on the other hand let's say you
know if your workload is mostly on right
operation uh most of the times then at
some point you'll hit a uh you know a
right operation that is compulsory
needed for you in any case right so if
write request comes
um comes then basically blocks
other right request right so these are
all the right request blocks until the
first request will be done so if you
want to scale this right operations and
want to paralyze then in your in in such
case you need to implement sharding
so
for if you want to know further about
the replication process we have a
dedicated video on our channel so you
make sure to check them out uh check
that on on our Channel we'll leave the
link in the description we didn't get
idea on how replication is different
from shading as well what are
relationships in mongodb the mongodb
relationships are the representation on
how different documents present in a
collection are collected logically to
each other database our TV relationships
helps in various different factors right
for example it relationships enforce
data integrated in religion and
databases and it also establishes
between documents which can help refine
the database structure as per your
requirement now we know that mongodb is
a low SQL database and has a lot of
unstructured data so in order to
properly confine all the documents into
a proper format and refining them into a
proper structure is quite beneficial not
just in terms of saving the data but it
also affects the performance and makes
execution time also shorter and finally
it basically links important entities in
the database so that is what
relationship and mongodb is now there
are different types of normative
relationship here guys we have embedded
and reference method so data
relationship can be achieved through
these methods wherein embedded documents
a relationship between data is by
storing related data into a single
document structure now let's say if I
have a collection I'll have two
different documents now as the word
suggests which is embedded I am
basically storing these two different
documents into a single document
structure which is known as embedded a
document relationship and similarly we
have a document reference method or
simply reference method which is used to
store the relationship between data by
including any links or references from
one document to another
now we will understand this with an
example here now if you consider this
embedded model uh you know collection
which I have here let's say I have uh
you know a details of a person whose
name is Prada whose ID is double one
eight zero two five his contact details
are there his phone number is email
address now this is basically one
document right now similarly I have
another document valid I'm having his
great details that is his subject which
is cs203 underscore that is the grade
that they have achieved is B now instead
of having two different uh documents in
the collection and basically merging
them that is I'm embedding both of these
into a single document so this is what
embedded model does it basically
combines two or two uh documents into a
single document structure
and similarly I have reference model the
reference model basically links two or
more documents right now let's say I
have again a student collection here
which is uh of Rohan whose uh contact
details his email ID phone number and
grade MP displayed here so let's say I
have
uh let's open a collection
uh in that I have three different
documents which is student contact
details and grade now instead of having
three separate uh model the three
separate documents I can simply combine
these or I can link uh with the help of
user ID I can basically come by the
contact details as well as the grade
into a single document so this is how
reference model works that is by
referencing or linking to our Word
documents into a single document
structure so that was all about
reference model and that is main
difference between Emirate and resonance
well we have these two embedded and
document reference relationships and
these can be achieved by three different
methods that is we can have one-to-one
relationship one to many relationships
and in document reference relationship
can be achieved through many too many
relationships now let us now understand
what exactly these are all right so
one-to-one relationship basically if you
have any one field it can only have one
value in such case it will consider as
one to one relationship between any data
that is present in the document and if
you consider one to many otherwise the
name suggests one two very so when one
field has multiple relationship between
the data in between documents that is
stored in the collection of a database
in that case in such case one to many
relationship model can be used
and similarly we have many too many now
let's say I have uh
you know three uh different you know
document structures wherein I have two
or more entities within a document and
having let's say a array of uh details
present in a single uh collection or in
a document so it can have multiple
relationships right so in in that case
we need to use many too many I hope this
is clearly understood uh we'll get into
detail by uh each of them we will
consider each of the relationship model
and understand how it is different from
each other with an example now
so firstly we have the one-to-one
relationship guys now whatever
relationships are created by linking two
documents from different collection
using a shared key that is sharing the
object ID of one collection to the other
uh which is a property of the same value
now also the best way to create this
relationship is to have the child
collection query which is the key value
of the first collection now object IDs
which basically are created by default
in memory are commonly used to make this
connection although it can be of any
other type now let's say I have another
example here which says that I have a
user's collection which has ID by
default name John and age is 40. and I
have address collection as well which
has ID which is by default again and the
address details like street name master
street number I'm having 14 21.0 city as
neuron now what what one-to-one
relationship does is it links to
different documents right so in order to
combine these these two I need a a
common property or a common key that is
done by using the object ID here so if
you look at the result the resultant set
of the document has been combinedly
showcasing the details of the user as
well as its address so you can clearly
see that we have the object ID the
details first here next we have the name
John 840 address again in address we are
basically documenting or adding the data
of the address in the same document
itself so this is one-to-one
relationship
let us now move ahead and understand
what is one two very relationship
so what do many relationship is another
relational model we use which is created
by linking a document in one collection
to multiple documents in other
collection so let's say I have a
without an example of a collection here
now this is basically a widely used
error to increase is to use increasingly
and you know where there are more array
values within a table so in such case
you can you can use one to very
relationship now for example I have a
authors collection which says uh the
name of the author is JK Rowling and we
have two different books and for that we
have object IDs as well so in other
collection we have the details of the
books now clearly which is ID again a
name of the book is philosopher stone
and next we have another book collection
uh the data that is of chambers of
secret now in order to combine this now
one to many is basically with the
reference of author collection are
basically collecting uh you know two
different book collection into a single
document so we have multiple documents
in the books collection right and we
have a single author collection now I'm
basically clocking these two are
creating a link between these two
collection and I'm creating a single
document so if you look at the result
resultant set I have the name of the
author that is JK Rowling and the books
are there IDs and the details of their
books that is the name that is
Philosopher's Stone and Chambers of
secret so in this way you can also use
one to many relationship model in order
to properly structure your data based on
the requirement
and similarly we also have many too many
relationship here guys but I'm not going
to discuss it let us know in the comment
section below uh and let us know what
can be a good example of buried to many
relationships and that brings us to the
end of today's session guys now while
embedded a data type eminent document
model is ideal for one to one and one to
manage relationship and referenced uh
data document model is ideal for many to
many relationship now
denormalization which is embedded
whereas normalization is the name given
the reference relationships now
establishing a good relationship between
documents can Aid in the refinement of
the database structure as we discussed
earlier which can overall impact uh can
impact the overall performance of the
database
reduce the execution time in the
database as well
we also need to store files in our
databases right but mongodb is one such
database that doesn't let you store any
file larger than 16 MB in a normal
document instead mongodb has a
functionality specifically for storing
large files and it goes by the name grid
FS well you heard it right Momo DB
becomes much more efficient when
combined with grid FS it divides a
document into parts or basically we call
them as chunks that are then stored as a
separate documents so in a nutshell grid
FS is a kind of file system used to
store files in a smaller segments on
that note hey everyone welcome to Simply
quotes YouTube channel I hope you guys
are doing good and staying safe in
today's session we'll be discussing
about grid Fs in mongodb how it is used
what is its significance and how to uh
you know add documents in smaller
segments or in chunks by using grid FS
method so without any further Ado let's
get started with today's topic but
before we begin if you're new to the
channel and have and subscribed already
consider getting subscribed to our
Channel simply code to stay updated with
all the latest tech content and hit that
Bell icon to never miss an update from
us
all right so what is grid Fs in mongodb
Grid FS is one of the powerful
specifications of mongodb that helps to
store and retrieve large-scale files so
it is a specification for storing and
receiving files larger than 16 MB limit
of based on documents now these files
can be structured or unstructured and
they include documents audio files
images recorded video clips binary files
Etc now gridface is similar to a file
system for the storage of files but
mongodb collections are used for storage
of data and files using grid refers
which has powerful features to store the
files of any format including files that
are even more than 16 MB in size So In
classical implementation there is a file
storage system of 16 MB but mongodb
gridfs can store and retrieve files
Beyond this limit too
now mongodb grid Affairs features allow
for the storage of large files as we
discussed earlier so in order to store
very large files it is not necessary to
load the entire file into RAM instead
chunks of the files are streamed to the
database so these files can be again of
any format it can be an audio pdf movie
and then they are converted into smaller
chunks and they are streamed into the
database so each chunk is limited to 255
KB in size this means that the last
chunk is normally either equal to or
less than 255 KB so it is the checks are
partitioned into smaller 255 KB files
and when you read from grade FS the
driver reassembles all the chunks as per
the user's requirement when they are
needed this means that you can read
sections of a file as per your query
range such as let's say listening to a
segment of an audio file audio trying to
fetching a particular section of an
image file now because as discussed
earlier files are separated into smaller
parts it is easier to access you know
specific areas of a file which saves
memory tasks such as loading the whole
file
now let us now understand why we use
grid Fs in mongodp
foreign
so as discussed earlier in mongodb we
use great FS for storing files which is
which are having you know size larger
than 16 MB so in some situations storing
large files may be more efficient in a
mongodb database than on a system level
file system and that is a reason we have
uh some reasons right a particular you
know significance of using grid refers
one such reason is if your file system
limits the number of files in the
current directory in the database
you can use grid FS to store as many as
files that are needed now the second
reason is when you want to access
information from portions of large files
without having to load the files into
the memory that is without calling the
whole uh you know data into the ram you
can use grid FS to recall sections only
of particular uh you know specific
sections of files without reading the
entire file into the memory and finally
if you want to store and sync files and
meta data across distributed system so
when you want to keep your files and the
data automatically synced and deployed
across a number of systems and
Facilities you can basically use grid FS
so mongodb can distribute files and
their metadata automatically to a number
of mongodb instances in the database
so these are some of the reasons on why
we use data grade FSN mongodb
so let us now move ahead and
and understand how exactly you know
grade FX Works in mongodb now grid FS
stores files into two collection now
these two collections are basically
known as chunks and files chunks
basically stores the binary chunks and
whereas the file store the files
metadata so if you look at this diagram
which we have uh in our presentation
that you are looking at we have let's
say a large file it can be an audio it
can be a video file or anything and
let's say we have we are dividing we are
using grid Fs in order to uh you know
convert into a chunk of files now when
you are basically converting into a
chunk of file it basically converts into
file metadata and the smaller segments
of data which we call as chunks so we
have fs.files collection
fs.chunks collection so basically gridfx
stores files in two collections right
now
it places the collection in a common
bucket so you can see we have FS bucket
which comprises of FS dot files and Fs
dot collection so it places the
collection in a common bucket by
prefixing each with the bucket name so
by default grade FS uses to collection
as you can see which is fs.files and Fs
dot collection you can choose a
different bucket name as well as create
multiple buckets in a single database
now the full collection name which
includes a bucket name is subjected to
your requirement and your and the need
of the uh
file that you're working on
so let us now understand what is grid FS
chunks collection now the each document
in the check collection represents a
distinct chunk of a file which is a a
smaller segment of the initial or the
original file
which represents a distinct chunk of a
file as represented in Grid FX so the
syntax office I wouldn't say it is uh it
has a syntax uh the basically it stores
the data in a format of ID files ID in
and data so basically a document from
the chunk collection contains these
following Fields now the chunk ID it is
basically the unique object ID of the
chunk now just like how when we store a
data it automatically creates a default
ID number mongodb database similar for
grade FS also we have an ID that is
being automatically generated next we
have the chunks.files ID now this is
basically the ID of the parent document
as specified in the files document next
we have in now chunks.n basically is a
sequence number of the chunk that is
being you know stored into the
collection now grid FS numbers have
chunk numbers starting with 0 and so on
and finally we have 10 dot data it is
basically
we know the data that it gives a
different serial number to the data that
we have inserted into our based on
document
next we have the grid FS chunks
collection
foreign
there's a mistake we have next grade FS
files collection right now we have
discussed what is you know chunk
collection now next we have the files
collection now each document in the file
correct represents a file in a grid
refers and similarly just like the chunk
collection we also have you know a
format and different fields uh you know
when we try to store uh collection grid
FS you know collections in our database
so some of the fields that are we that
are present in the collection are ID
length chunk size uploaded file name
content type aliases and metadata so
documents in the file collection contain
uh these following Fields now for
example the ID again it is the unique
identifier for this document and the ID
of the data type chooses for the
original document next we have the
length which is basically the size of
the document in bytes next we have the
chunk size which is basically the size
of each Chunk in bytes now basically
grade FS divides the document into chunk
size of uh you know as discussed earlier
it is default 255 KB each next we also
have upload date which is the date the
document was first taught by the grid
refers and next we have the content type
it is basically uh the type of you know
file that you're basically adding to uh
you know database to store information
related to the type of data phase files
and we also have optional uh field like
La asses and we also finally have
metadata which is an optional field
which may be of any data type and can
hold any additional information you want
to store
so I hope you understood what is grid
Affairs and what how it actually
performs what are chunks and how it is
dividing into sub you know segments like
you know chunks and files so let us now
get you to the direct execution part and
see how it gets executed
now now other than the theory of what uh
you know grade fsues it is also
important to understand how we can use
grid FS to store large files and we have
to uh remember that as the syntax is an
important aspect of executing the
greater facility mongodb so the one
thing that you have to remember is uh in
order to query or to insert a file into
grid FS it is not executed through
mongodb shell guys but it instead of uh
you can use you know windows or Linux or
Mac command prompt now before doing that
also you need to basically download some
you know mongodb database tools which
I'll be showing now so if you are using
Windows just uh go to Google and type
mongodb
database tools
all right
now when you scroll down a bit you'll
have this you know download mongodb
command line database tools click on
that
now after clicking that you will be you
know redirected to another page which is
basically the mongodb database tool
documentation which will basically show
everything about uh you know various
database tools that are available so on
the left side you can see various
database tools like mongodum store
based on Dom Bongo import export and so
on now we are concerned with files
which is the database tool which we're
going to use in order to store you know
data through uh you know greater fills
so just click on that and if you want to
just go and understand what files
is you can just read it a bit uh so just
click on installation here it will
redirect to the installation page now
you have three options for Linux Mac OS
Windows click on installing the database
tools on Windows
and uh
so it will basically tell you what all
to do here installation process it can
be installed with an MSI installer or
download as a zip archive select the
Tableau depending on a design
installation method so we'll be
basically using the MSI installer only
so open the mobile DB download Center
here
so I've already downloaded it on my
system so I'm just basically showing you
again what uh on how you can install
this click on download it's basically it
shows the version again just install the
latest version platform as Windows and
the package is a zip folder click on
download it will take some time based
upon your you know internet speed it
will just take some time so wait for it
now once you are done just extract the
file
now as you can see we have a folder
which is a mongodb database tools and
inside that you have a folder named bin
open on that now as you can see we have
the list of all databases that we have
we're not downloaded successfully now we
are only concerned with mongodb files
right so just copy paste this and now
what you have to do is go to the C drive
where mongodb is installed it is
basically in program files click on
program files search for mongodb
click on server 6.0 and you will find
the bin folder click on that and just
basically paste the whole folder or the
 files here so as you can see I've
already paid uh you know copy pasted the
same in my uh Bin folder here so just
click on that and again you'll be
redirected to bin here click on that
again so you can see we have the list of
all the uh database tools that we have
installed it on our system so this is
basically the location where you have to
uh you know copy uh the entire file so
otherwise it will throw an error right
so we have mongod file
successfully installed here let us now
uh try to understand how to insert a
file you know with a simple example so
you can see I have you know a PNG file
which is an image which is uh document
one we also have a video file which is
mp4 file which is mongodb replication it
says right so let us now uh try to
insert into uh
a database for that just click on write
right click in the same folder you will
find open in terminal click on that
so it will open the windows partial
this is where you have to write the
command prompt line all right so the
above syntax the syntax that you have to
write for this is basically by using the
put keyword which I'll be showing you
now
so we'll be just experimenting with one
simple example that F10 with a simple
image file that we are going to insert
now uh as you can see we don't have any
specific collection for grid FS files
but as we know mongodb has this feature
of creating new collection when we
insert a document into a non-existing
collection so the following query for
inserting a file in Grid FS unlike the
insert operation where we'll insert file
through shell right here we'll use
the again the window partial terminal
now the query to insert uh data into our
database is mention the files
 files is the keyword and after
that put mention the file name now the
file name that we have taken is document
one right so mention document one dot
and this file type which is of jpg
so the above carries basically this
query is a standard format for inserting
any file into great effects We have
basically navigate the terminal to the
location where files which is a
database Tool uh is being saved so our
query begins with the keyword which is
 files followed by the storage
option which is put keyword and it
specifies the database where the file is
to be stored and here our database name
is name is generally named as grid FS
only and at the moment we don't have any
database with such name but it will be
created so let's just execute click on
enter
all right it is throwing an error
so as you can see it says we have an
error here it says the command
phase was not found but does exist in
the current location Windows partial
does not load commands from the current
location
instead type okay now instead of typing
 files let's just copy this and see
if it is working or not
Monger files again mention the keyword
put
and mention the document also
I mean the document name that we are
trying to insert which is document1 dot
jpg
all right let us now click on enter
I hope it should work now
sure
so I'm not sure why it is uh throwing an
error guys so let's just take another
example we also have mongodb one which
is I can a JPG file let us try to add
that
now basically if you want to insert data
you have to store the files in this bin
folder only otherwise it will throw an
error so make sure you keep an eye on
this because uh you know adding huge
amounts of data can take a lot of time
so if you are trying to insert data
which is not specifically in this folder
then it will basically throw an error so
make sure you keep an uh an eye on that
so let's just uh try to add another
folder
so another file
dot uh so the keyword is dot under slash
 files put the file name is mongodb
one dot jpg and semicolon
so I'll click on enter well all right as
you can see in the status it is
connected to mongodb localhost and it
has added grid file mongodb one and I
think it is successful now so let's just
go to uh you know mongodb shell now and
let us see whether or not it is created
so just
let's just go to uh let's open mongodb
shell
so as you can see the shell has started
so now in order to find uh whether or
not the grid FS file is created or not
you have to use the
db.fs.chunks.find command so we can see
all the chunks present in the FX
collection uh by using this command so
let's just try to find it so the command
is DB dot FS Dot
files dot find
so click on that so as you can see it is
retrieving the ID Len chunk size upload
date file name and the metadata which we
have discussed in the earlier I know in
the presentation slide on what are the
different fields that we get so we can
also see uh the chunks present in the
fs.collection related to the stored file
with the following code using the
document ID in this which is this this
object ID right so I'm going to use this
and try to find how many number of
chunks that it has created for this
mongodb1.jpg file so the command the
query is db.fs dot chunks dot find
and inside that open the flower packets
and mention the files ID field
or whichever which you are trying to
find
okay mentioned colon
and mention this uh you know
object array that has created which is
639 and so on this I just copy paste
that and copy it here
and mentioned make sure it is on single
quotes
all right let us just close the brackets
and the flower brackets as well
okay there is an error sorry I just put
another square bracket
so I'm not sure why it is showing but uh
in in most of the cases the query will
return the number of documents that is
the whole uh you know mongodb one.jpg
file was divided into how many chunks of
data like for example 20 30 and so on so
in this way you can use grid FS to store
large amounts of files which are more
than 16 MB in size in your mongodb
database now just to cross verify uh go
to mongodb Compass and see how the data
in the uh database has been created so
you can see mongodb Compass we have a
test database that is created and we
have the fs dot chunks Dot and Fs dot
files which basically stores the
appropriate information of the uh date
the data that we have created in our
database right so you can see in FS dot
chunks we have ID files ID and 0 which
basically uh you know stores the data in
sequential manner like starting from 0 1
2 3 and so on and next in FS dot files
we also have ID length chunk size upload
date file name and metadata
so that was pretty much all about great
FSN uh mongodb I guess we have covered
almost all the concepts now grid FS is
basically a gift for developers who
wants to store huge files in mongodb so
if you are someone who is trying to uh
you know store data of audio files image
files or videos files features of more
than 16 MB which is the threshold value
of mongodb which is acceptable rate on
upper which only you can use grid
efforts so in that case grid FS storage
system allows developers to store big
files and retrieve only certain amount
of those files whenever needed and as a
result grid FS is an outstanding mongodb
features that can be used with variety
of application which makes it an
extremely useful tool for modern
applications like a nosql database like
mongodb let us understand what is
mongodb mapreduce mapreduce function is
widely used to access large data set
into a handful of aggregated results and
mapreduce command is used to execute
this function now as a result of this
the data is independently mapped and
reduced in different spaces before being
combined in the function and saved to
the specified new collection this map
reduce function was designed to work
with large data sets only you can
perform aggregation operations like Max
sum and average
on data using map reduce which is
similar to that of group by nsql so it
works independently and in parallel with
data aggregation
now let us understand what are the key
parameters in mapreduce mongodb provides
a mapreduce feature for aggregation
purpose now generally there are two
phases of map reduce in the first phase
each document is processed and emits
common and redundant part of the
document to pass a unique record for the
next phase which is the map function
next we have the reduce function in the
second phase all the unique paths get
together and aggregate to produce a
single result and finally we have the
query in this we'll pass the query to
filter the result set so with the help
of mapreduce user can perform like
sorting filtering and document
modification
so let us now understand the syntax of
mapreduce
foreign
this is mention the keyword function and
again open the square flower brackets
and mention the keyword Emit and as we
already discussed that mapreduce works
on the key value pair so mentioned the
key as well as the value that you want
to uh you know perform aggregation on
the data and then we have function again
we have to mention the key and values
this is basically the reduce operation
this is the reduce function we are going
to perform here and then mention the
return keyword and the reduce function
that you are going to perform it can be
you know any aggregation uh you know uh
processing it can be average sum or
maximum and inside that we have uh
certain keywords like out query sort and
limit so basically if I look if you look
at the first part here the collection
name it is basically defined as the
retrieved documents from The Collection
by using the map reduce command so we
can process large volumes of data using
this map reduce method in mongodb so
next we have the map reduce keyword it
is basically a data processing technique
which is used for large data and useful
aggregated results of large data in
mongodb and next we have this first part
is the map function guys and next we
have the reduce function in this you
will get a clear-cut idea on when we get
to the execution part so just have an
idea on what exactly we are doing here
so next we have the out keyword here out
is basically specifies that that result
location of the map reduce operation in
mongodb and we can set output as a
primary member and on the second
remember we can only set an you know
output for this next we have query query
defines the as the selection of
selection criteria of a document in
mongodb
so you are basically telling uh the uh
you know operation basically on the you
are filtering the data on which you want
to perform aggregation and next we have
an optional uh you know commands like
sort and limit as you know sort is used
to sort the documents from collection
this option is mainly useful for
optimization and also next we have limit
limit is a specified method that limits
the total number of documents in the
resulted output so I hope you understood
the basic syntax of map reduce model
so let us now go ahead and understand
how does mongodb map reduce works now
every input document in the map reduce
operation gets the map phase treatment
from mongodb that is documents in the
collection that match the query
condition so key value pairs are output
by the mapping function now this map
function is used to group all the data
based on the key value and next we have
the reduce function reduce function is
used to perform operations on the map
data so that data independently is
mapped and reduced in different spaces
and then combined together in the
function and the result will save to the
specified new collection so the reduce
phase which gathers and condenses the
aggregated data is used by mongodb for
keys that have multiple values and the
outcomes
are then kept by mongodb in a collection
so in a nutshell if I have to tell that
basically you have to mention the
mapping function first you have to
Define mapping function next you have to
define the reduce function to further
condense or process the aggregation
result now the output of the reduction
reduce function could opt optionally go
through a finalize uh you know function
wherein you are performing the complete
you know map reduce function
so let us just understand this with a
simple example here
so let's say I have certain collections
uh named as orders as you can see on the
left side we have four different orders
having customer ID amount status so we
have uh let's say I think we have two
different uh unique customer IDs which
is A123 and b212 now I'm basically
querying this based on the status that
is a and
d right so it is querying and it is
filtering the records based on this so
you can see A123
amount 500 status a next we have again
which is A123 amount 250 which is status
a again
and we also have A123 but the status is
D so it is not considering into the into
a resultant equation and also we have
this b212 which amounts 200 and the
status is a so the query is basically
filtering the resultant set in our
output next we are basically mapping the
function we are mapping based on the
customer ID here so we have two
different uh customer IDs which is A123
and b212 so we are and then we are
performing the reduce function based on
the amount right so it is
reducing the value into uh A1 to 3 and b
2 1 2 2 values that is 500 and 250 for B
to 12 it's only 200. so finally if we
look at the output we are performing a
sum aggregation here and you can see in
the final resultant output are uh you
know uh document which we have saved in
a new collection is being retrieved as
ID A123 value is 750 that is 500 plus
250 and also b212 which is value 200
which are which are saving in a new
collection name order totals so this is
how exactly map reduce work which is
again a similar to that of aggregation
you know pipeline method uh I'll let you
know what exactly uh you know how map
reduces different from aggregation
Pipeline and when you should be using
which method now before going to uh into
that let us go into the execution part
and see how a mapreduce Works in mongodb
Shell
so as you can see mongodb shell has
started so firstly let us
see the databases for that I'm using the
show DPS command so again we'll be using
the CMR simply code database so use
and click code one
and let us now see what are the
collections present of this database so
it will list all the different
collections present to this uh I mean
documents that are present in this
collection so we'll be using uh marks uh
you know collection for this uh to
perform map reduce so let me just uh
retrieve the values that are present in
this so DB dot marks dot find
enter it will retrieve all the records
so as you can see we have uh various
Fields like ID name subject and marks so
we have like id101 name Ravi match 94
and similarly we have different subjects
like Science History maths uh English
and so on so we'll be performing map
reduce on this collection and see how it
how it exactly
now what we're going to do is we have to
apply a map reduce operation to this Max
collection to group them by uh let's say
subject and then add the marks code in
each subject so to process this each
input document we have to define the map
function first this map function
basically refers to the document that
the map it is Operation is processing in
that function and for each document the
function Maps the marks field to the
subject and outputs the marks and the
both subject and marks together so let
us understand how to write the how to
define the map function first and the
query is written as where and mention
any keyword here it can be map here or
you can even keep it as mapping function
mapping function one you can Define as
per your own choice equals to mention
the function keyword
close the square brackets open Square
flower brackets and mention the keyword
emit
and in that we have to write the
function which is used with this dot so
we are performing aggregation on subject
and marks right so we have to mention
these two parameters here so mention
subject comma this dot marks close the
square brackets flower brackets and
mention the semicolon and press enter
all right we have now defined the
mapping from function first so next we
have to uh Define the reduce function so
the reduce function uh syntax is also
similar mentioned where again mentioned
the uh param I mean the function name as
per your own choice I'm just taking here
it is reduce
equals to
mention the function keyword again
and you have to pass two parameters here
since you have passed subjective marks
for our you know aggregation function so
just pass any two values it can be of
any name it can you can take it as key
and value or you can even use subject or
mugs so I'm just using the subject and
marks again here subject comma
marks
and mention the open flower brackets and
you have to return this parameter right
you have to return this function now I
want to perform let's say uh the
aggregation operation like let's say sum
so I'll write array Dot since it is uh
a document and we have various Fields
I'm just writing the array here array
dot sum and inside that mention the
parameter which you are performing are
the summation which is basically marks
right so just close the brackets and
closer for our brackets as well and
enter all right now we have also defined
the radius function now we are left with
only map reduce operation right so let
us now perform the map radius operation
so the Sim Lacs for that is DP dot
mention the collection name that is
marks which we have taken mention the
map reduce keyword make sure that R in
reduces in capital letters otherwise it
will throw an error and in that pass the
uh both mapping and reduce function
names that you have taken so we have
taken it as map
comma
red use so it can be any name that you
have chosen it can be like mapping
function one or as I've said earlier it
can be any name but make sure you're
passing the same value that you have
taken and mentioned the comma again
and in the flower brackets now we have
to mention the keyword out as we
discussed in our syntax previously now
we can give any uh you know collection
name you know to your output resultant
set it can be of any choice so I'm just
naming it as the result here
I think it will be good to go so let me
just execute the statement
all right uh
it is throwing an error
collection not map reduces deprecated
user aggregation instead okay I'm not
sure why it is uh showing that but we
can say result it is saying okay one
that means it has been successfully
executed so let us now and uh see
whether whether or not the aggregation
function that is summation has been
performed or data set or not
so for that I'm again using the find
command DB dot mention the uh collection
name that you have mentioned inside the
parameter and map reduce operation DB
dot result Dot
find enter
as you can see we have total four
subjects and the summation values are
showing as 93.96 I'm not sure why it
should perform the summation operation
so let's just check for history we have
93 and first again 96 all right so it is
showing simultaneously I mean side by
side it shouldn't be like that I'm not
sure why it is showing in this way
so let's just uh try to perform another
operation and see whether it is
showing for them as well I'm just
performing an average uh you know
operation here
all right let me just check okay we have
that password and let me just uh perform
the map reduce function as well
just copy paste this and you can
just change the name as result one okay
and click enter I think it's created so
let us find again DB Dot
uh which is again Result One Dot find
well I think there is some issue with
the back end of the mongodb database I'm
not sure why it is uh throwing an error
like this because average value should
be like uh this average of 40 let's say
93 96 right 49 and 47 it's showing in a
different way for maths it's 98 so it's
average it's 49 and for uh 94 it's 47
and the combined value we have to get
but I'm not sure why it is uh throwing
that error
so we'll get back to you guys uh but the
syntax and the execution is uh the same
you I think there is no mistake in the
uh syntax that you have written here it
is same there might be some issue with
the back end so we'll just get back to
you uh again so stay tuned for that
and well I think that's all about map
reduce we have discussed almost
everything uh you know what map reduces
it's syntax how it works and how uh you
know how it is used you know instead of
aggregation
foreign
and that brings us to the main question
on you know which method you have to be
using whether it's aggregation pipeline
method or it is mapreduce you know
function now complex queries are
difficult to handle in aggregation
framework it can be useful but I would
say it is not recommended for complex
queries whereas if you take small data
sets small data sets will take a long
time to load and map reduce and even
large data sets will take the same
amount of time to process now whether or
not the data set is small or large it
will take the same amount of time to
execute so as a result large data sets
should be handled using the map reduce
functions always and it is a recommended
option the map reduce function can
handle you know large data sets more
quickly due to its uh maybe it's its
flexibility over you know large data
sets so you can always use this uh while
you're you know handling large volumes
of data and on the other side you can
use the aggregation pipeline to handle
small data sets you know for a regular
usage when you're performing small
calculations that is present in your you
know documents that is present in your
collections I would say so this is how
uh both aggregation and mapreduce are
different from each other and when you
have to use them and I hope you
understood that as well also if you're
an aspiring data engineer looking for
online training and graduating from the
best universities or a professional who
likes to switch careers with data
engineering by learning from the experts
then try giving a shot to Simply last
postgraduate program in data engineering
from Toyota University in collaboration
with IBM the link in the description box
and the comment section should navigate
you to the home page where you can find
the complete overview of the program
being offered
so let me start with this
I told you that
the mass gave way to something called
replica sets so the Master Slave
replication is the oldest mode of
replication that mongodb supports in the
earlier versions of mongodb the master
slaver application was used for failover
backup and the reach scaling in the new
volumes it is replaced by replica sets
for the most number of use cases here
you can see there is a master and there
are slaves attached to that so replica
sets are recommended for new production
deployments to replicate data in a
faster than a Master Slave
architecture
so again how does a replicas in mongodb
works so a replica set consists of a
group of mongod instances that we just
saw that holds the same data set that
again we have saw the replica set
functions as follow
the primary mongodb receives all the
right operations and the secondary
mongod replicates operations from the
primary there's something that Sandeep
would have seen in a live working on his
replica set the primary node receives
the right operations from the client the
primary logs any changes or updates to
data sets in its AppLock
the secondary is replicate the op log of
the primary and apply all the operations
to the area sets
so replica set in mongodb
an extra mongod instance can be added to
a replica set to act as an Arbiter so
what is an Arbiter node so this is
specifically added to the replica set so
that you know the total number of uh
instances we can have a can be odd so
that if in case if the primary goes down
we can have a majority if an election
takes place so following are some of the
characteristics of an Arbiter so
Arbiters do not maintain a data set
Orbiter is the node we just participate
in an election to select the primary
node so the only purpose of it is to
take part in the election it doesn't
even store the data so again orbitals do
not require radicated Hardware again it
can just work as a command prompt you
know as we have done in our systems
secondary members in a replica set or
synchronously apply operations from the
primary important point to be noted over
here is Earth synchronously it's a lazy
right
these replica sets can function without
some secondary members as a result all
skin remembers may not return the
updated data to the clients so again
when I told Sandeep that you know you
make a right to the primary or an update
to the primary and see the data back in
the secondary so you guys would have
seen again that you know you are not
able to see the data over there in the
secondary it'll come after sometime
because again it's a lazy right to the
secondary
so a primary can convert to a secondary
or vice versa however an Arbiter remains
changed
automatic failover so there is something
which talks about the replication in
detail and what it talks about is when
the primary node of a replica effect
stops communicating with other members
for more than 10 seconds another member
is selected as the new primary
selection happens through an election
process the secondary node that gets
majority of the votes becomes the
primary a replica set supports
application needs in the following ways
again deploying a replica set in
multiple data centers
manipulating primary election by
adjusting the priority of the members so
that's what again when we initiate an
instance I can also when I specify the
config I specify the config again ID the
members along with that they can specify
the priority as well that you know if
the priority of the guy will be more I
can ensure that whether the secondary
will be able to become a primary ever or
not
supporting dedicated members for
functions such as reporting Disaster
Recovery or backup so again we can see
uh in the diagram that another primary
goes down what happens is election for a
new primary happens and again we see
that you know the new primary is elected
one of the secondary becomes the primary
and the other secondary just follows
what the primary shares
again the application members a replica
effect can also have Arbiter Arbiters do
not replicate or store data but again
play a crucial role in selecting a
secondary
to take the place of a primary when the
primary becomes unavailable a typical
replica set contains a primary secondary
and an Orbiter so again what we see is
we have a primary node we have a
secondary node and we have an Arbiter
and you can see there is a heartbeat
going constantly between all the nodes
again this heartbeat is on similar lines
you know what the heartbeat we see in
Hadoop in Hadoop we see all the
secondaries that is the data nodes you
know
share a heartbeat with the name node so
again like this all the nodes over here
in mongodb as well
share a heartbeat among themselves
an application in mongodb version 3.0
can have maximum 50 members with only
seven members capable of voting in the
election
so okay now we are specifically talking
about who are priority zero replication
members again when we set a member a
priority of zero what will happen that
will become a that will be a secondary
which can never become a primary so
again a priority zero member is a
secondary member that cannot become the
primary the characteristics of a
priority zero are it cannot trigger any
election
it can maintain data set copies except
and perform read operations and again
choose in electing a primary so again he
can vote an election though he cannot
trigger an election
so by configuring a priorities you
remember you can prevent secondaries
from becoming the primary in a
three-member replica set
one data center hosts both the primary
and the secondary and a second Data
Center host one priority zero member so
again you know I've just script one copy
of the data in some other data center
just to ensure if the full data center
goes off I still have some data with me
safe in some other Data Center
a priority zero member acts as a backup
and can immediately replace an
unavailable member in a replica set
because again it has the data so always
we recommend that you know we have a
priority zero uh a replica set member as
well in our replica set
now we have something called hidden
replicaset members again hidden members
of those which are not you know seen to
the client what again that means hidden
members of a replica set are invisible
to the client applications the
characteristics of a hidden member are
they store a copy of the primary's data
their priority zero members again they
mean committee pride is zero the main
thing which should come to your mind is
it's a secondary and it cannot ever
become a primary their priority General
members can elect a primary but cannot
actually become a primary or replace a
primary they are not given appropriate
read and write rights they can be used
for dedicated functions like reporting
and the backup so there's something you
see there is a primary there is
secondary secondary secondary and again
there is a secondary drivers priority is
zero
then there are some you know replicas
that's again an important thing which
you know is asked in the interviews
quite often put a delayed replica set
numbers again I can even set some
members in a replica set with a delayed
you know I can specify that you know you
copy you start copying the data from the
primary after these particular minutes
so those are called delayed replica set
numbers
so again delayed application members are
secondaries that copy data from the
primary nodes op log file after certain
interval or delay
delayed replication members reflect a
previous version or delayed state of the
store data set it's like you know I
create a backup of the data after every
some T hours what happens is in case of
a failure or something I can again make
the system come back from whatever time
it was earlier
so delayed replica asset members or
secondaries that copy data from the
primary node.log file after certain
interval delay delayed replication
numbers reflect the previous version or
delay Etc state of the store data sets
again uh what I was saying to you guys
was very importantly they are basically
used so that you know we can a
checkpoint you know some data so that if
in case of some failure I can still
bring the data back to the system to the
place it was earlier so delayed members
perform a role backup or on a historical
snapshot of the data set they help
manage various human errors and recover
from errors such as unsuccessful
application upgrade and drop databases
and collections
the characteristics of a delayed member
are as follows it must be a priority
zero member it must be hidden and not be
visible to Applications it again must
participate in electing a primary now
again we can see over here what is this
so what we're talking about is you can
configure delete you can remember with
the seconds given below so okay delete
change and remember it again has to have
a priority value of zero which again
means that it is a secondary which
cannot ever become a primary hidden
value is true it means it will be hidden
and again slave delay value means again
how much seconds you want the system to
wait till it mates
a copy of the op log to set an one hour
delay issue the operations given below
again you can see over here what we are
setting is we are setting a
configuration so config is equal to
rs.com
and again what we give over here is
conflicted members zero dot priority we
are giving a zero again members so again
please see that you know what you see
over here the members
the members you see over here is the
array which you had in your
configuration
so the first member his Paradigm setting
is zero his hidden and setting is true
he slave delay him setting as 3600 and
again after I made some configuration
changes I can reconfigure all right as
you know that mongodb relationship
represents how multiple documents are
logically connected to each other in
mongodb it provides two types of
relationships namely embedded and
reference embedded documents capture
relationship between data by storing
related data in a single document
structure on the other hand reference
models store the relationship between
data by including links or references
from one document to another now to
implement a normalized database
structure in mongodb we use the concept
of reference relationship that is if you
look at the left side of the screen here
you can have an example where it is a
reference model where we have student
collection and inside we have ID and
then we have another uh you know
document contact details where we are
referencing using this student document
right so in that way we can use
reference model for that so we use this
concept of reference relationship also
referred to as manual or references in
which we manually store the reference
document ID inside another document now
what if the data that you're trying to
search isn't present in different
collection or in different database and
that's where you have to use dbrevs
dbrevs are references from one document
to another using the value of the first
document ID field collection name and
optionally its database DBS basically
allow you to uh more easily reference
documents stored in multiple collections
or database so if you look at this
example I have a user collection here
and a post collection here in the user
collection I have ID name post as my
fields and I'm trying to
fetch those from the post collection
which is another collection in in that
case right so if I'm trying to retrieve
data from another collection which may
be present in another database in such
case you have to reference the database
that you are trying to search for and
that is where we use dbref so and that
will bring us to the main part what is
you know mongodb database references
mongodb database references allow you to
more easily reference documents stored
in multiple collections or database so
relationship between documents can be
represented using this ADB reps which
offer a standard format and type so if a
database needs to communicate with a
variety of Frameworks and tools present
in mongodb Database The dbre Format
offers common links for representing the
data between the documents however in
cases where a document contains
references from different collections in
that case we have to use mongodb ddrefs
so it basically represents a document
rather than a specific reference type
and if you're trying to find data in
more than one collection in such case
you have to use mongodb database
references all right I hope you
understood what it is and let us now
move ahead and understand uh the various
parameters that we use you know while
writing you know database reference
syntax first we have the dollar ref
keyword now ref field basically holds
the name of the collection whereas where
the reference document resides next we
have the ID field the ID field basically
contains the value of the ID field in
the reference document and finally we
have the optional DB which contains the
name of the database where the document
or the reference document resides so in
mongodb these are the three important
fields which should be used in order to
implement dbreps relationship as follows
let us now understand the syntax of
mongodb database reference and how it is
exactly used now let's say if I have an
address collection here which I'm
basically creating two different fields
which is ID and City so the command is
the DB dot address dot insert and ID is
145 and city is Bengaluru next we have
another document which is DV dot address
dot insert which is the idea is 124 city
is Delhi so firstly we have inserted two
documents in our address collection now
let us move ahead and see
and how we can implement this using
another uh you know collection which is
which might be present in different
database now let's say if I have another
student collection and I mean that I'm
inserting records wherein I am inserting
records of uh student details like ID
I'm providing as one is first name of
the student is Rahul here so as you can
see here inside uh you know the address
ID which is the database reference field
which is part of the document or the
collection student collection present in
this collection we are using mongodb
reference approach to refer the address
ID present in another collection which
we have taken from the address
collection here after defining three
fields which are basically ref ID and
optional DDP so the ref is basically by
providing the field which you want to
reference have a provider reference to
the collection that you are trying to
connect here so earlier we mentioned the
ID and the address in the address
collection right so I am referring to
that that's why I'm providing the
collection name as address and ID as105
and database is optional you can keep
whatever you want I am just taking
simply it as simply code one and
similarly we are again inserting another
document and again we are referencing it
with the DB ref dbrf field which is
again address ID and for reference I'm
taking again address collection and IDs
124 and DP dot simply code
now you might have a question now what
exactly and how exactly mongodb DB or
dbref works here now the syntax is
followed as VAR student DB dot student
dot find one which we use in order to uh
find the data now I'm trying to search
the first name with the name of Rohan so
I want to get the details or the address
of this student whose name is Rohan so
for that I'm querying as VAR student
address equals to student dot address ID
and after that mention the syntax as DB
in the Within These square brackets
student address dot dollar ref dot find
ID where student address dot ID now what
does it mean so I'm basically connecting
both the address collection and student
collection and that is what I'm
referring here student address dot
reference and student address dot ID so
in order to get the address of the
student Rohan you have to basically
provide a reference to both these uh
collections so that is what I'm doing
here so when you execute the statement
this will be the final output now for
Rohan we have uh the ID which is 145 and
his City the address is Bengaluru so
this is how exactly dbref Works in
mongodb and that brings us to the end of
today's session guys in this tutorial we
have revised the concepts of data
relationships in mongodb for the with
the likes of manual references used for
data modeling in the mongodb and
compared it against the concepts of
mongodb DB reps where the former is used
when the references are to be made to
the documents present in the same
collection so you can use manual
references when you are trying to make
references in the same documents or
which are present in the same collection
and the other uh you know part which is
mongodb dbrefs approaches used when the
references are to be made to the
documents present in different
Collections and in different database
now the main question comes is why is no
longer mongodb dvrf's Concepts is not
used it is deprecated uh all around the
world and it is not a suggested method
when you are trying to work on this
mongodb database and that is the reason
also mongodb documentation recommends
manual references unless you have
documents referred to in multiple
locations or the collections in a
database so when you have multiple
collections for your references to
Target we would highly recommend it's
still easier to store the object ID and
collection name in the own object
without specifying or with a special
name of dbrevs and that won't break if
someone insert the field out of the
order now all the dbrfs haven't been
deprecated in mongodb as such and the
functionality is unlikely to go away but
hopefully you can see there are good
reasons on why to use and how to avoid
this function that we have discussed in
this tutorial so why python mongodb we
understand mongodb is one of the most
important database which is so called
document based database available in
market and it is fantastic phenomenal in
terms of speed and the reliability
it is purely called nosql database okay
and helps you to go schema LS
now python is one of the most commonly
user-friendly programming language for
creating a complete web-based framework
so it offers you huge amount of
libraries with flexibility of connecting
wide variety of applications
so we would like to give you the idea of
like how Python and mongodb works
together
okay so you can use both the
products together to develop
different varieties of applications
which can suit
to different type of ideas now here we
have one of the very very popular tool
available name called Pi so Pi
 is actually the python Library
which is a kind of a driver through
which you will be able to connect with
your mongodb and perform basic
operations whichever you expect
okay so let's go ahead and start working
on those demos okay
so we will start with
creating a mongodb environment with
cluster in one of the very very popular
tool that is known as called mongodb
Atlas so we'll be opening our website
and go here and talk about call
mongodb Atlas
I search for mongodb Atlas that is
basically the mongodb they call database
as a service I'll be selecting the first
option
and go to the start free because it's
going to offer you by default some 500
MB of free space I say sign up with
Google
going ahead and selecting this
okay I say accept
and say submit
okay so it is starting up now
It'll ask you about a few things I would
rather say to you select skip
and continue
well it'll ask you about which
environment you would like to take so I
like to take this shared cluster I say
create cluster now here it will take a
while to get yourself ready for we can
see it is offering the sandbox of having
500 MB of free space
and this mongodb
no backup that is the battery for
cluster name you can give the name of
the cluster if you want but Let It Be by
default cluster zero I'm saying create
cluster
so my cluster is being ready so it will
take a while to get your cluster set up
so just wait till the timer cluster is
getting ready so I'll tell you what this
cluster is going to give you by default
to child and one parent so called a one
master and two
a child nodes where your cluster will
get ready
so you really don't need to set up any
kind of cluster in your local
environment and that is the best
environment I would suggest for most of
your development where your time reduce
there will be no software requirement
because sometimes version to version it
changes
and you can get all the benefits of
clusters
so we're just waiting till the time the
cluster is getting ready so once the
cluster is ready you will be seeing some
options where
will help you to create the Clusters in
your upcoming demos
so friends your cluster is now ready
you can see now in this cluster you have
got this environment so in this
environment you will see there are some
options they have given you one by one
build up your cluster create a first
database user add an IP address multiple
options they are telling you now so how
to set up so the first build of the
cluster which we have anyways done next
is called create your first database
user will select this
so it will highlight this area now you
can say like database access
and I'm going to create a first new
database user and new database user
giving the username for admin let's keep
very simple username and password admin
123. so admin admin123
yeah same and say add user
now you can see the user is created now
let's go back to the next option it's
telling me the network access now go
here and say sorry
now see add IP address
and I'll see allow access from anywhere
so that I can take it from anywhere I
say confirm
now it is telling me about a progress I
select this
and tell me about which type of
collections you want
okay so I select this
and inside this I'll be selecting this
call collections
okay and it's getting
ready
so it is doing with some options
well two options that will give you load
sample data set add my own data I'll say
add my own data give the database name
SL demo give the collection name EMP or
employee
remember database name SL demo or I can
better give the name code sldb
sldb and employee I say create
that is getting ready
okay so my database and table is ready
that's it so I think
we are all set
with this environment
okay well once it is ready your
collection is also ready I'll go back
and click on my
project zero
and here
yeah so once it is there then I'll be
clicking on this option called
connect
now it will give me the multiple options
how to connect
I'll select
the python
python version 3.11 or later so
certainly I'll be using those version
only
okay and in this I'm having this
so I will be using this to connect with
my backend
so that's how exactly you have
the setup of mongodb cluster driven so
we are all ready now with our
setup
cluster we have already created earlier
you remember about we have taken python
3.11 or later so here if I just group I
can check I have a code
3.8.5 which is Python 3 version which is
available so you can select based on
whichever we have it let's see 3.11 or
later we can say three point
six all later so there'll be no much
difference if I just see even if I just
talk about 0. so there's some change but
here 3.6 or later it is same so I have a
3.8.5
Okay so
I can use the same option so here in my
vscore editor I am using for my
development so here's a simple demo.pi I
have used welcome to check if it is
working fine so yes it is working fine
I'll start working with my first program
with mongodb so I just go back and say
uh demo
py or I can say uh
p y
demo Dot py
okay and here if I want to go back and
start working on the development
remember one thing we need first
dependency called Pi
okay what I need by and for this
we have already installed this
dependency here some time back this is
already installed
okay so we have this statement name
called what pip install Pi Momo
that is the first dependency which you
need to download in order to work with
this
okay so that's what we have taken this
installed by so if you've just
seen you can go back and start
developing this statement
okay so let's go back and start working
on this step number one you need to
always say import
number one the one dependence which
you've installed is called by
so as you can just say p y m o n g o
that is the dependency we have been
recently imported
from
okay let me go back and search from next
point so import by
from
here we are saying by
okay five
and we're also saying import
 Glide
that's the first thing we need to
remember
okay after that we would like to go back
and use the cluster
so we say cluster
equal to
 client and here I'll be passing
the complete values the one which we
have taken
so this complete line
I just take it
go back
and here
I'm pasting it
now here I have to basically replace
this password with admin123
okay and we are all set
okay now
once it is ready we can go ahead and
Define DB equal to
cluster and provide which database you
are talking about
okay so you remember about we had a
database which was available to us that
is known as call sldb so I can just use
the same sldp there and accordingly I
can use which collection I am correcting
it to so accordingly I can go back and
insert a record okay everybody so I can
see I have got this
file with me going forward I have to
tell so if this is what exactly the
connection URL you've received now if
you define which database you're working
on let me say PP equal to
cluster and we have to provide n
double quotes the database name called
sltp if you remember we have used this
after that we have to mention which
collection it was so
collection
equal to DB and here we just give the
name called employee
that was our collection name
so once it is ready then I have to
basically perform some insert operations
so I just say post
okay it says the name equal to and here
we just provide the properties like I
would say name
so do you know it to the Json based
database so I can just use the name I
say
and once again I can just say
email
and
say
another email.com
that's it so this is just the data which
I have now I want to insert so I can
certainly say collection dot because I
want to insert only one record you can
see I have open functions coming up
collections.insert1 and plus
post doesn't matter now we are all done
let's try to run this so I'll be running
this with Python 3 py mode demo Dot py
hit enter
now it's done let's confirm here into my
code I will just go back and check
here inside my
applications I can just go back to my
collections
an unemployed
yeah there we go we have got some
records coming up here
okay so these records are nothing but
the one which we have recently inserted
in our application
okay so fantastic so first example is
working perfectly fine how we can have
the records coming from the python and
insert it there like that I can have as
many number of Records I can add it so
how we can basically add if I want to
add more than one records
let's see this now here in increase if I
want to add more than one records so I
can just use compost one if I copy this
URL and paste it below and I say post
tool I say I'm a G and email I might
want to at the redmill.com and rather
let's say insert one I can use insert
many and inside this I'll be using this
square brackets and pass
post
post one or not
posture that's it
okay so let's change the little name
because it's already there
let's insert
yep records are inserted let me verify
once again
by refreshing it
but now we have a total number of three
records are available
yeah there we go so records are added
perfect so like this you can have as
many number of Records you can basically
add it in a similar one The Way We have
basically used this I can also perform
the search part too
okay so in case if you want to perform
the search part we have a very simple
statement available with us what I'll go
here
the way we have added this so
in this I'll just
these records which are added inside my
application I would not execute this
rather
I would like to go back and say
boom
no they are basically commented now and
uh
in fact I would like to use this also
okay I'll go here and find results
equal to
same collection
dot find if I want to find a name we can
just use
curly braces
name
colon
temperature
okay so let me say print
and plus
results
okay let's run this
okay so it will create what the results
for me
okay so it is just printing what the
cursor object for me saying like hey
this is what the record is available to
me we can also change in case if you do
not think the correct result is coming
up we can also go back and uh
we can use some alternative option that
is called file
okay so what we can do let's take a look
here we can use for
with this for vacancy result
okay in
other words and print this result
that could be one option through which
you can get the details with you
okay so what you can do you can run this
code again
oh I forgot about this semicolon here
or
Railway check
well that was my
requirement was so I'm having this let's
try to run this
well I got my result and this is what it
written which I have available to me so
very simple how you can basically find a
record and how you can basically
retrieve the records at the same time if
you want to have the specific field
rather than all the fields so here in my
code can this result
okay you can just put the square bracket
and tell which field you really want it
now suppose if you just want ID or else
if you want a name you can basically
pick that up
okay so if I just want that ID
like only ID is printed that's it
okay everyone so you have seen like in
my previous code how we were basically
trying to fetch all the records we were
using this find now in a similar light
you can also have the option available
because see when we used to talk about
confine it gets me lot many records
fine and because of that we were using
this Loop but in case if you want to
fetch the individual records
I'll be clear so in such cases you
really do not want to use file
you can just use find one so what you
can do is rather than using find I can
also use one more option called
find one and for which
I can come back just remove this all
yeah so here in this case rather than
using this file I can use file
underscore you can see this option
called find one
here we talk about
which are the properties you'd want so
Skip and which are the properties you
want so I can just use this option
called underscore
ID
okay
zero okay I just remove this
0 and here just print what results
that's it let's run
so let it try to fetch some of the
records for you because if you do not
have that ID which you've overrated it
will certainly not found it depends on
what you would like to take so if I just
say
foreign
but you know it very well how it
basically takes
now in a similar line we would like to
also perform one more activity to talk
about delete so for which what I will do
is this I just want to uncomment it
okay and I would like to insert some
records here so here I want to add the
ID by my own with name
so we already have this name
email I have it I would like to use
underscore ID
okay
so
we have this property underscore ID
colon
1 0 1.
okay
comma like this
copy the same
using it here
and this time
I'm using 102.
name and everything
it will be taken let me say
user one
okay we try to say user two okay so
collections dot many result five one I'm
just deleting it all
and let's try to
execute it first
okay so it's executed going back
okay so I have some records with ID 101
and one zero two
now here
I just delete this and perform some
actions here here we say results
equal to
collection Dot
delete so the options are available
delete one and delete many it totally
depends on what you really want
okay so if I just talk about call delete
one it will be only trading one record
delete many means where are the matching
records are available you deleted
fine so I'm just using this option
called delete many
okay wherever the property names are
matched quite possible name sometimes
match or whatever it is first day delete
many so the option is up to you now how
you want so the selected name you have
to offer it
whether you want to match it with the
name or whether you want to match it
with the email or whatever it is so that
will be offering it but there's also one
option available where you would like to
delete everything
are we clear so if you're planning to
delete it everything what you can do you
can just leave it as a blank and try to
run this
so collection
dot delete underscore meaning
let's check
great all records are deleted so as I've
told you earlier also so delete many
means what it will delete all the
records whichever I present in your code
now
okay in a similar one if I want to
perform insert so you remember about we
have an option called what
insert menu and here
we would like to pass
post one
post Loop let's execute
so it'll add
the records inside this
okay and next time what I want to
perform after adding this record I would
like to perform the update part
okay so what I really wanted my update
let's take a look update means certain
properties I'm looking forward to pick
it updated
okay so in case if I want to check the
record has to be updated I would first
go and check
whether the record does exist or not
yeah we have two names user one and user
two let's go back and update bar
here
I just seek collections
okay dot update one
update you can see update one here very
simple functionality here you will go
and tell which ID would like to perform
an update if I say underscore ID
colon
which side you want to consider I'm
saying one zero one
okay and what else so I just use another
curriculum basis and I say
sorry a dollar
set
and after this
I use this colon use a curly braces
name
okay and use whatever you want to use it
so suppose it is the user one I'm saying
use it one two three
okay let's see
it is loading and you can see the record
user123 is updated
perfect so
your code is absolutely working fine so
you talk about either insert you talk
about what update you talk about
anything it works so insert update 1
delete 1 insert one as the name suggests
they'd be taking care about inserting
updating and deleting one one records
but the moment you use many will be
performing multiple records so this is a
very simple way like how the python will
connect with your mongodb
indexes help perform the following
the following queries
query criteria without a collection scan
limit the number of documents a query
examines
store field value in the order of the
value
support equality matches which are again
arrange based queries again we need to
see over here that mongodb indexes are
similar to The indexes which we use in
in any of the race so these are
different types of indexes which we see
and the different types of indexes we'll
see in mongodb are so by default the
underscore ID we have that is by default
indexed
so each mongodb collection contains an
index on the default underscore ID field
so we can have a single field index it
means a single key on which we want to
put an index so for single field index
and sort operations mongodb can Traverse
the indexes either in the ascending or
the descending header so that's again
why the 1 and the minus one came into
picture set can do in both if we are
talking of a single field index then we
come across compound index so mongodb
supports user-defined indexes such as
compound indexes for multiple Fields so
now if I want to put a compound index on
the name and the age together so what is
the way out so the way out is again
putting a compound index on both the
name and the key
so then we are putting a compound X on
the name and the age I have an option
that I can make the name index sort in
an ascending model and make the age
index sort in a descending manner then
we have a multi-key index if we have
more than that so this is basically used
for indexing added data suppose we have
an array called hobbies and hobbies
again have three things called say TT
badminton and say volleyball
and what we see inside that is
internally what does will
create an index for every value inside
that array so it will create a different
index for hobbies.cricket
hobbies.tp hobbies dot badminton so
that's multiplay index
then we are talking about a geospatial
index again I will talk about the
geospatial queries as well going down
the lane and then we have something
called a text indexes so when we say
geospatial indexes that means that we
will be able to assign a latitude and a
longitude to a particular document so if
we talk about uh say again let's talk
about something called there is a
collection called for dealership so
again Ford dealership f o r d Ford is a
brand of a car and again if we are
looking for servicing our Ford you know
car in some service station Suppose
there is a collection which has all the
details about all the Ford dealership
centers there are in Bangalore let's
take the example of Bangalore
so now along with every document
containing information about every
single authorized for dealer it will
also contain a latitude and a longitude
which will tell the location from which
that particular document is associated
with
so after that so again in that if you
want to press if you want to put an
index on some index on some particular
key we will call that a geospatial index
index is used in geospatial queries are
called geospatial indexes so we can use
2D indexes and 2D sphere indexes so
we'll talk about both of them when we
see down the them in detail
then we have something called text
indexes research is data spring in a
collection then we have something called
hashed indexes so mongodb supports hash
based indexes and provides hashed
indexes so moving to the next slide
we have a single field induction now
we'll see every type of index in detail
what it has to offer to us
so now single field index mongodb
supports indexes on any document field
in a collection
by default the underscore ID field in
all collections have
indexes so that's what I already told
you moreover applications and users add
indexes for triggering queries and
Performing operations so mongodb suppose
both
single field
as well as multi-field indexes based on
the operations the index
type perform so here we are what we're
doing is there is a items collection and
what we are specifically doing
we are creating an index
on the item key
in the items collection so this is
another way how to create an index so we
can also do DB dot items dot ensure
index so both of them will result in an
index Creation in our collection so
either db.collection.create index or DB
dot items Dot create index both of them
will allow us to create a index moving
on to the next slide so single field
index if we want to have on an embedded
document how we can do it somewhere
document is something which we talked
about yesterday
so we can index top level Fields within
document similarly you can create
indexes within embedded document field
so we can see we have a document where
what we have is we have a guy whose ID
is three
whose item is book and available is true
and sold quantity is some number the
category is no SQL in the details is
another document internally with isbns
Publisher
and and the ISBN is one two three four
and the publisher is XYZ company so
again in this what we have done is we
have just created an index inside a
embedded document so we had uh details
document embedded inside a normal
document so we were able to create an
index specifically on that using a DOT
operator the command shows deleted items
at create index details dot ISD in Colon
1.
now what this shows so mongodb
supports compound indexes to query
multiple Fields a compound index
contains multiple single field indexes
separated by a comma the command shown
on the screen clearly suggests that it's
an example of a compound index on two
Fields the diagram depicts a compound
index for the fields user ID and score
the documents were first organized by
user ID
and within each user ID scores are
organized in the descending order the
sort order of fields in a component X is
very crucial the documents are first
sorted by an item field value and then
within each item field value they are
further sorted by the stock field values
so for a compound index it is imperative
to know that mongodb limits the fields
of a compound index to a maximum of 31
so we kind of more than 31 Keys take
part in a compound index so now we talk
of index prefixes so index prefixes are
created by taking different combination
of fields and typically they start from
the first field for example consider the
compound index given on the screen
it has item in the ascending order
and available in the ascending order as
the index prefixes so mongodb uses a
compound index even if the find queries
are for index prefixes Fields it uses
indexes for querying the item field the
available field and the sold quantity
field so very imperative to note over
here the TV cannot efficiently
support the query on the item and sold
quantity Fields by using index prefixes
as it would be like using separate
indexes for these specific Fields the
item field is a part of the compound
index and the index prefixes hence the
item item the item field should be used
in the fine query of the index
exclusively now if you come to the sort
order which we talked about you know
some time back the one and the minus one
again an important thing in mongodb
you can use the sort operations to
manage the sort order so you can
retrieve documents based on the sort
order in an index if you're unable to
obtain the document sorted from an index
the results will actually get sorted in
the memory
sort operations executed using an index
so better performance than those
executed without using an indexes again
as I told you uh the scanning of
documents how much of the gets scanned
so if we have an index definitely there
is a performance improvement over that
in addition sort operations performed
without an index gets terminated after
exhausting 32 megabytes of memory so
typically a Nexus store field references
in the ascending or the descending sort
order
so for single field indexes mongodb can
reverse the index in either direction
and Driver ascending all the resending
hence the sort order doesn't actually
become important but when we talk of the
component axis the sour order becomes
important because as it helps to
determine if the index can support a
sort operation or not
now the next thing which we have over
here we need to ensure that we don't end
up making too many indexes so that's why
the heading you can see in red ensure
the indexes fit in the ram so all of you
items I'm not very sure again you know
whether you guys are aware of this or
not but mongodb is a in-memory database
then I say it's an in-memory database
what I want to say it again brings the
data process first of all into the RAM
and then processes that and thus we get
faster efficiency so if there is a
chance there is a data set not in the
ram because again all over data I cannot
reside in the ram what will actually
happen is it will you know incur page
fault in operating system we would have
read something called page in and page
out so if there is a page which is
required by a mongodb to be processed
right now and if that page is right now
not in the a ram what the will do
it will do a page in from the hard disk
to the memory and but that will again
cause a separate overhead to get that
you know thing done so too much of paid
fall is something which is not
recommended so that is the reason we see
over here that we need to be very sure
that all of our index is fit environment
we don't end up making too many indexes
so to process Theory faster ensure that
a Nexus fit in your system Ram this will
help the system avoid reading the
indexes from the hard disk that's again
exactly what I told you
to confirm the index size use the query
given on the screen this Returns the
data in the bytes
to ensure this index fits your RAM you
must have more than the required RAM
available in addition you must have RAM
available for the rest of the working
set as well so for multiple collections
check the size of all the indexes across
all the collections the indexes and the
working sets both must fit in the ram
simultaneously to get a better query
so again if the index field contains an
array internally
so it's again which decides
whether it will create a multi-key index
on that or not so what we have over here
is multi key indexes so when indexing a
field containing an error value as you
know again multi K indexes I told you
the example of hobbies it has TT Batman
return and say volleyball so mongodb you
will do will create separate index
entries for each array component so
mongodb let's reconstruct multi-key
indexes for arrays holding scale values
such as strings numbers and nested
documents
create a multi
key index
here's a method given below so again
that's exactly what you know we were
using even earlier so DB dot collection
dot create index or Insurance index
button will work so again we need to
know that now the index field contains
an array mongodb automatically decides
whether it really needs to have a multi
key index being created or not so this
is something which the framework decides
implicitly so compound multi-key indexes
so in compound multi-key indexes each
index document can have maximum one
index field with an array value with
more than one field contain another
value compound multi K indexes cannot be
created so given below is an example of
the document structure so what we see is
the ID is one and the product ID we can
see it is an array which is having the
value 1 comma two similar way retail ID
another array having the value of 100
and 200 and then we have a category
which is having a normal sling so a
short key index
and the Hast index cannot be a multi key
index so we'll see down the lane you
know what is the short key we have not
come across uh sharding so we will
understand that once we I guess I guess
this is something which I told you in
the second class or I guess the first
class that we Shard our data
across multiple clusters using a Shard
key the way we had block size in Hadoop
which ensure that the data file gets
divided into blocks and then it gets
scattered across the cluster similar way
Shard key is the thing over here which
ensures
that
what happens it shards our data
accordingly so the short key suppose we
have an employee collection this the
perfect chart key will be employee ID so
I can make the first 20 uh Records for
that in the first cluster the next 20
somewhere else in the next 20 somewhere
else so a short key index and a hash
index cannot actually be a multi-key
index
now we talk of something called hash
indexes so the hashing function does The
Following what it's going to do is it's
gonna combine all the embedded documents
so what the hashing function will do the
ashing function combines all the memory
documents and computes hashes for all
the field values however again it
doesn't support multi-kindexes
hashed indexes support sharding so when
we are talking about sharding so hash
based partitioning is something which is
very important and which again is a very
relevant thing which the industry does
right now so these indexes use a shaft
short key to Shard a collection this
ensures an even distribution of data so
having your hashtag key what it helps us
is it helps us ensure an even
distribution of data mongodb users
hashed indexes to support equality
queries however range queries are
something which is not supported so let
me you know elaborate this a bit let me
elaborate this a bit so when we say it
supports sharding so there are two
things which are you know said over here
one is hashed shared key that is Hash
based purchasing and then we are talking
about range queries
also if you're an aspiring data engineer
looking for online training and
graduating from the best universities or
a professional who likes to switch
careers with data engineering by
learning from the experts then try
giving a short to Simply last
postgraduate program in data engineering
from her University in collaboration
with IBM the link in the description box
and the comment section should navigate
you to the homepage where you can find
the complete overview of the program
being offered right indexes are data
structures that can store collections
data set in a form that is easy to
Traverse
queries are efficiently executed with
the help of indexes in mongodb
indexes help mongodb find documents that
match the query criteria without
performing a collection scan
if a query has an appropriate index
mongodb uses the index and limits the
number of documents it examines
indexes store field values in the order
of the value
the order in which the index entries are
made support operations such as equality
matches and range-based queries
mongodb sorts and Returns the results by
using the sequential order of the
indexes
the indexes of mongodb are similar to
The indexes in any other databases
mongodb defines the indexes at the
collection level for use in any field or
subfield
in the next screen we will discuss index
types
mongodb supports the following index
types for querying default underscore ID
each mongodb collection contains an
index on the default underscore ID field
if no value is specified for underscore
ID the language driver or the mongod
creates an underscore ID field and
provides an object ID value
single field
for a single field index and sort
operation the sort order of the index
keys do not matter mongodb can Traverse
the indexes either in the ascending or
descending order
compound index for multiple Fields
mongodb supports user-defined indexes
such as compound indexes the sequential
order of fields in a compound index is
significant in mongodb
multi-key index to index array data
mongodb uses multi-key indexes
when indexing a field with an array
value mongodb makes separate index
entries for each array element
geospatial index to query geospatial
data mongodb uses two types of indexes
two D indexes and 2D spear indexes
test indexes these indexes in mongodb
searches data string in a collection
hashed indexes mongodb supports hash
based sharding and provides hashed
indexes these indexes the hashes of the
field value
we will discuss the index types in
detail later in the lesson
in the next screen we will discuss the
index properties
mongodb supports indexes on any document
field in a collection by default the
underscore ID field in all collections
have indexes moreover applications and
users add indexes for triggering queries
and Performing operations
mongodb supports both single field or
multiple field indexes based on the
operations the index type performs
the command given on the screen is used
to create an index on the item field for
the items collection
in the next screen we will discuss how
to create single field indexes on
embedded documents
you can index top level Fields within a
document similarly you can create
indexes within embedded document fields
the structure shown on the screen refers
to a document stored in a collection
in the document the details field
depicts an embedded document that has
two embedded Fields ISDN and publisher
to create an index on the ISDN field and
the embedded document called details
perform the queries shown on the screen
in the next screen we will discuss
compound indexes
mongodb supports compound indexes to
query multiple Fields a compound index
contains multiple single field indexes
separated by a comma the command shown
on the screen is an example of a
compound index on two fields
this diagram depicts a compound index
for The Field's user ID and score
the documents are first organized by
user ID and within each user ID scores
are organized in the descending order
the sort order of fields in a compound
index is crucial
the documents are first sorted by the
item field value and then within each
item field value they are further sorted
by the stock field values
for a compound index mongodb limits the
fields to a maximum of 31. in the next
screen we will discuss index prefixes
index prefixes are created by taking
different combination of fields and
typically start from the first field for
example consider the compound index
given on the screen
it has item in the ascending order and
available in the ascending order as the
index prefixes
mongodb uses a compound index even if
the find queries are for index prefixes
Fields it uses indexes for querying the
item field the available field and the
sole quantity field
mongodb cannot efficiently support the
query on the item and sold quantity
Fields by using index prefixes as it
would be like using separate indexes for
these fields
the item field is a part of the compound
index and the index prefixes hence the
item field should be used in the find
query of the index
we will discuss sort order in the next
screen
in mongodb you can use the sort
operations to manage the sort order you
can retrieve documents based on the sort
order in an index if you are unable to
obtain the document sorted from an index
the results will get sorted in the
memory
sort operations executed using and index
show better performance than those
executed without using an index in
addition sort operations performed
without an index gets terminated after
exhausting 32 megabytes of memory
typically indexes store field references
in the ascending or descending sort
order
for single field indexes mongodb can
Traverse the index in either direction
hence the sort order is not important
however for compound indexes the sort
order is important because it helps
determine if the index can support a
sort operation
in the next screen we will discuss how
to ensure that indexes fit in the random
access memory or Ram
when indexing a field containing an
array value mongodb creates separate
index entries for each array component
these multi-key indexes in queries match
array elements with documents containing
arrays and select them you can construct
multi-key indexes for arrays holding
scalar values such as strings numbers
and nested documents
to create a multi-key index you can use
the
db.collection.create index method given
on the screen
if the indexed field contains an array
mongodb automatically decides to either
create a multi-key index or not create
one you need not specify the multi-key
type explicitly
in the next screen we will discuss
compound multi-key indexes
in compound multi-key indexes each index
document can have maximum one indexed
field within array value
if more than one field has an array
value you cannot create a compound
multi-key index
an example of a document structure is
shown on the screen
in this collection both the product
underscore ID and Retail underscore ID
fields are arrays therefore you cannot
create a compound multi-key index
note that A Shard key index and a hashed
index cannot be a multi-key index
in the next screen we will discuss
hashed indexes in detail
the hashing function combines all
embedded documents and computes hashes
for all field values however it does not
support multi-key indexes hashed indexes
support charting these indexes use a
hashed Shard key to Sharda collection
this ensures an even distribution of
data mongodb uses hashed indexes to
support equality queries however range
queries are not supported
you cannot create unique or compound
index by taking a field whose type is
hashed however you can create a hashed
and non-hashed index for the same field
mongodb uses the scalar index for range
queries
you can create a hashed index using the
operation given on the screen this will
create a hashed index for the items
collection on the item field
in the next screen we will discuss TTL
indexes in detail
TTL indexes automatically delete machine
generated data
you can create a TTL index by combining
the
db.collection.create index method with
the expire after seconds option on a
field whose value is either a date or an
array that contains date values
for example to create a TTL index on the
last modified date field of the event
log collection use the operation shown
on the screen in the shell
the TTL background thread runs on both
primary and secondary nodes however it
deletes documents only from the primary
node TTL indexes have the following
limitations they are not supported by
compound indexes which ignores expire
after seconds the underscore ID field
does not support TTL indexes
TTL indexes cannot be created on a
capped collection because mongodb cannot
delete documents from a capped
collection
it does not allow the create index
method to change the value of expire
after seconds of an existing index you
cannot create a TTL index for a field if
a non-ttl index already exists for the
same field if you want to change a
non-ttl single field index to a TTL
index first drop the index and recreate
the index with the expire after seconds
option
in the next screen we will be discussing
creating unique indexes
to create a unique index use the
db.collection.create index method and
set the unique option to true for
example to create a unique index on the
item field of the items collection
execute the operation shown on the
screen in the Shell by default
unique is false on mongodb indexes
if you use the unique constraint on the
compound index then mongodb will enforce
uniqueness on the combination of all
those fields which were part of the
compound key unique index and missing
field
if the indexed field in a unique index
has no value the index stores a null
value for the document
because of this unique constraint
mongodb permits only one document
without the indexed field
in case there are more than one document
with a valueless or missing indexed
field the index build process will fail
and will display a duplicate key error
to filter these null values and avoid
error combine the unique constraint with
the sparse index
in the next screen we will discuss
sparse indexes
data stored by the operating system in
its memory memory map files use the mmap
system call to store the data the mmap
method Maps the file to original virtual
memory in the CPU so memory map file are
the critical pieces of the M map V1
storage engineer in mongodb and that
enables mongodb to access and manipulate
fast data manage and interact with all
types of data assign data files to what
is dual memory block having a byte for
byte conversion so I guess I guess again
I don't remember whether it was you or
someone else one guy was having a
problem he was you know installing some
version of mongodb which again wanted
him to work with wire tiger that is
again another type of engine which I'll
talk about just moments later so this is
Again One internal storage engine that
is M map even storage engine and again
how it internally stores files it stores
files in a memory mapped fashion which
means it will map every file to original
virtual memory in the ram in the CPU
here the node that only Excel data again
you can see a ping over here that only
Excel data is mapped to the memory there
is the data which we have not accessed
as of now is something which won't be
memory mapped so then this is something
which we have already talked about
journaling is something I've talked
about right concern is something I
talked about let's again see what this
guy has to say so mongodb uses write
operations before logging into an on
this journal mongodb first performs the
change operation in the journal before
making any changes to the data if a
mongodb instance encounters any error or
Terminator before writing the changes
from the journal to the data file
mongodb can reapply the right operation
to maintain a consistent state
foreign
exits unexpectedly without a journal you
must then run a repair or preferably a
resync from a clean member of the
replica set so whenever you see a mongod
something which is you know exited you
know not properly it is you know the
system is crashed before you start again
please make it a point that you repair
the DB when you started you can do it
with using an option called mongod
hyphen hyphen repair DB that's again the
command so otherwise we would have just
open the command prompt and type mongod
over here what I'm doing is again I'm
typing mongod
hyphen iPhone repair TV which is again
repair if there is some locks and all
over there it's gonna make sure of them
get cleared and again mongod is up
when journaling is enabled even if
mongodb stops unexpectedly the program
can recover all the written data to the
journal the recovered data is in a
consistent state by default the rights
lost by mongodb and the rights that were
not made in the journal are made in the
last 100 milliseconds it means again the
chance of myself losing data is again
the data which just got written in the
last 100 milliseconds which again is
quite a short of a fraction of a second
so the journey is enabled and if you
have sufficient nominal system the
entire data set and the entire right
working set can reside in the ram to
enable journaling start mongodb with a
journal command line option but again
with the 3.0 and above options of
mongodb versions of mongodb by default
mongodb comes with journaling enabled so
when we talk of storage engines so again
a storage engine manages how data is
stored in a disk
a database supports multiple storage
engines each and then performs specific
workloads as follows again with those
specific workloads can be again this can
be again manage read heavy operations
again it can be
higher throughput again for right
operations so again the they can be two
kinds of application again read
extensive and the right extensive again
both of them who handles again it's the
storage engine second as you can see
with multiple storage engine options
available you can choose one that best
suits your application
so have you have the first engine which
is M map even storage in them so again M
map even storage engine is based on
memory mapped files that
manages high volume operations such as
inserts reads and in place updates
again it is the default storage engine
in mongodb 3.0 and all the previous
versions
to ensure that all the data set
modification is stored in the disk
mongodb records all the modifications in
a journal it writes to the disk more
frequently than it writes all the data
files which again makes sense that I
just you know close out all the options
of me losing some data the journal lets
mongodb recover data from the data files
after mongodb instance exits without
making all the changes so that is why
you know we'll be able to backup the
data even if the database goes off and
the second engine we have is the wired
tiger storage engine again what it again
entails is in mongodb version 3.0 and
above
tiger is also available the features of
the wire tiger storage engine are as
follows again it's optionally available
in the 64-bit build of mongodb version
3.0 again what it does it it supports
High volumes of read insert and more
complex update workloads
all right operations occur within the
context of a document level lock so what
again why tiger brings in is white tiger
brings in document level locking it
means if I want to update parallely
multiple documents in a collection
I can do that with document level locks
if I am updating the document which is
by the name again lock will be done on
top of that so that in a no one else can
update that particular thing so that is
something which came in with the wired
tiger so again it uses a right ahead
transaction log in combination with the
various trick points which again helps
in recovery of the data so using wire
tiger mongodb commits a checkpoint to
the disk either every 30 seconds either
every 60 seconds or when there are only
2 GB of data to write so either
whichever is less either 2GB of data or
in 60 seconds will write a checkpoint to
the disk the checkpoint thresholds are
configurable and all data files between
Android widget points are always valid
so there's one thing which we can change
I can make the 60 or 30 60 is 90
according to other a requirement of my
mongodb application the white tiger
Journal persists all data modifications
between the checkpoints if mongodb exits
between the checkpoints again it enable
was a journal to replay all the data
modified since the last checkpoint when
it was done so then along with that why
tiger also allows a compression support
if I want to compress a document a
collection a database again it provides
an option to do that as well so it again
uses two types of compressions for
collections and indexes one is the
prefix it again uses for all the indexes
in the white tiger engine so again I
guess in your system what is running is
a white tiger with the 3.2 it is
becoming you know it is coming with as
the default storage engine we have so
again block all collection in wiretizer
use block compression combined with the
snappy algorithm so Snappy compression
is also something which you would have
seen in a hive you know when would you
would have talked of in a Hadoop so the
way Snappy can be used in Hadoop again
the snappy compression comes into
picture in with the help of this
white tiger storage engine so you can
modify the default compression settings
for all collection indexes during
collection and index creation you can
configure the compressions on per
collection and per Index this is again
when you create a collection I can
better specify you know whether I would
really want some compression technique
to be used or not the default
compression settings balance storage
efficiency and processing requirements
for most popular so again as I say any
analytics engine is a mix of two things
one is storage and one is performance so
again the current setting whichever are
again that's the mix and match of both
but again if there is something which
you want specifically more on it is
something which is configurable then we
look at you know the power of two sales
relocations so this is again an
important concept coming in are very
important I would like you know you to
specifically Focus over here so again in
earlier versions which was you know map
even and all there was by default a
thing called padding what is padding now
again you know I'm not writing anything
please you can close your eyes and hear
what I say suppose you know I have
stored a document in a collection
suppose it is 10 MB long
it is 10 MB long now mongodb has
allocated storage for this 10 MB in its
database
now I make an update to this document
and the update makes this 10mb document
as 14 MB please understand now when it
first got created and when I updated it
there was good amount of time between
the extra 15 days within 15 days a lot
of data has come in so now what is
happening is I have not allocated my
storage for the document as 14 MB it's
only 10. so now my 10 MB of the document
will result somewhere else 4mb will have
to reset somewhere else or I will have
to move the document somewhere else
which fits the size so this will be an
additional overhead to the system for
this purpose what used to do
used to implement a padding Factor so
whenever it's showing something it used
to keep some you know Factor internally
the framework decides that okay if it's
10 MB it is doing this read operation
this right operation let me put a
padding factor of 1.2 which will again
make the 10 uh MB of storage to say 12
MB
so always some padding is required so
that again the document isn't moved to
some other location which again will be
a overhead so that was something which
is by default with and map V1 what why
tiger gave us if again you have a
collection in which all you do is insert
you never update you don't have a chance
of you know increasing the document size
of a collection you can just decrease or
you know say no to that padding factor
which will again save some good space of
yours so that's what is you know written
on the slide now we'll go to the slides
so again power of two size allocation
mean again the size which can be
allocated to any document will again all
the time will be 2 raised power off so
mongodb version 3.0 uses the power of
two-sized allocation as the default
record allocation strategy for the M map
even storage engine each record has a
size and bytes that is a power of two
for example 32 64 128 256 512 and 2 MB
for documents larger than 2mb the
allocation is rounded up to the nearest
multiple of 2 MB the power of two size
allocation strategy has the following
Key Properties
it can reuse freed recalls and reduce
fragmentation that's what I just told
you quantizing recorder location size is
in a six set of values ensure that an
insert will fit into the three space
available due to delete deletion or
relocation of some earlier documents
that is it'll reduce the fragmentation
again the second thing can reduce moves
how again the added padding space gives
the document scope to grow without
requiring a move in addition to setting
the cost of moving this results in few
updates being made so that's what you
know this is saying that's what you know
uh the new thing which comes in no
padding allocation strategy so for some
collections the workloads that consist
of insert only your document update the
operation do not increase or change the
document sizes for such workloads you
can disable the power of two allocation
using the following two commands one is
the call mode command with the new
padding flag and one is again when I
create a collection I specifically you
know give the Nomad nobody option as a
parameter to that I specifically say
that create this collection and again
please don't put any padding because
highly improbable highly rare that I
will make an update which will make the
document size grow so prior to version
3.0 mongodb used in a location strategy
that included a dynamically calculated
padding as a factor of the document size
we didn't have actually a policy of
having a no padding allocation so
diagnosing performance issues so how we
can do that so degraded performance in
mongodb is typically a function that
depicts a relationship among the
following why can a performance be great
the quantity of data stored in the
database may be very large again it can
be a factor of what is the amount of
available system Ram the number of
connections which are making to the
database and again it can be the amount
of time the database spends in the lock
State all of them can be again a factor
in again the bigger performance in
the performance issues are also the
results of inadequate or inappropriate
induction strategies and again it can be
a result of poor schema design patterns
as well so again following are the some
of the causes of performance degradation
in mongodb so left inside Wheels 31st
that is the locks so again locks ensure
data set consistency that if one is
using other cannot update it block
related slowdowns are irregular to know
if a lock affects your database
performance how we can do that review
the data in the global log section of
the server status output so again how
again an administrator mongodb
Administration over there you know locks
or something which is having a serious
contribution to the degradation of
performance he can again you know run
the server status command so again you
remember we would have run the server
status command I guess one or two weeks
back which again gave us a lot of
information about how the server is
doing so if again the global lock dot
current queue dot total is constantly
High consistently High it means again
there are large number of requests which
are waiting for a lock to get released
which again means our performance is
getting degraduated because of again the
lock this indicates that a possible
concurrency issue is affecting database
performance which again means
concurrently more than two clients are
trying to change one particular document
at once so that was something about
locks talking about the memory usage how
again it helps so mongodb uses memory
mapped files to store data to determine
mongodb's memory users again I can do is
again the same server status command I
can just check the stack uses metrics
metrics of the server status command
will give us more input on how again
mongodb is using X memory if the
resident memory exceeds the system
memory and there is a significant amount
of data on the disk that is not in the
ram you have exceeded the capacity of
the system so again please be very
important to note over here a ram is
something which is a very important
component in mongodb so if again the
data which you have on the disk is much
more than the data you have in your RAM
it means this is something we will have
to have a look so if the memory if the
map memory is greater than the system
memory and operations read data from the
virtual memory then again it'll
negatively impact the system performance
again causing a lot of concerns so again
some more causes apart from the locks
and the memory which can be is One is
paid false so occur when mongodb reads
from or writes data to the data files
that are not located in its physical
memory the physical memory is exhausted
and pages of the physical memory are
swapped to the disk again a similar
concept page fault has with operating
system so if again I don't have the data
in my working set I'm going to make a
page fault from the physical memory
which again will always be an added
overhead page fault count is in mongodb
may increase because of poor performance
and large as I said access
increase the ram in mongodb or again
deploy A Shard to reduce the page fault
occurrences
the next thing which can actually cause
a performance to degrade is again number
of connections if the number of
connections between the application
layer and the database is too high it
results in performance irregularities if
the number of requests is high because
of the number of numerous concurrent
applications interacting take the
following actions again for read heavy
applications
increase the replica set size and
distribute read operations to secondary
window this is important I would
seriously want you to focus over here
for read heavy applications increase the
replica set size and distribute the read
operations to secondary membrane that
means don't make the read from primary
have a separate node where all the reads
will happen so that will ensure that you
don't have too much of trouble in your
right read heavy applications for write
heavy applications again what we can do
is we can deploy sharding and again
distribute whatever data we have among
the different mongodb instances in the
 set now again talking up again how
to optimize better our mongodb so many
factors can affect the database
performance and responsiveness
the following techniques are used for
evaluating the operational performance
of mongodb
and what again are those one is database
profiler so used to identify the
performance characteristic of each
operation against the database one is
the case cap collections so again cap
collections keep the documents in a
proper order even without using the use
of an index and then is the dollar
natural order so again if you want to
return the documents in the order they
exist on the disk and return solid
operations I can use the dollar natural
so again as a recommendation we should
use all the three to have better you
know our mongodb optimized in this case
consider tax sets for replica set so
again you can configure tax checks in a
replica set using the following methods
so what we can actually do is so DB dot
current top will give us you know
information about this so use this
method to evaluate mongodb operations
this is something which we've already
done this method reports the current
operations running on a mongod instance
so I'm very sure you remember when we
did that and then is again the Second
Step also something which you've already
done before so you will see a reputation
quite a reputation in this particular
module so
cursor.explainindb.colection.explain so
again we can get the execution order
with this command so use these explain
methods to evaluate a query performance
such as the index mongodb selects the
fulfill a query and its execution
statistics
you can learn the methods in the
following three modes to control the
amount of information returned again I
can use as a parameter query planner
execution stats and all plans execution
all three of them will give different
information about how the query which
you want to run is running so I guess at
that time we would have ran the
execution stats command then we did it
earlier so again some more things how
again basic things which again even if
we don't study that should be fine but
still we'll go through once so again how
we can optimize better query performance
again same as you know you would have
done in my in the MySQL or the mssql
server or the Oracle again create
indexes to support queries for commonly
issued queries create indexes for quick
Returns the search for multiple feeds
create a compound index for the query
limit query results to reduce Network
demand so again use the limit method to
reduce the demand for network resources
again I'm just emitting out my 10
records
use projections to return only necessary
data so again over here it is
recommending views if you don't want the
user to see everything again why
actually make him see everything just
give the projection which will again
lessen the data which we need to give to
the console use dollar hint to select a
particular index again use the hint
method and queries where you must select
the fields included in several indexes
to perform performance testing so again
if we want specifically some particular
query to run in a fashion with some
particular index again I can specify
with dollar hint and again I can use the
increment operator to perform operation
server side so again use the dollar
Incorporated to increment or decrement
values in documents if again the field
is a type number
so monitoring strategy is for mongodb
so monitoring is a critical component of
database Administration the following
three strategies are used for collecting
data and monitoring a mongodb instance
number one utilities so again
distributed with mongodb that provides
real-time reporting of database
activities our top our start
will come inside this database commands
so again return statistics regarding the
current database state with create
reliability again server status will
come inside this that explain will come
inside this and then again we have
something called MMS monitoring which is
again you know it again collects data
from the running mongodb deployments and
again provide visualization and alerts
based on that data so MMS is mongodb
monitoring service so it's again a
holistic system which will again create
some visualization and alert you want to
know what exactly is happening on the
system so on the Node we can see
monitoring strategies are complementary
and can help answer different questions
in a useful in different contexts
so here we are talking about the first
one which is again mongodb utilities so
mongodb includes the number of utilities
that quickly return status takes about
the performance and activity of an
instance so these activities or
utilities are as follows so Mongoose
that again what mongostat will do again
it captures and Returns the counts of
database operations by type
helps understand the distribution of
operation types and informs capacity
planning so that's something which Among
Us that does and again what top
does so it again tracks the current read
and write activities of a mongodb
instance how is Right operation activity
happening how is the right operational
activity happening it again reports
activity characteristics on per
collection basis
it enables checking whether database
activity matches your expectations or
not and again the third one we have HTTP
console it again helps receive
Diagnostic and monetary information in a
simple web page accessible from
localhost again which report number
you're running on if a locally running
mongodb is using the default 427017
again we can access it from the port
HTTP localhost 28017 so again what we
want to say over here is it's again
similarly as we had in the Hadoop name
node UI map produce UI we can even do
that over here mongodb use the following
commands that report the state of the
database DB dot current top helps
identify the in-progress operations of
database instance server status returns
and overview of the database status
again does not impact the mongodb
performance DB stats again returns a
document that addresses the storage
usage and the data volumes again we have
the call stats provide statistics such
as the number of documents size of
Collections and hard digitalizations per
collection how are the collections doing
a replica set get status is the same as
rs. status which again provides details
as a state and configuration of the
replica set and statistics about its
members and then we have something
called ganglia mongodb so again there
are two tools ganglia and nagios both of
them have capability to you know get
connected with the cluster and give
information about the cluster to monitor
the cluster so ganglia mongodb we have a
command which again allows viewing a
replica set information such as memory
usage BT statistics Master Slave status
over here so again M top
are the additional tools which again
used to check the server statistics and
the scripts so then we have mongodb is
something which internally it gives
nagios again we will have to integrate
it manually or to ensure uh things
happen so I guess most of these commands
you've already run we don't need to run
these commands I am moving to the next
slide it is MMS that is mongodb
Management Service and what it talks
about is so MMS is a cloud service that
helps monitor backup and scale mongodb
on the infrastructure of this voice we
can monitor more than 100 system metrics
and get custom alerts before your system
starts degrading so again as you can see
we can do that so you can create your
own alerts and integrate monitoring with
the tools which you already use so again
how we can make the data backup
strategies in mongodb again as I told
you mongodb restore will come into
the picture so when you deploy mongodb
in production you should have a strategy
for capturing and restoring backups to
prepare for the data loss events you can
perform a backup of mongodb clusters in
the following way back up by copying the
underlying data files backup a database
with mongodom use the MMS cloud backup
so most of the time what we do is we
back up a database with mongodont but
again we will see all of them one by one
what they again need so you can create a
backup for mongodb by copying its
underlying data files if the volume
where mongodb stores data files supports
point in time snapshots you can use them
to create backups the mechanics of
snapshots depend on the other length
storage system on a Linux computer the
logical volume manager that is the lgm
manager can create a snapshot to get an
appropriate snapshot we need to do the
following on a running mongodb process
enable the journaling and so again in
the mongodb version 3.0 and above it is
already enabled the journal must reside
in the same logical volume as the other
mongodb data files reside if again
journaling is not enabled snapshot is
something which may not be consistent or
valid
cluster we would again first disable the
balancer and then capture a snapshot
from every shot in config server again
why
balancer has to be disabled because
again it should not happen that the one
of the chunks is moving from one shot to
other so we need to take the exact
snapshot so we'll disable the blanks
balancer take the snapshot for every
shot and the config server if your
storage system does not support
snapshots copy the files directly using
the copy command in the Linux R sync or
a similar tool backups created by
copying the underlying data do not
support point in time recovery for the
replica sets and again are too difficult
to manage for large solid clusters these
backups are huge and it's something
which is not in general frequently done
in Linda what is done is this backup is
mongodb the tool for backing up small
mongodb deployments are dump so
what again mongodum does reads data from
a mongodatabase and creates these on
file so internally it creates bson files
which Does this mongodom does not
capture the contents of the local
database it only captures the documents
which are there in the database and
again this digitality called
restore what it's going to do operate
against the running mongodb process
rebuild the indexes after restoring the
data when connected to the mongodb
instance mongodum can adversely affect
the mongodb performance if the data
volume is largest in the available
system memory then the queries will push
the working set out of memory making
your system gets low to mitigate the
impact of mongod dump on the performance
of the replica set use mongodom to
capture backups from secondary member of
the replica set which makes all the
sense alternatively you can shut down a
secondary and use mongodom with the data
files directly that would not impact the
primary the reader in the right
efficiency if you shut down a secondary
to capture data with mongodb ensure that
the operation completes before its op
log is unable to replicate from the
primary again to restore a point in time
backup credit with oplog use
restore with the op log replay option
which will again get the backup restored
from a point in time then we have
something called fsync and lock so I can
ensure that you know when some part of
the data is getting copied from one
database to other we put a lock on the
database which again ensures things
happen perfectly fine so mongodb and
 restore allows you to perform data
backups without shutting down the
mongodb server we're not sure enough
anything we can just dump it we can just
restore it function of the hsync command
R it allows the copying of the data
directory of running mongodb server
without any risk of corruption prevents
any further ads to the database until
the server is locked how we can again
make that is they can make ourselves
shift to the database that is use admin
and then again run a command DB dot run
command F shrink is true and again lock
is true so again this will ensure that
the server only gets unlocked when again
the copy is finished to unlock the
database use the command given below
db.cmd.sys.unlog.find1 which is gonna
unlock the TV it allows a flexible
backup without shutting down the server
or sacrificing the point in time nature
of the backup one more way of backing up
the software is from mongodb ops manager
backup software so mongodb ops manager
is a service that allows you to manage
Monitor and backup mongodb
infrastructure
ops manager provide the following
Services one is Ops what is OPS provide
scheduled snapshots and point in time
recovery of mongodb replica sets and
sharded clusters this backup creates
snapshot of the standalones that are run
as single member replica sets and again
one is MMS which we just started
sometime back mongodb Management Service
again has a lightweight backup page and
that runs within the infrastructure and
backs up data from the specified mongodb
processes so again two things which you
use very frequently again one is the
mongodembury store and now with the
coming of this ops manager both of these
Ops and MMS are also used to backup and
the data which we have in our current
replica sets now talking of the security
strategies in mongodb so this is again
the last topic you know in this module
so mongodb provides various features to
maintain a secure deployment following
are some of the security strategies in
mongodb so again one is Authentication
so authentication it means only need to
authenticate that the client who is
connecting with the mongodb is actually
the guy who wants to connect so
mechanism for verifying a user and an
instance access to mongodb then we have
something called authorization which
again controls user or application
access to mongodb instances who is
authorized to view which all DBS and
virtual collections that all will come
in the authorization
control so again we can allow scope
privileges to specific collections which
can action which cannot access network
exposure and security discusses
potential security risks for decreasing
the possible network based attack
vectors for mongodb then we have the
security in mongodb API interfaces which
talks about again it reduces and control
potential risks related to mongodb
JavaScript HTTP invest interfaces and
then we have in general auditing where
again we talk about it all includes the
audit server and the client activities
for the different mongod and the
Mongoose instances so again when we talk
of authentication authentication can be
implemented in mongodb using three ways
so mongodb suppose the following three
authentication mechanisms one is x dot
509 certification one is Kerberos and
one is ldap so when we talk of x.509 so
this mechanism supports x.509
certificate authentication for use with
a secure SSL connection so again secure
socket layer it is used for server and
membership authentication when we talk
of Kerberos so that is again an
Enterprise uh standard Authentication
Protocol for large client server system
so that is something which is again
industry-wide famous and then we have
ldap proxy Authentication
as well which again the full form of
ldap is lightweight directory access
protocol if your guy if you again would
have graduated from a computer science
if you have a computer science graduate
degree you would have studied that in a
computer networks in a subject ldap is
lightweight directory access protocol so
mongodb Enterprise supports proxy
authentication through an ldap Service
as well so again security is something
authentication is something which they
have ensured using these three
authentication protocols inside mongodb
so again how I can actually ensure
authentication in a replica set where
you know there are primaries we have
secondaries and we have the clients
accessing both of them to authenticate
the members of a single mongodb
deployment to each other use the key
file and x.509 mechanisms when you use
the key file authentication this also
enables the authorization for all the
members in a replica set
clusters in a trusted and networking
environment ensure that the network uses
the firewall and network routing the
network is either a VPN or a wide area
network a network configuration allows
every member of the replica effect to
contact every other member and again the
key file configuration is done and all
the members through permit
authentication so key file configuration
is done on all the replica sets where
you know I copy the public key of one
node to the all the system so that again
when that node contacts whether the node
it has the public key through which it
is able to connect so what I do is I
generate two keys one is a public
keyword is a private key I give a public
key to all the nodes which again ensures
when the system contacts the guy it has
a public key through which it is
authenticating that okay this is the guy
I already know I have the public key he
can access me so now we talk of
authentication on solid clusters so in
shorted clusters applications
authenticate directly to the mongodb
instances to the s instances that
is a query routers the charge in the
sharded cluster contains credentials
allowing clients to authenticate
directly to the charge for maintenance
functions applications and clients
connect to the solid cluster through the
 s that we know maintenance
operations such as cleanup or sand
Compact and rs config require direct
connections to the specific charge in
the Charlotte cluster so again the
request which goes in that internally
has an Authentication Protocol which
again conveys whether it connects The
Shard or not to perform these operations
with authentication enabled connect
directly to visad and authenticate as a
Shard local administrative user to
create a sharp local administrative user
connect directly to The Shard and create
the user again direct connections to The
Shard should only be for short specific
maintenance and configuration so
basically whenever the application tries
to get in through the OS
internally the application Level logic
need to ensure that it has the proper
authentication to read through all the
replica sets which are there in a
particular shot after authentication we
talk of authorization who all users are
authorized to do what all tasks so here
in this case authorization we would have
also you know all these things would
also be there in Ms SQL server and
Oracle where I specify different roles
and again there are different people
doing all the roles there will mean
there is a route and all those things so
authorization defines a user access to a
systems resource and operations key
features of mongodb's authorization are
users are be able to perform only those
operations that are required to fulfill
their defined job roles role-based
access control system controls all the
users access and ensures that all the
granted access applies as not only as
possible authorization is not enabled by
default then authorization is enabled
mongodb requires authentication for all
the connections after authorization is
enabled mongodb controls each user
access through its assigned role each
role consists of a set of Privileges and
each privilege consists of actions a set
of operation similar way the way we have
an msql official users can access
virtual collection what all operations
they can do so they can read whether
they can write they can execute so
mongodb provides several building
controls such as the read read write DB
admin and the root roles users can have
several concurrent roles and receive all
the Privileges of this and then we have
an end-to-end auditing for compliance
what it again tells and mongodb
administrator needs to implement
security policies to control the
activities in a system auditing enables
the viewing following functions verify
that the implemented security policies
are controlling the activities as
desired by retaining the audio
information ensure that you have enough
information to perform forensic
investigation and comply with the
regulation and policy that requires the
audit data which is cluster is handling
the auditing facility allows users to
track a system activity for deployments
with multiple users and applications the
auditing facility can write audit events
to the console the system organization
file a revision file as we want so with
this we come to the end of this module
as well which we talked about you know a
bit of you know authentication
authorization auditing a bit of you know
storage engines a bit of cap file a bit
of grid Affairs and then a bit of
journaling a bit of right concern as
well
mongodb is a document-based database
the basic idea behind shifting from
relational data model to a new data
model is to replace the concept of a row
with a flexible model the document the
document-based approach allows embedded
documents arrays and represents a
complex hierarchical relationship using
a single record
this is how developers using
object-oriented languages want to
represent their data mongodb is schema
free the keys used in documents are not
pre-defined or fixed without a fixed
schema massive data migrations have
become unnecessary
while migrating data to mongodb any
issues of new or missing keys can be
resolved at the application Level rather
than changing the schema in the database
this offers developers the flexibility
of working with evolving data models
the table given on the screen depicts
the various SQL terminology and Concepts
and the corresponding mongodb
terminology and Concepts
in mongodb the table and view structure
is known as collection
typically these Collections Group
documents that are structurally or
conceptually similar
mongodb allows embedding of related
document to one another these documents
are used to query related data the data
for a table in mongodb are distributed
among different shards which is similar
to the concept of partition in
relational database Management systems
or rdbms
after grouping structurally similar
documents into collection
mongodb groups different collections
into databases
for instance a single instance of
mongodb is capable of Hosting multiple
independent databases
ideally you should store data related to
a single application at one database
you need separate databases when storing
multiple application or users data on
the same mongodb server
the data model in mongodb is document
based although documents provide Rich
structure they need not conform to any
pre-specified schema
in a relational database rows are stored
in a table and each table has a strictly
defined schema that specifies the
permitted types and columns if a row in
a table requires an extra field the
entire table needs to be altered
mongodb on the other hand groups
documents into collections that do not
follow any schema
each individual document in collection
can have a completely independent
structure
in practice documents in a collection
are relatively uniform
for example if you are creating a
collection review underscore comments
for storing review comments given by the
customer then every document in this
collection will have Fields such as
title tags comments and so on
the lack of schema offers many
advantages
first since structure is defined by the
application code not the database this
speeds up initial application
development when the schema tends to
change frequently
second a schema-less model lets you
represent data with variable properties
compared to rdbms such as MySQL which
supports two-phase commit mongodb only
supports a single phase commit at each
document level
a right operation in a single document
is considered Atomic in mongodb even if
the operation Alters multiple embedded
documents however the entire operation
is not Atomic and other operations May
interlave
some of the key features of mongodb are
as follows
ad hoc queries
mongodb allows performing of search
functions by field range queries and
regular expression searches
queries can return specific document
fields and may include user-defined
JavaScript functions
querying
for document retrieval mongodb uses Rich
query language it also allows you to
write any complex condition to retrieve
documents fast In-Place updates
mongodb allows you to choose write
semantics enable journaling and thus
control the speed and durability
All rights are sent across a
transmission control protocol or TCP
socket and do not require a database
response
to get a response use the special safe
mode of the drivers and perform a right
this generates a response acknowledging
the receipt of the right with no errors
server-side JavaScript execution
mongodb uses JavaScript inquiries and
aggregation functions such as mapreduce
which are sent to the database for
execution
capped collections
capped collections are fixed size
collections supported by mongodb these
collections maintain insertion order and
once the specified size has been reached
behaves like a circuit or Q
mongodb supports other data types while
retaining json's essential key value
pair characteristic
how values of each type are represented
depends on the language used
following is a list of the commonly
supported data types null is used to
represent both a null value and a
non-existent field for example field X
has null value
undefined is used in documents
JavaScript has distinct types for null
and undefined for example field X is
undefined
Boolean is used to represent true and
false values for example field X is a
Boolean variable whose value is true
32-bit integer cannot be represented on
the shell
JavaScript supports only 64-bit floating
Point numbers hence 32-bit integers will
be converted to 64-bit
64-bit integer the shell cannot
represent these and will display them
using a special embedded document
64-bit floating Point number
all numbers in the Shell must be of this
type
here are a few more data types supported
by mongodb
maximum value
Basin contains a special data type that
represents the largest possible value
the shell does not support this type
minimum value
Basin contains a special data type that
represents the smallest possible value
the shell does not support this type
object ID object ID data type is unique
faster generate and ordered
these consist of 12 bytes where the
first four bytes represent the object ID
creation time
string Beeson strings are utf-8
compliant typically when serializing and
deserializing besan programming
languages convert language strings to
utf-8 format this allows easy storing of
international characters in vs and
strings
symbol symbols are not supported by the
shell when the shell gets a symbol from
the database it converts it into a
string timestamps
Basin offers a special timestamp for
internal mongodb use that is not
associated with the regular date type
note that within a single mongod
instance timestamp values are always
unique
date date and Beeson is a 64-bit integer
that denotes the number of milliseconds
since the Unix Epic it can represent a
date range of about 290 million years
into the past and future
regular expression documents contain
javascript's regular expression Syntax
for example
X is the field whose value contain
substring simply learn
following are some more data types
supported by mongodb
code documents can contain JavaScript
code for example logic inside function
binary data it is a string of arbitrary
bytes it cannot be manipulated from the
shell
array sets or lists of values can be
represented as arrays
courses is the field whose value is an
array this array holds three elements
PMP cloud and mongodb
embedded document
documents can contain entire documents
embedded as values in a parent document
for example course underscore duration
is the embedded document which has field
name mongodb the value for this field is
24 hours
the core database server of mongodb can
be run as an executable process called
mongod or
mongodb.exe on Windows
the mongod process receives a command to
run the mongodb server over a network
socket through a custom binary protocol
the data files for a mongod process are
stored by default in the directory slash
data slash DB
you can run a mongod process in several
modes the most common mode is the
replica set
typically replica set configurations
comprise two replicas and an Arbiter
process that reside on a third server
the auto sharding architecture of
mongodb consists of mongod processes
configured as per Shard replica sets it
also consists special metadata servers
called config servers
in addition s a separate routing
server is used to send requests to the
appropriate shard
 s queries from the application
layer and locates the data in the
sharded cluster to complete these
operations
a mongo-s instance is identical to any
mongodb instance
mongodb tools consists of the following
JavaScript shell database drivers and
command line tools
the JavaScript shell
the command shell in mongodb is a
JavaScript based tool it is used to
administer the database and manipulate
data a executable loads the shell
and connects it to a specified mongod
process
in addition to inserting and querying
data the shell allows you to run
administrative commands
database drivers
the mongodb drivers are easy to use
it provides an application program
interface or API that matches the syntax
of the language used while maintaining
uniform interfaces across languages
10gen a company behind mongodb supports
drivers for C C plus plus C hash erlang
Haskell Java Perl PHP python Scala and
Ruby
command line tools mongodb contains the
following command line utilities
mongodump and restore are standard
utilities that help backup and restore a
database
mongodump can save the data and the
Beeson format of mongodb and thus is
used for backups only
this tool is used for hot backups and
can be restored with restore
easily
 export and import are used
to export and import Json comma
separated value or CSV and tab separated
value or tsv data these tools help you
get data in widely supported formats you
can use import for initial Imports
of large data sets however you need to
adjust the data models for best results
in such a case you can use a custom
script to easily import the data through
one of the drivers
 sniff is a wire sniffing tool used
for viewing operations sent to the
database this tool translates the Beeson
that is transmitted to human readable
shell statements
 stat is similar to iostat
mongostat provides helpful statistics
including the number of operations per
second for example inserts queries
updates deletes and so on
it also provides information such as the
amount of virtual memory allocated and
the number of connections to the server
this demo will show the steps to install
mongodb on Linux
in this demo you will learn how to
install mongodb on Linux machine
first download the latest mongodb binary
for Linux platform
to download type the command shown on
the screen
after the mongodb binary is downloaded
on turret by executing the command shown
on the screen
next create a directory slash mongodb by
executing the command make directory
hyphen P slash mongodb
next copy the untarred directory by
executing command shown on the screen
to run mongodb from anywhere in Linux
you need to add mongodb installation
path in the dot bash RC file to do so
execute the command v i space slash root
slash dot bash RC
next type the two commands given on the
screen
note that your dot bash RC file location
may be different based on your username
and profile
reload the environment variable by
executing the command Source slash root
slash dot bash RC
next execute the command Echo dollar
mongodb underscore home to verify
whether the environment variable mongodb
underscore home has been set or not
this concludes the demo on installing
mongodb on Linux computer
this demo will show the steps to install
mongodb on a Windows computer in this
demo you will learn how to install
mongodb on a Windows computer
mongodb four Windows runs only on
Windows Server 2008 R2 Windows Vista or
the later versions
the dot MSI installer includes all
software dependencies
if you have an older version of mongodb
installed on your computer the dot MSI
file will automatically upgrade it to
the latest version
to install first go to the site given on
the screen
in the download and run mongodb page
scroll down and click download to MSI
and then click run
once the MSI file is downloaded the
installation wizard opens automatically
next follow the default options on the
wizard to install mongodb
this concludes the demo on installing
mongodb on a Windows computer this demo
will show the steps to start mongodb on
Linux in this demo you will learn how to
run the mongod server and the
shell on Linux
to start the mongod server type mongod
in the command prompt the mongod script
file is in the slash bin directory of
your mongod home path
once mongod server starts running open
another terminal
to open the shell type in
the second terminal
in the shell perform the mongodb
insert operation by executing the
command given on the screen
to check whether document was inserted
use the find method on courses
collection
this concludes the demo on starting
mongodb on Linux this demo will show the
steps to start mongodb on Windows in
this demo you will learn how to run
mongod server and shell on Windows
machine
to begin navigate to The Path C colon
backward slash program file slash
mongodb slash server slash 3.0 slash bin
to start the mongod server double-click
mongod.exe
once the mongod server starts running
open another command prompt to open the
mongod shell
to open the shell double-click the
mongo.exe in the same directory
to perform the insert operation in the
 shell execute the command given on
the screen
to check whether the document was
inserted execute the command DB dot
courses dot find
also if you're an aspiring data engineer
looking for online training and
graduating from the best universities or
a professional who likes to switch
careers with data engineering by
learning from the experts then try
coming a shot to Simply last
postgraduate program in data engineering
from Toyota University in collaboration
with IBM the link in the description box
and the comment section should navigate
you to the homepage where you can find
the complete overview of the program
being offered
so first of all we'll look into how Java
and interacts
so again if you're aware of java
this is something which will be very
easy again you know the same manga thing
which I did how it can interact with
Java with sdb and then we'll talk about
you know how Noah Joe is how node.js can
interact with
both of them pretty simple and after we
talk about that we'll look into some of
the admin features
and when I see this this is relatively
very very very easy some other utilities
like you know dump
we have restore
we have stacks
we have top
some of the utilities apart from what
we've already started we'll have a look
so again mongodb used to you know dump a
database into our DB on the restore
again if you want to bring back any DB
which you're already dumped we can use
the mongodistorability among the staff
should use to you know uh visualize see
the statistics how the cluster is doing
and again top will give me a which
ride and read operation is actually
taking a lot of time and which of those
operations which are you know being done
are very easily so again that is what
you know here we'll also see some part
of you know how the authorization
Authentication
and security is something which
takes care of
so I feel this will not take a lot of
time and this is well should be pretty
easy to go with so that is what the
agenda for the today's class will be
so again mongodb drivers and the client
libraries so applications communicate
with mongodb through Clan libraries or
drivers that handle all the interactions
with the database in a language that is
appropriate and sensible
the following languages again can be
used for the communication again in all
of them JavaScript
will be the Java all of them can
internally be used to communicate with
mongodb
so let's again see how we can actually
develop a Java application with mongodb
so again to install the Java driver what
we can actually do perform the following
steps download the jar from the link
given below that is the GitHub live from
where you can download the Java
driver this the second will be again add
the jar through your class path
the Java castles you need to use in a
normal application are in the
com.mongodb and again the
com.mongodb.gridfs packages so these are
the two packages which will require to
again interact with the database
the jar file contains a number of other
packages as well apart from these two
here it is Packet is only to either
modify the driver's internal
functionality or again exchange its
functionality so again I guess as you
are pretty comfortable with Hadoop as
well similarly Hadoop has the hdfs API
which it exposes and you know in that
what we do is we create a configuration
object in the configuration object we
share the property you know FS dot
default.name which again internally
caters to the name node IP address and
then what we do is we create a file size
file system instance
object and again pass that configuration
is a parameter to that so again in the
end the file system is able to know
where the name node is running and that
is how internally hdfs API allows
operations to be done on top of
similarly again this is the list there
so again how to connect to using
the Java program so to create a normal
Java application so again what we need
to do is we need to create a new Java
project in eclipse and add the mongodb
Java driver into its build in the class
pass again we'll need to set the
environment variables once that is done
the Java driver of the mongodb provides
the
com.mongodb.mongo class to connect to
the mongodb server to establish a
connection create new object and
pass the EP address and port number of
the mongodb server as a parameter as
shown in the code below so this is
something which is exactly similar to
how even Hadoop used to do work so again
you can see in the top we can we've
imported the packages and then I'm
making a class whose name is item search
I'm trying to search for an item in the
collection and again I have my main
method and the main method would I do I
have made a client object and what
I'm doing is I'm just passing that you
know the server details over there that
you know it's my system and again the
port number is 27017. after that I'm
making a B object and again passing the
test so test is the database over here
we're passing the database as a
parameter to the DB object and after
that we have a collection we have a
class called DB collection I'm making an
object of that with the names items and
I'm again just saying the
db.getcollection the item so it will
connect
to the test database so again what is
happening is the first line is
contacting with the server which is
again up on the localhost 27017
after that it is connecting with the
test database after that it's just
getting the details of the items
collection in that particular database
so
again how we can so again what we will
see is both the Java and the node.js so
we will see how to do a credit operation
from java how to do a credit operation
from node.js so again it'll include how
to create a thing how to insert things
how to update things and again then how
to delete things from that so let's see
you know how we can actually create a
collection from again the Java program
so you can create a collection from a
Java program using the create collection
method of the com.mongodb.db class so
that's again from the package we
imported a DB object instance is Created
from the return object of the Monger
client dot get DB method or function so
you can see the main method it is just
explaining what actually is doing so
first of all the client again I
pass on the server details that is
localhost 27017 then I connect to the
databases I told you I know that I've
connected to the database which is test
and after that I have made a object of
the BB collection and then I'm just
saying DB dot create collection so this
DB again has the same is connecting with
the mongod instance dot create
collection I again pass my call is the
name of the collection which I want to
pass and the second parameter I passed
is null then again I just write a cache
function as well which again says if
Again by chance it's not able to create
one it should be able to pass on the
message to the terminal so once again we
have the collection created what I can
actually have a look at is how I can
insert a document into a collection
which I just created so again uh two
things we have seen right now first of
all again a client I just passed
the local 27017 after that what I do is
I just connect to the test TV after I
connect the test DB I can actually look
into any collection which I already have
we looked at you know the items and
again we want to create one I can just
BB dot create collection the same
command which you used to use I
can use and again make a collection of
our own so after the collection now has
been made let's see how we can actually
insert documents from a Java program so
again quick simple so documents in Java
must be instances of the or dot bson.db
object a document can be created in
multiple ways in Java however the
simplest way is to create one using the
com.mongodb dot basicdb object class so
that's again and the class already which
mongodb supports which allows us to
easily insert documents in a collection
in mongodb
so to create a document that is
represented by the cell as item book
sold quantity 500 again the command
which has to be used is something which
you can see on the screen I've made a
basic DB object Doc is object of the
basic DB object class I'm initializing
it after that I'm just doing doc dot put
I'm just specifying the key value which
I want in that particular
collection so again a similar way how we
used to do in just
programmatically I'm just entering
things into my collection
so insert documents using Java code
example what we just saw so create an
instance of the DB collection object by
calling the get collection method of the
DB object after that what we need to do
create basic DB object to represent the
Json document in the Java code then we
can do is we can call the append method
to set the values for all the fields
that need to be populated again we can
just call the insert method of the DB
collection after the basic DB object
actually gets initialized so easily
they'll be able to insert documents into
a collection with the help of a Java
program so the demo I guess you know
what we can do is is you can try that
out on your end and then actually you
can get back to me and I'll be able to
help you out on that because this will
actually consume a lot of time and I
guess this is pretty simple again we
know the concepts is that you know we
need to integrate you know the Java with
the mongodb so this is something which
is definitely doable you can try it out
with your end and I guess I'll be there
at your disposal to help you if you
found
so right now again just to summarize the
results there again I just made sure
that my connection happens to the Local
Host I connect with the Dave BB I'm
going to the test BB all I've done is
I've looked for a collection then I've
created a collection and now I've
installed it into a collection using the
basic DB object class given in the
package now what I want to do I want to
update documents using the Java code
how I can look into that
so again the way we use DB dot
collection dot
createdb.collection.insert the same
manner db.collection.update the same
thing being used over here
so the DB dot collection.update method
is used to update an existing document
in a collection and the code given on
the screen the DB cursor object is used
to iterate through the list of documents
in the while loop
an update is document by inserting the
field like with its value as 100 so
again the same way how we used to do
things in a normal mongodb command
prompt which you see over here we made a
class by the name update documents I
have the main method over there and
again in the cryblock what I'm actually
running is I've made an object of the DB
collection class again I just get the
collection items over there we'll give
the collection items into that once I
have the items collection with me I'm
making an object of the DB cursor which
will again return a cursor because again
my thing is collection dot find so
please again you know I hope this is
something which is very easily
understandable that c-o double call now
has items collection it Returns the
cursor again when I do a collection at
fine internally what gets fired is DB
dot items that's fine and again I told
you we already know the DB Road items
that find will internally return a
cursor which again iterates through all
the documents in a particular collection
so now cursor again has that cursor
which we can iterate then I will write
the while loop where while cursor dot
has next it means while there is a
document in the collection all I can
write is again I make a DB object
another object by the name update
document and I just do a cursor.net so
it moves to the first document and there
I can just write update document.put
again like is something as 100 so again
200 will be something which will be set
to the like key and then I can do is Vol
again you know please remember this is
the collection which is items I can just
update because I can see will it update
I can give the first parameters null and
the second parameter is update and I
will keep whatever was earlier into the
document and the next parameter will
again add whatever key values are set
into the document now we've seen how to
create it how to insert it how to update
this now again the deleting thing again
very simple the way we should do it over
there similar way Dave used to have a
thing called DBW items that remove here
you have a thing called again collection
dot remove so again c o l again will be
an object of a class which will again
get the collection
so here what we see is we have made a
public class delete document what we
again do is we make a main method in the
main method again what we do is we have
a try block again the same old thing
which we're doing even from the previous
slides I make a DB collection object
where I give the collection so here
please see col c o double l has my call
collection in it then I just did
system.printellin collection my call
selected successful it means I have the
my call collection with me right now
then after that what I can do I have
made an object of DB object class again
what I'm doing is call Dot find one get
me one document in that particular
collection once you get that what you
can do is call or remove my dog whatever
document you just got with the find one
thing it's going to remove that and then
what I can do is I can just do DB cursor
cursor is equal to call DOT fine so
it'll again get me all the records which
are there in the present so that was
something using you know how we can
actually make you know Java interact
with you know mongodb and again have the
credit operations done so now again uh
Guild effect is something which we
looked at you know yesterday now again
if we want to do that you know with Java
so again to store images what we can do
below is so again please use the code
given below please hear the code I made
a class called save image if I want to
save an image in my mongodb using
Java what I need to do again I have a
main function again in the play block
what I have is I have connected to a
 system which is running on the
port which is running on the IP address
192.168.133.128 and once it is connected
again I'm just getting the DB
you know which DB I need to connect to
that is the image database one after
that what I'm doing is again we can do
both of these things you can see over
here
again the same thing which you know it
connects to the test database it's again
just gets to the image database so both
of these things one of these objects we
can make and actually get a thing done
so in this I am connecting to the email
database and I'm storing that particular
thing into the test collection so that's
the collection we've got after that what
I do is I again make a string object new
file name give that name a grid of Fez
Java image then for that I will have to
create a file as well so again I'm
storing an image a file has to be
created by the name conduct a Java image
but again we have that file actually has
to resize it has to result in the
location which I just specified in the
parameter of the file object so again
that creates internally a photo name
space once that is something which is
done how to create a photo name special
something which will you know the below
uh commands will actually guide us how
to make a photo namespace so that is
done by again using the gridface cast so
that's again the DFS API which it
exposes I'll use the grid FS class I
make an object of that that is DFS photo
again the parameter I just passed the DB
so DB is coming from the top you see
image database one and again the photo
so photo is something the new namespace
which you know I will be generating
where the photos will get stored then
again we have a class in the interface
API by the name gridface input file
again create an object of it and again I
create a file and in that file I gave
the parameter image file you can see
image file in the top there you know it
is again given the parameter C butterfly
jpg that you know here I want to create
a file so here the file will get created
and after that once it is created the
same object GSS file I'm just setting
the file name as the file name which is
specified over there which is grid FS
Java image so a new file will be
generated with the name as grid FS Java
image after that what I can do is I can
just save the image file into mongodb by
writing the command by writing invoking
the function Save which is again given
in the grid FS API so GFS file let's say
ultimate level save that image of you
know whatever thing I want to store into
my photo name space in the text
collection in the image database file so
again once I've stored my things into
the grid of phase using the refs API how
I can actually retrieve those images
back so to retrieve DB cursor objects
having referenced the file stored in
Grid FS
we can use the code below so what I do
is again I make a cursor object of a DB
cursor class what I do is I do a GFS
photo.getfile list it's going to return
a cursor so now my cursor qrsur has
again the list of all the files I have
what I do is I just you know I trade
through the while loop while cursor dot
has next please keep on printing out the
cursor.nix again I'll keep on getting
the images
from you know my great FS or right there
into my screen so after that again grid
files DB file image for output is equal
to GFS photo dot find one again the new
file name so again just you know before
what the file we have stored in our in
our collection that was Again by the
name so again the same file if I want to
retrieve again what I've done is I have
just invoking the function find one
another find one I'm just passing the
file name which properly you know I
would specifically search for so that's
how I would I'm gonna retrieve any
images using Google FS API in mongodb so
again I've saved an image I have
retrieved an image again how to remove
an image again the same day they used to
have our Command Prompt you server
remove method the Java I normally use
server
all I have to do is again DFS photo dot
remove again just keep that specific you
know find one again pass the parameter
which particular image you would want to
delete and that file internally will be
deleted from the grid itself so that was
something about you know how again
would connect to Java just to again
rephrase what I just said so again Java
and how will they interact all you
need to do is just you know download the
jar which again is the Java driver
once I have done that all I need to do
is again simple things first thing is
again how particularly we can create a
collection in Java we could easily see
that in the client thing we pass
the localhost 37017 that is the port
number alternatively connected to the
test the moment we are into the DB I can
use git collection to get whichever
collection so that get collection is the
method I can use to retrieve whichever a
collection is in my particular DB then
we looked at creating a selection using
Dot create collection method then we
upgrade our collection using again a DB
basic object we create an object of that
and with the help of that put function
again something programmatically is very
easy so we set the keys and values to
some particular document so again the
syntax again was dot update document and
then we thought of you know how can we
remove it dot remove and then what we
saw was if we want to store something
using the grid access API some image or
some video into the again how we
can do that so de malab this is
something which is fine with you a
smiley from your side will communicate
to me that we are good with this and we
can move to the next thing which is
node.js which is even simpler than what
we just saw now so node.js will be
something which will be pretty similar
to even what we do on the command prompt
so let's move further to you know how
node.js can actually be interacted with
the database
so again to work with the database
first create a connection so again the
same old story will again you will see
again but even with more easy because
syntax over here again is more or less
in the same line as what we did on the
command prompt okay so I get that I get
that I get that so you have experience
in MySQL and Ms SQL so it makes all the
sense to make a switch and because
uh having an experience in the
relational database is definitely given
Advantage because you already understand
how the rotational World works and again
now with this on top of that that
definitely is like you know uh the best
of both the worlds so I guess I guess I
guess that should be fine so to work
with the database first create a
connection so you can use mongodb's
native node.js driver to create a
connection with the mongodb server to
install the mongodb native drivers first
install the mongodb module by using the
npm command run the command given below
so npm basically is the package with
which node.js gives which internally
allows all the classes to be used inside
 so what I do is in Kim install
mongodb so MPS is a package manager that
provides a central repository for all
the custom open source modules for the
node.js and the JavaScript so I install
this packet manager which will gonna
help me install all the packages which
again come as modules for the node.js
and the JavaScript inside that once that
is done so again what mpm is npm helps
manage modules diversions the
distributions easily the npm install
command is used to install the required
module in a project so again to work
with the database first create a
connection you can use so again this is
something which we did let's move to the
next idea so Step One is again a lot of
mongodb module using the code given
below so again what I do is let's
require import the mongodb native
drivers so what I do is where mongodb is
it will require mongodb so again I'm
just requesting or you know importing
all the mongodeminated drivers from the
npm over here so once that is done
Define the URL you need to connect to so
again I just specify where URL is equal
to you know mongodb is running on which
particular server I specify its
localhost to 7017 and the DB I want to
connect to is test
step three is again connect to the DB
use the clients interface connect
method to connect to the database so
again uh claims interface has a
Connect method that you can use which
I'm using over here and again the same
old Story the uh URL their IMU I used to
pass a mango client object which again
has the same thing here I'm just passing
that URL which again now has the server
details where it is running
to the parameter and along with that it
passes a function and what it possible
the function first parameter is error
and the second parameter is DB so again
you will see the function which it
returns over here the first parameter
always will be a error and the second
parameter always will be the actual
thing which I will get and that will
return to the object so how we can
actually do an insert operation using
node.js so after you have a DB
connection ready you can communicate
with the database and perform some basic
operations on the database when
using the mongodb network driver you
need to ensure that the query function
names and the parameters are similar to
that of the Native mongodb commands the
query functions take the Callback as the
last argument this is something which is
important I just told you you know just
moments back the query functions take
the Callback as the last argument the
Callback function Returns the first
argument is an error and the second
argument is a result so whatever result
is that will be in the second argument
so the result is actually the output or
the result provided by mongodb on
running these commands there is
something how you know the insert will
happen to create an items collection and
save a few items in it use the code
given below so again this has three two
things one is the create collection and
then is the insert collection
so we get the items collection over here
again how to create some more users
inside that again I just need to so this
is again like the normal JavaScript so
again where item one is equal to I
specify the document item is book sold
quantity is 500. similarly I added some
three items again these are variables
again how to insert them into the
collection all I can do is collection
dot insert so again this collection PC
this wire collection is actually this
object over here this variable over here
collection it insert I specify these
over here and again the second parameter
again the function which again has two
parameters one is the error and second
is the result which is again will be the
insertion of all of these three items
into my items collection
operation you perform the following
steps what we have just done I use the
DB dot collection method to get the
collection preparator to be inserted
that is the variables which have created
which will be inserted and then I just
insert them into the database so that
was how the insertion used to happen now
again insertion is done how we can
actually update it it's updated in
simple dot update is the thing and again
one more thing you will see very similar
over here is this is exactly the same
how the command prompt used to work so
you can update records using the
collection.update method the name and
parameters of the object method are
similar to that of native mongodb
queries the code given below updates the
document from node js so how to get the
collection document so again this is
something which we just saw in the
previous slide where collection is equal
to DB dot collection items so here my
collection variable has now the items
collection then I already do is insert
some users so again I'm doing collection
Dot
update
again update that document whose item is
stencil and again as you can see I can
use the dollar set variable the same way
I can use this dollar set operator in
the native mongodb query and again I'm
saying update that document whose item
is pencil and again what you need to do
is set its availability to files so
again
second parameter is function which again
has two parameters first is an error and
the second is actually the num which
actually got updated so then what I'm
doing is if again you know what I
actually return is error if the function
where it returns an error so what you do
is consult whatever it comes you just
you know send it to the console which is
again I should see that error on the
screen okay that is not the case else if
them updated or if it returns is
something which is num updated what you
need to do you can put it on the log
that update it successfully as many
documents as many would have got done
and again if that also doesn't happen
what you need to do is you need to put
it like you know I couldn't find a
document with the actually find criteria
that is any item which has item
essential exactly the same way how we
used to do in Native mongodb coding so
again how to retrieve the documents
using node.js so again to retrieve the
document from the mongodb trigger the
find command on the collection object
just as in the mongodb Shell so again
what we have done is first of all get
the documents collection so you can see
where collection is equal to DB dot
collection items so here the collection
variable has the items collection and
now what I'm doing is I'm just trying to
find records which again have some
things so again the way I used to do
over there TV DOT you know orders.sign
is to specify some parameters inside
same thing I am doing instead of the DB
which again used to connect to the
mongodb instance I'm using hair
collection which internally anywhere
that's connecting with the TV
collection.find item is pencil dot two
array so dot two array something which
is exactly same as dot pretty
you used to do a DOT pretty to see a
pretty result instead of that pretty you
can also your dot to array both of them
will do the same thing the difference
between dot two array and pretty is the
two array will bring all the data into
the memory and then show so it's
recommended you always do pretty instead
of you know actually a two array again
it returns two things first parameters
or the result so again if it's an error
give the error to the console if again
it's actually the result again output it
the result along with output the found
along with whatever results we have
actually got
and again if that also doesn't happen
you can just give out in the console
that I couldn't found any document which
had the criteria which is specified in
the find function I now I can actually
retrieve documents using the DB cursor
this again retrieve just by using uh a
simple collection.find method again if I
have to use it using a cursor what I can
do is you can use the DB curves instead
of each document or use two array to
return the full array of all the
documents here what I'm doing is again
wire collection is DB dot collection
items my collection variable has item
selection right now now I already do is
variable car storage below collection
that find item is book you know every
find function returns a cursor so here
that cursor is with cursor then what I'm
doing is again I'm sorting the cursor in
a reverse order of item again I'm
limiting the results to 10 and I'm
skipping zero results it means I just
want the results to be shown from number
one so again now the cursor is with me I
need to iterate on the result which I
get so what I can do is cut dot each
again I can give the function error
comma doc so again I can just do is
again if you get an order console print
it there and again if that doesn't
happen what you do is on the console you
can print it out whatever fetched
fetched is something which will be
printed as such along with Doc so doc
will be something uh the document which
we would have retrieved after the cursor
would have gone through the full
collection so that's how again if I want
to use a cursor to get the documents
this is the way which I can follow
so that what we saw was we saw again
mongodb with node.js again a different
approach the same way however did it but
again the syntax would vary here there
so now again there is a very good module
inside node.js as well which is Mongoose
so what Mongoose helps us do mongoose
helps us you know design the schema in
mongodb so we'll just see you know how
Mongoose helps us design the schema in
 so Mongoose JS is a popular
library in node.js that provides a
straightforward
schema based solution to model your
application data and includes built-in
type casting validation query building
and business logic hooks
using the Mongoose interface features
such as automatic connection and a
collection Pool Management we can easily
work with mongodb to work with Mongoose
you need to First install the Mongoose
module so again all I can do is the way
I ran npm install mongodb similarly npm
install Mongoose will help us install
the Mongoose module once the Mongoose
module is up and running I can fit the
schema like this so in the code you are
doing the following things what you're
doing is connecting to the database
using the mongoose.connect so again I
was connecting over there with mongoded
connect here I'm using the Mongoose
module to actually connect to my
database
and then what I'm doing is creating a
model using the Mongoose dot model so
again to my third Mongoose dot connect
and Mongoose that model let's see you
know how the code does it so again how
to load the Mongoose module in our
program so again please again correlate
with what we started earlier we used to
write where is equal to where
mongodb is going to require mongodb I
actually loaded the mongodb module now
because I need to load the Mongoose
module I write where Mongoose is equal
to require Mongols it'll actually load
the Mongoose module in a program once
that is done we'll connect the database
using the DB server URL so again I get
mongoose.connect this is the URL the
server URL which we use to specify in
the node.js as well that okay localhost
or whatever 27017 again this DB I want
to specifically connect to
once we have connected to the DB as well
we need to Define our model for user
entity so user over here you look at
user as a collection so iOS the way I
design a schema for a table here I will
design a schema for a collection
so let's define our model for user
entity this model represents the
collection in the database so we Define
the possible scheme of user document and
data types of each field so again as you
can see over here where user is equal to
Mongoose dot model
again user is something which is a
collection and again how the documents
in my collection is going to look like
see the name is string rolls is array
ages number so it will even allow us to
store some relational information as
well into my DB this is something which
I remember I guess I don't know whether
you asked it or someone else has this
that you know whether we really need to
set some you know visibility to tell our
 that this thing particular which
I'm giving is a string or integer or
something else so that is something
which I can definitely do over here
or then you know let's create a new user
so again how we create a new user so
where user work is a new user and again
what I just did was I did the same thing
use this schema and again give name as
modular segment ages 42 and again the
role he has is admin his moderator and a
user
once that is something which is done I
can easily add that into my collection
so create view so you perform the
following actionable code given below
create a new user object
so you can create as many user objects
using the model as desired and modify
them so this user object see each object
will represent document in the database
please see this user object whichever I
have created what is this this is one
document
and it says so again see what will
happen is so uh simply learn only gives
you node.js and Java suppose you want to
do it with python but you will say no I
don't know python I don't so okay you
don't even know JS so look at you know
the similarities between being done all
over
things there things they will change the
syntax but the cracks will remain the
same the objects usable over here what
is actually this this is an object and
again same thing is saying is so you can
create as many user objects means you
can create as many collections as many
documents in a collection and again each
document each object will represent
document in the DB that's something
which I guess is pretty easy and you
know straightforward
then what I can do is so I've kept on
adding these user objects now I need to
really save this user using the same
method as well the way I used to have a
save and an insert method in the normal
native mongodb coding same way we have
it over here as well so save the user
within the same method the Mongoose
model has many methods available on the
entity objects in this case you will use
the same method to save the document in
the database so again what we do is so
user one dot name is equal to
user1.name.2 uppercase it means all I'm
doing is I'm trying to update the
document which I already had I had a
user one again I'm just checking that
can you please convert the name into
uppercase once again I've done that I
want to see whether the output is
correct or not all I do is console.log
user1 so in Java I used to do
system.out.pentelin and see I used to do
printf and python I used to do print in
node.js I use console.log so these are
the syntax changes basically I'm just
outputting user one I should see the
updated result when that happens let's
save it use the one that say again the
function will return two things error of
the user object if we get an error print
out this error if we get the user object
again write it save successfully and
give the user object over there that's
how again you know I'm gonna Define a
schema using Mongols that's how I'm
gonna insert updates and documents using
mongoose and with that we have reached
the end of this session on Advanced
mongodb full course if you have any
questions or if you require the
resources that we used in this session
like PPD dataset code documentation Etc
please feel free to let us know in the
comment section below and our team of
Expos will be more than happy to resolve
all your queries at the earliest until
next time stay safe keep learning and
get ahead thank you for watching stay
tuned for more from Simply learn staying
ahead in your career requires continuous
learning and upskilling whether you're a
student aiming to learn today's top
skills or a working professional looking
to advance your career we've got you
covered explore our impressive catalog
of certification programs in Cutting
Edge domains including data science
cloud computing cyber security AI
machine learning or digital marketing
designed in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know more
thank you
hi there if you like this video
subscribe to the simply learned YouTube
channel and click here to watch similar
videos to nerd up and get certified
click here
foreign