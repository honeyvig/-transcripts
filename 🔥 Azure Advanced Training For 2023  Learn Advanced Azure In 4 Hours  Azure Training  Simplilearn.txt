did you know that cloud computing is
revolutionizing the Way businesses
operate in fact Global public Cloud
spending is projected to soar to an
astonishing 591 billion in 2023 marking
a remarkable 20.7 increase from the
previous year this extraordinary growth
showcases the immense popularity and
potential of cloud computing the world
has undergone significant socio-economic
changes with the pandemic and remote
work requirements driving the adoption
of cloud computing companies have
swiftly embraced cloud-based
applications to facilitate a digital
transformation and support remote
workers all while ensuring client
satisfaction as we March into 2023 the
momentum behind digital transformation
shows no signs of slowing down cloud
computing is said to dominate the tech
landscape and you can capitalize on this
trend with simply learns Azure Advanced
full course so join our expert Microsoft
Azure specialist as they guide you
through an engaging video that dives
deep into the world of azure discover
the fundamental concepts of azure gain
an in-depth understanding of azure's
core principles and explore the powerful
features it offers but that's not all we
will delve into the captivating services
offered by Azure uncover its unique
differentiators and discover how it
competes with AWS and gcp so by the end
of this video all your questions are
doubts about Azure and cloud computing
will be answered our experts are ready
to provide comprehensive guidance and
ensure you have a firm grasp of topics
covered if you're craving a more
Hands-On and detailed approach to Azure
simply learns Caltech postgraduate
program in cloud computing is the
perfect fit for you this comprehensive
course will Empower you with the
Knowledge and Skills necessary to
navigate the cloud landscape with
confidence so dive deep into the cloud
architecture deployment models security
and migration strategies gain expertise
in the leading Cloud platforms such as
Amazon web service is Microsoft Azure
and Google Cloud platform don't miss out
on this incredible opportunity to
transform your career and join the ranks
of successful cloud computing
professionals click the link in the
description to explore more about this
course and to help you better understand
the impact of cloud computing and our
cloud computing certifications here's a
success story of one of our Learners
that will help you build your belief and
boost your confidence to master this
technology
I will be permanently moving to Europe
with my family so simply learn this
course has helped me back a great job
offered there will be the 60 salary high
we cannot wait to start our new life in
Finland we are also excited hey I am
and I am currently living in Algeria I
am working as Chief Information
Technology officer at Aries tires after
working for 23 years in I.T sector in
Algeria I felt that my car had become
stagnant here I wanted to experience
what is like to live in Europe so I
started applying to various jobs there
as someone who is responsible for making
a decision I wanted to upgrade my skills
I also realized that to get a new job I
needed to have a professional
certification in cloud computing so last
year I started the postgraduate program
cloud computing in association with
Caltech homestein video it's not easy to
get access to Caltech but simply didn't
provided that with this course I had the
choice to study while I continued with
my job
either Technologies like ews and Azure
during the course luckily my new
employers were looking for someone who
knew these Technologies I have just
copulated the course but my new
employers were aware that I was taking
this course
and that is how I got this new job offer
with 60 percent salary high in Finland I
will be leading the cloud computing unit
of my new company
I am really excited not just for myself
but for my family as well I have 30
dollars I think I will be able to help
them with their higher studies in Europe
as a father you always want to make
decision that have a positive impact on
your children as for me I am going to
live my dream now I think dreams come
true when you work hard to achieve them
also don't miss out on this incredible
opportunity subscribe to our YouTube
channel and hit the Bell icon to stay
updated with all the latest content from
Simply learn in this video we'll go
through Azure machine learning in detail
including its capabilities the Azure
ecosystem that supports machine learning
and the various ways we train and build
models
starting with
what is azure machine learning followed
by who is machine learning for
then we will look into its
infrastructure Readiness and security
then we will dive into machine learning
project workflow
following that we will understand
mlops devops for machine learning and at
last we will explore the Azure machine
Learning Studio
after that we will have a demo too
so without doing any further delay let's
start with the video
so what is azure machine learning
Azure machine learning is a Cloud
solution that helps you speed up and
manage your machine learning projects it
can be used by Machine learning
Specialists data scientists and
engineers in the daily workflows models
are trained and deployed and mlops are
managed
you can use an open source platform like
pytorch tensorflow or scikit-learn to
build a model or use one created in
Azure machine learning
model monitoring retraining and
redeployment are all made easier using
these tools
but this brings us to a question
that who exactly machine learning is for
so individuals and teams deploying mlo
piece inside their company can use Azure
machine learning to move machine
learning models into production it is
safe and auditable environment
data scientists and machine learning
experts will find tools to help them
speed up and automate their daily tasks
tools for embedding models into
applications or services will be
available to application Developers
platform developers will find a strong
set of tools for constructing Advanced
ml technology underpinned by resilient s
Azure resource manager apis
now that we know the basics of azure ml
let's have a look at its infrastructure
Readiness and security
so Azure machine learning is an Azure
Cloud platform that adds security
to machine learning projects
so Integrations for security include the
following network security groups in
Azure virtual Networks Azure keyword is
a world where you may store security
Secrets like storage account access
details
and set up an Azure container registry
behind the v-net
so now let's dive down deep and explore
its project workflow
models are usually created as part of
project with a specific goal and
objective multiple people are usually
involved in these projects iterative
development is used while experimenting
with data algorithms and models
now coming to the Project Life Cycle
while the project lifespan will differ
depending on the project it will
typically look like this
a workspeak space organizes a project
and facilitate collaboration among
multiple users who are all working
toward the same goal
users in a workspace May easily share
the result of the experiments through
the studio user interface
or they can use versioned assets for
jobs like environments and storage
references
so users work can be automated in a
machine learning Pipeline and activated
on a timetable or https request when a
project is ready for operation therefore
models can be deployed to the manage
interferencing solution in real time or
batch abstracting away the
infrastructure management that is
traditionally necessary for model
deployment
now let's proceed further and understand
the concept of mlops that is devops for
machine learning
mlops or devops for machine learning is
a process for generating models for
production use
if not reproducible the lifetime of a
model from training to deployment must
be auditable
mlops or machine learning operations is
based on devops principles and methods
to improve workflow efficiency
continuous integration delivery and
deployment for example these ideas are
applied to the machine learning process
by mlops with the purpose of
experimentation and model deployment can
be done more quickly and quality
assurance and end-to-end lineage
tracking are more efficient ways to put
models into production
now
let's explore what is azure ml Studio
Azure machine Learning Studio is an
online service that includes low code
and no code alternators for project
development and assets Management in
Azure machine learning
basically it is a workspace where you
can create build train the machine
learning models
for inclusive data science platform the
studio integrates no code and no code
first experience
so now that we have covered all the
important concepts of azure machine
learning
let's have a demo for a better
understanding of how machine learning is
used in azure
so let's start with the Demo First you
need to browse the link studio. Azure
ml.net and here you need to login with
your Azure account
so once you have logged in you will be
led to a new window
this is new window here you can see a
few options
so let's start and see one by one what
these options are
so the first one is projects basically
this gives you a list of all the
experiments that you have already worked
on so here you can see we haven't worked
on any experiment yet
then comes uh experiment
experiments are all the programs and
codes that you have worked on to create
it or deploy a model that you've just
created for an experiment
so as I said we haven't created any
experiment yet so the list is null over
here
when you click on samples you can see a
few
sample experiments provided to you by
azure
portal by default
and following that we have web services
so we all know since Azure is a cloud
computing platform so all the data
gathered from our experiments needs to
be uploaded to the cloud so web services
gives you a list of all the experiments
that you have in the cloud so you can
access them from anywhere
so uh when you create an experiment and
work on it when you add it to the cloud
the data is stored here
so then comes data sets
it gives you all the data sets you have
in your Azure portal when you click on
the samples option
again you can see all this data sets
provided to you by default in your Azure
portal
then comes train models
so while working on an experiment you
will come across a point where you need
to train your model
so basically this gives you a list of
all the models that you have trained in
the experiments or Azure programs
and in the last com settings
any changes that you want to make to
your workspace is done under settings
here you can see uh this is your
workspace name workspace description
which is by default and all the details
is provided
here only so whatever changes you want
to make your workspace you'll be doing
this over here
so now let's start with a demo
so down below you can see the ad or new
Option here
so click on it
and then you can see there are a few
ways templates provided by you
provided to you by Azure itself so we'll
click on blank experiment
once you click on the blank experiments
you'll be guided to a new experiment
window
so this is the new window and this
window is divided into three parts
these are the components
where you will plan your model
this is the canvas to design your model
and then the properties of the model
in the components section you can see
samples already present there so you can
select any one of them according to your
requirement so here when I'm typing
samples
uh
I'll work on airport codes data sets so
I just need to drag this option over
here
but before starting with our experiment
let's change the name
so here I'm changing it to airport
codes
demo model
so now you can see the name of the
experiment this changed
now when you click on it
and select visualize
in just a second
you can see the number of rows and
columns provided to it the datas which
is required
for its data set to be created and for
its model to be created
so the four rows four columns are
airport ID city state and name
and now we will move towards the part
where we Define field we need to make a
predictions for so type columns in the
search
bar
under manipulation section
you can
see there are multiple options provided
to you
so here we will select
select columns and data sets
as we are working on data sets
now connect your data set with this
option
so you can see a red alert over here
so
when you click on it
you can see it is asking for values in
your data set so to add values click on
the launch column selector under
properties
section
so once you click on it here you need to
select all the options needed per
required values so for my experiment
model I need all these data sets so I'll
add all of these and then click on the
save option
so let me just add this
let's see now I have saved
all the values I need in our in my data
set
so now you can see the alert is gone
so now we have the data sets that we
want to work on so let's look for an
appropriate algorithm for it
so while looking into the classification
algorithm
we know that our
so here you can see it under
classification model we have
these options
so we know that the target value is
divided into two classifications so the
algorithm we will be using is a
two class
so we will be using two class booster
decision tree
because it calculates the accuracy for
every node and once the calculated
accuracy is more than a required
accuracy then only it moves to the next
node
so basically this gives you a prediction
value close to the accurate value of the
model
so we will just drag this option over
here
so now the next step we have is to train
our model
so we just need to type train over here
and select train model option
so
just drag it to the canvas now connect
the two boosted decision tree to the
train model
now you can again see the red alert for
a required data as it doesn't have any
data to work on so our next step is to
split the data
so we'll type split
and drag this play data option on our
canvas
as you can see this is also saying
it needs an input Port data set so we
connect a data set with it
so
that it is provided with the
data
so when you click on it you can see it
it is asking for a split percentage
so you split the data into training and
testing where 80 goes to training and 20
to testing so we will mention 0.08 over
here
and
so now we will just connect the 80 data
up to the train model
as we said the 80 goes for training
but you can still see the alert in the
train model because it is not aware of
the column
it needs to train on
so we will click on
uh
launch column selector
now you just need to select all the
columns
you need to work on so I'm selecting the
airport ID number
now you can see uh once I save it
but the alert is gone
now our next step is to find the score
of a model so let's type score
in our search bar
and drag the score model over
here
let me just reduce the size of the
canvas yeah
so we will just connect our train model
to the score model
so
again you will see the Red Alert as it
doesn't know the data it needs to test
on so for that we will connect the
remaining testing data in the split data
option to the
score model
now you can see the alert option is gone
now coming to the final step that is
evaluation of the model so let's type
evaluation
and here you can see the evaluate model
option we just need to drag it to the
canvas
so
let's
connect it with our score model
now your model for the airport code data
set is complete so this is the whole
model now you need to save the model and
then click on run option
here I've saved it and
see it's running
you can see the model running and going
through every node
as you can see the green mark
as it's verifying through every node
so once it's done click on evaluate
model
and then click on visualize
now you can see the accuracy is a
98. here you can see the accuracy is 98
which is almost the prediction value now
you can see the positive and negative
labels as well
so this whole data is known as confusion
Matrix
now for the values close to the pos
positive label it gives me the number of
true predictions
that uh the number of data I'll provide
it will it shows that 72 predictions
will be right and one will be wrong
now let's go back and
run this model over the web
so by clicking on a setup web service we
will click on predictive web service
now we will just connect web service
input to the score model
so that once the program is uploaded to
the cloud it is directly connected to
the score model
and gives us the output
so now you need to save this
and run
this will execute the entire model now
all uh we are left with is deploying the
model
now
you just need to click on deploy web
service
so then you will see you will be taken
to a new window
here you can see
the response page where it's showing
test option you need to click on it
so here you can see a new window has
popped up so you just need to mention
the details like for City I am
mentioning Bangalore
for state I'm mentioning Karnataka
and name of the airport is
Camp Pagoda
International
Airport
and I just need to save this data
so now down below you can see it gives
me predictive values
and this is the airport ID
for my mentioned details
so the accuracy of this ID will be 0.98
which is 98 percent
which is almost accurate to the hundred
percent
so this was our experiment and this is
how we can use ml in Azure what is azure
active directory now here we're in a
situation where we have two colleagues
having a conversation with each other so
one of them complains that he is finding
a hard time managing multiple user
logins at the same time his friend
suggests that he has a solution that the
company start using as your active
directory he says that with Azure ad
they'll be able to handle multiple user
logins without any issue so just like
the question in all our minds the friend
asks how is azure active directory going
to help us so to help you understand
let's think about a scenario now you're
an employee working for an organization
and you want to use a particular service
in this case SQL database so you are
assigned a set of username and password
then you want to use another service a
machine learning service again you're
assigned a different username and
password and likewise for any number of
services that you want to use so for
every service that you're going to
choose you need to be assigned a new
username and password but this becomes a
huge issue for the administrator as they
have to handle a large number of
username and passwords now if you think
about a large organization where there's
more than thousand people working you
can understand how much of a hassle it's
going to be for the administrator at the
same time it's also a really difficult
thing for you to remember that many
numbers of username and passwords it's
difficult on the user as well and that's
where Azure active directory helps now
here's a scenario where we're applying
Azure active directory now you're an
employee you want to use a particular
service and you're assigned a single
username and password and with this
username and password you can access all
the services that you want so there's
only one set of username and passwords
that you need to remember you can use
any of the services that you want as
long as the administrator has given you
access to it so what is azure active
directory now Azure active directory is
a service that falls under the identity
domain it allows multiple users and is a
cloud-based directory and identity
management service now here's an ideal
scenario you're joining an office newly
the admin helps you sign up to whatever
Services they want and you can access
these Services anywhere over the cloud
so now let's talk about something
different Windows ID and Azure ad now
Windows 80 was the previous version of
azure ID so now we'll talk about why we
needed to change from Windows Active
Directory to Azure active directory so
what is Windows Active Directory now
it's an OS directory service which
allows you to work with multiple systems
multiple network resources in a unified
manner now the biggest draw when it came
to Windows ad was that it had many
layers now different layers that did
different bits of work so now let's talk
about each of these layers the first
layer is adds or the windows active
directory domain Services now each layer
as I said before has a different role to
perform adds allows admin to manage
information relating to user logins and
other details like when they sign up up
how much they're using and things like
that the next layer is ADLs or the Azure
data Lake storage services this layer is
for allowing you to store any amounts of
data of any type or size then you have
the adfs or the active directory
Federation Services where you're given a
single option for sign up with which you
get access to all systems and
applications then we have the fourth
layer the adcs or the active directory
and certification services this enables
administrators to customize services and
then be able to manage and issue public
certificates and the final layer is
adrms or the active directory Rights
Management Service and this is used for
data protection now here's where Azure
active directory changed the whole game
this means that there's a large number
of layers that administrators need to
take care of now how about there was a
solution for this and Azure ad is that
solution as your active directory
integrates all these five layers into
two and these are the windows Azure
active directory or the the waad where
it combines all the problems when it
comes to identification management which
is almost all file layers taken into one
and the windows Azure Access Control
service enables the Federation or the
division of all these Services of an
organization and by division I mean
assigning each of these services to
these users so that is taken care of by
the windows as your Access Control
service hence as your active directory
is able to simplify a lot of the
problems that Windows Azure active
directory had for example the
application Office 365 uses Azure active
directory to manage user identities
here's how now you're an employee who
wants to access one of The Office 365
Services which could be Excel PowerPoint
Microsoft Word or something like that so
you go talk to the administrator and he
gives you access to these services with
the help of a single username and
password now as long as you have this
username and password and the
administrator has given you access to it
you can use any of these services so
who's the service audience who is using
the active directory service now there
are three types of audience when it
comes to Azure active directory the
first one is ID administrator the second
one application developers and online
customers so the idea administrators
their main emphasis is to ensure that
the sign-in takes place they take care
of all the sign-in procedures they also
solve issues when it comes to
authentication for example to
authenticate a particular user the
problem is solved by the it
administrators then you have application
developers who use these services to
develop applications and with this they
have a easier time developing
applications as all these resources are
easily available you have online
customers who make use of services like
Office 365 and other CRM services and
have all their demands catered
immediately so now let's have a look at
how we can use Azure active directory to
provide access to a particular
individual so if you log into the Azure
account this is what you see or you go
into active directory list of all the
people who are using or have been given
permission to use resources from Azure
okay now we're going to create a profile
we need to set up his name which is John
and second name Jacob
now for properties we need to determine
the source of authority which is already
the active directory so that's fine we
can select a group or add them to a
particular group if we feel like it now
if we add them to a particular group it
means that they have access to all the
resources that everyone in the group has
access to earlier so we'll do that later
we'll select their directory role or we
can select it here if we need to it
could be user administrator or a limited
administrator and now we'll set up a
password so we already got one and we'll
create
and that's it we have created a user now
we'll go to their profile
so what we can see here is that you have
access to every bit of detail related to
this account so you have the name your
first name the username the object ID
job info everything you can even have
other details like how often they've
signed in when did they sign up you can
check their password you can reset the
password delete their account and so
much more
now we can even add a directory role
which we saw earlier and now let's add
this person to the admin group so you
know he gets access to all the services
those people have access to and select
that's it we've added them now the other
things that you can see here there are
applications licenses devices these are
all restrictions you can add or remove
like which device you can use the system
through or with and stuff like that so
that's it and with that we've created a
user and given a Maxis to certain
Services why should you be interested in
data Factory now let's consider a
scenario so here we have two colleagues
having a conversation with each other
and they say that the data that they're
generating from their applications or
products is increasing exponentially now
considering that this data is coming
from a number of different products
it'll be a bit of a task to analyze and
store all of this data so he wonders how
they're going to manage that his friend
suggests that they use azure's data
Factory now what does azure's data
Factory actually do first it stores data
with the help of the data link storage
now any kind of data can be stored in
the data Lake storage then you can
analyze the data you can transform the
data with the help of pipelines and you
can publish the organized data you can
visualize the data with third-party
applications like Apache spark or Hadoop
as well now what exactly is data Factory
so now let's have a look at what exactly
is data Factory now data Factory falls
under the identity domain of services in
the Azure catalog and is a cloud-based
integration service basically what it
does is it works on your data it stores
your data it orchestrates and automates
the movement or transformation of data
it works heavily on the data that you
store now let's see how it actually
works or how the flow of its processes
are firstly we have the input data set
which is nothing but the data that you
have within your data store the one that
you need processed then you pass this
data through a pipeline now what does a
pipeline do a pipeline basically
performs an operation on the data that
transforms it which could be anything
from just data movement or some data
transformation now data transformation
is possible with the help of usql some
stored procedures or high now after this
is done you get an output data set now
this output data set will contain data
that is in a structured form because
it's already been transformed and made
structured in the pipeline stage then it
is given into Link services like Azure
data Lake block storage or SQL now what
it does is restore information that is
very important when it comes to
connecting to an external Source now
this is you know if you wanted an
example you know how in an SQL Server
you need to mention the source and
destination of your data now for example
consider an SQL Server so you need a
connection string so that you can
connect to an external device you need
to mention the stores and the
destination of your data this is how the
Link services work and finally you need
a Gateway now a Gateway basically
connects your on-premises data to the
cloud so you do need a client installed
on your our on-premises system so that
you can connect to the Azure cloud and
finally you have the cloud here what
happens is your data can be analyzed or
visualized with a number of different
analytical softwares like Apache spark R
Hadoop and so on so all this time I've
been mentioning that data lake is a very
important part when it comes to Azure
data Factory's proper functioning so now
let's talk about what exactly is data
Lake now data lake is a data storage or
a file system which is highly scalable
and distributed it is located in the
cloud and works with multiple analytics
Frameworks which is external Frameworks
like Hadoop Apache and so on so now
let's have a look at it so first you
have your output data set which is data
from the mobile video web social media
so much more it is sent into the Azure
data Lake store and then it is provided
two external Frameworks like R Apache
and Spark so that they can be worked on
now there are two main Concepts when it
comes to data Lake storage so so one of
them is storage and the other one is
analytics now storage is of unlimited
size it can be petabytes terabytes
gigabytes and so much more it shows a
wide variety of data it could be
unstructured or structured data and it
can store really large files and another
concept when it comes to data lake is
analytics now how it works now here are
two examples of how analytics works when
it comes to data Lake now when it comes
to analytics you can monitor and
diagnose real-time data for example data
that you're getting from vehicles or
buildings these can be used to optimize
how they work respond to certain events
or generate alerts in case something
goes wrong then you can also identify
fraudulent transactions on your credit
card or you can identify the current the
geographical position of your card
perhaps monitor how many transactions
have been taking place on that card and
so on so now we're going to have a look
at how we can use the Azure data Factory
to move data from an SQL database to a
blob storage on the cloud so here's what
we're going to do so first off to make a
database what you're going to need a
software known as ssms so you can find
it on Google it's called you just need
to Google it ssms the first thing you
can take here and there you have it so
you just need to click here and download
the file so we I've already downloaded
the file so basically this is used to
create a database which we'll be
transferring to The Blob storage so this
will take about depending on your
computer speed pretty long or little to
no time I've already downloaded it the
process is very simple just directly go
on saying yes yes and finally once the
installation is done here's what we're
going to do we should go into the
dashboard of Microsoft Azure we need to
create a data warehouse so we'll go into
all the sources Creator Source go to
database
and select SQL data warehouse there we
have it now it's very important that you
remember the names of the service of
everything that you're going to write
here because each of these become very
important later on so I've already set
up a possible set of names
YouTube
it's free trial resource is already
created
a blank database the server we need to
create a new one so
we'll name it as YouTube server
YouTube
admin as the server admin login the
password as
right the location does not matter
okay that's done now here the server is
done and here we need to change how much
you want the lowest I mean how much
computation you want how much did
workload how important your workload is
so we'll put it at the lowest since we
don't require much we'll apply the rest
is normal and great
so now we're creating an SQL data
warehouse so we'll wait so now the
deployment is done so we'll go to the
notification and go to the resource here
now this is done so we'll go to the ssms
which I've already opened here and then
go here
and copy this paste it here SQL
authentication login which details we
have already stored here which is admin
YouTube admin and the password which is
also given there
options we go to the database name which
is YouTube
everything else is there we need to
change it to TCP
and connect
you sign in
we'll add the password
again we're going to sign in now
right
so now that that's completed you can see
that this is what will pop up so this is
the name of the server we've given as
you saw earlier we've got a databases
and here you have the YouTube database
that we just created right click this
and add a new query
I already have a code for this program
it's a very simple program so
copying and pasting this
now if you need the code for this
program let us know in the comments
below it's very simple what we're doing
is creating a table called demo tab with
first name Clark Kent last name is Bruce
Wayne and the table that's created will
have these two rows so now we're going
to execute this there you have it two
rows have been affected so now let's
have a look at our table
um
let's give this line and there you go
the tables here so now that this is done
we're going back into azure
back and we need to create a storage
account so that's where the storage
where the blob storage is going to
happen so we're going to storage
accounts and click on ADD so here it's a
free trial Resource Group is YouTube
storage account name is
okay us performance is standard
general purpose
you can do locally since we don't need
to be very reliable at least for this
one Advanced just fine view and create
that's done and we create now we'll wait
for the deployment to finish
and that's it the deployment is done so
we'll go to the resource
and go to blobs so this is where the
storage is happening we need to create a
blob
simply
blob
which does not exist and okay
it has been created
now for the next bit we need to create
the data Factory now so we go to all
services search for data Factory
we press add
so here we'll
free trial use existing which we have
YouTube ecos and create so now we've
created a new data Factory
now we'll wait while it's been deployed
so now it's created so we'll go here and
here we click on copy data and this
opens up
we'll name it
description and once now
I want to know okay
all right so we press next so we need to
connect to a data source so so what you
need to do is select a secure Azure SQL
data warehouse so once again go to
previous here we select Azure SQL data
warehouse go here
search for
source
as your subscription free trial a
YouTube server and the databases YouTube
you also need to provide your username
and password I've saved it here
YouTube admin
[Music]
right
okay now we can select the table which
is demo tab next
next
and now for our destination so where are
we going to connect this to we're going
to Azure blob storage next
destination
subscription free trial and simply store
now we need to name our
name our storage path next although this
can be
passed on so here's what we're doing it
copying whatever is inside this to the
Azure blob storage that's what's
happening right now
all of that is set
and
next
it's validating and we'll wait now
it's registering connections creating
database and in the end it's creating a
pipeline
so you can monitor the pipeline from
here if you feel like it
now here's what we're going to find so
here's the here's the visual
representation of what's Happening
it's being copied into the blob storage
now let's have a look if it's actually
worked out go to our database we'll go
into
storage accounts simply store
go to blobs
we've created a new one
and there you have it So based on the
container that you've named there it's
created a new one here so actually I
earlier created the name called simply
blob but as you can see here as long as
you name a container we'll create a
folder inside which you will find your
particular thing that you copied and
that's it you've copied data similarly
you can do a number of multiple
operations on this container on the on
the pipeline you just created with the
data Factory and that's that now we know
what Azure is and its key benefits let's
now move on to on to Azure watching
machine
before that let's consider a scenario
Rachel had to host 10 virtual machines
at once per project there was an issue
when her computer RAM was not compatible
with the instances the computer RAM was
only 8 GB and the instances that
required were 10 GB then she says I wish
there is a service that's cost effective
and also provides extra RAM memory one
of a colleague heard this and he comes
up with an idea he says can we use Azure
virtual machine it has a pay as you go
pricing and has this for storage
you can pay for what you use and create
any number of instances with high
storage capacity also if any technical
difficulty arises you can easily
retrieve the files through the backup
server so now she's happy and she wants
to know more about Azure washing machine
Azure virtual machine is one of the wide
range of services that Azure offers to
create your instance a virtual machine
is a computer file typically called an
image which behaves like an actual
computer it runs in a window giving the
user the same experience on a virtual
machine as they have on the host
operating system itself multiple virtual
machines can run simultaneously on the
same physical computer each virtual
machine provides its own Hardware like
CPUs memories and other devices as your
watching machine offers a high range of
flexibility and it maintains the
physical Hardware that runs on it let me
explain some of the benefits of azure
watching machine first we have easy
development and test as your virtual
machine has a quick and easy way to
configure the computer that is required
to code and test an application next
agility and scale Azure virtual machine
is agile and the ability to clone and
spin up multiple instances of the same
virtual machine allows us to scale
services and applications rapidly
efficiently and very cost effectively as
your virtual machine provides enhanced
performance demands for applications can
fluctuate so you pay for the virtual
machines you need and shut down the
unnecessary ones to save the cost
as your virtual machines provide
extended Data Center and can be easily
connected to an organization's Network
it is easy to set up your redundant
infrastructure in Azure and Azure
provides a full Disaster Recovery site
at a fraction of the cost furthermore
let me explain Azure virtual machine
components in details virtual machine
comes under the compute domain of azure
it also offers various services like
availability sets snapshots disks images
and many other services like hosts
virtual machine can be clubbed with
other services like disk images
availability sets hosts and many more so
the first component and the most
important component is the operating
system the operating system creates
connections to the remote desktop
session host there are many operating
systems available like Ubuntu Red Hat
Linux Windows Server sent OS you can
also set the operating disk size so that
the memory is not wasted the next
component is disks as your original
machine use attached virtual hard disks
for storage take two types of virtual
hard disks first is an image it is a
template for creation of new Azure
virtual machine then we have disks it is
a bootable virtual hard disk all durable
disks are backed up by Page blobs in
Azure storage therefore the disks
inherit the benefits of blob storage
High availability durability and many
more with this amounted as drives on the
VM the next component is virtual Network
many components operate the virtual
machines in a scalable and secure manner
virtual networks could include equipment
such as separate Network spaces for
internet facing and back-end servers
load balancers firewalls and more many
of these components are deployed into an
Azure virtual Network as your virtual
Network provides many features such as
subnet IP address load balancer and
Network Security Group
another important component of azure
virtual machine is availability sets if
in case there's a slight chance there
could be a failure in physical servers
then these come into picture so in case
of such failure the Azure platform will
migrate the failed virtual machine to a
healthy host to reconstitute the VM it
is highly recommended to deploy at least
two instances of the virtual machine and
virtual machines placed on an
availability set perform identical set
of functionalities
now that we know what Azure virtual
machine is let's look into the demo in
this Demo First we are going to create a
virtual machine connect it and then
create a web server and modify the web
server and finally launch the web
application so let's go ahead into the
demo now so the first step is to log
into Microsoft Azure with your
credentials now let's click on Virtual
machines and create a new one
so I can put add
and you can use the subscription you
want either pay as you go pricing or
free tile
Resource Group will create a new one
that is pre-roll
one
okay virtual machine we can create I'm
going to use VM web
001
and then region I'll be using Okay East
US
then image I'll be using Windows Server
R2 Data Center
size I'll be using B1 MS
select
username and admin
and then password of your choice
and then I'm going to allow selected
ports and choose rdb3389
and next
so always this step I'll be using
standard HD
and then
yeah next
so I can see a default virtual Network
and a default submit in public IP as
well as default
then next
you can allow for auto shutdown but
again it's entirely your choice
I'm going to select an extension to
install and I'm going to install
Microsoft anti-malware
create okay
I'm going to create a few tags now let's
go ahead with it
so I've created Five tags now review
plus create
okay so everything seems good let's
create now
so the deployment is going to take a few
minutes let's wait for it
okay so that's done now let's go to
Virtual Machine and see our virtual
machine
okay so it's been deployed
now let's get into the virtual machine
and copy the IP address
then hit Windows plus r
and open mstsc
and
paste the IP address and connect
let's use a different
account you have to use the
administrator account that we created
before with the same password
click ok
now the remote desktop session host
opens
the next step is to click on server
manager
and add rules and features
click on next
select rule base of feature based
installation and click on next
then select the virtual machine you've
created and next
and then we are going to select
web server IIs next
sorry
okay so it's already installed my
computer but you have to install this
then let's close this
and open Internet Explorer
let's type in
http
localhost
yeah so now we can see the default was
opening let's minimize this
and let's try it here
we have just put the IP address
I think there's an issue
okay so let's add an inbound Port
networking select networking and add in
one port
let's move for DT
and add
okay so it's added now let's go into
fresh it
now we can see the default web browser
opening so the next step is to modify
the web browser let's go ahead with that
go back to your remote session host
let's go file explorer
so certain folders are created from the
C drive let's open that
it would be under eyelid Pub
because this is where the default is
coming from now let's make a new text
document
open that and put
hello
welcome
to this demo
by simply learn
save it
close it let's rename this as
index
dot HD sorry
Mill
so this is a text document so we need to
change that
okay let's remove this
okay
let's start
now let's go back to our Internet
Explorer and hit F5
let's refresh this
let's try and okay so let's
yep so it's done now let's go back to
the previous browser and try let's
refresh
yeah that's done
if you're craving a more Hands-On and
detailed approach to Azure simply learn
skal Tech postgraduate program in cloud
computing is the perfect fit for you
click the link in the description to
explore more about this course first of
all let's look into why is azure virtual
Network important
so why Azure virtual network is required
so somewhere far away at an office a
company was struggling with few
challenges
the company got a bigger projects which
lead to the following challenges that
includes poor network connectivity time
consuming process and building Network
topologies could not divert Network
traffic to its destination on time so
these were a couple of challenges the
company was facing so the employees
thought that what could be the possible
solution to these challenges
and then we require the Azure virtual
Network in that case so first of all
let's understand what is azure virtual
network is an Azure v-net or a virtual
Network represents your network or
environment to run VMS and applications
in the cloud
when it is created the services and
virtual machines within the network
interact securely with each over the
Internet so virtual Network you can
consider it as a virtual Cloud which is
basically kind of a cloud space
virtually assigned to the users or or to
the organization which they can
dedicatedly use for their purpose so for
example if you have to create some
instances or virtual machines onto the
Azure cloud
and you want to connect it with the
on-prem servers for example then you
might require the virtual Network in
that case let's assume that those
instances that are created in the
virtual Network require the range of IP
addresses that you want to allocate to
them and that is something you can
customize using the Azure virtual
Network
how do you want that the traffic should
be routed to your instances in the
virtual Network how the firewall
Securities should be applied everything
the end user can control in the virtual
Network so it seems like that you are
working in your own data center ideally
you would be working on to the Azure
Cloud using the virtual Network
now what are the advantages of using the
Azure virtual Network so couple of them
are it provides an isolated environment
for your application so as I said that
it feels like it seems like that you are
working in your on-prem environment that
means within your data center but
ideally it is a virtual space that is
allocated to you which is a kind of an
isolated environment and that is
specifically designed for your tasks and
the activities
are generally a subnet in a v-net can
access the public internet by default so
we create a subnet inside the virtual
Network which can access the public
internet so there is a public network
connectivity that is enabled in the
virtual net so that a subnet which will
be created in the v-net can be accessed
traffic can be easily filtered from
different resources so you can have some
control lists defined you can have some
security groups created and how do you
want to allow the traffic onto the
servers or the application that is
something which you can control it is a
highly secure network and the security
groups and the policies are basically
implemented by the end user so you can
design how the security should be
implemented High network connectivity so
you have a higher bandwidth as compared
to the normal internet connection you
might be having in the data center
compared to that you use the Azure
Network only which gives you the higher
network connectivity it builds
sophisticated Network topologies in a
simple Manner and which is easily
manageable as well as there are less
troubleshooting issues that we would
encounter
now what are the components of azure
virtual Network
one of them is the subnets
then you have routing
then you have network security groups
now what do we mean by subnets
the subnet is one of the major or a
prime important component in the virtual
Network so what you have to do is first
obviously you would be creating a
virtual Network
inside that you can create the subnets
subnets you can consider it a logical
partitioning or virtual partitioning
inside the
virtual Network
subnet lets user segment the virtual
Network into one or more sub networks
for example let's assume that you're
working in an organization and in the
organization there are different
departments for every Department there
should be some set of IP addresses that
you want to allocate to the machines
that the employees are using or all the
department should be isolated that means
that they should have their own network
IDs and the network addresses allocated
to their machines and in that case what
you would do is you would create the
subnets and the subnet IDs that would be
allocated to those departments these sub
networks can be separated logically and
each subnet consists of a server so what
you do is when you create a subnet you
can you can create a server or an
instance inside that subnet and how do
you want to give an access to that
instance depends on criteria or the
requirement
hence a subnet can further be divided
into two parts one as the public subnet
and the other one as the private subnet
these are the naming conventions of the
subnet then how do you want to give the
internet connectivity depends on how the
public subnet should be interacting with
the internet and for the private subnet
as the name suggests that the internet
is blocked so that means it is
completely isolated in the virtual
Network
the private instances though if you want
that any instance created in the private
subnet should have the internet
connectivity or an access you can
primarily go with the NAT gateways in
that case which is a network address
translation or kind of a translator
which converts the private to public and
vice versa
and that would actually enable the
internet connectivity to your subnets
then in the public instances they can
directly access the instance as the name
suggests public instances that public
subnets that means they have the direct
internet connectivity next component is
routing and the routing is primarily a
routing rules you can say that are
applied and those are actually applied
to the routers only so since on the
cloud we cannot have a direct router
access and hence using the routing as a
component we can Define some routing
rules which are directly applied to the
router in the infrastructure
it delivers the data by choosing a
suitable path from source to destination
for each subnet Azure virtual Network
automatically routes traffic and creates
a route table when you create a virtual
Network automatically a route table is
created and that basically is required
to Route the traffic and that can be
used by every subnet that doesn't mean
that you only have to create a single
route table in the virtual Network you
can have multiple route tables also
created which can be associated with
different subnets as well then you have
the network security groups it is kind
of a firewall that protects the virtual
machine by limiting the network traffic
it restricts inbound and outbound
Network traffic depending upon the
destination IP address port
and the protocol so it is basically
the network security group sits on the
instances and uh or virtual machines and
they basically Define that how the
traffic should be reaching to the ports
onto the virtual machine so how do you
want to open up the ports and for which
IP addresses you want to open up the
ports that is something the end user or
the administrator has to specify our
design so they act as a kind of a
firewall rules only that protects the
virtual machines
so how to launch an instance using azure
v-net so first of all you have to create
a virtual Network so virtual Network act
as a container for subnets so first
thing is that you would be creating a
virtual Network then you would be
creating subnets which are considered as
a subset within the virtual Network
so Cloud instance is included in the
subnet so first v-nets are created then
the subnets are created and then you
configure the properties in the security
group
have a look at this in detail
now with respect to the virtual Network
what you need to do is you have to
create a virtual Network in the Azure
cloud
then you have to create subnets into
each virtual Network which is kind of a
subset of a virtual Network so you can
create one as a public subnet the other
one as a private subnet for example
now you have to assign instances so when
you create an instance you have to
specify that what is the virtual Network
for which virtual Network you're
creating an instance within that virtual
Network you have to select that on which
particular subnet the instance should be
created and then connect instance to a
relevant network security group so
attach your network security group to
the instances and based on the
properties or the rules that are defined
in the network security group that will
be applied to the instances within the
subnets finally configure the properties
in the network security and set the
policies as a result you will be able to
launch your instance on Azure within the
virtual Network
now we will be seeing one demo that how
we can create Azure virtual Network
subnets and new network security group
so just be there to watch our demo on
the Azure virtual Network in today's
session I would be showing how you can
create the virtual networks onto the
azure
and for that you require the credentials
on Microsoft Azure and here you can see
on my screen that I have already logged
in into the Azure console
now what you need to do is in order to
search virtual Network you can type and
search in the dashboard in the search
bar with respect to the virtual Networks
and here you can find
the virtual Network and the gateways so
what you need to do is you just have to
click on the virtual networks and then
it will give you the options to add the
components inside the virtual Networks
so let me first open up the virtual
Network
right now in theory we discussed that
the virtual network comprises of
multiple components and sub components
so primarily is that first you have to
create a virtual Network then you have
to assign the ipv for cidr Block to the
virtual Network
and then you create the subnets inside
the network which is a subset of the
virtual Network along with that you
define the routing rules and likewise
you create the instances inside the
subnets that will be part of the virtual
Networks
so that's what we are going to do uh in
this demo so I would be adding up a new
virtual Network so you can see here
there are already two virtual networks
that have been added one is the demo
v-net which is by default so when you
created the Azure credentials the demo
virtual network was already created by
the Azure so that it can provide you the
default settings and then the test one
has been created by me and that's the
customized one or you can say a
non-default virtual Network
so I'll I'm going to add another v-net
and
would Define
the name to it so let's wait for
the details to appear so here you have
to define the virtual Network to create
obviously we will be going with the free
trial only and then you have to create a
resource Group so what is a resource
Group it is primarily a collection of
resources that share the same lifecycle
permissions and the policies so if you
have a resource Group created you can
use it otherwise you can create a new
Resource Group so I already have one
that is the demo one I would be using
that in the instance details you have to
specif the name of the virtual Network
so these are certain
uh parameters that you have to go with
while defining the name so let's say I
put something like test v-net
as the virtual Network that I want to
create and that is you have to select a
region where you want to get that
created so these are the available
regions that you can select I would go
with us East
us only and then we have to define the
IP addresses also
see so in the IP addresses uh these cidr
blocks are allocated to the virtual
networks and that becomes a fixed IP
address for that v-net so what you can
do is you can specify a range of IP
addresses now whenever we talk about a
virtual Network and the IP addresses we
primarily focus on the private IPS only
so this is the private IP that we are
actually talking about so I can reserve
some IP address cidr for our v-net and
that is the range of
40.0.0.0 16. I'm going to reserve so now
we'll create one subnet and we'll name
that subnet so as we discussed that
subnets are the sub components of the
v-net so here you can see we have
already created one
subnet with the name public subnet so
likewise we can add another subnet also
and let's name it to something like demo
subnet right and the subnet should have
the IP address range and that IP address
range should be part of the winner in
vtn so same subnet address range you
would be defining in the subnet as well
so that will be 40.0.1 dot or we can
select 2.0
slash 24.
the rest of the things would be default
we are not attaching any route table as
of now so just click on OK and here you
can see that the subnet is created
now once the subnet is created now we
are going to create a virtual machine
inside that subnet and for that we'll go
to the search bar and here we'll type
virtual machines
now we'll create a virtual machine in
the same v-net that is the test we net
and inside the demo subnet so that our
virtual machine gets the private IP
address from the subnet that has been
created in the v-net itself so what you
need to do is you have to open up the
virtual machines click on ADD
and here you should add a new virtual
machine
so you should select the name of the
virtual machine and the network details
where we would be defining the v-net as
well as the subnet where the virtual
machine should be created
so in the subscription we'll go with the
free trial and in the resource Group we
will go with the demo that has already
been created we'll put a virtual machine
name uh something like test VM
and the rest of the things will be
default
so we'll quickly skip the disk check
also now in the networking we would be
selecting
the test we net as our virtual Network
and in the subnet we would be selecting
the demo subnet so that is the recently
one added in the test we net and we want
that our virtual machine should be part
of that subnet only
now obviously since we are creating a
virtual machine so it should be part of
it should have the public IP also
assigned since from the public network
we need to access those virtual machines
so we'll keep it enabled right and the
next uh would be the default settings
that we are going to proceed with
so let's review all the configurations
and then
create your virtual machine
so here you can see that our virtual
machine has been created validation has
been passed and it takes couple of
minutes to get that updated so let's
wait for a few more minutes so that our
virtual machine is ready and primarily
what we want to look into is that our
virtual machine is created in a correct
v-net and it gets the private IP address
from the subnet that has been part of
the v-net which has been defined in the
creation of a virtual machine so let's
wait for a couple of more minutes and
we'll look into the status of the main
now you can see here our test virtual
machine has been created now what we
wanted to look into is that our virtual
machine is created in a correct subnet
or not and that is something which we
can validate by checking the private IP
address so it got the private IP from
the range of the IP address that we have
specified in the subnet now in order to
access this particular virtual machine
you have to use the public IP since uh
since we have to access it from the
internet so from the private IP the
social machine will not be accessible
so that's the reason that when we
created a virtual machine we allocated
the public IP address also for this
instance
so that is with respect to
uh the virtual Network and the
demonstration on it and how we can
create a v-net and the sub components of
the v-net how they are associated or
interlinked with each other and that
actually creates a kind of an isolated
environment on the public Cloud which
gives you the understanding that you can
work into uh just like an on-prem
environment
so what is azure devops Azure devops
enables Steam
steel organize work collaborate on code
development and build and deploy
applications using developer Services
Azure devops the culture and set of
protocols that brings together
developers project managers and
contributors to collaborate on software
development it enables businesses to
create and enhance products more quickly
then they could with traditional
software development methods you can use
Azure devops services in the cloud or
Azure devops server on premises
Azure devops has built-in functionality
that you may access via a web browser or
an ID client depending on your business
needs you can use one or more of the
following standard owned services
Azure repos Azure devops a built-in
functionality so for sourced management
of your code Azure reports offer git
repositories or team Foundation Version
Control
Azure pipelines build and release
services provided by Azure pipelines to
assess continuous integration and
delivery of your applications
Azure boards using kanban and scrum
methodologies Azure both provides a set
of agile tools for planning and tracking
for code bugs and issues
Azure test plans manual and exploratory
testing and continuous testing are among
the options available in Azure test
plans for testing your applications
and at last Azure artifacts this allows
teams to share packages from public and
private sources including Marvin npm
nuget and more and it a corporate
package sharing into their pipelines so
this brings us to the features of devops
first we have is dashboard control you
can rapidly navigate to different
regions of the project build and manage
dashboards and set dashboard widgets
using the devops dashboard functionality
then we have improved Source control git
and team Foundation Version Control a
centralized client server system which
are two prominent method of source
control supported by Azure devops
solution to observe change history you
can add and manage Azure git tags
reviews downloads and modify files
following that we have plan and track
your work you can utilize Azure devops
systems to track teachers requirements
user stories tasks issues and more using
a variety of work items then we have
integrated collaboration servers Zoom
that allows teams to collaborate
throughout the whole Azure devops
feature set including team dashboards
project Wiki discussion within work item
forms and many others then we have
support for exploratory testing manual
exploratory and continuous testing are
made easier with Azure devops which
include workflow customization
end-to-end traceability criteria based
selection and real-time visualization
that show the test activities and at
last comes continuous integration and
deployment many developers use CI CD and
Azure devops makes it so easy to do so
developers May automate various design
activities with Azure pipelines
including defining and Building
Association steps writing test
instructions and managing simultaneous
releases well this brings us to Azure
devops services
you get an integrated set of services
and tools with Azure devops to manage
your software project from planning to
development to testing and deployment a
client or server model is used to
deliver these Services many of them are
offered via a user-friendly web
interface that works with all media
browsers The Source control Bill
pipelines and work cracking are just a
few of the services that may be managed
to a client you can see the left pane is
where to access Azure devops Services as
demonstrated in the figure below so now
that we have covered Azure devop
services
let's move on to Azure devops server
Version Control reporting requirements
management project management automated
bills testing and release management are
all capabilities of azure devops server
a Microsoft product it provides devops
features and spans the complete
application cycle so now that we know
what Azure devops services and Azure
develop server are so let's have a crisp
comparison between them to know how
exactly they differ from each other
despite the fact that Azure devops
service is a hosted version of azure
devop server there are seven features
that differ some functions of azure
develop server aren't available in Azure
devops services
so when deciding which platform to use
or considering a transition from
on-premises to the cloud keep the
following points in mind cope and scale
data authentication users and groups and
manage use access so first is scope and
scale data Azure devops services and
Azure devops server are slightly
different
organizations and projects are currently
the only alternatives for scoping and
scaling data Azure devops Services
organization get their own URLs and
always have exactly one project
collection whereas deployments project
collection and projects are the three
methods of scoping and scaling data in
Azure devops server then we have
authentication to connect to Azure
devops services using the public
internet depending on your
organization's Arrangement you can use
Microsoft account credentials or Azure
ad credentials to login you can also
configure Azure ad to require
multi-factor authentication IP address
restriction and other security features
but you connect to an intranet serving
using Azure devops server Windows
authentication and active directory
doming credentials are used to log in so
this method is completely open and you
will never be asked to sign in next we
have users and group you may use a
similar technique to Grant access to
groups of users on Azure devops Services
Azure ad groups can be added to Azure
devops Services Group so you must add
users one at a time if you utilize
Microsoft account instead of azure 80.
on the other hand by adding active
directory groups to multiple Azure
devops groups you make chance user
access to deployments in Azure devops
server the membership of AD groups are
kept in sync so users gain and lose
access to Azure devops server as they
are added and withdrawn in Erie and at
last there is manage user access to
manage access to features in Azure
devops and Azure devops server by
signing users to an access level each
user in your Azure devops Services
organization must be assigned an access
level as usual as Visual Studio
subscriber sign-in Azure devops Services
verifies them so without a visual studio
subscription you can give basic access
to five users of coffee whereas all use
of azure devops server is on the honor
System specify the access levels on the
administrative Administration page to
set access level per user based on their
license and assign unlicensed user
stakeholder access only so now that we
have covered all the important features
and concepts of azure devops now let's
move on to the next very important
aspect of azure devops which is azure
devops lab
the Azure devop lab is a place where you
can learn about software development and
operations with Azure devops Services
you can simplify and speed up the devops
process it explains how to use Azure
devopservices to automate software
delivery and satisfy business
requirements so to understand it in a
better way let's have a demo of azure
devops lab so let's start with our Azure
devops demo so first what we need to do
is navigate to this
website Azure dot microsoft.in or we can
directly login through
dev.assure.com also the first what we
need to do is sign into a Microsoft
Azure account
so after
signing in
will be led to this page in that
you just need to click on continue
and here what you need to do is create
an organization under which you're gonna
create your projects multiple projects
and you're gonna attach your team
members to it or group members to it
when you want to give the access
to your projects
so what is the difference between
organization and project is if you have
given anybody access to your
organization or somebody is a part of
your organization then
then that particular individual will
have access to all of your projects but
if you have given somebody only access
to a project then you'll be only
restricted to that particular project he
won't be able to access any other
project that is present under that
particular organization that you both
are part of so basically organization is
something that is used to connect to
groups of or related project or somebody
who is already a part of a particular
organization so here we will give it a
name so I am giving uh simply
demo as the organization needs and here
you can see that the projects under this
organization will be hosted under the
South India region
and you need to enter the captcha
and click on continue
in just a second
so now you can see this saying that it
is taking you to an organization
okay so we already have an organization
of the same name so let's just change it
to something else let's give it simply
demo
org
so here you can see that I see this
thing that it's taking to your Azure
devops organization where you'll be
creating your projects
so now you can see your organization
name
here
and well you just need to create the
project name
so I'm giving it to
simply
gem
project
not below you can see the visibility we
can opt either public or private so what
is public or private so basically if you
keep its keep the project off keep the
visibility of the project public then
once
you copy this
URL
so as I was sitting once you copy this
URL into some other browser or incognito
mode you will be able to have the access
to the project
but if you keep its visibility private
then only the people who have real
access to your organization or to your
project will be able to access that
project or will be able to see that
project or work on it
as you can see public products are
visible for our organization so we can't
select public so we'll go for private
and click on create project
now here or you can see
the home page of your organization where
you have
this project
and here you can access the statistics
of project how it is performing how much
time you have contributed to it or what
all services you have added to your
project
and down below you'll be able to see
that there is just one member which is
the root user of this project and once
you start adding more members to your
project it will their details will be
added to this particular
block
so now here you can see these other
services boards reports pipelines test
runs
and artifacts services that is provided
to you to add to your project
so now let's have a look
at them one by one so first one is votes
as we click on boards you can see
multiple options there are work items
both padlocks Sprints queries delivery
plans
here you can see it is all empty as we
haven't added any service or we haven't
worked on a project yet
let's just click on
new work item
so here you can see one is epic issue
and task
so epic is an option that is uh you can
see a pro auction
for work items
so basically epic represents business
initiative to be accomplished and it is
basically available for basic agile
scrum and the cmmi process templates
so what it exactly does it increases
customer engagement that whoever
whatever your project is if it's
uh the engagement
of your project that how it's performing
and how it is performing towards the
people
whom you have given access to the
project also helps to create new
architecture to improve the performance
of your project
and it also support mobile application
so basically when you're deploying any
mobile application in your project or
creating a mobile application as a
project so it will be able to
support that as well
let's click on it
so here you can see you need to enter a
title for your
epic option
so where you need to add the title of
the Epic like for say
we are creating a healthcare or an
e-commerce application so obviously it
will be segmented into different parts
like you'll be having search options or
Support options or home page so we just
need to give with a name
and where you can see its state is to do
for now we just have to do because we
haven't
actually created anything in our project
and we haven't given any input
so it's in to-do list and once we start
working on it it gets we can change the
state it it can be in progress or
completing so there are multiple States
for your Epic
and here you can see the area is simply
done a project that means that we want
to assign this
search you know Epic into this project
and we can also click description over
here that what exactly our new epic is
about like for search options we need to
specify or give a description that
this is for searching options related to
our application like for healthcare one
can type
medicines or
doctors
or slots
so
that is that that is thing that we can
add in our description
that it will help the user to understand
what this feature is about
so this was epic and once done we can
click on Save
so here you can see other
starts also like priority
so we can select priority according to
our
will so here by default it is probably
two
so priority basically is which function
will come first
and here you can mention start date
Target date
so once it's done you can click on Save
now let's move
to the next one
second what we have is issue
so basically issues are the for you to
track your work
and the epics are used to track the
group work under large scenarios but
this is that like like we saw the
project statistics so it will help you
to understand the individual progress
so basically issues are raised when you
find any obstacle in your
progress or in your work so it can be
compared to impediments also so when
you're working with agile uh
you need to deal with issues so by
default we have agile
to our project assign
so like for example we can see that uh
we have a meeting so during the meeting
members report if they have encountered
any bug or any any impediments
so what next we have to do is we have to
track them and resolve it so these are
the issues that can uh one can find
like possibilities
so you can assign here
and give it a description again
and just save it so
once a user faces these issues
we can keep a track of it
and
once it is raised we can resolve it
coming to the
next one
next we have is task
so by the name only we can uh well
understand what task is
so a task is a smaller item or
smaller segment to track activity
that contains all the information needed
to accomplish a part of a of an issue or
you can say user story requirements so
this option is available for basic agile
scrum and cmmi process templates
so again we can give it a name what task
we want to assign
and give it a description
and according to that we can
select the priority
and save it
so the task will be added to your
project
we are not for assigning any tasks right
now because as I said we haven't added
any uh particular
project or particular details or
application or we haven't deployed any
application yet in a project so
that is why we are not adding anything
over here again because first we need to
understand what these services are and
what these services are used for
next we have backlogs so backlogs helps
you
to understand the flow of your problem
like today you have contributed 10
percent
of your time and you have completed the
10 of the work or you have worked on
certain segments of the project like for
say you have worked in the support area
so
it helps you to
understand and keep a track of the flow
of your project how it is performing and
how it is developing and how it is built
every day
thank you
next we have a string
so Sprints are basically a time box
intervals that support set team's
ability
to work using the agile processors and
tools so what you can do is whether
you're having let's say you're having a
healthcare application so you just need
to
have a segment of it and drop it over
here
so what would what it will do is uh it
will get attention of all the team
members so basically what it does it it
makes the project more manageable
it increases the quality of your project
and also makes it work even more faster
and more frequently once you add the
segment to the Sprint so you can see it
in one way that's the priority and
people need to work on it and it gives
your project more flexibility to adapt
to change
now now sometimes what happens is many
Associates Trump Sprints with agile
software development
so sometimes
agile often thought to be the same thing
coming to the next one we have queries
so the creative page basically remembers
the view you have
last navigated and when you log in again
or when you come back again
the same portal it returns you to that
very particular view only
so it can you can say that it runs with
Azure devops command line interface
and all the open like all the pages like
you have gone through you can keep
attack of it over here
you just need to click over here all and
you can just see all the queries you
have
uh Define in all this while and also you
can share the queries with the clean
members
so they can also know that where you
have been working lately
or which segment you have been working
on or what was the last navigation
which you have been going through in
this whole project
so it can help you manage your project
in a more efficient way
and keep a track of how and what all
segments you have been working on and
what all segments you need to work on in
your project
coming to the next one we have delivery
plans
so here you can see uh we haven't
created any plan yet so basically
delivery plans are a talented view of
multiple teams or team backlogs or
individual backlogs from different
projects
so basically it replaces the delivery
plans Marketplace extension
and it is only available for Azure
devops services
so here you can hack you can or you can
say it's a summary or a Time summary of
all the projects you have been working
on in a particular organization
so now that we have covered both uh
let's
move to the next one which is repose
so with the name itself we can well
understand that repo stands for
repositories so basically there's a set
of repositories that allows you to
control and manage your project code
like of course say you're deploying a
healthcare application so
these Repose options help you create
repositories and
manage your code of that particular
application and more efficiently
so what you can do is you can connect
project solutions by using the repos
link
as you can see here it is shown
so let's look into its option one by one
first we have
files
so in files your project solution will
be available in this section
so
repositories can create manage and
import those Solutions
okay so you just need to upload your
Solutions of your code or your project
here and it will just create
repositories for it and it will help you
create manage those
Solutions in a better way
you can see this year
flown to your computer portion existing
repository from command line and
imported repositories if you want to
import any solution like here you can
just
click or import and add the solution
toward the person three
so this is what files do
basically you can see It'll say it is a
it's like a physical folder itself where
you have all your
name files or repositories or Solutions
you can say of data
so basically it's it functions like a
physical folder itself
so it helps you keep a track of your
codes and everything
next comes is comments
so uh in comment section we can manage
commit history
for your repositories that you have
created in files
so it just commits those repositories
with author details from branches like
per se we have a team one from
spot branch and one from management
branch so
whoever creates that repositories and
have the solution it commits that
repositories under that under that
particular member of the team
with the branch name
then comes pushes
so push his fees are available in this
section
from each pull request done by the
developers Developers for sale the team
members we who have been working on this
particular project and creating
repositories and solutions
so what is pull request
so pull request or PRS are a way to
change or a review of merge code in our
repositories
so basically team uses these PRS to
review code and get feedbacks or changes
whether like uh for saying you are
deploying a code or a solution
so one can review them what all changes
needs to be named or what all
upgradation needs to be made or whether
the code is already fine or not
so basically teams use these PRS to
review the solutions and codes stored in
these repositories
or you can merge multiple Solutions or
multiple codes into the main branch
so basically the viewers can step
through the proposed changes and leave
those comments and what to approve or
reject that particular code
or you can say to upgrade or what are
changes you want to make it they vote
for it that whether that needs to be
made to that particular solution or not
so these are the TRS
next we have branches so we can manage
multiple branching information in this
particular section you can create create
or release branches from Master to death
okay so all users
can actually
can actually create or release branches
from branching information available in
this particular section
next come
tags
tags are used to point out specific
comments
like giving message tags and detail
information to branches you can create
your name is conventions to branches by
using submit tags
and the second the next one is pull
request which we have already discussed
the PRS that are basically used in
pushes
so now we are committed some completed
Repose also so let's move on to the next
one which is
pipeline
so here you can see see that we don't
have any pipeline
created for us yet so let's have a look
at this
provided options one by one
the first one is environments
so basically it is a collection of
resources where you are actually deploy
your application that you're working on
so it content you can say it contains
one or more virtual machines containers
web apps Etc whatever uh resources you
have actually used for deploying your
application
or model Services you have used for
creating the environment for the
deployment of your application of course
say we need to deploy our application
and it needs an uh
windows
Java environment so whatever resources
you need to create that environment that
will be added to this environment list
it will be listed over
this section
next we have releases option
so basically this pipeline stores the
data of your pipelines or stages
or tasks
and
deployments in Azure pipelines that in
departments you have done so far in your
applications for your applications
actually
so you can say that uh it helps your
team continuously deliver software to
your customers at a past pace
with a very minimum you can say lower
risk
so it you can fully automate and
automate the testing and the delivery of
your
software or applications on multiple
stages
or you can also set up an automated
process with approvals and on-demand
deployments
then comes
Library
so again you can see the page is blank
from the name itself you can scrutinize
that it will be a collection
of assets from
Azure devops projects so basically it is
a collection of build and release assets
of a particular project
assets defined in a library can be used
in multiple bills and multiple releases
pipelines on the project
so all assets that are defined you know
Library share a common security model
so you can control who can Define new
items in a library and who can use an
existing item that you have already
added in this Library
or roles are defined for our library
items per say you have added a
particular asset or particular item to
this Library segment
and you can assign a particular member
who will be working on this item
okay so the rules are defined here for
these and these governs the operation
you can perform on those items
that person will be keeping track
whatever changes have been made or
whatever upgradation has been made to
the particular item that has been added
to this
segment Library segment
so then comes uh task groups
so task groups are a way to standardize
and centrally managed deployment steps
for all applications in your projects
so when you include the task group in
your definition and then make a change
centrally to the task group the changes
automatically reflected in all the
definitions
so we can conclude with this that a task
group allows you to encapsulate a
sequence of tasks already defined and
you can say build or release Pipelines
or into a cycle task group
it just encapsulates all those sequences
tasks
so you can choose to extract the
parameters from those encapsulated tasks
as configured variables and
abstract the rest of the task
information
so what happens is the new task group is
automatically added to the task catalog
and it is ready to be added to other
release and build Pipelines
task groups are stored at the project
level are not accessible outside the
projects group so the task groups will
be only limited to the members who you
have assigned in this project and it
won't be
accessible to the other people or other
team members from different projects
even though they are the member of the
same organization so you can say it's
more of a private
second
now that we have covered task groups
next we have deployment groups
so deployment groups are only available
with classic release flight Pipelines
and it is totally different from the
deployment jobs
it is basically a collection of
deployment related steps Define in a y a
ml file to accomplish a specific task
so
in nutshell it is a logical set of
deployment Target machines that have
agents installed on each one
the deployment groups represent the
physical environment for example testing
or development of production environment
so a Development Group is just another
grouping of Agents much like in agent
pool you can say
so what you can do with this is you can
specify the security context and runtime
targets for the agents or you can let
yourself use live logs for each server
as a deployment take place
or you can also enable you to use
machine tags to limit deployment to a
specific set of
servers
so this was about deployment groups now
that we have covered one more service
let's move on to the next one that is
test plans
so
test plans the first one we have is
progress report
so you can
analyze with this only the progress
report will be the progress of the
project you have been working on or the
deployments you have been doing or the
tasks you have been performing
so
basically it lets you analyze and view
data for
more than one or an individual test
plans in a particular project
data for test plans can migrated can be
migrated from
an on-premises Azure devops server that
won't show up in this report
okay
so basically the section lets you drill
down by each test plans and give you
summary of each test
plan in it the section also lets you to
navigate to a test plan or shoot of
Choice by double clicking on it okay
so this was the progress report next we
have runs
so basically if super sends the
execution of Pipelines we're doing a run
the pipeline is processed and Allegiance
process one or more jobs
so when you run a python many things
happen under the couple while you often
won't need to know about them
occasionally it's usual to have the
bigger picture right
so
Azure pipelines will get processed under
this
test runs
segment so we'll be able to see water
performance
is happening over here like while you're
running a pipeline you can see uh the
running state
the the date you have started that
or what all that
returning pipeline includes like jobs
steps and tasks
runs power both continuous integration
and continuous delivery Pipelines
much we have load test
so basically as your load testing is a
fully managed as Azure service that
enables developers and testers to
generate High scale load with custom
Apache J meter strips and gain
actionable insights to catch and fix
performance bottlenecks at scale
so basically the application performance
and resiliency are more important than
ever before
so how you can run an Azure devops test
so first you need to click on it and
select a test suit that contains all the
automated tests
and you can just choose the run test
option
and it will start processing it so the
service this service basically simulates
traffic for your application you can say
regardless of for on which platform or
where it is actually hosted
so now that we have covered test plans
as well let's move on to the next one
that is artifex so this is the last
service that is provided to a project by
azure devops
so artifacts is a
byproduct produced during the software
development process
so it mainly consists of the project
source code dependency or binaries or
resources that could be represented in
different layout depending on the
particular technology
so it's like an extension that makes it
easier
to discover install or publish
and Maven packages in azure devops
it's basically deeply integrated with
other hubs like build so that package
management can become a seamless path
for your existing workflows
so what is exactly it is used for
so it basically it can be used
for both public and private organization
with teams of any size it it basically
manages your
npm or new get packages via feeds and it
allows you to create and share your
makeup
it's a package management solution
all about the services that is provided
to your projects so now that you know
what our service is
do for your project and what are their
benefits and how they function now you
can actually plan your project and start
creating and working on it and start
deploying with the users and what all
services you want for your particular
projects so what you can do is click
here on Project settings
second
yeah you can just click on Project
setting
so now what you can do is you can add in
description that uh what your actual
project is about because I like I said
if you're creating in a healthcare
application so you can just give it a
description that it is for him scare
related to issues employees and helps
needed and like you're trying that
particular application if it doesn't
possibles or Healthcare organization so
you can actually add those information
in this description
and the process which basically it is
basic or private one
but you do get a range of process
for your project when it depending on
the visibility of it like for HR and or
strum you can say
so now here you can see that only my uh
ID is attached to it as I'm the only
member here and I'm the administrator so
you can add members here and
scrolling down you can now that you know
what all services uh provide you or what
they provide to your projects depending
on the need of your project you can just
so select the services you want to
assign to your particular project like
per se if I don't want both assigned to
it or you can say if I don't want the
services provided by the coach I can
just click on it and select remove both
and I just need to refresh it
here you can see I have overview reposed
pipelines artifacts but I don't have uh
test plans on both as you can see
there's planning is basically all the
collection of whatever you're managing
which is initially assigned for both
so as you remove the test band also get
removed okay
once
like this you can just uh select what
all services you want specifically and
if you want to delete your projects you
can just go ahead and delete it
so this was all about
it's no Azure devops services and I'll
share the robot the studio we can see
the demonstration of how a project
actually functions in this virtual
Studio
if you're craving a more Hands-On and
detailed approach to Azure simply learns
Caltech postgraduate program in cloud
computing is the perfect fit for you
click the link in the description to
explore more about this course Azure
certification path we'll go over the
Microsoft Azure certification test in
this video and present useful
information to assist you to decide on a
career path Microsoft offers free
certification paths for a variety of
technical jobs to gain certification you
must complete a series of exams and the
first one is fundamentals certification
these certifications are suitable for
those who are just getting started in
technology are considering a career
shift second is role-based certification
to begin acquiring valuable job role
abilities choose a role-based
certification third is additional
certification examine my true soft
office technical qualifications as well
as special specialist and Microsoft
certified educator certifications now in
each category we have sorted the
certifications for your better
understanding in the first category
fundamental certification are Microsoft
certified Azure fundaments Microsoft 365
certified fundamentals and Microsoft
certified Power Platform fundamentals in
this second category role-based
certifications are Microsoft 365
certified Security administrator
associate Microsoft certified Azure
developer associate and Microsoft
certified Dynamics 365 sales functional
consultant associate and in the third
category additional certifications are
Microsoft certified Azure for sap
workload specialty Microsoft certified
educator and Microsoft Office specialist
Microsoft wordpix support so let's start
with the first one Microsoft certified
Azure fundamentals the Azure fundamental
certification allow allows you to
demonstrate that you understand Cloud
Concepts Azure Services Azure workloads
Azure security and privacy and Azure
pricing and support candidates should
have basic understanding of technical
fundamentals such as networking storage
computation application support and
application development candidates for
the Azure fundamental certification
should have a solid understanding of
cloud services and how Microsoft Azure
deliver them this certification is for
applicants who are new to Azure or who
are just starting to work with
cloud-based Solutions and services
moving ahead let's look into its skills
requirement describe Cloud Concepts
describe four Azure Services describe
core Solutions and management tools on
Azure describe general security and
network security features describe
identity governance privacy and
compliance features and describe Azure
cost management and service level
agreements this certification is
suitable for job roles like
administrator business user developer
student technology manager and its exam
code is AZ 900. price of this
examination is 99 USD and the renewable
time is two years coming to the next one
is the Microsoft 365 certified
fundamental certification it verifies
that you are familiar with Microsoft 365
feature and benefits as well as the
advantages of using cloud services the
software as a service cloud model and
the Microsoft 365 cloud service these
are the skills required to earn this
certification describe Cloud Concepts
describe core Microsoft 365 services and
Concepts explain security compliance
privacy and Trust in Microsoft 365 and
describe Microsoft 365 pricing and
support this certification is apt for
job tools like business user and
administrator and the exam code for this
examination is ms900 the examination fee
is 99 USD and the renewable time is 2
years next is Microsoft certified Power
Platform fundamentals if you're a
student a business user or a new
technical professional using your
Microsoft Power Platform skills to
better your team's efficiency this
certification can help you advance your
career to prepare for it you only need a
basic understanding of computer
technology data analytics cloud
computing and the internet consider a
fundamental certification the initial
step towards expanding your skill set
and moving on to more advanced
certifications like Microsoft Power
Platform functional consultant and the
skill set required for this
certification are describe the business
value of Power Platform identify the
core components of Power Platform
demonstrate the capabilities of power
platform describe the capabilities of
power apps demonstrate the capabilities
of power automate demonstrate the
business value of power virtual agents
this certification is perfect for job
roles like business user functional
consultant student and its exam code is
pl-900 the examination fee for this exam
is 99 USD and its renewable time is 2
years now let's dive into the second
category which was rule-based
certification the first certification
examined this category is Microsoft 365
certified Security administrator
associate Microsoft 365 security
administrators protect Microsoft 365
Enterprise and hybrid environments by
proactively securing them and
implementing and managing security and
compliance Solutions responding to
threats and enforcing data governance
policy this exam accesses your ability
to use Microsoft so 365 to implement and
manage identity and access threat
protection information security and
governance and compliance features the
skills required for this certification
are Implement and manage identity and
access Implement and manage threat
protection Implement and manage
information protection manage governance
and compliance features in Microsoft
365. now this certification is perfect
for the administrator role and its exam
code is ms500 its examination fee is 165
USD and its renewable time is again two
years then comes Microsoft certified as
your developer associate candidates for
the user developer associate
certification should have experience
designing developing testing and
supporting Microsoft Azure Cloud
applications and services participating
in all aspects of cloud development from
requirements definition
and designed to develop deployment and
maintenance as well as performance
tuning and monitoring is part of its
role responsibilities now the skill set
essential for the certification are
develop Azure compute Solutions
developed for Azure storage Implement
Azure security monitor troubleshoot and
optimize Azure Solutions connect to and
consume Azure services and third-party
services now this certification is for a
job role like developer and its exam
code is az204 its examination fee is 165
USD with the renewable time of two years
moving on next is Microsoft certified
Dynamics 365 sales functional consultant
associate this certification could help
you advance in your career if your
functional consultant a Microsoft
Dynamics 365 sales professional or a
developer wishing to improve your
Consulting skills it enables you to
better page yourself for projects and
demonstrates to your company how
Dynamics 365 sales can be used to
empower sales people you have expertise
with Microsoft Power Platform and are
familiar with Dynamics 365 model driven
apps and data modeling techniques as a
candidate for this certification for
this certification skills required are a
form configuration manage core sales
tables configure additional tools and
services configure Microsoft dataverse
create apps by using Microsoft power
apps create and manage Microsoft power
automate Implement Microsoft power
virtual agent chatbots integrate
Microsoft power apps with other apps and
services and manage Solutions now this
certification is suitable for the
functional consultant profile and the
exam code for this exam are pl-200 and
mb210 the examination fee for this exam
is 165 USD and the renewal time is two
years now comes the third category
additional certification and the first
certification exam in this category is
Microsoft certified Azure for sap
workloads specialty Architects or
Engineers with substantial experience
and knowledge of the sap system
landscape and Industry standards that
are particular to the initial migration
or integration as well as the long-term
operation of an sap Solution on
Microsoft Azure should apply for the
certification making recommendations on
services and modifying resources as
needed for optimal resiliency
performance scale provision size and
monitoring are among the
responsibilities of an architect or
engineer for Azure for sap workloads
skills required for this certification
are migrate sap workloads to Azure
design and Implement an infrastructure
to support sap workloads design and
Implement High availability ability and
Disaster Recovery maintain sap workloads
on Azure now this certification is
perfect for job roles like administrator
solution architect and its exam code is
az120 its exam fee is 165 USD with the
renewable time of two years then comes
Microsoft certified educator the
Microsoft certified educator MCE
credential verifies that teachers
possesses the global educator technology
literacy competencies required to
provide students with a rich
personalized learning experience
Educators in training instructors at
teachers education colleges and
in-service Educators all benefit from MC
certification so these are the skills
required facilitate student
collaboration skilled communication
self-regulation real world problem
solving and Innovation facilitates two
wouldn't use of information and
communication tools and use ICT to Be an
Effective educator now this
certification is suitable for developer
and educator profiles and its exam code
is 62193 its examination fee is 127 USD
and its renewable time is 2 years now
comes the last but not the least one in
this category and it is Microsoft Office
specialist Microsoft Word expert on the
Microsoft Office specialist work expert
certification to show that you have the
skills needed to get the most out of
word this credential demonstrate
Proficiency in the creation and
management of professional papers for
variety of purposes and scenarios the
skills essential to gain this
certification are manage document
options and settings use of Advance with
editing and formatting features creating
a custom document elements and use
Advanced word features now this
certification is suitable for job
profiles like business users and its
exam code is mo101 the exam fee for this
certification is 100 USD and its
renewable time is two years so this was
all about Azure certification fast apart
from this not only will you need to
learn how to design manage and protect
Azure Cloud systems in order to become
certified and land a job but you'll also
need real hands-on experience I will
take you through its various important
factors that you need to know before
proceeding with the certification
so without further Ado let's get started
but before moving any further please do
subscribe to our YouTube channel and do
hit the Bell icon to never miss an
update so simply don't
so let us first see what are topics that
we are going to cover in this video
first we will explore the basics and
understand what Azure certifications are
then we will explore what Azure
administrator certificate is about
after which we will look into who can
take this certification
then we will see what all syllabus we
need to cover on to appear for this
examination
after that we will explore how to apply
for the certification
later on we will discuss some tips and
tricks required for this examination
preparation
and then we will look into some of the
practice questions for your better
understanding
and in the end we will see what will
companies hire Azure administrators
so let's first understand what Azure
certification is
aspirants who wants to manage upgrade
and establish applications and
networking routes over the global
channel can get a specialization in
cloud computing with the Microsoft Azure
certification
Microsoft Azure is well known and
respected around the world as the most
trustworthy cloud provider as a result
folks who have earned a Microsoft
certification have a plethora of options
to choose copy now that we know what
Azure certification is let's move on to
the explanation of what Azure
administrator Associates certification
is about
Azure administrators are in charge of
cloud storage security networking and
compute Services the Microsoft Azure
administrator associate certification is
a role-based certification that verifies
a professional's competence to implement
manage and maintain Microsoft Azure
systems including major compute Services
storage Network and Security Services
now let's have a look at who all can
apply for this examination
candidate must have at least six months
of hands-on experience administering
Azure and a solid understanding of key
Azure services in order to take this
certification
along with that one should also have
experience in Powershell as your CLI
Azure portal and Azure Resource
Management templates
now let's dive deeper into this and
explore what syllabus are required to
appear for this examination
first is manage Azure identities and
governance
now this topic covers 15 to 20 percent
of the examination
then comes Implement and manage storage
this topic also covers 15 to 20 of the
examination
after that we have deploy and manage
Azure company resources
this covers 20 to 25 of the examination
then we have configure and manage
virtual networking this covers 25 to 30
of the examination
and then we have Monitor and backup
Azure resources which covers 10 to 15
percent of the examination
now let's have a look at how to apply
for this examination
now the details you need to focus on are
the cost of the examination is 165 USD
and its annual salary is 107
683 dollars
the duration of this examination is 120
minutes and the number of question
varies between 40 to 60.
the types of question can be either
multiple choice or multiple response
and the passing score to Ace this
examination is 70 with the renewable
time of two years
now that we have covered all the
technical details needed to appear for
this examination let's have a look at
some of the important tips for the
preparation of this examination
first is
check Microsoft official
az104's exam page
you should review the official ez104
exam detail page on the Microsoft
website before beginning your
preparation
this is Microsoft most reliable page for
sharing the most up-to-date and accurate
examine informations
second is understand the exam topics
each exam has its own set of modules and
weights as a result it's critical to
thoroughly comprehend the revised az104
exam objectives
if you have a good understanding of each
domain and module you can prepare
successfully for the exam this act will
assist you in maintaining a higher level
of concentration on the modules that
have a high weightage in the exam
third is online training resources and
reference books online training is one
of the simple and convenient training
techniques that can help you prepare for
the exam you will study the topics of
the exam modules from industry experts
through online training classes you can
also pay for customized instructor-led
instruction from any other training
provider to prepare for exam goals but
this can be costly also you can seek
help from books like Microsoft Azure
administrator exam reference is at 103
book that is a part of exam reference
series
fourth we have study groups and online
discussion forums joining study groups
and discussion forums for exam
preparation should be the first step in
your preparation
joining study groups and discussion
forums gives you the opportunity to
network with other as your
administrators and exam candidates on
forums you may get answers to your
concerns and have your issues fixed as a
result it's critical to participate in
some Azure discussion groups
and at last but not the list the fifth
one is practice with simulators and mock
exams
you can improve your confidence and have
everything set for your easel 104 exam
in this Final Phase when you feel you
have covered all of your bases in terms
of resources and preparation steps you
should focus on getting some good
simulators these az104 test simulators
are meant to simulate a real exam
setting you can use the simulator to
identify your skills and weaknesses so
that you can work on them
now let's have a look at some of the
practice questions for your better
understanding of this examination
so the first question is you have an
Azure subscription named subscription
one that contains an Azure log analytics
workspace named workspace 1. you need to
view the error events from a table named
even
which query should you run in the
workspace one and the options are
get event where event type equal equal
error
option b
search in event Arrow
option C select from event where even
type equal equal error
and D search an even where even type is
equal Arrow
and the correct answer is
option b
now moving on to the next question you
have an Azure subscription name
subscription one
subscription 1 contains the resource
groups in the following table
rg1 has a web app named web app one web
app one is located in West Europe
you move web app to rg2 what is the
effect of the move
and the options are
the app service plan for web app one
remains in the west Europe policy 2
applies to web app one
option b the app service plan for web
app one moves to North Europe policy 2
applies to web app one
option C the app service plan for web
app one remains in the west Europe and
policy 1 applies to web app one
and option D the web app service plan
for web app one moves to North Europe
policy 1 applies to web app one
and the correct answer is option A
if the source and Target plans are in
the same Resource Group and geographical
region you can migrate an app to another
app service plan
now the app service plan in which your
app runs determines the region in which
it runs you cannot however change the
location of an app service plan
so now coming on to the next question
you have an Azure subscription linked to
an Azure active directory cleanint the
tenant includes a user account name
user1
you need to ensure that user 1 can
assign a policy to the tenant Root
Management Group
what should you do and the options are
assign the owner role for the Azure
subscription to user one and then modify
the default conditional access policies
option b assign the owner role for the
Azure subscription to user one and then
instruct user want to configure access
management for Azure resources
option C assign the global administrator
role to user one and then instruct user
want to configure access management for
Azure resources
and option D create a new management
group and delegate user one as the owner
of the new management
and the correct answer is B
now let's move on to the next question
you need to ensure that an Azure active
directory username admin 1 is assigned
the required role to enable traffic
analytics for an Azure subscription
now the solution is you assign the owner
role at the subscription level to admin
one
does this meet the goal
and the option is either yes
or no
and the correct answer is
yes your account must meet one of the
following to enable traffic Analytics
so your account must have any one of the
following Azure rules at the
subscription scope owner contributor
reader or network contributor
now the next question is you have an
Azure subscription
users access the resources in the
subscription from either home or from
customer sites from home users must
establish a point-to-site VPN to access
the Azure resources the users on the
customer sites access the Azure
Resources by using site to site vpns
so you have a line of business app named
app one that runs with several Azure
virtual machines the virtual machines
run Windows server 2016. so you need to
ensure that the connections to app one
are spread across all the virtual
machines so what are the two possible
Azure services that you can use
and the options are a an internal load
balancer b a public load balancer
C
and Azure content delivery Network or
CDN
option D traffic manager
and option e and Azure application
Gateway
and the correct answer is A and E
Network traffic from the VPN Gateway is
routed to the cloud application to an
internal load balancer the load balancer
is located in the front-end subnet of
the
applications
now let's have a look at the companies
that hire Azure administrator associate
excellent NCR Corporation cognizant
Bosch Microsoft and Yahoo are some of
the great companies that hire Azure
administrator with great amount of
packages
and good amount of salary
I would like to welcome you to this
Azure interview preparation session
knowing Azure is one thing having worked
on Azure is another thing and being able
to answer interview questions in Azure
is a totally different thing although
one helps the other it's still different
skills and our aim through this video is
to prepare you with common product and
scenario based interview questions so
why wait let's get started a common
Cloud interview question is what's the
difference between SAS pass and is we
all know that software as a service is
Thin Client model of software
provisioning where client in this case
usually is simply a web browser
providing the point of access to
softwares running on the servers now SAS
is the most familiar form of cloud
service for customers SAS moves the task
of managing software and its deployment
to third-party services meaning the
vendor actually gets to manage all that
so SAS is software as a service
involving applications being consumed
and used by organizations so it's
generally using an application and
usually organizations pay for their use
of this particular application now some
examples of SAS would include Office 365
Salesforce is another very good example
of SAS and a lot of Google Apps and
Storage Solutions like box and Dropbox
are a very good example of software as a
service talking about platform as a
service or pass it actually functions at
the lower level than SAS now typically
it provides a platform on which software
can be developed and deployed now here
we developed the software we deploy the
software now Paz actually provides an
abstract of much of the work dealing
with servers and giving client an
environment in which the operating
system and the server software and the
Hardwares the network are managed and
taken care in other words with a
platform as a service all the things
that I've mentioned like these servers
the server software the hardware
everything is managed by the provider
and we can focus on business side of the
scalability and we can focus on
application development of our product
or the service so in short platform as a
service is a service that enables
developers to build and work with
applications without even having to
worry about the infrastructure or
management of the underlying hosting
environments and some examples of pass
in Azure is SQL and Azure storage
talking about infrastructure as a
service I as now this is moving down the
stack even further now we get to the
fundamental building block of the cloud
service which is in infrastructure as a
service is now is is fully of Highly
automated scalable Computer Resources is
full of storage is full of the network
capability that's what is now is clients
have direct access to the servers and
storage just as they would to do
traditional service but in this case
it's going to be in the cloud in this
case it's going to be more scalable so
is very similar to what you would do in
your on-premises physical data center
but when we talk about is we get to do
everything but it's stored in the cloud
so if we need to build a definition
around is is or infrastructure as a
service provides users with components
it provides components it does not give
us a built environment it simply
provides a component such as operating
system a networking capabilities and a
lot more now this is a paid for based on
the usage and can be used to host Apple
applications in other words this is pay
as you go type the more you use the more
you pay the less you use the less you
pay and some of the examples of is in
Azure is a virtual machine that's a
great example for is and v-nets for
networking that's another good example
for is in Azure another common question
in Azure interview is what are the
instant types offered by Azure the main
intention of this question is how well
have you understood the different
offerings in Azure and how well are you
trained to pick the right offering for
the right service now one size does not
fit all and thereof there are a lot of
services in Azure that under the carpet
it does the same thing but depending on
how different your requirement is we'll
have to pick the appropriate server so
this actually this question what are the
different instant types offered by Azure
it's to test how well have you used the
product and services available in Azure
and how well have you applied them for
for the given requirement you should be
provisioning more you should be
provisioning less at the same time so
it's kind of matching the right service
to the right requirement so what are the
instant types offered by Azure as you
see in the list we have general purpose
compute optimized memory optimized
storage optimized GPU virtual machines
and high performance compute virtual
machines now answering just the names
won't be enough in an interview you'll
have to go further and explain why and
in What scenario you would use general
purpose and what are the use cases what
type of servers is a good fit for a
general purpose and what type is a good
fit for computer optimized so on and so
forth and that's exactly what we're
going to do now so the general purpose
VMS you know they provide a balanced CPU
to memory ratio and it's very good for
testing very good for development
environment very good for small and
medium databases and also for low to
medium traffic web servers and some of
the use cases are like we said test
servers low traffic web servers small to
medium databases some Enterprise grade
applications it's also good for
relational database it's also good for
servers used for in-memory caching it's
also good for some small analytic
database very good for microservices and
if you're trying to build a proof of
concept for an idea that you just have
or just parked and this is another good
server for doing proof of Concepts
because you're not going to send actual
traffic to it I just want to show that
you know your idea works so developer
server is a very good use case for those
scenarios and the largest instance size
we can get in general purpose is
standard d64 V3 which comes with 256
gigabit of memory and 1600 gigabit of
SSD temporary storage on the other hand
compute optimized VMS have an a high CPU
to memory ratio and are very good for
medium traffic web servers very good for
batch processing servers very good for
application servers now because it's
computer optimized and compute means a
CPU it's an excellent choice for
workloads that demand faster CPU but
does not need as much memory or
temporary storage virtual CPU some of
the workloads that run very well on
computer optimized are analytic
workloads gaming servers require more
CPU they run really well batch
processing are some of the applications
that can be placed in a computer
optimized and by doing that we get the
actual benefit of the computer optimized
instance and the largest instance size
or the largest instance size type is
standard f72s a V2 and here we get 144
gigabit of memory and 576 gigabit of SSD
temporary storage in compute optimized
VMS in the same lines memory optimized
to VM they offer High memory to CPU
ratio and that are great for databases
databases require more memory so it's a
great fit for a database and it's a
great fit for medium to a large scale
caches applications that require
in-memory analytics so this memory
optimized memories more so it's very
good for in-memory analytics
applications and the largest instance
size we get here is standard
m128m and look at the gigabit of memory
it's a 3892 gigabit of memory and look
at the temporary storage it's a 1400
336 a gigabit of temporary storage on
the same lines storage optimized now I
guess I don't have to explain to you
what storage optimized is used for you
might have easily guessed looking at the
flow yes storage optimized VM offer High
disk throughput and IO and are very
ideal for Big Data SQL nosql databases
data warehousing servers large
transactional databases and lot more and
some of the examples of the applications
that can be launched on storage
optimized are Cassandra mongodb Cloudera
redis these are some familiar
applications that can get benefited when
we run them on storage optimized and one
difference between storage optimized and
the other servers are they are generally
optimized to use the local disk on the
Node attached directly to the VM rather
than using an durable disk which is
actually an a remote disk space now what
does this allow this allows for greater
input outputs per second or throughput
for the workload so that's what we get a
greater throughput a greater input
outputs per second is what we get and
when we use storage optimized and the
largest instant size available and
storage optimized is a standard l32s and
the memory is 256 gigabit and look at
the temporary storage it's a
5630 gigabit of temporary storage GPU
type VMS easy to guess at GPU optimized
VMS are specialized virtual machines
available with multiple gpus attached to
them now these sizes are designed for or
these VMS are designed for computer
intensive graphic intensive
visualization workloads that require a
lot of graphical Processing Unit
attached to it so in short these are
virtual machines that specialize in
heavy graphic rendering and video
editing it also helps with model
training and interferencing with the
standard nd24 RS which has a 448 gigabit
of memory and 2948 gigabit of temporary
storage and the last but not the least
but the best last but the best is high
performance compute or Azure hedge
series virtual machines now they are the
latest in high performance Computing VMS
and are aimed to handle workloads like
batch processing analytic molecular
modeling and fluid dynamics a lot of
complicated applications in this VM and
this is the fastest and Powerful CPU
virtual machine with the optional High
throughput interfaces and the largest
instance size that's available is a
standard l32s which comes with the 224
gigabit of memory and 2000 gigabit of
SSD temporary storage and a third common
question is what are the deployment
environments offered by Azure there are
two main deployment environments one is
the staging environment and the other
one is the production environment now in
staging environment let's talk about
staging first so when you're deploying a
web app or web app on Linux you can
deploy them to a separate slot instead
of the default production slot when
running them in standard premium or
isolated app service plan tiers now the
deployments slots are actually live app
with their own host name and at a later
point the staging environment can be
swapped with the production environment
so why do we need an staging environment
what are the benefit of it so the
benefit of deploying an application to a
non-production or staging environment it
provides a platform to validate changes
to our application before it can be made
live in the production environment and
in this staging environment the app can
be identified using the azure's global
unique identifier also called as the
guid URL and it's very very similar to
the production URL except that it has a
custom name in front of it that
identifies it as staging environment and
for production environment this is the
live production environment that's
serving customers request that serving
the customer content now it can be
slightly different from the staging
environment in a way that the URL that's
used to identify the production
environment that's more often DNS
friendly name like the name of the
actual service dot
cloudapp.net that way it differs in case
of staging environment you have a custom
name right before it so the custom name
and then the cloudapp.net but in this
case you get the direct service name as
the name of the URL so this is live
production environment which receives
and handles and serves customer traffic
another commonly asked question in Azure
is what are the advantages of scaling in
Azure the actual thought behind the
question is to see how much have you
understood the scale how much have you
seen and how much have you applied the
scaling effect in the production
environment and have received benefits
in return so let's talk about it
advantages of scaling in Azure some of
the advantages are or we get the maximum
application performance now Auto scaling
is a built-in feature for the cloud
services be it AWS Azure Google and
couple of other cloud service providers
it's a built-in feature for a cloud
service a cloud service should be Auto
scalable and that includes mobile
services virtual machines and when we
run our applications on mobile services
or virtual machines the website actually
gets the best performance during the
change in the demand again a different
applications might require different
performance needs for example for some
apps the performance measured based on
memory and another a good example is the
fluctuating demand for example you could
have a web app that handles millions of
requests during the day and literally
nothing at the night and auto scaling
this environment Auto scaling any of
this environment will automatically
scale or fatten your environment so to
receive the all the incoming traffic and
during lean period it actually gets
Slimmer and Slimmer so to help you with
the car so it actually maximizes the
performance that's what Auto scaling
does and like we said Auto scaling
scales up and scales Down based on
demand it not only scales up but also
scales down so to help you with the cost
and if you know the particular pattern
in which the application is going to
receive traffic then we can very well go
ahead and schedule scaling to our
application or schedule scaling that
infrastructure based on time if we
already know that Monday to Friday
that's the traffic that I would get and
it's a constant one it's not a public
facing but you know it's an internal
application so I know all the 500 users
are a thousand or the 5000 users who
will be using it so at any given point
it's just five thousand users it's not
going to go beyond that and during
Saturday and Sunday literally nobody's
going to be in office so no load at all
so in that case I pretty much know how
the pattern is going to be I can go for
scheduled scaling if I know at the
pattern and auto scaling like I said not
only helps with keeping the application
highly available it also helps with the
cost effectiveness of our infrastructure
so anytime there's a VM or a group of
VMS running on less CPU Auto scaling is
going to actually get the environment
Slimmer and Slimmer so we're not
unnecessarily running any resources and
paying for it if you're being
interviewed for the infra site in Azure
this is another common question that
gets asked how are Windows Active
Directory and Azure active directory
different let's talk about the Windows
Active Directory first the non-cloud
Windows Active Directory was the service
was released along with Windows 2000
server Edition and this active directory
is essentially a database that helps
organizations to organize the users
organize the computers and a lot more it
provides authentication and
authorization to the applications not
only to the applications but also to
file servers to printers and lot of
other on-premises resources that's what
the basic non-cloud active directory
does on the other hand the Azure active
directory is not designed to manage a
web-based Services the Azure active
directory on the other hand was designed
to support web-based services that use
rest API interfaces for Office 365
salesforce.com Etc unlike the plain
active directory this uses an completely
different protocol so protocol wise it's
different and the services that it
supports is quite different now besides
that it also has couple of other
differences as well and let's look at
them so the actual active directory or
the windows actual directory is a
directory service that facilitates
working with interconnected complex and
different network resources in a very
unified manner on the other hand Azure
active directory is Microsoft's
multi-tenant cloud-based directory and
identity management service and the
Windows Active Directory has five layers
to store data to store user details and
to issue the management certifications
on the other hand Azure active directory
integrates or compresses the five layers
into just two layers here Windows Active
Directory works with on-premises servers
like applications file servers and
printers Etc on the other hand Azure
active directory it works on web-based
services that use restful interfaces if
you're being hired for the development
environment or for the cloud devops
support environment or even for the
production support environment you might
find yourself being asked this question
what are the types of cues offered by
Azure now Azure supports two types of
queue mechanisms the storage queue and
the service bus queue Let's Talk About
Storage queue first now the storage
queue which are part of azure storage
infrastructure it provides a simple rest
based interface simple rest based get
put and Peak interface it provides
reliable persistent messaging within and
between other services it follows the
pub sub model or a pub sub messaging
infrastructure and it's best suited for
users that need to store more than 80
gigabit of messages in the queue it can
provide a logs for all the transactions
executed against the user's queue so
that's what we get with storage queue
and on the other hand service bus queue
the service bus queues are built on top
of broader messaging infrastructure and
they are designed to integrate
applications and applications comp
component that can span multiple
communication protocols so that way it
differs so this is good for applications
and components that may span multiple
communication protocols and even
different totally different network
environments so in short these service
buses are the service bus queues in
Azure are part of azure's messaging
infrastructure and they integrate
applications or application components
that can actually span multiple
different protocols and multiple
different network environments it also
provides an first and first out style
for delivery and the user's queue size
has to remain under 80 gigabits another
familiar question is what are the
advantages of azure resource manager now
this resource manager helps us to manage
the usage of the application resources
this question is actually to test how
well have you tested how well have you
used resource manager and have gotten
the benefit of it this question actually
tests how easy it has become after the
introduction of resource manager
compared to when doing deployments or
when provisioning resources without the
resource manager so let's get into the
answers for the question what are the
advantages of azure resource manager the
in-shared resource manager is called arm
so the arm helps deploy manage and
monitor all the resources for an
application a solution or a group so all
the interconnected application all the
interconnected Services can be monitored
as group using resource manager and a
users can be granted to access to
resources that they require within a
resource manager so in an account I can
have like 10 different resources created
by resource manager or a resource Group
created by resource managers and I can
allow deny connection to those services
or only to those Services based on
whether the user should be accessing one
and not accessing the other so that way
it becomes easy to give access to a
group of application it helps in getting
billing details for for the group of
resources now which group is using more
which group is using less and which
group has contributed more to this
month's bill stuff like that so those
details can be obtained using Azure zos
manager and provisioning resources is
made much easier with the help of this
resource manager another question is how
has integrating hybrid Cloud been useful
for Azure well with the use of hybrid
Cloud we get the best of both the worlds
so what's hybrid Cloud it's nothing but
a combining the public cloud and the
private cloud and allowing data and
applications to be shared between them
so whenever the compute or the
processing demand fluctuates hybrid
cloud computing gives businesses the
ability to seamlessly scale their
on-premises infrastructure in the public
cloud and handle any kind of
overflow in the requirement or overflow
in handling the application so it really
helps it helps it boost the productivity
of our on-premises application so with
the hybrid Cloud we get a greater
efficiency with combination of azure
Services a devops processes and tools
for the application running in
on-premises and by having an hybrid
Cloud environment users can take
advantage of a constantly updated Azure
service and other AWS Marketplace
applications for their on-premises
environment and the other benefit is
with hybrid Cloud environment we can
simply deploy applications regardless of
its locations in case of on-premises
we'll have to worry about the location
but when we expand our on-premises
environment in the cloud and they can or
we can pick any of the locations and
simply deploy it in them and this
enables the applications to be created
at a greater speed what's federating in
Azure SQL now this question is very
specific about SQL how can we scale the
SQL database now this is a very good
question button or a valid question or
an important question in the interview
because many customers or companies have
not been able to meet the user demand
because they could not scale out the
databases the theory of scaling out or
adding servers to accommodate the
increased workflows and traffic is not
hard to understand but the implications
can be very complicated the implications
can be very expensive we're well aware
of scaling the web servers that's very
common but how do we scale the database
so Microsoft provides the tools and
Technologies so we can scale out the
database in the cloud and that's what is
called SQL or Federation in Azure SQL so
the way we scale out the SQL database is
by sharing sharing the database so
sharing actually enables users to take
advantages of the resources in the cloud
not only that it allows users to have
their own database or a shared database
amongst each other because we're
creating a highly available database
because we're having shards in a
database it actually reduces the
possibility of a single point of failure
for our database and more importantly
because we're sharing because we're
using Federation and Azure SQL it
provides an cost effective scaling of
our databases by using Cloud resources
or by using billing only for the cloud
resources that we have used so no
pre-provisioning no over provisioning it
Provisions the right amount and we pay
the right amount let's talk about this
one what are the different types of
storage offered by Azure now the
different types of storage offered by
Azure are as you already know and as you
can see they are Azure blob storages
table storages file storage and queue
storage so let's expand one after the
other now blob storage are nothing but a
massive scalable object storage and
that's very good for storing text and
binary data and Azure blob storage is a
Microsoft's object storage solution for
the cloud now lab storage is optimized
for storing massive massive amount of
unstructured data that can be in form of
text or or in form of binary data so in
short blob storage enables users to
store unstructured data and those data
can be in the format of pictures music
video files and lot more and it stores
them along with their metadata and
another advantage or another feature
benefit that we get from blob storage is
when object is changed it is verified to
ensure it is of the latest version
number one and number two it provides
maximum flexibility to optimize the
user's storage needs and this
unstructured data is available to
customers through an URL or an rest
based object storage so they are the
benefits that come along with The Blob
storage table storage on the other hand
is an a nosql store for schema Less
storage of secured data now this Azure
table storage is a service that stores
structured no SQL data in the cloud and
because this table is schema-less it's
very easy to save your data it's very
easy to adapt your data as the need for
your application grows and this table
storage is very fast and cost effective
for many type of applications so some of
the some of the type of data that we can
store is table storage is good for
flexible databases like user data for
web applications address book storage
device information storage and if you
want to store metadata this is a very
good use case to store them in Azure
table storage Azure files is another
storage here it's an managed file share
for cloud or on-premises deployment so
file storage provides a file sharing
capabilities accessible by the server
messaging block protocol and this can be
accessed from the cloud and this can be
be accessed from on-premises as well now
here in file storage the data is
protected by SMB 3.0 and https protocols
and the more important thing is azure
takes care of managing hardware and the
operating system deployments for Azure
file storage so this additional file
storage can be used when we want to
burst the storage capacity in
on-premises so on-premises the primary
and cloud is the secondary or the
extended on-premises storage so it
actually improves the on-premises
performance and capabilities for our
on-premises data center and then we have
cues Azure queues it's a messaging store
for Reliable messaging between the
application components so we spoke a
little about this in the previous
question so the Azure queue storage is a
service for storing a large amount of
messages that can be accessed from
anywhere in the world via HTTP or https
a protocol and here the a single message
can be up to 64 kilobits in size and in
a queue we can have millions of messages
and the limit can actually go up if we
have not reached the limit of the
storage account so it's millions and
millions of requests that can be stored
in the storage tube or the queue storage
so the queue storage in short provides
message queuing for large workloads and
it enables users to build flexible
applications and separate the functions
one from another so one failing doesn't
affect the other application which is
running healthy and this Q storage it
ensures the application is scalable and
less prone to individual component
failures because they are decoupled
separate now it also helps in monitoring
the queue which ensures the customers
demands are met so Q is a great place to
monitor or a great component to monitor
so we understand how much a peak have
you reached for a particular application
location service or a container what is
text analysis API in Azure machine
learning now a text analysis is actually
an cloud based analytics API and it
provides an advanced natural language
processing over the raw text and it has
got four main functions like the
sentiment analysis or and the key phrase
analysis language deduction and a few
other things now what do you mean by
sentiment analysis now sentiment
analysis is from the logs from the
commands from the text commands that we
receive I do an analysis and find out
whether that's an positive or A negative
statement now if it is a the API the API
returns and sentiment score between 0
and 1 and 1 is positive and 0 is
negative and then in text analysis we
have a key phrase extraction which is it
will automatically extract the key
phrase to quickly identify the main
points in that key phrase for example if
you're analyzing a text which says the
food was delicious and there were
wonderful stuff then the API Returns the
main talking points of that phrase like
food food is the main talking point and
wonderful stuffs that was a main talking
point so that's another feature that
this text analysis has and then we have
language deduction in text analysis
right irrespective of what you paste it
can try to gauge and try to align it to
the 120 or up to 120 languages that it
supports so I can simply take text from
the internet and I can paste it and the
text analysis software is going to
identify the language and then can run
phrase and sentiment analysis on those
texts right so in short text analysis is
an API a set of web services that can be
used for text analysis it can be used to
analyze unstructured statement sentiment
analysis key phrase extraction and lot
more and the results are generally
between 0 and 1 and 1 being positive and
0 being the negative sentiment there is
no much training or in other words this
is not as complicated as couple of other
text analysis softwares are available in
the market we can simply paste we can
simply upload the text and we can call
the service and it runs a sentiment
analysis on it all by itself let's look
at this question what are the advantages
of azure queue storage if you're going
to work on a development environment if
you are going to work on an environment
that Embraces devops this could be a
question what are the advantages of
azure queue storage now Azure queue
storage is built to flexibly operate the
applications and separate the functions
between the applications that run large
workloads so when we design applications
for scale these applications can be
decoupled so that they can scale
independently you know anything
happening on an application is not
dependent on another application and
anything happens to an section of the
application will not affect the other
application because they are now
decoupled and corrected through the
queue storage so the queue storage gives
us asynchronous message queuing for
communication between the applications
irrespective of whether they are running
in the cloud or whether they are running
in desktop or whether they are running
on premises or on mobile devices so in
short this queue storage enables message
queuing for large workloads in a simple
and cost effective and a durable manner
talking about the advantages advantages
is it provides Rich client libraries for
Java Android C plus plus PHP Ruby and
lot other services getting added during
every new release from Azure and the
main advantage again is a it enables
users to build flexible apps and
separate the functions for bigger or
greater durability again introduction of
cues into our application it ensures our
users applications are scalable and less
prone to individual component failures
meaning one component failing is not
going to take the whole application down
right if one component fails it's just
that component that stays fails the rest
are healthy and the rest are going to
function it also helps us to monitor the
cues and ensure the servers are
overwhelmed by sudden traffic burst so
how much do I have in the queue kind of
determines the traffic for my
application and if the queue is more I
can always go and auto scale my
environment and the queue is less I can
always go and Shrink or make my
environment thinner so it can save cost
and anytime there is more data in the
queue I can Auto scale monitor the
metric and do auto scaling based on that
metric so the environment knows that
there are more data is coming in I need
to expand myself to handle that much
amount of data this is a very common
question what are the two kinds of azure
web service roles now a service role is
a set of managed and load balanced
virtual machines that work to perform
some tasks and based on what it's going
to run on top of it is it going to run a
web service or is it going to run a
worker service defines what kind of
roles that gets attached or that goes on
this virtual machines so we have two
types web role and worker roles the web
role is a cloud service role that's
configured to run web applications
developed on programming languages
Technologies and majorly they support
IIs internet information service and
they support asp.net PHP Windows
communication foundation and so on so
that's web rows and these web roles it
automatically deploys and hosts
application through the users IIs
internet information service on the
other hand worker roles are roles that
runs applications and service level
tasks which generally do not require IAS
so IIs is actually the differentiating
factor so in worker roles is not
installed by default the worker roles
are mainly used to perform supporting
background process along with web roles
and do tasks automatically compressing
or uploading the images running scripts
and or doing some changes in the
database getting new messages from the Q
and processing and lot more you know the
work the applications or the work that
does not require IAS that's what this
worker role does again the main
difference between the web role and the
worker role is that the web role
automatically deploys and hosts your
application through is whereas the
worker role does not use IAS and runs
our application as Standalone this is is
another classic question what is azure
service fabric so Azure service fabric
is actually a distributed system
platform that makes it easy to pack
deploy and manage a scalable and
reliable microservices and containers
now service fabric also addresses some
of the significant challenges in
developing and managing Cloud native
applications and the problem that IT
addresses and fixes is now developers
and administers can avoid complex
infrastructure problems and focus on
implementing Mission critical and
demanding workloads that can be scaled
and that can be managed through the
console or from the single place in
short service fabric provides a platform
that makes the process of developing
microservices and managing application
life cycle a lot easier and the
advantages of service fabric is that now
we can produce application with faster
time to Market because all the worry
about the infrastructure is taken away
from us we don't have to design an
infrastructure here all that we need to
worry about is simply the application
and the application life cycle again the
advantage is it supports Windows it
supports Linux not only that it supports
servers on premises and in the cloud
with service fabric we can scale up our
environment to even thousand machines in
just a single command or if there is a
immediate need for thousand machines I
can immediately scale them up to
thousand machines that's possible with
service fabric now let's look at this
question you can expect this question if
the customer is running hybrid
environment meaning having some of the
applications in on-premises and running
some of the applications from the cloud
and for some reason when classifying the
application that goes to the cloud and
that stays on premises they have decided
to keep the database in-house so in that
environment a lot of customers do that
so in that environment this is a classic
and a scenario based question a client
wants the front end of their application
to be hosted on azure in the cloud and
wants the database to be hosted in
on-premises for security reasons or to
have full control on that databases how
do we go about suggesting a solution for
this customer the ideal solution in this
scenario is to use the v-net based point
to site VPN solution so all the
front-end applications will be in the
cloud and they'll be hosted in a v-net
and from the v-net they'll be connecting
to the database through and point to
site or VPN so the traffic and the
writings and the reads are not coming
through the internet but through a point
to site VPN link that's connecting the
Azure v-net and the on-premises
environment and this model or this
approach or the solution is best suited
for scenarios where there are only a
limited number of resource that needs to
be connected between on-premises and the
cloud this is a very common question
what's Azure traffic manager of course
we know more running applications on a
single server we know more running
applications on or or from a single
environment right the same application
is being run from multiple environments
within Azure and it can be running from
Azure and on-premise as well so multiple
environments between Azure and
on-premises and a lot of customers have
such environment and if you are facing
an interview with such customer this
could be an ideal question what is azure
traffic manager now the Azure traffic
manager is a dns-based traffic load
balancer that actually enables us to
distribute traffic between Services
across Azure Global regions and by doing
this it provides a good availability and
a good responsiveness to the application
and this traffic manager it uses DNS to
direct client requests to the most
appropriate service endpoint based on
the traffic routing logic and the health
of the endpoints that it maintains so in
short this traffic manager is a load
balancer that in enables users to
provide High availability and
responsiveness by Distributing traffic
in an optimal manner across the Azure
when we run the same application in
different regions so some of the
advantages or some of the use cases of
using Azure traffic manager is it
provides multiple automatic failover
options it also helps with reduced
downtime it also helps with the
distribution of user traffic across
multiple locations so one location is
not overloaded and then it helps with
users knowing from where our customers
are getting connected from that's
another big use case with Azure traffic
manager let's look at this question
right this is an ideal question now
there are group of servers connected
together within an virtual Network and
now we need to move them or create a
separation between them how do you go
about achieving it so the question goes
like this you need to isolate Network
traffic among VMS in a subnet which is
part of a virtual network with little
downtime and impact on the user so
that's the given scenario and the best
way we can do it is create a new virtual
Network and move all the VMS in that
subnet to the new virtual Network now
this feature is not possible with a lot
of other cloud service providers like
AWS and lot of other providers now in
those environments we might need to shut
down we might need to stop the VM create
a new VM based on the image and it's an
Hefty process but here in Azure I can
simply move the VMS from one subnet to
another virtual Network without needing
for any additional security like the
network security group I can simply
isolate them if I need to by creating a
simple a new virtual Network and moving
the servers to the new virtual Network
look at this one this is another common
question with respect to Azure what is
public private and hybrid Cloud so this
is really to test how well have you
understood the different Cloud offerings
in the market public private and hybrid
or at least the three basic offerings in
the market public private and hybrid
Cloud now the public cloud is the most
common way of deploying cloud computing
applications and it has resources like
servers storage and are owned and
operated by third-party cloud service
providers like Microsoft Azure Microsoft
Azure is a very good example of public
Cloud so here every component that the
user is using is running only on Azure
that's public Cloud right let me talk to
you about some of the advantages of
public Cloud some of the advantages is
low cost because there's no need to
purchase Hardware or software and we pay
only for the services that we use in
public cloud and there is literally no
maintenance because the service provider
maintains the environment for us and
with public Cloud we have nearly
unlimited scalability meaning we can get
resources on on demand and can meet our
business requirements on demand and the
public clouds are very highly reliable
because they have a vast network of
servers and they ensure that our
application does not fail so there are
some advantages of public Cloud let's
talk about private Cloud now private
Cloud consists of compute resources used
extensively by one business or one
organization now this private Cloud can
be physically located at our
organizations on-site data center or it
can be hosted by a third-party service
provider whichever the case the private
cloud services and infrastructure are
always maintained on a private Network
and they're maintained on hardware and
software that are dedicated solely for
one organization or solely for your
organization so in short private cloud
in Azure is azure Services being run
within an on-premises data center or
on-premises data center used by the user
to host systems or applications and some
of the advantages some of the advantages
is it gives more security resources are
not shared with others so a higher level
of control and security over our
resource and application is possible and
then we have a hybrid Cloud now hybrid
cloud is the best of both worlds so it
combines the features of both public and
private cloud and some of the user
components are being run on Azure and
others within on-premises data center so
they kind of share the resources in
other words they kind of share the
application half of the application
would be running in on-premises and half
of them would be in the cloud and they
will be working in harmony to support
the application and the business need so
that's hybrid Cloud this is one another
good example question that wants to test
how well you pick services or how well
have you understood the Azure products
and services and are picking the right
service for the need so the question
would go like this what kind of store
storage is best suited to handle
unstructured data a lot of storage
options available and the requirement
here is what or which one would you
choose for unstructured data the answer
for that question is block storage
because blob storage is designed to
support unstructured data it works in
this way it places the data into
different tiers based on how often they
are accessed different tier means
different performance different
performance means different costs
associated with it so a lot of add-on
advantages will we get when we use blob
storage for unstructured data in
addition to web any type of unstructured
data can be stored in a blob storage
this is not true with couple of other
storage options that we have in Azure
only with blob storage we can store any
type of unstructured data and the data
Integrity is maintained every time an
object is changed in the blob storage
and the best part is the blob storage
helps increase applications performance
and reduces the band with consumption
and reduces the bandwidth consumption
for that application so they are the
benefits that we get for Block storage
and blob storage are the ones that are
well suited for unstructured data and
that's what your answer should be it's
really an five-step process and if you
have worked and if we have done some
Labs some basic Labs with Azure you can
easily answer this question so it's a
five-step process first step is to log
into the Azure the second one is to
create an resource resource or a
resource manager and within the resource
manager you will be selecting the
resource and then pick the offering
system do you want windows or Linux and
within Windows what's the flavor you
want or within Linux what's the flavor
you want so decide on it and then
entering the relevant information
relevant information like the name of
the instance or the VM that we're gonna
launch and the password the URL that
goes with it and couple of other
relevant information that goes gets
itself attached with the Via M and then
select the size of the virtual machine
different size different types available
for the kind of application and for the
intensity of the application that will
be running on top of it so select the
virtual select the size of the virtual
machine review everything whether
they're good or not if there are any
changes required go back and edit them
and then come back and launch and your
VM is there for you to start working
within like three or four minutes not
even five minutes within three or four
minutes it gets ready and you can start
working on it so it's a quick and it's a
five step process and you should be able
to answer it easily if you have done few
labs in Azure let's now look at some
scenario based question you've been
posted with a scenario so we thought
through it and we picked some common
scenario based question that are being
asked in interview and I thought we'll
present it for you with the answers with
explanation so you can get benefited
through it so let's look at this
question you're asked to make sure your
your virtual machines are able to
communicate securely with each other to
ensure security or to have good amount
of security what would you do and the
correct and the best answer for this
would be using virtual Network in Azure
which enables us to communicate with the
internet securely which enables us to
communicate with the on-premises data
center in a secure fashion so the
advantage of using virtual network is
users can create their own private
Network users can pick their own private
IP ranges users can create their own
subnet users can create their own
routing between those two subnets a lot
more goes into that virtual Network so
it's very customizable and the users are
provided with an isolated and highly
secure environment for applications it's
completely isolated from other customers
it's completely isolated from other
applications that are running in other
virtual Network that we own So within
our account we can have multiple virtual
networks and one application running on
a virtual machine is completely isolated
from other applications running on other
virtual machines and of course all
traffic stays within the Azure Network
Azure virtual machine or within the
Azure Network depending on how you set
up the routing if you have set up
routing to go or reach the Internet it's
going to go otherwise it's going to stay
within Azure if you have set up routing
to reach on-premises then it's going to
go and reach on-premises otherwise it's
not going to go and reach on premises
it's going to stay within the Azure and
it also allows users to design their own
network like we already discussed
picking up IPS picking routing you know
picking subnets you know how many
servers should be present in that
particular subnet or how many servers
should that subnet accommodate the size
of the subnet the IP ranges the natting
the masking of ips creating of VPN all
that's possible with the virtual Network
so it really allows users to design
their own network and using virtual
machine is how we secure applications in
the cloud let's look at this other
scenario how do you ensure that every
time a user logs in they are not asked
to re-enter the password as part of
authentication so you really don't want
your users to re-enter the password
every time they log in to a different
application well all the applications
have their authentication mechanism in
place all of them wants to authenticate
the user before they log in ensuring the
user does not login every time does not
mean that no wiping away all the
authentication and authorization that's
present in that application you still
need that in place but how do you make
the user hassle free so they're not
asked to re-enter the password or the
same password again and again let's look
at the options available the first one
is to enable Microsoft account
authentication well it's not going to
fix because with that the user will
still need to re-enter the username and
password deploy express route it's not
going to fix either because express
route is a network level service that
connects on premises to the cloud so
that has got nothing to do with
prompting or not prompting for password
and then we have set up VPN between
on-premises Data Center and Azure set up
80 domain controller in VM and Implement
integrated Windows authentication well
you can use the same username and
password for on-premises and the cloud
but this setup the VPN and the area
controller set up it's not going to stop
you asking for repeated passwords so
this is all about using the same
password in on-premises and in the cloud
and this has got nothing to do with not
prompting the user to re-enter the
password all right so that's same
password is different from not prompting
the user to re-enter the password there
are two different scenarios so that is
also out of the equation and the last
one is configure ad sync to use single
sign-on that's the right one so when we
configure the ad to use a single sign on
then it's going it's not going to ask
for the username and password every time
we access an application because we have
logged in and that login is going to
stay active for like 24 hours or so
depending on how you configure it and
within that time you can access a lot of
other applications and it's not going to
ask for the username and password
because you already have a single signed
on and you have signed in using the
right credentials let's look at this one
you need to ensure that a virtual
machines remain available while
migrating to Azure what would be the
appropriate service to use right let's
look at the options traffic manager
traffic manager is is literally and DNS
service and then let's look at the other
one update domains it again has to do
with traffic manager updating the URL so
the traffic manager gets updated and
then starts sending request to that
particular URL it's going to take some
down time because when we update the URL
they will have to be populated to all
different places and it takes time so
within that time any user trying to
access it's going to fail and then we
have express route and cloud services
express route could be the in fact it's
the right answer because express route
it's an extension of our on-premises and
Cloud environment and in this question
it really comes out from a customer
who's having an hybrid environment so
they have applications running in
on-premises they have applications
running in the cloud and they want to
have a way to migrate applications from
on-premises to the cloud in other words
kind of do a cut over between
on-premises and the cloud and this
express route is a service that connect
between on-premises and the cloud so
when you do the cutover the traffic is
now sent to the cloud instead of being
handled in on-premises in fact the
services and the application is getting
down are getting shut down in
on-premises so the request will come in
the same pattern instead of there being
handled in on-premises they are now
routed to the cloud using express route
and the API calls get addressed or the
the queries gets answered in the cloud
through the express route service look
at this question you are an
administrator for a website called Web
game and you are required to validate
and deploy changes made to your website
by your development team with minimum
downtime so the real question is how do
you validate the deployment changes
that's made by the development team
let's look at the options create a new
linked resource create a staging
environment for the site enable remote
debugging on the website and then create
a new website well why would you want to
create a new website just to validate
the changes and doing a remote debugging
is not going to help because debugging
only captures logs of the changes
happening it does not do anything with
with validating the changes create a
staging environment could be or is the
right answer because when we have
staging environments anything that we
run on production can be run on staging
environment and any failures that would
happen in production if we simply run it
in production can be captured when we
run the application in the staging
environment so that way staging
environment is a very helpful and useful
service and that way I can catch any
errors in other words I can validate the
changes that were done by my development
team before I move it to production and
that reduces the downtime in the
production environment look at this one
last question that we have for you it's
a standard tier application is used
across the world and uses Azure website
standard tier it uses large amount of
image files so you can get it this could
be an e-commerce website which has a lot
of pictures in it and this is causing
the application to load slow how can we
handle this situation let's look at the
options given configure blob storage
with custom domain well this application
has pictures but the pictures only the
pictures is not all that the application
has all right so configuring blob
storage might not help this could be an
very interactive website and that can't
be run from blob storage let's look at
the other options configure Azure
website Auto scaling to increase
instances at high loads now it's the
picture that's causing issues for the
website it's not the CPU or it's not the
memory unavailable memory not enough
that's causing the application to be
slow so we need to identify what's
causing the application to be slow so
it's not the CPU it's not the memory so
configure Azure for auto scaling is not
going to help and then what are the
other options let's see configure Azure
CDN to cache all responses from the
applications web endpoint a CDN could be
the right answer but look at that it
says a CDN to cache all responses from
the applications web endpoint CDN is not
designed for that though it can't do it
that's not the best way to use CDN to
capture all responses from the
application's web endpoint the proper
design for CDN would be to Cache the
frequently used ones in other words cash
the static content which are photos
videos logos and pictures and lot more
and static content that never changes
let's look at the last option configure
Azure CDN to Cache site images and
content stored in Azure blob storage
absolutely correct so here we will have
to redesign the application to store the
pictures high quality lazy loading or
slow loading pictures because of the
high quality and the bigger size so
store them in CDN and then the content
let it be stored in Azure blob storage
that's the right way of Designing the
application and if we do it this
application is going to run faster or
the application is going to respond
faster to the users and there you have
it the conclusion of our captivating
Azure Advanced full course we hope you
found this video both useful and
entertaining if you have any questions
about the topics covered please feel
free to ask about in the comment section
below our experts will be there to
address your concerns thank you for
watching and keep learning staying ahead
in your career requires continuous
learning and upskilling whether you're a
student aiming to learn today's top
skills or a working professional looking
to advance your career we've got you
covered explore our impressive catalog
of certification programs in Cutting
Edge domains including data science
cloud computing cyber security AI
machine learning or digital marketing
designed in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know more
hi there if you like this video
subscribe to the simply learned YouTube
channel and click here to watch similar
videos turn it up and get certified
click here
thank you