1
00:00:01,020 --> 00:00:05,650
[Music]

2
00:00:14,679 --> 00:00:16,840
so hello there and welcome to another

3
00:00:16,840 --> 00:00:19,720
tutorial my name is Tam Baki and this

4
00:00:19,720 --> 00:00:21,640
time I'm going to be going over how you

5
00:00:21,640 --> 00:00:24,000
can create a system that I like to call

6
00:00:24,000 --> 00:00:26,920
T pronounce using a sequen to sequence

7
00:00:26,920 --> 00:00:30,119
lstm model built in tensorflow let's

8
00:00:30,119 --> 00:00:33,320
begin now what will this application do

9
00:00:33,320 --> 00:00:35,600
well put it put simply this application

10
00:00:35,600 --> 00:00:38,520
will allow you to enter a word any word

11
00:00:38,520 --> 00:00:41,440
even a non-dictionary English word uh

12
00:00:41,440 --> 00:00:44,719
into a an lstm and the lstm will tell

13
00:00:44,719 --> 00:00:47,199
you how to pronounce this word uh based

14
00:00:47,199 --> 00:00:50,160
off of pronunciations of other words and

15
00:00:50,160 --> 00:00:51,760
so what I do is there's actually a

16
00:00:51,760 --> 00:00:54,399
database online called the CMU

17
00:00:54,399 --> 00:00:57,079
pronouncing Set uh and so essentially

18
00:00:57,079 --> 00:00:58,840
this is created by the Carnegie melon

19
00:00:58,840 --> 00:01:01,239
University uh and it is a data set which

20
00:01:01,239 --> 00:01:04,280
contains uh the actual uh American

21
00:01:04,280 --> 00:01:06,200
English words uh and then their

22
00:01:06,200 --> 00:01:09,240
pronunciation in American English accent

23
00:01:09,240 --> 00:01:11,200
uh and so this pronunciation uh of

24
00:01:11,200 --> 00:01:14,040
course uses uh uses uh specific uses the

25
00:01:14,040 --> 00:01:15,680
specific sort of syntax which I'll be

26
00:01:15,680 --> 00:01:18,040
talking about in just a moment uh and

27
00:01:18,040 --> 00:01:20,280
let me explain exactly how the system

28
00:01:20,280 --> 00:01:23,119
works of course we begin with a data set

29
00:01:23,119 --> 00:01:25,720
and this data set contains hundreds of

30
00:01:25,720 --> 00:01:28,240
thousands of individual English words

31
00:01:28,240 --> 00:01:30,240
and their pronunciations attached to

32
00:01:30,240 --> 00:01:33,920
them uh and so this is called

33
00:01:33,920 --> 00:01:36,920
CMU

34
00:01:39,079 --> 00:01:42,399
pronouncing data

35
00:01:42,680 --> 00:01:47,280
set okay so we've got the data

36
00:01:47,360 --> 00:01:50,280
set now after you've got the data set it

37
00:01:50,280 --> 00:01:52,000
has to go through some processing and

38
00:01:52,000 --> 00:01:53,880
I'll tell you about this processing in

39
00:01:53,880 --> 00:01:57,320
just a moment in the Mac

40
00:01:58,840 --> 00:02:01,920
part after your data goes through some

41
00:02:01,920 --> 00:02:04,000
processing you're ready for it to

42
00:02:04,000 --> 00:02:08,159
actually go into something called

43
00:02:11,680 --> 00:02:15,200
translate but what is translate well put

44
00:02:15,200 --> 00:02:17,160
simply translate is an example that

45
00:02:17,160 --> 00:02:20,200
tensorflow already has for you uh how to

46
00:02:20,200 --> 00:02:23,200
build sequence to sequence lstm models

47
00:02:23,200 --> 00:02:26,120
this is the way it works by default what

48
00:02:26,120 --> 00:02:28,640
this model will do is it will I mean if

49
00:02:28,640 --> 00:02:30,720
I actually just uh create a little

50
00:02:30,720 --> 00:02:33,040
boundary here which will

51
00:02:33,040 --> 00:02:36,440
contain uh the translate system so this

52
00:02:36,440 --> 00:02:39,840
is the regular vanilla tensorflow

53
00:02:39,840 --> 00:02:42,239
translate system that they already have

54
00:02:42,239 --> 00:02:45,000
for you what this does is it takes a

55
00:02:45,000 --> 00:02:48,319
bunch of text in

56
00:02:48,319 --> 00:02:51,040
English and it takes that exact same

57
00:02:51,040 --> 00:02:53,959
text but in

58
00:02:55,040 --> 00:02:58,760
French and it'll feed it into a

59
00:02:58,760 --> 00:03:02,239
sequence to

60
00:03:03,159 --> 00:03:06,159
sequence

61
00:03:07,159 --> 00:03:09,640
model now the sequence to sequence model

62
00:03:09,640 --> 00:03:11,959
will then train on that data and then

63
00:03:11,959 --> 00:03:16,840
you can actually pass it some input like

64
00:03:17,440 --> 00:03:23,120
hello and it'll output something like

65
00:03:25,319 --> 00:03:28,319
bonjour

66
00:03:28,400 --> 00:03:31,360
sure like that

67
00:03:31,360 --> 00:03:33,799
in fact okay but the thing is there are

68
00:03:33,799 --> 00:03:36,040
a few limitations with this system

69
00:03:36,040 --> 00:03:37,920
because the thing is this was built for

70
00:03:37,920 --> 00:03:40,159
language translation but what we want to

71
00:03:40,159 --> 00:03:43,200
do is have the system learn how to

72
00:03:43,200 --> 00:03:45,280
pronounce English words and not actually

73
00:03:45,280 --> 00:03:48,319
translate from English to French and so

74
00:03:48,319 --> 00:03:50,200
I've actually gone ahead and made a few

75
00:03:50,200 --> 00:03:52,720
modifications to the system I basically

76
00:03:52,720 --> 00:03:55,159
used almost the same code and what it'll

77
00:03:55,159 --> 00:03:58,239
do is the new translate

78
00:03:58,239 --> 00:04:02,120
system will actually

79
00:04:05,560 --> 00:04:09,560
take so the translate that was made for

80
00:04:09,560 --> 00:04:12,040
T

81
00:04:13,439 --> 00:04:15,879
pronounce now this will actually go

82
00:04:15,879 --> 00:04:19,000
ahead uh and take some

83
00:04:19,000 --> 00:04:21,000
words and it'll actually take the

84
00:04:21,000 --> 00:04:24,440
pronunciations for those

85
00:04:28,600 --> 00:04:32,160
words it'll feed them into that same

86
00:04:32,160 --> 00:04:35,560
type of sequence to sequence

87
00:04:38,759 --> 00:04:41,360
model and then you can actually input

88
00:04:41,360 --> 00:04:44,360
something like uh tme which again is

89
00:04:44,360 --> 00:04:47,320
actually not an actual English word it's

90
00:04:47,320 --> 00:04:49,520
a non-dictionary English

91
00:04:49,520 --> 00:04:52,600
word and then it'll output the

92
00:04:52,600 --> 00:04:54,560
pronunciation for t which in this case

93
00:04:54,560 --> 00:05:02,440
it outputs T a e n n m e

94
00:05:02,919 --> 00:05:05,720
y I'll talk about exactly how this type

95
00:05:05,720 --> 00:05:07,960
of uh this type of uh pronunciation is

96
00:05:07,960 --> 00:05:10,400
structured in just a moment inside of

97
00:05:10,400 --> 00:05:13,120
the Mac part but this is a simplified

98
00:05:13,120 --> 00:05:14,840
explanation of the system we're going to

99
00:05:14,840 --> 00:05:16,520
be building uh if you'd like to find out

100
00:05:16,520 --> 00:05:18,080
more about sequence to sequence models

101
00:05:18,080 --> 00:05:19,560
I'll have an entirely separate video

102
00:05:19,560 --> 00:05:21,400
about that coming out soon uh but

103
00:05:21,400 --> 00:05:23,759
essentially there're basically two lstms

104
00:05:23,759 --> 00:05:25,440
stacked on top of each other with an

105
00:05:25,440 --> 00:05:27,880
encoder and a decoder uh in order to

106
00:05:27,880 --> 00:05:30,160
actually take in a sequence and instead

107
00:05:30,160 --> 00:05:32,120
of classifying that sequence it'll

108
00:05:32,120 --> 00:05:34,120
actually output another sequence based

109
00:05:34,120 --> 00:05:35,680
off of the sequence that you gave as

110
00:05:35,680 --> 00:05:38,000
input but now let's get over to the Mac

111
00:05:38,000 --> 00:05:39,600
part where I'll show you how you can use

112
00:05:39,600 --> 00:05:41,800
tensorflow in order to build the system

113
00:05:41,800 --> 00:05:43,479
behind me and has quite a few different

114
00:05:43,479 --> 00:05:45,520
use cases like for example if you're

115
00:05:45,520 --> 00:05:46,960
unsure how to pronounce someone's name

116
00:05:46,960 --> 00:05:48,360
you can actually feed it into the system

117
00:05:48,360 --> 00:05:50,919
or a specific word or a specific word

118
00:05:50,919 --> 00:05:53,720
that's not in the dictionary U so now

119
00:05:53,720 --> 00:05:55,360
though let's get to the Mac part where

120
00:05:55,360 --> 00:05:57,919
I'll show you how to build this system

121
00:05:57,919 --> 00:05:59,919
all right so welcome back to the Mac

122
00:05:59,919 --> 00:06:01,759
part and now I'm going to show you how

123
00:06:01,759 --> 00:06:05,080
you can actually build this lstm system

124
00:06:05,080 --> 00:06:06,680
all right so now if I actually go over

125
00:06:06,680 --> 00:06:09,240
to this uh Ubuntu machine I've got

126
00:06:09,240 --> 00:06:11,759
running over here uh as you can see I

127
00:06:11,759 --> 00:06:13,639
actually seated into a directory uh

128
00:06:13,639 --> 00:06:16,400
inside of my home directory called

129
00:06:16,400 --> 00:06:20,599
models tutorials RNN translate uh so if

130
00:06:20,599 --> 00:06:22,599
you actually go ahead and get over to

131
00:06:22,599 --> 00:06:26,440
github.com uh Slash uh

132
00:06:26,440 --> 00:06:28,880
tensorflow Slash models you can see

133
00:06:28,880 --> 00:06:31,080
they've got an GitHub repository

134
00:06:31,080 --> 00:06:33,240
dedicated to tensorflow models that

135
00:06:33,240 --> 00:06:36,599
they've pre-built for you uh and so if

136
00:06:36,599 --> 00:06:38,199
you go inside of here you can see that

137
00:06:38,199 --> 00:06:41,120
there is a folder uh call or a file

138
00:06:41,120 --> 00:06:44,479
called translate. py inside of tutorials

139
00:06:44,479 --> 00:06:46,800
RNN translate and so this is the file

140
00:06:46,800 --> 00:06:48,440
you're going to be using in order to

141
00:06:48,440 --> 00:06:50,440
create your sequence to sequence lstm

142
00:06:50,440 --> 00:06:52,479
model of course you could build your own

143
00:06:52,479 --> 00:06:54,440
sequence to sequence model either in

144
00:06:54,440 --> 00:06:56,840
tensorflow or another language like or

145
00:06:56,840 --> 00:06:59,960
another SDK like uh carass uh but for

146
00:06:59,960 --> 00:07:02,120
now I will be going with this and maybe

147
00:07:02,120 --> 00:07:03,520
I'll show you how to actually build one

148
00:07:03,520 --> 00:07:05,360
from scratch in another

149
00:07:05,360 --> 00:07:07,560
video but as you can see getting back to

150
00:07:07,560 --> 00:07:09,639
the point over here as I mentioned

151
00:07:09,639 --> 00:07:11,000
before this script was actually

152
00:07:11,000 --> 00:07:13,319
originally created to actually convert

153
00:07:13,319 --> 00:07:15,800
English to French and so it's an English

154
00:07:15,800 --> 00:07:18,160
to French translation system however I

155
00:07:18,160 --> 00:07:20,520
have modified this code to actually work

156
00:07:20,520 --> 00:07:22,400
so it it can tell me how to pronounce

157
00:07:22,400 --> 00:07:25,240
things in fact here is a demo if I were

158
00:07:25,240 --> 00:07:26,960
to actually go up over here take this

159
00:07:26,960 --> 00:07:30,440
command and run a decode with the script

160
00:07:30,440 --> 00:07:31,879
I'll tell you exactly what that means in

161
00:07:31,879 --> 00:07:33,800
just a moment but as you can see it

162
00:07:33,800 --> 00:07:34,879
actually starts

163
00:07:34,879 --> 00:07:37,280
initializing uh the the

164
00:07:37,280 --> 00:07:39,680
script uh and then once it initializes

165
00:07:39,680 --> 00:07:41,680
and once it loads the pre-trained uh

166
00:07:41,680 --> 00:07:43,800
pronunciation model uh we should be good

167
00:07:43,800 --> 00:07:47,720
to go and ask it how to pronounce some

168
00:07:48,000 --> 00:07:50,159
stuff all right so give that just one

169
00:07:50,159 --> 00:07:51,759
moment uh okay there you go it's

170
00:07:51,759 --> 00:07:54,080
starting to read the model parameters

171
00:07:54,080 --> 00:07:55,560
and in just a moment as you can see it

172
00:07:55,560 --> 00:07:57,919
gives us a prompt now from here I should

173
00:07:57,919 --> 00:08:00,680
be good to go and ask it to ask it how

174
00:08:00,680 --> 00:08:03,080
to pronounce something like for example

175
00:08:03,080 --> 00:08:06,440
tme is not an English dictionary word

176
00:08:06,440 --> 00:08:08,039
however it is written in English so

177
00:08:08,039 --> 00:08:10,159
technically I should be able to uh say

178
00:08:10,159 --> 00:08:13,680
tme inside of this prompt click enter

179
00:08:13,680 --> 00:08:16,080
and as you can see it returns exactly

180
00:08:16,080 --> 00:08:18,919
what I told you tan May uh now if I were

181
00:08:18,919 --> 00:08:20,599
to actually go over to the CMU

182
00:08:20,599 --> 00:08:22,440
pronouncing dictionary

183
00:08:22,440 --> 00:08:26,560
website uh you can see uh if I were to

184
00:08:26,560 --> 00:08:28,479
or not the Wikipedia page the official

185
00:08:28,479 --> 00:08:31,479
CMU pronounce ing dictionary page uh you

186
00:08:31,479 --> 00:08:33,880
can see there are a few different types

187
00:08:33,880 --> 00:08:35,680
of the CMU pronouncing dictionary some

188
00:08:35,680 --> 00:08:38,479
with the lexical stress some without Etc

189
00:08:38,479 --> 00:08:40,839
however it uses this specific phon name

190
00:08:40,839 --> 00:08:43,839
set in order to uh in order to uh

191
00:08:43,839 --> 00:08:46,480
convert uh from from words to

192
00:08:46,480 --> 00:08:48,560
pronunciations you can actually see all

193
00:08:48,560 --> 00:08:51,519
the 39 phones uh and how they're used

194
00:08:51,519 --> 00:08:54,440
and a translation uh and so for example

195
00:08:54,440 --> 00:08:58,120
AA uh is used in odd uh and the

196
00:08:58,120 --> 00:09:00,680
translation is AA a d for odd to the

197
00:09:00,680 --> 00:09:04,560
phon and so a is a a sound and then of

198
00:09:04,560 --> 00:09:06,360
course you've got those examples for all

199
00:09:06,360 --> 00:09:09,279
of the other phones in the

200
00:09:09,279 --> 00:09:11,760
set now if we were to go back over here

201
00:09:11,760 --> 00:09:13,440
to this data set I'll show you one more

202
00:09:13,440 --> 00:09:15,200
demo in just a moment but let's exit out

203
00:09:15,200 --> 00:09:18,000
of the demo by doing control D now that

204
00:09:18,000 --> 00:09:19,560
we're out of the demo let me show you a

205
00:09:19,560 --> 00:09:22,040
bit about the data that goes behind this

206
00:09:22,040 --> 00:09:24,240
if I were to go into the data folder as

207
00:09:24,240 --> 00:09:27,000
you can see I able to actually Nano the

208
00:09:27,000 --> 00:09:28,839
actual word data set now I've actually

209
00:09:28,839 --> 00:09:31,240
made few modifications to the CMU

210
00:09:31,240 --> 00:09:33,440
pronouncing dictionary uh which allows a

211
00:09:33,440 --> 00:09:35,519
sequen to sequence lstm model to

212
00:09:35,519 --> 00:09:37,680
actually understand the data so if I

213
00:09:37,680 --> 00:09:40,040
were to actually go ahead and open up

214
00:09:40,040 --> 00:09:43,480
the words file over here as you can see

215
00:09:43,480 --> 00:09:45,720
we've got a lot of individual words and

216
00:09:45,720 --> 00:09:47,839
these words are of course from the CMU

217
00:09:47,839 --> 00:09:49,800
pronouncing dictionary I can actually

218
00:09:49,800 --> 00:09:53,160
search up tan here in fact and

219
00:09:53,160 --> 00:09:55,320
theoretically I shouldn't get

220
00:09:55,320 --> 00:09:57,920
anything as you can see tan was not

221
00:09:57,920 --> 00:10:00,440
found which means that is truly not in

222
00:10:00,440 --> 00:10:02,519
the CMU pronouncing dictionary but

223
00:10:02,519 --> 00:10:04,200
moving on as you can see let's just say

224
00:10:04,200 --> 00:10:07,720
we were to take a random word here say

225
00:10:07,720 --> 00:10:10,320
uh we had uh if I were to just go down

226
00:10:10,320 --> 00:10:13,399
here maybe

227
00:10:13,399 --> 00:10:16,360
hello okay you can see that there is a

228
00:10:16,360 --> 00:10:19,240
word hello here now by default the CMU

229
00:10:19,240 --> 00:10:21,399
pronouncing dictionary gives me this

230
00:10:21,399 --> 00:10:24,880
word hello however I've tried training a

231
00:10:24,880 --> 00:10:27,320
sequence to sequence lstm like this and

232
00:10:27,320 --> 00:10:30,200
sequence to sequence lstm never learns

233
00:10:30,200 --> 00:10:32,800
how to pronounce uh these words if you

234
00:10:32,800 --> 00:10:35,040
do not put spaces in between the letters

235
00:10:35,040 --> 00:10:37,120
but why is that well it's actually

236
00:10:37,120 --> 00:10:38,639
because of the way that the sequence to

237
00:10:38,639 --> 00:10:41,360
sequence lstm model is coded what

238
00:10:41,360 --> 00:10:42,839
happens is when you have spaces in

239
00:10:42,839 --> 00:10:45,079
between the characters the entire

240
00:10:45,079 --> 00:10:47,839
sequence is equal to H then an e then an

241
00:10:47,839 --> 00:10:51,240
L then an L then an O but if you do not

242
00:10:51,240 --> 00:10:53,160
have spaces in between then the then the

243
00:10:53,160 --> 00:10:55,839
entire sequence is just one element of

244
00:10:55,839 --> 00:10:58,320
ago and that means that it's not able to

245
00:10:58,320 --> 00:11:00,160
learn meaning that of course it's not

246
00:11:00,160 --> 00:11:02,399
able to give us the correct output uh in

247
00:11:02,399 --> 00:11:04,079
the sequence to sequence model however

248
00:11:04,079 --> 00:11:06,639
when you put spaces again these are all

249
00:11:06,639 --> 00:11:08,880
different elements of a sequence which

250
00:11:08,880 --> 00:11:12,120
allow it to train

251
00:11:12,120 --> 00:11:14,200
properly but after that of course I'm

252
00:11:14,200 --> 00:11:15,880
not going to save the changes there but

253
00:11:15,880 --> 00:11:17,720
I'm going to go into the pronunciations

254
00:11:17,720 --> 00:11:20,200
file and that was not the correct file

255
00:11:20,200 --> 00:11:23,000
this is the correct file as you can see

256
00:11:23,000 --> 00:11:24,320
this just contains a bunch of

257
00:11:24,320 --> 00:11:25,839
pronunciations and of course the reason

258
00:11:25,839 --> 00:11:27,320
you don't need to put spaces in between

259
00:11:27,320 --> 00:11:29,120
every single letter here is because

260
00:11:29,120 --> 00:11:30,600
you're actually just putting spaces in

261
00:11:30,600 --> 00:11:32,880
between each individual phon name for it

262
00:11:32,880 --> 00:11:34,279
to actually learn what types of

263
00:11:34,279 --> 00:11:36,079
characters get translated into what

264
00:11:36,079 --> 00:11:38,279
types of phon names and so as you can

265
00:11:38,279 --> 00:11:40,360
see this is actually I mean one one more

266
00:11:40,360 --> 00:11:41,959
plus point about having a system like

267
00:11:41,959 --> 00:11:44,800
this is it's so much more versatile uh

268
00:11:44,800 --> 00:11:45,800
meaning that if you've got

269
00:11:45,800 --> 00:11:47,760
non-dictionary word you're not just

270
00:11:47,760 --> 00:11:49,440
putting a bunch of IFL statements for

271
00:11:49,440 --> 00:11:51,279
every single little rule that a

272
00:11:51,279 --> 00:11:53,320
pronunciation could have what you're

273
00:11:53,320 --> 00:11:55,360
doing is you're taking a bunch of

274
00:11:55,360 --> 00:11:57,360
examples of how words are pronounced and

275
00:11:57,360 --> 00:11:59,600
you're training a neural network to

276
00:11:59,600 --> 00:12:01,800
understand how these words are

277
00:12:01,800 --> 00:12:03,600
pronounced all right so now that you've

278
00:12:03,600 --> 00:12:05,440
taken a look at that data and also by

279
00:12:05,440 --> 00:12:07,839
the way just so you know uh the way that

280
00:12:07,839 --> 00:12:09,480
this data is structured makes the

281
00:12:09,480 --> 00:12:11,720
translate files think that it's actually

282
00:12:11,720 --> 00:12:13,959
still converting English to French but

283
00:12:13,959 --> 00:12:15,639
the English is actually just a bunch of

284
00:12:15,639 --> 00:12:17,519
words in the French is actually just a

285
00:12:17,519 --> 00:12:20,199
bunch of phon names or pronunciations uh

286
00:12:20,199 --> 00:12:23,320
and so that conversion uh is done uh

287
00:12:23,320 --> 00:12:24,959
just as if it's being converted from

288
00:12:24,959 --> 00:12:26,639
English to French because it's almost

289
00:12:26,639 --> 00:12:30,079
the exact same algorithm uh to go for

290
00:12:30,079 --> 00:12:32,360
each all right but once you've got your

291
00:12:32,360 --> 00:12:34,360
data ready and of course all this data

292
00:12:34,360 --> 00:12:35,639
and code will be available in the

293
00:12:35,639 --> 00:12:37,199
description then you're ready to

294
00:12:37,199 --> 00:12:39,279
actually train the model in fact this is

295
00:12:39,279 --> 00:12:40,639
actually quite a long command so I

296
00:12:40,639 --> 00:12:42,839
already have this ready here and so this

297
00:12:42,839 --> 00:12:44,360
is the command what it'll do is it'll

298
00:12:44,360 --> 00:12:47,120
call the translate. py file it'll pass

299
00:12:47,120 --> 00:12:49,040
it the data directory the training

300
00:12:49,040 --> 00:12:50,959
directory it'll give it the English

301
00:12:50,959 --> 00:12:53,360
vocabulary size which is 40,000 in this

302
00:12:53,360 --> 00:12:55,399
case and the French vocabulary size

303
00:12:55,399 --> 00:12:58,079
which is 40,000 once more and again

304
00:12:58,079 --> 00:12:59,880
these are just default values you can of

305
00:12:59,880 --> 00:13:01,320
course play around with these and see

306
00:13:01,320 --> 00:13:03,680
what gives you the best result uh but

307
00:13:03,680 --> 00:13:05,560
then of course once you click enter it

308
00:13:05,560 --> 00:13:07,079
should actually start loading up tensor

309
00:13:07,079 --> 00:13:09,360
flow uh creating these layers and

310
00:13:09,360 --> 00:13:10,760
actually starting to train now I'm going

311
00:13:10,760 --> 00:13:12,440
to immediately stop this though because

312
00:13:12,440 --> 00:13:14,360
I've already got it trained and I don't

313
00:13:14,360 --> 00:13:17,040
want it to overwrite my trained model

314
00:13:17,040 --> 00:13:19,320
however once you are ready to go ahead

315
00:13:19,320 --> 00:13:21,480
uh and actually test out your model then

316
00:13:21,480 --> 00:13:23,399
just remove those vocabulary size

317
00:13:23,399 --> 00:13:26,240
arguments and change this to decode so

318
00:13:26,240 --> 00:13:29,440
Das Das decode at the endend click enter

319
00:13:29,440 --> 00:13:31,000
and it should actually go into something

320
00:13:31,000 --> 00:13:33,680
called decode mode now decode mode will

321
00:13:33,680 --> 00:13:35,399
actually tell the script that instead of

322
00:13:35,399 --> 00:13:37,440
encoding input and actually training the

323
00:13:37,440 --> 00:13:39,880
lstm or sequence to sequence model you

324
00:13:39,880 --> 00:13:42,760
want to actually decode output from it

325
00:13:42,760 --> 00:13:44,560
uh and so just give that one moment and

326
00:13:44,560 --> 00:13:46,800
we should be ready to go and test out

327
00:13:46,800 --> 00:13:49,040
and do one more demo of the system as

328
00:13:49,040 --> 00:13:51,720
you can see I trained this for 8,800

329
00:13:51,720 --> 00:13:54,279
iterations it uh it uh and so what

330
00:13:54,279 --> 00:13:56,399
happens is over time you're there's a

331
00:13:56,399 --> 00:13:58,320
there's a variable called the perplexity

332
00:13:58,320 --> 00:13:59,560
variable

333
00:13:59,560 --> 00:14:01,480
or I guess if if you're already familiar

334
00:14:01,480 --> 00:14:03,360
with something like loss uh it's it's

335
00:14:03,360 --> 00:14:05,560
similar to that it's basically how good

336
00:14:05,560 --> 00:14:09,440
your model is uh at uh at doing these

337
00:14:09,440 --> 00:14:12,160
sorts of pronunciation conversions uh

338
00:14:12,160 --> 00:14:14,199
and so uh I was able to reach a

339
00:14:14,199 --> 00:14:15,759
perplexity of

340
00:14:15,759 --> 00:14:18,000
1.19 which is actually quite low but you

341
00:14:18,000 --> 00:14:19,440
can get much much lower if you were to

342
00:14:19,440 --> 00:14:22,160
train it for many more iterations uh in

343
00:14:22,160 --> 00:14:24,199
fact I have gotten lower before it's

344
00:14:24,199 --> 00:14:25,839
just that I wanted to train this uh

345
00:14:25,839 --> 00:14:29,600
fresh for you uh and so now

346
00:14:29,600 --> 00:14:31,079
as you can see I should be able to pass

347
00:14:31,079 --> 00:14:33,240
it in something else like for example my

348
00:14:33,240 --> 00:14:36,600
last name uh so back sheet and then hope

349
00:14:36,600 --> 00:14:40,759
it it is able to give us the correct

350
00:14:40,759 --> 00:14:43,160
pronunciation as you can see it does

351
00:14:43,160 --> 00:14:47,040
back she and it gives us the correct uh

352
00:14:47,040 --> 00:14:48,920
pronunciation if you're not sure if this

353
00:14:48,920 --> 00:14:50,279
is correct and you want to know if your

354
00:14:50,279 --> 00:14:52,279
model is doing nicely or if it's not

355
00:14:52,279 --> 00:14:54,160
doing nicely you can actually go over to

356
00:14:54,160 --> 00:14:56,360
the CMU pronouncing dictionary and take

357
00:14:56,360 --> 00:14:59,639
each phon for example AE over here and

358
00:14:59,639 --> 00:15:02,120
what does AE sound like well AE is used

359
00:15:02,120 --> 00:15:05,000
in the word at uh and so as you can see

360
00:15:05,000 --> 00:15:07,680
this is the translation from at to phon

361
00:15:07,680 --> 00:15:10,800
which is AE and then a t and so AE we

362
00:15:10,800 --> 00:15:12,959
can you know successfully derive that AE

363
00:15:12,959 --> 00:15:16,040
would mean an A sound so

364
00:15:16,040 --> 00:15:19,800
B and so as you can see that is correct

365
00:15:19,800 --> 00:15:21,120
uh and it was able to give us the

366
00:15:21,120 --> 00:15:23,399
correct pronunciation for the words that

367
00:15:23,399 --> 00:15:25,399
we gave it even though again these are

368
00:15:25,399 --> 00:15:28,240
not dictionary words uh these are

369
00:15:28,240 --> 00:15:29,600
completely these are words that it's

370
00:15:29,600 --> 00:15:31,839
never heard before and yet it was able

371
00:15:31,839 --> 00:15:34,480
to correctly classify them and correctly

372
00:15:34,480 --> 00:15:36,639
tell us exactly what the pronunciation

373
00:15:36,639 --> 00:15:38,759
should be using a sequence to sequence

374
00:15:38,759 --> 00:15:42,519
model built on top of

375
00:15:42,519 --> 00:15:45,120
lstms all right so that's all I had to

376
00:15:45,120 --> 00:15:46,680
share with you in this video today thank

377
00:15:46,680 --> 00:15:48,680
you very much for joining I really do

378
00:15:48,680 --> 00:15:49,959
hope you're able to learn from this

379
00:15:49,959 --> 00:15:52,120
video and of course enjoy the video as

380
00:15:52,120 --> 00:15:53,720
well if you believe that this could help

381
00:15:53,720 --> 00:15:55,079
anybody else youd know please do

382
00:15:55,079 --> 00:15:57,079
consider sharing the video and liking it

383
00:15:57,079 --> 00:15:59,480
as well if it did help you out

384
00:15:59,480 --> 00:16:00,680
of course so if you've got any more

385
00:16:00,680 --> 00:16:02,199
questions suggestions or feedback leave

386
00:16:02,199 --> 00:16:03,880
them down in the comment section below

387
00:16:03,880 --> 00:16:05,639
and I'd be glad to get back to you uh

388
00:16:05,639 --> 00:16:07,160
and of course you can also email them to

389
00:16:07,160 --> 00:16:09,720
me at tagim man gmail.com or tweet it to

390
00:16:09,720 --> 00:16:12,160
me at tagim Manny of course though if

391
00:16:12,160 --> 00:16:13,360
you really like my content and you want

392
00:16:13,360 --> 00:16:15,040
to see more of it please do continue

393
00:16:15,040 --> 00:16:16,480
please do subscribe to the channel as it

394
00:16:16,480 --> 00:16:18,399
really does help out a lot uh and of

395
00:16:18,399 --> 00:16:19,600
course if you'd like to be notified

396
00:16:19,600 --> 00:16:21,839
whenever I release new content please do

397
00:16:21,839 --> 00:16:23,440
turn on notifications by clicking the

398
00:16:23,440 --> 00:16:25,399
little bell icon beside subscribe Button

399
00:16:25,399 --> 00:16:27,279
as well thank you very much for joining

400
00:16:27,279 --> 00:16:31,519
in today that's going to be it goodbye
